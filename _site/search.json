[
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_2.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_2.html",
    "title": "Hands-on_Ex08_2",
    "section": "",
    "text": "Proportional symbol maps (also known as graduate symbol maps) are a class of maps that use the visual variable of size to represent differences in the magnitude of a discrete, abruptly changing phenomenon, e.g. counts of people. Like choropleth maps, you can create classed or unclassed versions of these maps. The classed ones are known as range-graded or graduated symbols, and the unclassed are called proportional symbols, where the area of the symbols are proportional to the values of the attribute being mapped.\nObjective of this exercise:\n\nTo import an aspatial data file into R.\nTo convert it into simple point feature data frame and at the same time, to assign an appropriate projection reference to the newly create simple point feature data frame.\nTo plot interactive proportional symbol maps.\n\n\n\n\nEnsure that tmap package of R and other related R packages have been installed and loaded into R.\n\npacman::p_load(sf, tmap, tidyverse)\n\n\n\n\n\n\nThe data set use for this hands-on exercise is called SGPools_svy21. The data is in csv file format.\nFigure below shows the first 15 records of SGPools_svy21.csv. It consists of seven columns. The XCOORD and YCOORD columns are the x-coordinates and y-coordinates of SingPools outlets and branches. They are in Singapore SVY21 Projected Coordinates System.\n\n\n\n\nThe code chunk below uses read_csv() function of readr package to import SGPools_svy21.csv into R as a tibble data frame called sgpools.\n\nsgpools &lt;- read_csv(\"data/aspatial/SGPools_svy21.csv\")\n\nAfter importing the data file into R, it is important for us to examine if the data file has been imported correctly.\nThe code chunk below shows list() is used to do the job.\n\nlist(sgpools) \n\n[[1]]\n# A tibble: 306 × 7\n   NAME           ADDRESS POSTCODE XCOORD YCOORD `OUTLET TYPE` `Gp1Gp2 Winnings`\n   &lt;chr&gt;          &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Mar… 2 Bayf…    18972 30842. 29599. Branch                        5\n 2 Livewire (Res… 26 Sen…    98138 26704. 26526. Branch                       11\n 3 SportsBuzz (K… Lotus …   738078 20118. 44888. Branch                        0\n 4 SportsBuzz (P… 1 Sele…   188306 29777. 31382. Branch                       44\n 5 Prime Serango… Blk 54…   552542 32239. 39519. Branch                        0\n 6 Singapore Poo… 1A Woo…   731001 21012. 46987. Branch                        3\n 7 Singapore Poo… Blk 64…   370064 33990. 34356. Branch                       17\n 8 Singapore Poo… Blk 88…   370088 33847. 33976. Branch                       16\n 9 Singapore Poo… Blk 30…   540308 33910. 41275. Branch                       21\n10 Singapore Poo… Blk 20…   560202 29246. 38943. Branch                       25\n# ℹ 296 more rows\n\n\n\n\n\nThe code chunk below converts sgpools data frame into a simple feature data frame by using st_as_sf() of sf packages\n\nsgpools_sf &lt;- st_as_sf(sgpools, \n                       coords = c(\"XCOORD\", \"YCOORD\"),\n                       crs= 3414)\n\nThings to learn from the arguments above:\n\nThe coords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\nThe crs argument required you to provide the coordinates system in epsg format. EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by refering to epsg.io.\n\nFigure below shows the data table of sgpools_sf. Note that a new column called geometry has been added into the data frame.\n\nWe can display the basic information of the newly created sgpools_sf:\n\nlist(sgpools_sf)\n\n[[1]]\nSimple feature collection with 306 features and 5 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 7844.194 ymin: 26525.7 xmax: 45176.57 ymax: 47987.13\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 306 × 6\n   NAME                         ADDRESS POSTCODE `OUTLET TYPE` `Gp1Gp2 Winnings`\n * &lt;chr&gt;                        &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Marina Bay Sands)  2 Bayf…    18972 Branch                        5\n 2 Livewire (Resorts World Sen… 26 Sen…    98138 Branch                       11\n 3 SportsBuzz (Kranji)          Lotus …   738078 Branch                        0\n 4 SportsBuzz (PoMo)            1 Sele…   188306 Branch                       44\n 5 Prime Serangoon North        Blk 54…   552542 Branch                        0\n 6 Singapore Pools Woodlands C… 1A Woo…   731001 Branch                        3\n 7 Singapore Pools 64 Circuit … Blk 64…   370064 Branch                       17\n 8 Singapore Pools 88 Circuit … Blk 88…   370088 Branch                       16\n 9 Singapore Pools Anchorvale … Blk 30…   540308 Branch                       21\n10 Singapore Pools Ang Mo Kio … Blk 20…   560202 Branch                       25\n# ℹ 296 more rows\n# ℹ 1 more variable: geometry &lt;POINT [m]&gt;\n\n\nThe output shows that sgppols_sf is in point feature class. It’s epsg ID is 3414. The bbox provides information of the extend of the geospatial data.\n\n\n\n\nTo create an interactive proportional symbol map in R, the view mode of tmap will be used.\nThe code churn below will turn on the interactive mode of tmap.\n\ntmap_mode(\"view\")\n\n\n\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = 0.5,\n           border.col = \"black\",\n           border.lwd = 1)\n\n\n\n\n\n\n\n\nTo draw a proportional symbol map, we need to assign a numerical variable to the size visual attribute. The code chunks below show that the variable Gp1Gp2Winnings is assigned to size visual attribute.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = \"Gp1Gp2 Winnings\",\n           border.col = \"black\",\n           border.lwd = 1)\n\n\n\n\n\n\n\n\n\nThe proportional symbol map can be further improved by using the colour visual attribute. In the code chunks below, OUTLET_TYPE variable is used as the colour attribute variable.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 1)\n\n\n\n\n\n\n\n\n\n\nAn impressive and little-know feature of tmap’s view mode is that it also works with faceted plots. The argument sync in tm_facets() can be used in this case to produce multiple maps with synchronised zoom and pan settings.\n\ntm_shape(sgpools_sf) +\n  tm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 1) +\n  tm_facets(by= \"OUTLET TYPE\",\n            nrow = 1,\n            sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBefore ending the session, it is wiser to switch tmap’s Viewer back to plot mode by using the code chunk below.\n\ntmap_mode(\"plot\")\n\n\n\n\n\n\n\n\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\n\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\n\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 8-2"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_2.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_2.html#overview",
    "title": "Hands-on_Ex08_2",
    "section": "",
    "text": "Proportional symbol maps (also known as graduate symbol maps) are a class of maps that use the visual variable of size to represent differences in the magnitude of a discrete, abruptly changing phenomenon, e.g. counts of people. Like choropleth maps, you can create classed or unclassed versions of these maps. The classed ones are known as range-graded or graduated symbols, and the unclassed are called proportional symbols, where the area of the symbols are proportional to the values of the attribute being mapped.\nObjective of this exercise:\n\nTo import an aspatial data file into R.\nTo convert it into simple point feature data frame and at the same time, to assign an appropriate projection reference to the newly create simple point feature data frame.\nTo plot interactive proportional symbol maps.",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 8-2"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_2.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_2.html#getting-started",
    "title": "Hands-on_Ex08_2",
    "section": "",
    "text": "Ensure that tmap package of R and other related R packages have been installed and loaded into R.\n\npacman::p_load(sf, tmap, tidyverse)",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 8-2"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_2.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_2.html#geospatial-data-wrangling",
    "title": "Hands-on_Ex08_2",
    "section": "",
    "text": "The data set use for this hands-on exercise is called SGPools_svy21. The data is in csv file format.\nFigure below shows the first 15 records of SGPools_svy21.csv. It consists of seven columns. The XCOORD and YCOORD columns are the x-coordinates and y-coordinates of SingPools outlets and branches. They are in Singapore SVY21 Projected Coordinates System.\n\n\n\n\nThe code chunk below uses read_csv() function of readr package to import SGPools_svy21.csv into R as a tibble data frame called sgpools.\n\nsgpools &lt;- read_csv(\"data/aspatial/SGPools_svy21.csv\")\n\nAfter importing the data file into R, it is important for us to examine if the data file has been imported correctly.\nThe code chunk below shows list() is used to do the job.\n\nlist(sgpools) \n\n[[1]]\n# A tibble: 306 × 7\n   NAME           ADDRESS POSTCODE XCOORD YCOORD `OUTLET TYPE` `Gp1Gp2 Winnings`\n   &lt;chr&gt;          &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Mar… 2 Bayf…    18972 30842. 29599. Branch                        5\n 2 Livewire (Res… 26 Sen…    98138 26704. 26526. Branch                       11\n 3 SportsBuzz (K… Lotus …   738078 20118. 44888. Branch                        0\n 4 SportsBuzz (P… 1 Sele…   188306 29777. 31382. Branch                       44\n 5 Prime Serango… Blk 54…   552542 32239. 39519. Branch                        0\n 6 Singapore Poo… 1A Woo…   731001 21012. 46987. Branch                        3\n 7 Singapore Poo… Blk 64…   370064 33990. 34356. Branch                       17\n 8 Singapore Poo… Blk 88…   370088 33847. 33976. Branch                       16\n 9 Singapore Poo… Blk 30…   540308 33910. 41275. Branch                       21\n10 Singapore Poo… Blk 20…   560202 29246. 38943. Branch                       25\n# ℹ 296 more rows\n\n\n\n\n\nThe code chunk below converts sgpools data frame into a simple feature data frame by using st_as_sf() of sf packages\n\nsgpools_sf &lt;- st_as_sf(sgpools, \n                       coords = c(\"XCOORD\", \"YCOORD\"),\n                       crs= 3414)\n\nThings to learn from the arguments above:\n\nThe coords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\nThe crs argument required you to provide the coordinates system in epsg format. EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by refering to epsg.io.\n\nFigure below shows the data table of sgpools_sf. Note that a new column called geometry has been added into the data frame.\n\nWe can display the basic information of the newly created sgpools_sf:\n\nlist(sgpools_sf)\n\n[[1]]\nSimple feature collection with 306 features and 5 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 7844.194 ymin: 26525.7 xmax: 45176.57 ymax: 47987.13\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 306 × 6\n   NAME                         ADDRESS POSTCODE `OUTLET TYPE` `Gp1Gp2 Winnings`\n * &lt;chr&gt;                        &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Marina Bay Sands)  2 Bayf…    18972 Branch                        5\n 2 Livewire (Resorts World Sen… 26 Sen…    98138 Branch                       11\n 3 SportsBuzz (Kranji)          Lotus …   738078 Branch                        0\n 4 SportsBuzz (PoMo)            1 Sele…   188306 Branch                       44\n 5 Prime Serangoon North        Blk 54…   552542 Branch                        0\n 6 Singapore Pools Woodlands C… 1A Woo…   731001 Branch                        3\n 7 Singapore Pools 64 Circuit … Blk 64…   370064 Branch                       17\n 8 Singapore Pools 88 Circuit … Blk 88…   370088 Branch                       16\n 9 Singapore Pools Anchorvale … Blk 30…   540308 Branch                       21\n10 Singapore Pools Ang Mo Kio … Blk 20…   560202 Branch                       25\n# ℹ 296 more rows\n# ℹ 1 more variable: geometry &lt;POINT [m]&gt;\n\n\nThe output shows that sgppols_sf is in point feature class. It’s epsg ID is 3414. The bbox provides information of the extend of the geospatial data.",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 8-2"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_2.html#drawing-proportional-symbol-map",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_2.html#drawing-proportional-symbol-map",
    "title": "Hands-on_Ex08_2",
    "section": "",
    "text": "To create an interactive proportional symbol map in R, the view mode of tmap will be used.\nThe code churn below will turn on the interactive mode of tmap.\n\ntmap_mode(\"view\")\n\n\n\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = 0.5,\n           border.col = \"black\",\n           border.lwd = 1)\n\n\n\n\n\n\n\n\nTo draw a proportional symbol map, we need to assign a numerical variable to the size visual attribute. The code chunks below show that the variable Gp1Gp2Winnings is assigned to size visual attribute.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = \"Gp1Gp2 Winnings\",\n           border.col = \"black\",\n           border.lwd = 1)\n\n\n\n\n\n\n\n\n\nThe proportional symbol map can be further improved by using the colour visual attribute. In the code chunks below, OUTLET_TYPE variable is used as the colour attribute variable.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 1)\n\n\n\n\n\n\n\n\n\n\nAn impressive and little-know feature of tmap’s view mode is that it also works with faceted plots. The argument sync in tm_facets() can be used in this case to produce multiple maps with synchronised zoom and pan settings.\n\ntm_shape(sgpools_sf) +\n  tm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 1) +\n  tm_facets(by= \"OUTLET TYPE\",\n            nrow = 1,\n            sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBefore ending the session, it is wiser to switch tmap’s Viewer back to plot mode by using the code chunk below.\n\ntmap_mode(\"plot\")",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 8-2"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_2.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_2.html#reference",
    "title": "Hands-on_Ex08_2",
    "section": "",
    "text": "tmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\n\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\n\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 8-2"
    ]
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07.html",
    "href": "In-class_Ex/In-class_Ex07.html",
    "title": "In-class_Ex07",
    "section": "",
    "text": "tidyverts is a family of R packages specially designed for visualising, analysing and forecasting time-series data conforming to tidyverse framework. It is the work of Dr. Rob Hyndman, professor of statistics at Monash University, and his team. The family of R packages are intended to be the next-generation replacement for the very popular forecast package, and is currently under active development.\nLoad and launch packages\nUse tool to install packages: tsibble, feasts, fable and seasonal first.\n\n\nShow the code\npacman::p_load(tidyverse, tsibble, feasts, fable, seasonal)\n\n\n\n\n\n\n\n\n\nShow the code\nts_data &lt;- read_csv(\"data/visitor_arrivals_by_air.csv\")\nhead(ts_data)\n\n\n# A tibble: 6 × 34\n  `Month-Year` `Republic of South Africa` Canada   USA Bangladesh Brunei China\n  &lt;chr&gt;                             &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 1/1/2008                           3680   6972 31155       6786   3729 79599\n2 1/2/2008                           1662   6056 27738       6314   3070 82074\n3 1/3/2008                           3394   6220 31349       7502   4805 72546\n4 1/4/2008                           3337   4764 26376       7333   3096 76112\n5 1/5/2008                           2089   4460 26788       7988   3586 64808\n6 1/6/2008                           2515   3888 29725       8301   5284 55238\n# ℹ 27 more variables: `Hong Kong SAR (China)` &lt;dbl&gt;, India &lt;dbl&gt;,\n#   Indonesia &lt;dbl&gt;, Japan &lt;dbl&gt;, `South Korea` &lt;dbl&gt;, Kuwait &lt;dbl&gt;,\n#   Malaysia &lt;dbl&gt;, Myanmar &lt;dbl&gt;, Pakistan &lt;dbl&gt;, Philippines &lt;dbl&gt;,\n#   `Saudi Arabia` &lt;dbl&gt;, `Sri Lanka` &lt;dbl&gt;, Taiwan &lt;dbl&gt;, Thailand &lt;dbl&gt;,\n#   `United Arab Emirates` &lt;dbl&gt;, Vietnam &lt;dbl&gt;, `Belgium & Luxembourg` &lt;dbl&gt;,\n#   Finland &lt;dbl&gt;, France &lt;dbl&gt;, Germany &lt;dbl&gt;, Italy &lt;dbl&gt;, Netherlands &lt;dbl&gt;,\n#   Spain &lt;dbl&gt;, Switzerland &lt;dbl&gt;, `United Kingdom` &lt;dbl&gt;, Australia &lt;dbl&gt;, …\n\n\nIn the code chunk below, dmy() of lubridate package is used to convert data type of Month-Year field from Character to Date.\n\n\nShow the code\nts_data$`Month-Year` &lt;- dmy(\n  ts_data$`Month-Year`) #to replace the column.\nhead(ts_data)\n\n\n# A tibble: 6 × 34\n  `Month-Year` `Republic of South Africa` Canada   USA Bangladesh Brunei China\n  &lt;date&gt;                            &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 2008-01-01                         3680   6972 31155       6786   3729 79599\n2 2008-02-01                         1662   6056 27738       6314   3070 82074\n3 2008-03-01                         3394   6220 31349       7502   4805 72546\n4 2008-04-01                         3337   4764 26376       7333   3096 76112\n5 2008-05-01                         2089   4460 26788       7988   3586 64808\n6 2008-06-01                         2515   3888 29725       8301   5284 55238\n# ℹ 27 more variables: `Hong Kong SAR (China)` &lt;dbl&gt;, India &lt;dbl&gt;,\n#   Indonesia &lt;dbl&gt;, Japan &lt;dbl&gt;, `South Korea` &lt;dbl&gt;, Kuwait &lt;dbl&gt;,\n#   Malaysia &lt;dbl&gt;, Myanmar &lt;dbl&gt;, Pakistan &lt;dbl&gt;, Philippines &lt;dbl&gt;,\n#   `Saudi Arabia` &lt;dbl&gt;, `Sri Lanka` &lt;dbl&gt;, Taiwan &lt;dbl&gt;, Thailand &lt;dbl&gt;,\n#   `United Arab Emirates` &lt;dbl&gt;, Vietnam &lt;dbl&gt;, `Belgium & Luxembourg` &lt;dbl&gt;,\n#   Finland &lt;dbl&gt;, France &lt;dbl&gt;, Germany &lt;dbl&gt;, Italy &lt;dbl&gt;, Netherlands &lt;dbl&gt;,\n#   Spain &lt;dbl&gt;, Switzerland &lt;dbl&gt;, `United Kingdom` &lt;dbl&gt;, Australia &lt;dbl&gt;, …\n\n\nNow we see it’s converted to date data type.\n\n\n\n\n\n\n\nShow the code\nts_data\n\n\n# A tibble: 144 × 34\n   `Month-Year` `Republic of South Africa` Canada   USA Bangladesh Brunei China\n   &lt;date&gt;                            &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 2008-01-01                         3680   6972 31155       6786   3729 79599\n 2 2008-02-01                         1662   6056 27738       6314   3070 82074\n 3 2008-03-01                         3394   6220 31349       7502   4805 72546\n 4 2008-04-01                         3337   4764 26376       7333   3096 76112\n 5 2008-05-01                         2089   4460 26788       7988   3586 64808\n 6 2008-06-01                         2515   3888 29725       8301   5284 55238\n 7 2008-07-01                         2919   5313 33183       9004   4070 80747\n 8 2008-08-01                         2471   4519 27427       7913   4183 66625\n 9 2008-09-01                         2492   3421 21588       7549   3160 52649\n10 2008-10-01                         3023   4756 25112       7527   2983 54423\n# ℹ 134 more rows\n# ℹ 27 more variables: `Hong Kong SAR (China)` &lt;dbl&gt;, India &lt;dbl&gt;,\n#   Indonesia &lt;dbl&gt;, Japan &lt;dbl&gt;, `South Korea` &lt;dbl&gt;, Kuwait &lt;dbl&gt;,\n#   Malaysia &lt;dbl&gt;, Myanmar &lt;dbl&gt;, Pakistan &lt;dbl&gt;, Philippines &lt;dbl&gt;,\n#   `Saudi Arabia` &lt;dbl&gt;, `Sri Lanka` &lt;dbl&gt;, Taiwan &lt;dbl&gt;, Thailand &lt;dbl&gt;,\n#   `United Arab Emirates` &lt;dbl&gt;, Vietnam &lt;dbl&gt;, `Belgium & Luxembourg` &lt;dbl&gt;,\n#   Finland &lt;dbl&gt;, France &lt;dbl&gt;, Germany &lt;dbl&gt;, Italy &lt;dbl&gt;, …\n\n\nWe can also use class() to check.\n\n\n\n\n\nShow the code\nts_data_ts &lt;- ts(ts_data)       \nhead(ts_data_ts)\n\n\n     Month-Year Republic of South Africa Canada   USA Bangladesh Brunei China\n[1,]      13879                     3680   6972 31155       6786   3729 79599\n[2,]      13910                     1662   6056 27738       6314   3070 82074\n[3,]      13939                     3394   6220 31349       7502   4805 72546\n[4,]      13970                     3337   4764 26376       7333   3096 76112\n[5,]      14000                     2089   4460 26788       7988   3586 64808\n[6,]      14031                     2515   3888 29725       8301   5284 55238\n     Hong Kong SAR (China) India Indonesia Japan South Korea Kuwait Malaysia\n[1,]                 17103 41639     62683 37673       27937    284    31352\n[2,]                 21089 37170     47834 35297       22633    241    35030\n[3,]                 23230 44815     64688 42575       22876    206    37629\n[4,]                 17688 49527     58074 26839       20634    193    37521\n[5,]                 19340 67754     57089 30814       22785    140    38044\n[6,]                 19152 57380     70118 31001       22575    354    40419\n     Myanmar Pakistan Philippines Saudi Arabia Sri Lanka Taiwan Thailand\n[1,]    5269     1395       18622          406      5289  13757    18370\n[2,]    4643     1027       21609          591      4767  13921    16400\n[3,]    6218     1635       28464          626      4988  11181    23387\n[4,]    7324     1232       30131          644      7639  11665    24469\n[5,]    5395     1306       30193          470      5125  11436    21935\n[6,]    5542     1996       25800          772      4791  10689    19900\n     United Arab Emirates Vietnam Belgium & Luxembourg Finland France Germany\n[1,]                 2652   10315                 1341    1179   6918   11982\n[2,]                 2230   13415                 1449    1207   7876   13256\n[3,]                 3353   14320                 1674    1071   8066   15185\n[4,]                 3245   15413                 1426     768   8312   11604\n[5,]                 2856   14424                 1243     690   7066    9853\n[6,]                 4292   21368                 1255     624   5926    9347\n     Italy Netherlands Spain Switzerland United Kingdom Australia New Zealand\n[1,]  2953        4938  1668        4450          41934     71260        7806\n[2,]  2704        4885  1568        4381          44029     45595        4729\n[3,]  2822        5015  2254        5015          49489     53191        6106\n[4,]  3018        4902  1503        5434          35771     56514        7560\n[5,]  2165        4397  1365        4427          24464     57808        9090\n[6,]  2022        4166  1446        3359          22473     63350        9681\n\n\nCheck how the conversion goes.\n\nclass(ts_data)\n\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n\nclass(ts_data_ts)\n\n[1] \"mts\"    \"ts\"     \"matrix\" \"array\" \n\n\n\n\n\n\nA tsibble (or tbl_ts) is a data- and model-oriented object. Compared to the conventional time series objects in R, for example ts, zoo, and xts, the tsibble preserves time indices as the essential data column and makes heterogeneous data structures possible. Beyond the tibble-like representation, key comprised of single or multiple variables is introduced to uniquely identify observational units over time (index).\nThe code chunk below converting ts_data from tibble object into tsibble object by using as_tsibble() of tsibble R package.\n\nts_tsibble &lt;- ts_data %&gt;%\n  mutate(Month = yearmonth(`Month-Year`)) %&gt;%\n  as_tsibble(index = `Month`)\n\n\n\nLearning from the code\n\n\nmutate() of dplyr package is used to derive a new field by transforming the data values in Month-Year field into month-year format. The transformation is performed by using yearmonth() of tsibble package. + as_tsibble() is used to convert the tibble data frame into tsibble data frame.\n\n\n\n\nShow the code\nts_tsibble\n\n\n# A tsibble: 144 x 35 [1M]\n   `Month-Year` `Republic of South Africa` Canada   USA Bangladesh Brunei China\n   &lt;date&gt;                            &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 2008-01-01                         3680   6972 31155       6786   3729 79599\n 2 2008-02-01                         1662   6056 27738       6314   3070 82074\n 3 2008-03-01                         3394   6220 31349       7502   4805 72546\n 4 2008-04-01                         3337   4764 26376       7333   3096 76112\n 5 2008-05-01                         2089   4460 26788       7988   3586 64808\n 6 2008-06-01                         2515   3888 29725       8301   5284 55238\n 7 2008-07-01                         2919   5313 33183       9004   4070 80747\n 8 2008-08-01                         2471   4519 27427       7913   4183 66625\n 9 2008-09-01                         2492   3421 21588       7549   3160 52649\n10 2008-10-01                         3023   4756 25112       7527   2983 54423\n# ℹ 134 more rows\n# ℹ 28 more variables: `Hong Kong SAR (China)` &lt;dbl&gt;, India &lt;dbl&gt;,\n#   Indonesia &lt;dbl&gt;, Japan &lt;dbl&gt;, `South Korea` &lt;dbl&gt;, Kuwait &lt;dbl&gt;,\n#   Malaysia &lt;dbl&gt;, Myanmar &lt;dbl&gt;, Pakistan &lt;dbl&gt;, Philippines &lt;dbl&gt;,\n#   `Saudi Arabia` &lt;dbl&gt;, `Sri Lanka` &lt;dbl&gt;, Taiwan &lt;dbl&gt;, Thailand &lt;dbl&gt;,\n#   `United Arab Emirates` &lt;dbl&gt;, Vietnam &lt;dbl&gt;, `Belgium & Luxembourg` &lt;dbl&gt;,\n#   Finland &lt;dbl&gt;, France &lt;dbl&gt;, Germany &lt;dbl&gt;, Italy &lt;dbl&gt;, …\n\n\n\n\n\n\nIn order to visualise the time-series data effectively, we need to organise the data frame from wide to long format by using pivot_longer() of tidyr package.\n\n\nShow the code\nts_longer &lt;- ts_data %&gt;%\n  pivot_longer(cols = c(2:34),\n               names_to = \"Country\",\n               values_to = \"Arrivals\")\n\n\n\n\n\n\nShow the code\nts_longer %&gt;%\n  filter(Country == \"Vietnam\") %&gt;%\n  ggplot(aes(x = `Month-Year`,\n             y = Arrivals)) +\n  geom_line(size = 0.5, color = \"#3AA6B9\")\n\n\n\n\n\n\n\n\n\n\n\nLearning from the code\n\n\n\nfilter() of dplyr package is used to select records belong to Vietnam.\ngeom_line() of ggplot2 package is used to plot the time-series line graph.\n\n\n\n\n\n\nTo plot multiple countries\n\n\nShow the code\nggplot(data = ts_longer, \n       aes(x = `Month-Year`, \n           y = Arrivals,\n           color = Country))+\n  geom_line(size = 0.5) +\n  theme(legend.position = \"bottom\", \n        legend.box.spacing = unit(0.5, \"cm\"))\n\n\n\n\n\n\n\n\n\nIn order to provide effective comparison, facet_wrap() of ggplot2 package is used to create small multiple line graph also known as trellis plot.\n\nggplot(data = ts_longer, \n       aes(x = `Month-Year`, \n           y = Arrivals))+\n  geom_line(size = 0.5) +\n  facet_wrap(~ Country,\n             ncol = 3,\n             scales = \"free_y\") + #y is not fixed axis.\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\n\n\n\ntsibble_longer &lt;- ts_tsibble %&gt;%\n  pivot_longer(cols = c(2:34),\n               names_to = \"Country\",\n               values_to = \"Arrivals\")\n\n\n\nA seasonal plot is similar to a time plot except that the data are plotted against the individual seasons in which the data were observed.\nA season plot is created by using gg_season() of feasts package. Below assume season is MONTH.\n\ntsibble_longer %&gt;%\n  filter(Country == \"Italy\" |\n         Country == \"Vietnam\" |\n         Country == \"United Kingdom\" |\n         Country == \"Germany\") %&gt;% \n  gg_season(Arrivals)\n\n\n\n\n\n\n\n\n\n\n\nA cycle plot shows how a trend or cycle changes over time. We can use them to see seasonal patterns. Typically, a cycle plot shows a measure on the Y-axis and then shows a time period (such as months or seasons) along the X-axis. For each time period, there is a trend line across a number of years.\nWe can start with the plot below, before digging deeper. Note that both lines reveal clear sign of seasonal patterns but not the trend.\n\ntsibble_longer %&gt;%\n  filter(Country == \"Vietnam\" |\n         Country == \"Italy\") %&gt;% \n  autoplot(Arrivals) + \n  facet_grid(Country ~ ., scales = \"free_y\")\n\n\n\n\n\n\n\n\n&lt;feast package&gt; In the code chunk below, cycle plots using gg_subseries() of feasts package are created. Notice that the cycle plots show not only seasonal patterns but also trend, by month.\n\ntsibble_longer %&gt;%\n  filter(Country == \"Vietnam\" |\n         Country == \"Italy\") %&gt;% \n  gg_subseries(Arrivals) \n\n\n\n\n\n\n\n\n\nincreasing trend.\nrate high\nJuly and August are higher than others.\nItaly: most months are very low, except Aug.\n\n\n\n\n\nTrend, seasonal and error\nTime series decomposition allows us to isolate structural components such as trend and seasonality from the time-series data.\n\n\nIn feasts package, time series decomposition is supported by ACF(), PACF(), CCF(), feat_acf(), and feat_pacf(). The output can then be plotted by using autoplot() of feasts package.\nIn the code chunk below, ACF() of feasts package is used to plot the ACF curve of visitor arrival from Vietnam.\n\ntsibble_longer %&gt;%\n  filter(`Country` == \"Vietnam\") %&gt;%\n  ACF(Arrivals) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\nIn the code chunk below, PACF() of feasts package is used to plot the Partial ACF curve of visitor arrival from Vietnam.\n\ntsibble_longer %&gt;%\n  filter(`Country` == \"Vietnam\") %&gt;%\n  PACF(Arrivals) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\n\ntsibble_longer %&gt;%\n  filter(`Country` == \"Vietnam\" |\n         `Country` == \"Italy\" |\n         `Country` == \"United Kingdom\" |\n         `Country` == \"China\") %&gt;%\n  ACF(Arrivals) %&gt;%\n  autoplot()\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\nACF(): compare with the previous (relation with the previous) autoplot() gives the plotting. - China and Vietnam are similar, but not the same. China is 6 months period, while VN is 12 months. - blues lines are confidence intervals to check whether they are statistically significant. China is more significant then VN. The rest are weak. UK - trend is not significant, but still have seasonal.\n\n\nOn the other hand, code chunk below is used to prepare a trellis plot of PACFs for visitor arrivals from Vietnam, Italy, United Kingdom and China. PACF() has Lag 1 and 2, … keeps looking at the correlation. It is the correlation between two variables under the assumption that we know and take into account the values of some other set of variables. For instance, consider a regression context in which y is the response variable and X1, X2, and X3 are predictor variables. The partial correlation between y and X3 is the correlation between the variables determined taking into account how both y and X3 are related to X1 and X2.\n\ntsibble_longer %&gt;%\n  filter(`Country` == \"Vietnam\" |\n         `Country` == \"Italy\" |\n         `Country` == \"United Kingdom\" |\n         `Country` == \"China\") %&gt;%\n  PACF(Arrivals) %&gt;%\n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, STL() of feasts package is used to decomposite visitor arrivals from Vietnam data.\n\ntsibble_longer %&gt;%\n  filter(`Country` == \"Vietnam\") %&gt;%\n  model(stl = STL(Arrivals)) %&gt;%\n  components() %&gt;%\n  autoplot()\n\n\n\n\n\n\n\n\nTrend and Seasonal need to compose well, both needs to be clear.\n\n\n\n\ntsibble_longer %&gt;%\n  filter(`Country` == \"Vietnam\") %&gt;%\n  model(\n    classical_decomposition(\n      Arrivals, type = \"additive\")) %&gt;%\n  components() %&gt;%\n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\nNeed to keep the last few time hold-out data.\nIn this example we will use the last 12 months for hold-out and the rest for training.\nFirst, an extra column called Type indicating training or hold-out will be created by using mutate() of dplyr package. It will be extremely useful for subsequent data visualisation.\n\nvietnam_ts &lt;- tsibble_longer %&gt;%\n  filter(Country == \"Vietnam\") %&gt;% \n  mutate(Type = if_else(\n    `Month-Year` &gt;= \"2019-01-01\", \n    \"Hold-out\", \"Training\"))\n\nNext, a training data set is extracted from the original data set by using filter() of dplyr package.\n\nvietnam_train &lt;- vietnam_ts %&gt;%\n  filter(`Month-Year` &lt; \"2019-01-01\")\n\n\n\n\n\n\n\nthe residual should look normal distribution so it means good forecasting.\n7.4\n\n\nSee the stats result and plotting result on forecast and observed value.\n\nWH-M value is the smallest, also showing closest to the observed value.\n\n\n\n\n\nGood fitting: buffer should be very thin.\nonly need to see the last two (zoom in)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07.html#getting-started",
    "href": "In-class_Ex/In-class_Ex07.html#getting-started",
    "title": "In-class_Ex07",
    "section": "",
    "text": "tidyverts is a family of R packages specially designed for visualising, analysing and forecasting time-series data conforming to tidyverse framework. It is the work of Dr. Rob Hyndman, professor of statistics at Monash University, and his team. The family of R packages are intended to be the next-generation replacement for the very popular forecast package, and is currently under active development.\nLoad and launch packages\nUse tool to install packages: tsibble, feasts, fable and seasonal first.\n\n\nShow the code\npacman::p_load(tidyverse, tsibble, feasts, fable, seasonal)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07.html#import-the-data",
    "href": "In-class_Ex/In-class_Ex07.html#import-the-data",
    "title": "In-class_Ex07",
    "section": "",
    "text": "Show the code\nts_data &lt;- read_csv(\"data/visitor_arrivals_by_air.csv\")\nhead(ts_data)\n\n\n# A tibble: 6 × 34\n  `Month-Year` `Republic of South Africa` Canada   USA Bangladesh Brunei China\n  &lt;chr&gt;                             &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 1/1/2008                           3680   6972 31155       6786   3729 79599\n2 1/2/2008                           1662   6056 27738       6314   3070 82074\n3 1/3/2008                           3394   6220 31349       7502   4805 72546\n4 1/4/2008                           3337   4764 26376       7333   3096 76112\n5 1/5/2008                           2089   4460 26788       7988   3586 64808\n6 1/6/2008                           2515   3888 29725       8301   5284 55238\n# ℹ 27 more variables: `Hong Kong SAR (China)` &lt;dbl&gt;, India &lt;dbl&gt;,\n#   Indonesia &lt;dbl&gt;, Japan &lt;dbl&gt;, `South Korea` &lt;dbl&gt;, Kuwait &lt;dbl&gt;,\n#   Malaysia &lt;dbl&gt;, Myanmar &lt;dbl&gt;, Pakistan &lt;dbl&gt;, Philippines &lt;dbl&gt;,\n#   `Saudi Arabia` &lt;dbl&gt;, `Sri Lanka` &lt;dbl&gt;, Taiwan &lt;dbl&gt;, Thailand &lt;dbl&gt;,\n#   `United Arab Emirates` &lt;dbl&gt;, Vietnam &lt;dbl&gt;, `Belgium & Luxembourg` &lt;dbl&gt;,\n#   Finland &lt;dbl&gt;, France &lt;dbl&gt;, Germany &lt;dbl&gt;, Italy &lt;dbl&gt;, Netherlands &lt;dbl&gt;,\n#   Spain &lt;dbl&gt;, Switzerland &lt;dbl&gt;, `United Kingdom` &lt;dbl&gt;, Australia &lt;dbl&gt;, …\n\n\nIn the code chunk below, dmy() of lubridate package is used to convert data type of Month-Year field from Character to Date.\n\n\nShow the code\nts_data$`Month-Year` &lt;- dmy(\n  ts_data$`Month-Year`) #to replace the column.\nhead(ts_data)\n\n\n# A tibble: 6 × 34\n  `Month-Year` `Republic of South Africa` Canada   USA Bangladesh Brunei China\n  &lt;date&gt;                            &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 2008-01-01                         3680   6972 31155       6786   3729 79599\n2 2008-02-01                         1662   6056 27738       6314   3070 82074\n3 2008-03-01                         3394   6220 31349       7502   4805 72546\n4 2008-04-01                         3337   4764 26376       7333   3096 76112\n5 2008-05-01                         2089   4460 26788       7988   3586 64808\n6 2008-06-01                         2515   3888 29725       8301   5284 55238\n# ℹ 27 more variables: `Hong Kong SAR (China)` &lt;dbl&gt;, India &lt;dbl&gt;,\n#   Indonesia &lt;dbl&gt;, Japan &lt;dbl&gt;, `South Korea` &lt;dbl&gt;, Kuwait &lt;dbl&gt;,\n#   Malaysia &lt;dbl&gt;, Myanmar &lt;dbl&gt;, Pakistan &lt;dbl&gt;, Philippines &lt;dbl&gt;,\n#   `Saudi Arabia` &lt;dbl&gt;, `Sri Lanka` &lt;dbl&gt;, Taiwan &lt;dbl&gt;, Thailand &lt;dbl&gt;,\n#   `United Arab Emirates` &lt;dbl&gt;, Vietnam &lt;dbl&gt;, `Belgium & Luxembourg` &lt;dbl&gt;,\n#   Finland &lt;dbl&gt;, France &lt;dbl&gt;, Germany &lt;dbl&gt;, Italy &lt;dbl&gt;, Netherlands &lt;dbl&gt;,\n#   Spain &lt;dbl&gt;, Switzerland &lt;dbl&gt;, `United Kingdom` &lt;dbl&gt;, Australia &lt;dbl&gt;, …\n\n\nNow we see it’s converted to date data type.\n\n\n\n\n\n\n\nShow the code\nts_data\n\n\n# A tibble: 144 × 34\n   `Month-Year` `Republic of South Africa` Canada   USA Bangladesh Brunei China\n   &lt;date&gt;                            &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 2008-01-01                         3680   6972 31155       6786   3729 79599\n 2 2008-02-01                         1662   6056 27738       6314   3070 82074\n 3 2008-03-01                         3394   6220 31349       7502   4805 72546\n 4 2008-04-01                         3337   4764 26376       7333   3096 76112\n 5 2008-05-01                         2089   4460 26788       7988   3586 64808\n 6 2008-06-01                         2515   3888 29725       8301   5284 55238\n 7 2008-07-01                         2919   5313 33183       9004   4070 80747\n 8 2008-08-01                         2471   4519 27427       7913   4183 66625\n 9 2008-09-01                         2492   3421 21588       7549   3160 52649\n10 2008-10-01                         3023   4756 25112       7527   2983 54423\n# ℹ 134 more rows\n# ℹ 27 more variables: `Hong Kong SAR (China)` &lt;dbl&gt;, India &lt;dbl&gt;,\n#   Indonesia &lt;dbl&gt;, Japan &lt;dbl&gt;, `South Korea` &lt;dbl&gt;, Kuwait &lt;dbl&gt;,\n#   Malaysia &lt;dbl&gt;, Myanmar &lt;dbl&gt;, Pakistan &lt;dbl&gt;, Philippines &lt;dbl&gt;,\n#   `Saudi Arabia` &lt;dbl&gt;, `Sri Lanka` &lt;dbl&gt;, Taiwan &lt;dbl&gt;, Thailand &lt;dbl&gt;,\n#   `United Arab Emirates` &lt;dbl&gt;, Vietnam &lt;dbl&gt;, `Belgium & Luxembourg` &lt;dbl&gt;,\n#   Finland &lt;dbl&gt;, France &lt;dbl&gt;, Germany &lt;dbl&gt;, Italy &lt;dbl&gt;, …\n\n\nWe can also use class() to check.\n\n\n\n\n\nShow the code\nts_data_ts &lt;- ts(ts_data)       \nhead(ts_data_ts)\n\n\n     Month-Year Republic of South Africa Canada   USA Bangladesh Brunei China\n[1,]      13879                     3680   6972 31155       6786   3729 79599\n[2,]      13910                     1662   6056 27738       6314   3070 82074\n[3,]      13939                     3394   6220 31349       7502   4805 72546\n[4,]      13970                     3337   4764 26376       7333   3096 76112\n[5,]      14000                     2089   4460 26788       7988   3586 64808\n[6,]      14031                     2515   3888 29725       8301   5284 55238\n     Hong Kong SAR (China) India Indonesia Japan South Korea Kuwait Malaysia\n[1,]                 17103 41639     62683 37673       27937    284    31352\n[2,]                 21089 37170     47834 35297       22633    241    35030\n[3,]                 23230 44815     64688 42575       22876    206    37629\n[4,]                 17688 49527     58074 26839       20634    193    37521\n[5,]                 19340 67754     57089 30814       22785    140    38044\n[6,]                 19152 57380     70118 31001       22575    354    40419\n     Myanmar Pakistan Philippines Saudi Arabia Sri Lanka Taiwan Thailand\n[1,]    5269     1395       18622          406      5289  13757    18370\n[2,]    4643     1027       21609          591      4767  13921    16400\n[3,]    6218     1635       28464          626      4988  11181    23387\n[4,]    7324     1232       30131          644      7639  11665    24469\n[5,]    5395     1306       30193          470      5125  11436    21935\n[6,]    5542     1996       25800          772      4791  10689    19900\n     United Arab Emirates Vietnam Belgium & Luxembourg Finland France Germany\n[1,]                 2652   10315                 1341    1179   6918   11982\n[2,]                 2230   13415                 1449    1207   7876   13256\n[3,]                 3353   14320                 1674    1071   8066   15185\n[4,]                 3245   15413                 1426     768   8312   11604\n[5,]                 2856   14424                 1243     690   7066    9853\n[6,]                 4292   21368                 1255     624   5926    9347\n     Italy Netherlands Spain Switzerland United Kingdom Australia New Zealand\n[1,]  2953        4938  1668        4450          41934     71260        7806\n[2,]  2704        4885  1568        4381          44029     45595        4729\n[3,]  2822        5015  2254        5015          49489     53191        6106\n[4,]  3018        4902  1503        5434          35771     56514        7560\n[5,]  2165        4397  1365        4427          24464     57808        9090\n[6,]  2022        4166  1446        3359          22473     63350        9681\n\n\nCheck how the conversion goes.\n\nclass(ts_data)\n\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n\nclass(ts_data_ts)\n\n[1] \"mts\"    \"ts\"     \"matrix\" \"array\" \n\n\n\n\n\n\nA tsibble (or tbl_ts) is a data- and model-oriented object. Compared to the conventional time series objects in R, for example ts, zoo, and xts, the tsibble preserves time indices as the essential data column and makes heterogeneous data structures possible. Beyond the tibble-like representation, key comprised of single or multiple variables is introduced to uniquely identify observational units over time (index).\nThe code chunk below converting ts_data from tibble object into tsibble object by using as_tsibble() of tsibble R package.\n\nts_tsibble &lt;- ts_data %&gt;%\n  mutate(Month = yearmonth(`Month-Year`)) %&gt;%\n  as_tsibble(index = `Month`)\n\n\n\nLearning from the code\n\n\nmutate() of dplyr package is used to derive a new field by transforming the data values in Month-Year field into month-year format. The transformation is performed by using yearmonth() of tsibble package. + as_tsibble() is used to convert the tibble data frame into tsibble data frame.\n\n\n\n\nShow the code\nts_tsibble\n\n\n# A tsibble: 144 x 35 [1M]\n   `Month-Year` `Republic of South Africa` Canada   USA Bangladesh Brunei China\n   &lt;date&gt;                            &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 2008-01-01                         3680   6972 31155       6786   3729 79599\n 2 2008-02-01                         1662   6056 27738       6314   3070 82074\n 3 2008-03-01                         3394   6220 31349       7502   4805 72546\n 4 2008-04-01                         3337   4764 26376       7333   3096 76112\n 5 2008-05-01                         2089   4460 26788       7988   3586 64808\n 6 2008-06-01                         2515   3888 29725       8301   5284 55238\n 7 2008-07-01                         2919   5313 33183       9004   4070 80747\n 8 2008-08-01                         2471   4519 27427       7913   4183 66625\n 9 2008-09-01                         2492   3421 21588       7549   3160 52649\n10 2008-10-01                         3023   4756 25112       7527   2983 54423\n# ℹ 134 more rows\n# ℹ 28 more variables: `Hong Kong SAR (China)` &lt;dbl&gt;, India &lt;dbl&gt;,\n#   Indonesia &lt;dbl&gt;, Japan &lt;dbl&gt;, `South Korea` &lt;dbl&gt;, Kuwait &lt;dbl&gt;,\n#   Malaysia &lt;dbl&gt;, Myanmar &lt;dbl&gt;, Pakistan &lt;dbl&gt;, Philippines &lt;dbl&gt;,\n#   `Saudi Arabia` &lt;dbl&gt;, `Sri Lanka` &lt;dbl&gt;, Taiwan &lt;dbl&gt;, Thailand &lt;dbl&gt;,\n#   `United Arab Emirates` &lt;dbl&gt;, Vietnam &lt;dbl&gt;, `Belgium & Luxembourg` &lt;dbl&gt;,\n#   Finland &lt;dbl&gt;, France &lt;dbl&gt;, Germany &lt;dbl&gt;, Italy &lt;dbl&gt;, …"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07.html#visualising-time-series-data",
    "href": "In-class_Ex/In-class_Ex07.html#visualising-time-series-data",
    "title": "In-class_Ex07",
    "section": "",
    "text": "In order to visualise the time-series data effectively, we need to organise the data frame from wide to long format by using pivot_longer() of tidyr package.\n\n\nShow the code\nts_longer &lt;- ts_data %&gt;%\n  pivot_longer(cols = c(2:34),\n               names_to = \"Country\",\n               values_to = \"Arrivals\")\n\n\n\n\n\n\nShow the code\nts_longer %&gt;%\n  filter(Country == \"Vietnam\") %&gt;%\n  ggplot(aes(x = `Month-Year`,\n             y = Arrivals)) +\n  geom_line(size = 0.5, color = \"#3AA6B9\")\n\n\n\n\n\n\n\n\n\n\n\nLearning from the code\n\n\n\nfilter() of dplyr package is used to select records belong to Vietnam.\ngeom_line() of ggplot2 package is used to plot the time-series line graph.\n\n\n\n\n\n\nTo plot multiple countries\n\n\nShow the code\nggplot(data = ts_longer, \n       aes(x = `Month-Year`, \n           y = Arrivals,\n           color = Country))+\n  geom_line(size = 0.5) +\n  theme(legend.position = \"bottom\", \n        legend.box.spacing = unit(0.5, \"cm\"))\n\n\n\n\n\n\n\n\n\nIn order to provide effective comparison, facet_wrap() of ggplot2 package is used to create small multiple line graph also known as trellis plot.\n\nggplot(data = ts_longer, \n       aes(x = `Month-Year`, \n           y = Arrivals))+\n  geom_line(size = 0.5) +\n  facet_wrap(~ Country,\n             ncol = 3,\n             scales = \"free_y\") + #y is not fixed axis.\n  theme_bw()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07.html#visual-analysis-of-time-series-data",
    "href": "In-class_Ex/In-class_Ex07.html#visual-analysis-of-time-series-data",
    "title": "In-class_Ex07",
    "section": "",
    "text": "tsibble_longer &lt;- ts_tsibble %&gt;%\n  pivot_longer(cols = c(2:34),\n               names_to = \"Country\",\n               values_to = \"Arrivals\")\n\n\n\nA seasonal plot is similar to a time plot except that the data are plotted against the individual seasons in which the data were observed.\nA season plot is created by using gg_season() of feasts package. Below assume season is MONTH.\n\ntsibble_longer %&gt;%\n  filter(Country == \"Italy\" |\n         Country == \"Vietnam\" |\n         Country == \"United Kingdom\" |\n         Country == \"Germany\") %&gt;% \n  gg_season(Arrivals)\n\n\n\n\n\n\n\n\n\n\n\nA cycle plot shows how a trend or cycle changes over time. We can use them to see seasonal patterns. Typically, a cycle plot shows a measure on the Y-axis and then shows a time period (such as months or seasons) along the X-axis. For each time period, there is a trend line across a number of years.\nWe can start with the plot below, before digging deeper. Note that both lines reveal clear sign of seasonal patterns but not the trend.\n\ntsibble_longer %&gt;%\n  filter(Country == \"Vietnam\" |\n         Country == \"Italy\") %&gt;% \n  autoplot(Arrivals) + \n  facet_grid(Country ~ ., scales = \"free_y\")\n\n\n\n\n\n\n\n\n&lt;feast package&gt; In the code chunk below, cycle plots using gg_subseries() of feasts package are created. Notice that the cycle plots show not only seasonal patterns but also trend, by month.\n\ntsibble_longer %&gt;%\n  filter(Country == \"Vietnam\" |\n         Country == \"Italy\") %&gt;% \n  gg_subseries(Arrivals) \n\n\n\n\n\n\n\n\n\nincreasing trend.\nrate high\nJuly and August are higher than others.\nItaly: most months are very low, except Aug."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07.html#time-series-decomposition",
    "href": "In-class_Ex/In-class_Ex07.html#time-series-decomposition",
    "title": "In-class_Ex07",
    "section": "",
    "text": "Trend, seasonal and error\nTime series decomposition allows us to isolate structural components such as trend and seasonality from the time-series data.\n\n\nIn feasts package, time series decomposition is supported by ACF(), PACF(), CCF(), feat_acf(), and feat_pacf(). The output can then be plotted by using autoplot() of feasts package.\nIn the code chunk below, ACF() of feasts package is used to plot the ACF curve of visitor arrival from Vietnam.\n\ntsibble_longer %&gt;%\n  filter(`Country` == \"Vietnam\") %&gt;%\n  ACF(Arrivals) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\nIn the code chunk below, PACF() of feasts package is used to plot the Partial ACF curve of visitor arrival from Vietnam.\n\ntsibble_longer %&gt;%\n  filter(`Country` == \"Vietnam\") %&gt;%\n  PACF(Arrivals) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\n\ntsibble_longer %&gt;%\n  filter(`Country` == \"Vietnam\" |\n         `Country` == \"Italy\" |\n         `Country` == \"United Kingdom\" |\n         `Country` == \"China\") %&gt;%\n  ACF(Arrivals) %&gt;%\n  autoplot()\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\nACF(): compare with the previous (relation with the previous) autoplot() gives the plotting. - China and Vietnam are similar, but not the same. China is 6 months period, while VN is 12 months. - blues lines are confidence intervals to check whether they are statistically significant. China is more significant then VN. The rest are weak. UK - trend is not significant, but still have seasonal.\n\n\nOn the other hand, code chunk below is used to prepare a trellis plot of PACFs for visitor arrivals from Vietnam, Italy, United Kingdom and China. PACF() has Lag 1 and 2, … keeps looking at the correlation. It is the correlation between two variables under the assumption that we know and take into account the values of some other set of variables. For instance, consider a regression context in which y is the response variable and X1, X2, and X3 are predictor variables. The partial correlation between y and X3 is the correlation between the variables determined taking into account how both y and X3 are related to X1 and X2.\n\ntsibble_longer %&gt;%\n  filter(`Country` == \"Vietnam\" |\n         `Country` == \"Italy\" |\n         `Country` == \"United Kingdom\" |\n         `Country` == \"China\") %&gt;%\n  PACF(Arrivals) %&gt;%\n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, STL() of feasts package is used to decomposite visitor arrivals from Vietnam data.\n\ntsibble_longer %&gt;%\n  filter(`Country` == \"Vietnam\") %&gt;%\n  model(stl = STL(Arrivals)) %&gt;%\n  components() %&gt;%\n  autoplot()\n\n\n\n\n\n\n\n\nTrend and Seasonal need to compose well, both needs to be clear.\n\n\n\n\ntsibble_longer %&gt;%\n  filter(`Country` == \"Vietnam\") %&gt;%\n  model(\n    classical_decomposition(\n      Arrivals, type = \"additive\")) %&gt;%\n  components() %&gt;%\n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\nNeed to keep the last few time hold-out data.\nIn this example we will use the last 12 months for hold-out and the rest for training.\nFirst, an extra column called Type indicating training or hold-out will be created by using mutate() of dplyr package. It will be extremely useful for subsequent data visualisation.\n\nvietnam_ts &lt;- tsibble_longer %&gt;%\n  filter(Country == \"Vietnam\") %&gt;% \n  mutate(Type = if_else(\n    `Month-Year` &gt;= \"2019-01-01\", \n    \"Hold-out\", \"Training\"))\n\nNext, a training data set is extracted from the original data set by using filter() of dplyr package.\n\nvietnam_train &lt;- vietnam_ts %&gt;%\n  filter(`Month-Year` &lt; \"2019-01-01\")\n\n\n\n\n\n\n\nthe residual should look normal distribution so it means good forecasting.\n7.4\n\n\nSee the stats result and plotting result on forecast and observed value.\n\nWH-M value is the smallest, also showing closest to the observed value.\n\n\n\n\n\nGood fitting: buffer should be very thin.\nonly need to see the last two (zoom in)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05.html",
    "href": "In-class_Ex/In-class_Ex05.html",
    "title": "In-class_Ex05",
    "section": "",
    "text": "pacman::p_load(tidyverse, readxl, SmartEDA, easystats, gtsummary, ggstatsplot)\n\ngtsummary: meant to summarise modeling results. allows to create elegant tables for reporting results.\nIf the package is not in CRAN yet, install devtools as well in Tools first.",
    "crumbs": [
      "![](/images/house.svg)",
      "In-class Exercise",
      "In-class_Ex5"
    ]
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05.html#getting-started",
    "href": "In-class_Ex/In-class_Ex05.html#getting-started",
    "title": "In-class_Ex05",
    "section": "",
    "text": "pacman::p_load(tidyverse, readxl, SmartEDA, easystats, gtsummary, ggstatsplot)\n\ngtsummary: meant to summarise modeling results. allows to create elegant tables for reporting results.\nIf the package is not in CRAN yet, install devtools as well in Tools first.",
    "crumbs": [
      "![](/images/house.svg)",
      "In-class Exercise",
      "In-class_Ex5"
    ]
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05.html#importing-data",
    "href": "In-class_Ex/In-class_Ex05.html#importing-data",
    "title": "In-class_Ex05",
    "section": "Importing data",
    "text": "Importing data\n\ncar_resale &lt;- read_xls(\"data/ToyotaCorolla.xls\", \"data\"\n)\n# In the file, there is another tab called \"metadata\", so \"data\" tab is specified in the code above.\n\n\nsummary(car_resale)\n\n       Id            Model               Price         Age_08_04    \n Min.   :   1.0   Length:1436        Min.   : 4350   Min.   : 1.00  \n 1st Qu.: 361.8   Class :character   1st Qu.: 8450   1st Qu.:44.00  \n Median : 721.5   Mode  :character   Median : 9900   Median :61.00  \n Mean   : 721.6                      Mean   :10731   Mean   :55.95  \n 3rd Qu.:1081.2                      3rd Qu.:11950   3rd Qu.:70.00  \n Max.   :1442.0                      Max.   :32500   Max.   :80.00  \n   Mfg_Month         Mfg_Year          KM         Quarterly_Tax   \n Min.   : 1.000   Min.   :1998   Min.   :     1   Min.   : 19.00  \n 1st Qu.: 3.000   1st Qu.:1998   1st Qu.: 43000   1st Qu.: 69.00  \n Median : 5.000   Median :1999   Median : 63390   Median : 85.00  \n Mean   : 5.549   Mean   :2000   Mean   : 68533   Mean   : 87.12  \n 3rd Qu.: 8.000   3rd Qu.:2001   3rd Qu.: 87021   3rd Qu.: 85.00  \n Max.   :12.000   Max.   :2004   Max.   :243000   Max.   :283.00  \n     Weight     Guarantee_Period    HP_Bin             CC_bin         \n Min.   :1000   Min.   : 3.000   Length:1436        Length:1436       \n 1st Qu.:1040   1st Qu.: 3.000   Class :character   Class :character  \n Median :1070   Median : 3.000   Mode  :character   Mode  :character  \n Mean   :1072   Mean   : 3.815                                        \n 3rd Qu.:1085   3rd Qu.: 3.000                                        \n Max.   :1615   Max.   :36.000                                        \n     Doors           Gears         Cylinders  Fuel_Type        \n Min.   :2.000   Min.   :3.000   Min.   :4   Length:1436       \n 1st Qu.:3.000   1st Qu.:5.000   1st Qu.:4   Class :character  \n Median :4.000   Median :5.000   Median :4   Mode  :character  \n Mean   :4.033   Mean   :5.026   Mean   :4                     \n 3rd Qu.:5.000   3rd Qu.:5.000   3rd Qu.:4                     \n Max.   :5.000   Max.   :6.000   Max.   :4                     \n    Color             Met_Color        Automatic       Mfr_Guarantee   \n Length:1436        Min.   :0.0000   Min.   :0.00000   Min.   :0.0000  \n Class :character   1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:0.0000  \n Mode  :character   Median :1.0000   Median :0.00000   Median :0.0000  \n                    Mean   :0.6748   Mean   :0.05571   Mean   :0.4095  \n                    3rd Qu.:1.0000   3rd Qu.:0.00000   3rd Qu.:1.0000  \n                    Max.   :1.0000   Max.   :1.00000   Max.   :1.0000  \n BOVAG_Guarantee       ABS            Airbag_1         Airbag_2     \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:1.0000   1st Qu.:1.0000   1st Qu.:1.0000   1st Qu.:0.0000  \n Median :1.0000   Median :1.0000   Median :1.0000   Median :1.0000  \n Mean   :0.8955   Mean   :0.8134   Mean   :0.9708   Mean   :0.7228  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n     Airco        Automatic_airco   Boardcomputer      CD_Player     \n Min.   :0.0000   Min.   :0.00000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :1.0000   Median :0.00000   Median :0.0000   Median :0.0000  \n Mean   :0.5084   Mean   :0.05641   Mean   :0.2946   Mean   :0.2187  \n 3rd Qu.:1.0000   3rd Qu.:0.00000   3rd Qu.:1.0000   3rd Qu.:0.0000  \n Max.   :1.0000   Max.   :1.00000   Max.   :1.0000   Max.   :1.0000  \n  Central_Lock    Powered_Windows Power_Steering       Radio       \n Min.   :0.0000   Min.   :0.000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.000   1st Qu.:1.0000   1st Qu.:0.0000  \n Median :1.0000   Median :1.000   Median :1.0000   Median :0.0000  \n Mean   :0.5801   Mean   :0.562   Mean   :0.9777   Mean   :0.1462  \n 3rd Qu.:1.0000   3rd Qu.:1.000   3rd Qu.:1.0000   3rd Qu.:0.0000  \n Max.   :1.0000   Max.   :1.000   Max.   :1.0000   Max.   :1.0000  \n   Mistlamps      Sport_Model     Backseat_Divider  Metallic_Rim   \n Min.   :0.000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.000   1st Qu.:0.0000   1st Qu.:1.0000   1st Qu.:0.0000  \n Median :0.000   Median :0.0000   Median :1.0000   Median :0.0000  \n Mean   :0.257   Mean   :0.3001   Mean   :0.7702   Mean   :0.2047  \n 3rd Qu.:1.000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:0.0000  \n Max.   :1.000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n Radio_cassette      Tow_Bar      \n Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000  \n Mean   :0.1455   Mean   :0.2779  \n 3rd Qu.:0.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000",
    "crumbs": [
      "![](/images/house.svg)",
      "In-class Exercise",
      "In-class_Ex5"
    ]
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05.html#data-overview",
    "href": "In-class_Ex/In-class_Ex05.html#data-overview",
    "title": "In-class_Ex05",
    "section": "Data overview",
    "text": "Data overview\n\nlist(car_resale)\n\n[[1]]\n# A tibble: 1,436 × 38\n      Id Model    Price Age_08_04 Mfg_Month Mfg_Year     KM Quarterly_Tax Weight\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n 1    81 TOYOTA … 18950        25         8     2002  20019           100   1180\n 2     1 TOYOTA … 13500        23        10     2002  46986           210   1165\n 3     2 TOYOTA … 13750        23        10     2002  72937           210   1165\n 4     3  TOYOTA… 13950        24         9     2002  41711           210   1165\n 5     4 TOYOTA … 14950        26         7     2002  48000           210   1165\n 6     5 TOYOTA … 13750        30         3     2002  38500           210   1170\n 7     6 TOYOTA … 12950        32         1     2002  61000           210   1170\n 8     7  TOYOTA… 16900        27         6     2002  94612           210   1245\n 9     8 TOYOTA … 18600        30         3     2002  75889           210   1245\n10    44 TOYOTA … 16950        27         6     2002 110404           234   1255\n# ℹ 1,426 more rows\n# ℹ 29 more variables: Guarantee_Period &lt;dbl&gt;, HP_Bin &lt;chr&gt;, CC_bin &lt;chr&gt;,\n#   Doors &lt;dbl&gt;, Gears &lt;dbl&gt;, Cylinders &lt;dbl&gt;, Fuel_Type &lt;chr&gt;, Color &lt;chr&gt;,\n#   Met_Color &lt;dbl&gt;, Automatic &lt;dbl&gt;, Mfr_Guarantee &lt;dbl&gt;,\n#   BOVAG_Guarantee &lt;dbl&gt;, ABS &lt;dbl&gt;, Airbag_1 &lt;dbl&gt;, Airbag_2 &lt;dbl&gt;,\n#   Airco &lt;dbl&gt;, Automatic_airco &lt;dbl&gt;, Boardcomputer &lt;dbl&gt;, CD_Player &lt;dbl&gt;,\n#   Central_Lock &lt;dbl&gt;, Powered_Windows &lt;dbl&gt;, Power_Steering &lt;dbl&gt;, …",
    "crumbs": [
      "![](/images/house.svg)",
      "In-class Exercise",
      "In-class_Ex5"
    ]
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05.html#smarteda",
    "href": "In-class_Ex/In-class_Ex05.html#smarteda",
    "title": "In-class_Ex05",
    "section": "SmartEDA",
    "text": "SmartEDA\nHelp organise data to do EDA &gt; review summary statistics.\n\ntype = 1type = 2\n\n\n\nsummary_1 &lt;- car_resale %&gt;%\n  ExpData(type = 1) #store the result into a data table.\nsummary_1\n\n                                          Descriptions     Value\n1                                   Sample size (nrow)      1436\n2                              No. of variables (ncol)        38\n3                    No. of numeric/interger variables        33\n4                              No. of factor variables         0\n5                                No. of text variables         5\n6                             No. of logical variables         0\n7                          No. of identifier variables         1\n8                                No. of date variables         0\n9             No. of zero variance variables (uniform)         1\n10               %. of variables having complete cases 100% (38)\n11   %. of variables having &gt;0% and &lt;50% missing cases    0% (0)\n12 %. of variables having &gt;=50% and &lt;90% missing cases    0% (0)\n13          %. of variables having &gt;=90% missing cases    0% (0)\n\n\nCan print out summary_1 for report.\n\n\n\nsummary_2 &lt;- car_resale %&gt;%\n  ExpData(type = 2) #store the result into a data table.\nsummary_2\n\n   Index    Variable_Name Variable_Type Sample_n Missing_Count Per_of_Missing\n1      1               Id       numeric     1436             0              0\n2      2            Model     character     1436             0              0\n3      3            Price       numeric     1436             0              0\n4      4        Age_08_04       numeric     1436             0              0\n5      5        Mfg_Month       numeric     1436             0              0\n6      6         Mfg_Year       numeric     1436             0              0\n7      7               KM       numeric     1436             0              0\n8      8    Quarterly_Tax       numeric     1436             0              0\n9      9           Weight       numeric     1436             0              0\n10    10 Guarantee_Period       numeric     1436             0              0\n11    11           HP_Bin     character     1436             0              0\n12    12           CC_bin     character     1436             0              0\n13    13            Doors       numeric     1436             0              0\n14    14            Gears       numeric     1436             0              0\n15    15        Cylinders       numeric     1436             0              0\n16    16        Fuel_Type     character     1436             0              0\n17    17            Color     character     1436             0              0\n18    18        Met_Color       numeric     1436             0              0\n19    19        Automatic       numeric     1436             0              0\n20    20    Mfr_Guarantee       numeric     1436             0              0\n21    21  BOVAG_Guarantee       numeric     1436             0              0\n22    22              ABS       numeric     1436             0              0\n23    23         Airbag_1       numeric     1436             0              0\n24    24         Airbag_2       numeric     1436             0              0\n25    25            Airco       numeric     1436             0              0\n26    26  Automatic_airco       numeric     1436             0              0\n27    27    Boardcomputer       numeric     1436             0              0\n28    28        CD_Player       numeric     1436             0              0\n29    29     Central_Lock       numeric     1436             0              0\n30    30  Powered_Windows       numeric     1436             0              0\n31    31   Power_Steering       numeric     1436             0              0\n32    32            Radio       numeric     1436             0              0\n33    33        Mistlamps       numeric     1436             0              0\n34    34      Sport_Model       numeric     1436             0              0\n35    35 Backseat_Divider       numeric     1436             0              0\n36    36     Metallic_Rim       numeric     1436             0              0\n37    37   Radio_cassette       numeric     1436             0              0\n38    38          Tow_Bar       numeric     1436             0              0\n   No_of_distinct_values\n1                   1436\n2                    372\n3                    236\n4                     77\n5                     12\n6                      7\n7                   1263\n8                     13\n9                     59\n10                     9\n11                     3\n12                     3\n13                     4\n14                     4\n15                     1\n16                     3\n17                    10\n18                     2\n19                     2\n20                     2\n21                     2\n22                     2\n23                     2\n24                     2\n25                     2\n26                     2\n27                     2\n28                     2\n29                     2\n30                     2\n31                     2\n32                     2\n33                     2\n34                     2\n35                     2\n36                     2\n37                     2\n38                     2\n\n\n\n\n\n\nlist(car_resale)\n\n[[1]]\n# A tibble: 1,436 × 38\n      Id Model    Price Age_08_04 Mfg_Month Mfg_Year     KM Quarterly_Tax Weight\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n 1    81 TOYOTA … 18950        25         8     2002  20019           100   1180\n 2     1 TOYOTA … 13500        23        10     2002  46986           210   1165\n 3     2 TOYOTA … 13750        23        10     2002  72937           210   1165\n 4     3  TOYOTA… 13950        24         9     2002  41711           210   1165\n 5     4 TOYOTA … 14950        26         7     2002  48000           210   1165\n 6     5 TOYOTA … 13750        30         3     2002  38500           210   1170\n 7     6 TOYOTA … 12950        32         1     2002  61000           210   1170\n 8     7  TOYOTA… 16900        27         6     2002  94612           210   1245\n 9     8 TOYOTA … 18600        30         3     2002  75889           210   1245\n10    44 TOYOTA … 16950        27         6     2002 110404           234   1255\n# ℹ 1,426 more rows\n# ℹ 29 more variables: Guarantee_Period &lt;dbl&gt;, HP_Bin &lt;chr&gt;, CC_bin &lt;chr&gt;,\n#   Doors &lt;dbl&gt;, Gears &lt;dbl&gt;, Cylinders &lt;dbl&gt;, Fuel_Type &lt;chr&gt;, Color &lt;chr&gt;,\n#   Met_Color &lt;dbl&gt;, Automatic &lt;dbl&gt;, Mfr_Guarantee &lt;dbl&gt;,\n#   BOVAG_Guarantee &lt;dbl&gt;, ABS &lt;dbl&gt;, Airbag_1 &lt;dbl&gt;, Airbag_2 &lt;dbl&gt;,\n#   Airco &lt;dbl&gt;, Automatic_airco &lt;dbl&gt;, Boardcomputer &lt;dbl&gt;, CD_Player &lt;dbl&gt;,\n#   Central_Lock &lt;dbl&gt;, Powered_Windows &lt;dbl&gt;, Power_Steering &lt;dbl&gt;, …\n\n\n\ncol &lt;- c(\"Mfg_Month\", \"HP_Bin\", \"CC_bin\", \"Doors\", \"Gears\",\n         \"Cylinders\", \"Fuel_Type\", \"Color\", \"Met_Color\", \"Automatic\",\n         \"Mfr_Guarantee\", \"BOVAG_Guarantee\", \"ABS\", \"Airbag_1\",\n         \"Airbag_2\", \"Airco\", \"Automatic_airco\", \"Automatic_airco\", \n         \"Boardcomputer\", \"CD_Player\", \"Central_Lock\", \"Powered_Windows\",\n         \"Power_Steering\", \"Radio\",\"Mistlamps\", \"Sport_Model\", \"Backseat_Divider\",\n         \"Metallic_Rim\", \"Radio_cassette\", \"Tow_Bar\")\ncar_resale &lt;- read_xls(\"data/ToyotaCorolla.xls\", \"data\") %&gt;%\n  mutate(Id = as.character(Id)) %&gt;%\n  mutate(across(all_of(col), as.factor))\n\n\ncar_resale %&gt;%\n  ExpNumViz(target=NULL,\n            nlim=10,\n            Page=c(2,3))\n\n$`0`\n\n\n\n\n\n\n\n\n\n\ncar_resale %&gt;%\n  ExpNumViz(target=\"Price\",\n            nlim=10,\n            Page=c(2,2))\n\n$`0`\n\n\n\n\n\n\n\n\n\nBar plots for all categorical vars.\n\ncar_resale%&gt;%\n  ExpCatViz(target=NULL,\n            col = \"#e0bcc0\",\n            clim = 10,\n            margin = 2,\n            Page = c(4,4),\n            sample = 16)\n\n$`0`",
    "crumbs": [
      "![](/images/house.svg)",
      "In-class Exercise",
      "In-class_Ex5"
    ]
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05.html#explanatory-model",
    "href": "In-class_Ex/In-class_Ex05.html#explanatory-model",
    "title": "In-class_Ex05",
    "section": "Explanatory Model",
    "text": "Explanatory Model\n\nAvoid Multi-collinearity\nMethod_1. Correlation analysis: correlation matrix.\nMethod_2. Easystats\n&lt;Model&gt;\n\nmodel &lt;- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n               KM 1.46 [ 1.37,  1.57]         1.21      0.68     [0.64, 0.73]\n           Weight 1.41 [ 1.32,  1.51]         1.19      0.71     [0.66, 0.76]\n Guarantee_Period 1.04 [ 1.01,  1.17]         1.02      0.97     [0.86, 0.99]\n\nHigh Correlation\n\n      Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n  Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\n\n\ncheck_c &lt;- check_collinearity(model)\nplot(check_c)\n\n\n\n\n\n\n\n\n&lt;Model 1&gt;\n\nmodel1 &lt;- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\ncheck_normality(model1) #diagnostic check / normality assumption test\n\nWarning: Non-normality of residuals detected (p &lt; .001).\n\n\n\ncheck_heteroscedasticity(model1)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p &lt; .001).\n\n\n\ncheck_model(model1)\n\n\n\n\n\n\n\n\nLinearity - should be a horizontal line. If not, can be affected by the outliers.\nHeteroscedasticity - good to build two models based on the observations.",
    "crumbs": [
      "![](/images/house.svg)",
      "In-class Exercise",
      "In-class_Ex5"
    ]
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05.html#gtsummary",
    "href": "In-class_Ex/In-class_Ex05.html#gtsummary",
    "title": "In-class_Ex05",
    "section": "gtsummary",
    "text": "gtsummary\n\nsummary(model1)\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10249.4   -768.6    -15.4    738.5   6356.5 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      -2.186e+03  9.722e+02  -2.248   0.0247 *  \nAge_08_04        -1.195e+02  2.760e+00 -43.292   &lt;2e-16 ***\nKM               -2.406e-02  1.201e-03 -20.042   &lt;2e-16 ***\nWeight            1.972e+01  8.379e-01  23.533   &lt;2e-16 ***\nGuarantee_Period  2.682e+01  1.261e+01   2.126   0.0336 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1413 on 1431 degrees of freedom\nMultiple R-squared:  0.8486,    Adjusted R-squared:  0.8482 \nF-statistic:  2005 on 4 and 1431 DF,  p-value: &lt; 2.2e-16\n\n\nInstead of using summary(), we can use tbl_regression(). It’s designed for regression modeling. This makes the table output professional looking.\n\nlibrary(gt)\ntbl_regression(model1,\n               intercept = TRUE) %&gt;%\n  add_glance_source_note(\n    label = list(sigma ~ \"\\U03C3\"), #  \"\\U03C3\" to extract sigma value\n    include = c(r.squared, adj.r.squared,\n                AIC, statistic, p.value, sigma)\n  ) %&gt;%\n  as_gt() %&gt;%\n  tab_options(\n    table.background.color = \"#f1f4f5\") \n\n\n\n\n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n-2,186\n-4,093, -278\n0.025\n    Age_08_04\n-119\n-125, -114\n&lt;0.001\n    KM\n-0.02\n-0.03, -0.02\n&lt;0.001\n    Weight\n20\n18, 21\n&lt;0.001\n    Guarantee_Period\n27\n2.1, 52\n0.034\n  \n  \n    \n      R² = 0.849; Adjusted R² = 0.848; AIC = 24,915; Statistic = 2,005; p-value = &lt;0.001; σ = 1,413\n    \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\n\np_model1 &lt;- parameters(model1) #save the result into p_model1; later can plot it.\n\nWe can also visualise them as a plot, instead of table form above.\n\nplot(parameters(model1)) #created by See.\n\n\n\n\n\n\n\n\nBelow gives more stats details, an improved version.\n\nggcoefstats(model1,\n            output = \"plot\"\n            ) \n\n\n\n\n\n\n\n\nTeemap requires at least: 2 categorical (hierarchy) + 2 numerical data\nSee In-class_Ex05 for Tableau visualisation.",
    "crumbs": [
      "![](/images/house.svg)",
      "In-class Exercise",
      "In-class_Ex5"
    ]
  },
  {
    "objectID": "Take-home_Ex/test.html",
    "href": "Take-home_Ex/test.html",
    "title": "Slopegraph for take-home",
    "section": "",
    "text": "devtools::install_github('rensa/ggflags')\n\nUsing GitHub PAT from the git credential store.\n\n\nSkipping install of 'ggflags' from a github remote, the SHA1 (fb6ca53f) has not changed since last install.\n  Use `force = TRUE` to force installation\n\n#load packages\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggflags) \nlibrary(countrycode) # to convert country names to country codes\nlibrary(tidytext) # for reorder_within\nlibrary(scales) # for application of common formats to scale labels (e.g., comma, percent, dollar)\n\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\n\n\n\nShow the code\nlibrary(ggplot2)\nlibrary(ggiraph)\nlibrary(dplyr)\nlibrary(tidyr)\n\n# Create sample data\ndata1 &lt;- data.frame(\n  id = LETTERS[1:5],\n  left = c(80, 65, 45, 30, 50),\n  right = c(95, 40, 70, 20, 60)\n)\n\ndata2 &lt;- data.frame(\n  id = LETTERS[1:5],\n  left = c(35, 55, 70, 40, 60),\n  right = c(75, 45, 90, 25, 50)\n)\n\n# Add graph identifiers\ndata1$graph &lt;- \"Graph 1\"\ndata2$graph &lt;- \"Graph 2\"\n\n# Combine data and convert to long format\ncombined_data &lt;- rbind(data1, data2) %&gt;%\n  pivot_longer(cols = c(left, right), \n               names_to = \"position\", \n               values_to = \"value\")\n\n# Create the plot with ggiraph\np &lt;- ggplot(combined_data, aes(x = position, y = value, group = id, color = id)) +\n  geom_line_interactive(aes(tooltip = id, data_id = id), size = 0.5) +\n  geom_point_interactive(aes(tooltip = paste0(id, \": \", value), data_id = id), size = 1) +\n  facet_wrap(~graph, scales = \"free_x\") +\n  scale_color_brewer(palette = \"Set1\") +\n  theme_minimal() +\n  labs(title = \"Interactive Slopegraphs\", x = \"\", y = \"Value\") +\n  theme(legend.position = \"none\")\n\ngirafe(ggobj = p, width_svg = 5, height_svg = 7) %&gt;%\n  girafe_options(\n    opts_sizing(rescale = FALSE),\n    opts_hover(css = \"stroke-width:3px;\"),\n    opts_hover_inv(css = \"opacity:0.2;\"),\n    opts_selection(type = \"single\", only_shiny = FALSE)\n  ) \n\n\n\n\n\n\n\nlibrary(ggplot2)\nlibrary(ggiraph)\nlibrary(dplyr)\n\n# Create data in long format\ndata1 &lt;- rbind(\n  data.frame(id = LETTERS[1:5], time = \"Start\", value = c(80, 65, 45, 30, 50), graph = \"Graph 1\"),\n  data.frame(id = LETTERS[1:5], time = \"End\", value = c(95, 40, 70, 20, 60), graph = \"Graph 1\")\n)\n\ndata2 &lt;- rbind(\n  data.frame(id = LETTERS[1:5], time = \"Start\", value = c(35, 55, 70, 40, 60), graph = \"Graph 2\"),\n  data.frame(id = LETTERS[1:5], time = \"End\", value = c(75, 45, 90, 25, 50), graph = \"Graph 2\")\n)\n\ncombined_data &lt;- rbind(data1, data2)\n\n# Create interactive plot\np &lt;- ggplot(combined_data, aes(x = time, y = value, group = id, color = id)) +\n  geom_line_interactive(aes(data_id = id), size = 1) +\n  geom_point_interactive(aes(data_id = id, tooltip = paste0(id, \": \", value)), size = 3) +\n  geom_text_interactive(data = subset(combined_data, time == \"Start\"), \n                        aes(label = id, data_id = id), hjust = 1.5) +\n  facet_wrap(~graph, scales = \"free_x\") +\n  scale_color_brewer(palette = \"Set1\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\ngirafe(ggobj = p, width_svg = 4, height_svg = 5) %&gt;%\n  girafe_options(\n        opts_sizing(rescale = FALSE),\n    opts_hover(css = \"stroke-width:3px;\"),\n    opts_hover_inv(css = \"opacity:0.2;\")\n  )\n\n\n\n\n\n\nlibrary(ggflags)\nlibrary(ggiraph)\nlibrary(ggplot2)\n\n# Add country codes to your data\ndata1$code &lt;- c(\"us\", \"ca\", \"gb\", \"de\", \"fr\")\ndata2$code &lt;- c(\"us\", \"ca\", \"gb\", \"de\", \"fr\")\ncombined_data &lt;- rbind(data1, data2)\n\n# Create interactive plot with flags\np &lt;- ggplot(combined_data, aes(x = time, y = value, group = id, color = id)) +\n  geom_line_interactive(aes(data_id = id), size = 1) +\n  geom_point_interactive(aes(data_id = id, tooltip = paste0(id, \": \", value)), size = 3) +\n  # Add country flags\n  geom_flag(data = subset(combined_data, time == \"Start\"), \n           aes(country = code), size = 5, hjust = 2.2) +\n  facet_wrap(~graph, scales = \"free_x\") +\n  scale_color_manual(values = c(\"A\" = \"red\", \"B\" = \"grey\", \"C\" = \"grey\", \n                               \"D\" = \"grey\", \"E\" = \"grey\")) +\n  theme_minimal() +\n  theme(\n    panel.grid.minor = element_blank(),  # Remove minor grid lines\n    panel.grid.major.x = element_line(color = \"skyblue\"),  # Keep light major x grid\n    panel.grid.major.y = element_line(color = \"grey70\", linetype = \"dotted\" ),\n    legend.position = \"none\",\n    plot.background = element_rect(fill = \"#f1f4f5\", color = \"#f1f4f5\"),\n    panel.background = element_rect(fill = \"#f1f4f5\", color = \"#f1f4f5\")) \n\nWarning in geom_flag(data = subset(combined_data, time == \"Start\"), aes(country\n= code), : Ignoring unknown parameters: `hjust`\n\ngirafe(ggobj = p, width_svg = 5, height_svg = 7) |&gt;\n  girafe_options(\n    opts_sizing(rescale = FALSE),\n    opts_hover(css = \"stroke-width:3px; opacity:1;\"),\n    opts_hover_inv(css = \"opacity:0.2;\")\n  )\n\n\n\n\n\n\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(stringr)\n\n\nv1_data &lt;- read_xlsx(\"data/Mtrade_commodity.xlsx\", \"T1\")\n\nNew names:\n• `` -&gt; `...1`\n• `` -&gt; `...2`\n• `` -&gt; `...3`\n• `` -&gt; `...4`\n• `` -&gt; `...5`\n• `` -&gt; `...6`\n• `` -&gt; `...7`\n• `` -&gt; `...8`\n• `` -&gt; `...9`\n• `` -&gt; `...10`\n• `` -&gt; `...11`\n• `` -&gt; `...12`\n• `` -&gt; `...13`\n• `` -&gt; `...14`\n• `` -&gt; `...15`\n• `` -&gt; `...16`\n• `` -&gt; `...17`\n• `` -&gt; `...18`\n• `` -&gt; `...19`\n• `` -&gt; `...20`\n• `` -&gt; `...21`\n• `` -&gt; `...22`\n• `` -&gt; `...23`\n• `` -&gt; `...24`\n• `` -&gt; `...25`\n• `` -&gt; `...26`\n• `` -&gt; `...27`\n• `` -&gt; `...28`\n• `` -&gt; `...29`\n• `` -&gt; `...30`\n• `` -&gt; `...31`\n• `` -&gt; `...32`\n• `` -&gt; `...33`\n• `` -&gt; `...34`\n• `` -&gt; `...35`\n• `` -&gt; `...36`\n• `` -&gt; `...37`\n• `` -&gt; `...38`\n• `` -&gt; `...39`\n• `` -&gt; `...40`\n• `` -&gt; `...41`\n• `` -&gt; `...42`\n• `` -&gt; `...43`\n• `` -&gt; `...44`\n• `` -&gt; `...45`\n• `` -&gt; `...46`\n• `` -&gt; `...47`\n• `` -&gt; `...48`\n• `` -&gt; `...49`\n• `` -&gt; `...50`\n• `` -&gt; `...51`\n• `` -&gt; `...52`\n• `` -&gt; `...53`\n• `` -&gt; `...54`\n• `` -&gt; `...55`\n• `` -&gt; `...56`\n• `` -&gt; `...57`\n• `` -&gt; `...58`\n• `` -&gt; `...59`\n• `` -&gt; `...60`\n• `` -&gt; `...61`\n• `` -&gt; `...62`\n• `` -&gt; `...63`\n• `` -&gt; `...64`\n• `` -&gt; `...65`\n• `` -&gt; `...66`\n• `` -&gt; `...67`\n• `` -&gt; `...68`\n• `` -&gt; `...69`\n• `` -&gt; `...70`\n• `` -&gt; `...71`\n• `` -&gt; `...72`\n• `` -&gt; `...73`\n• `` -&gt; `...74`\n• `` -&gt; `...75`\n• `` -&gt; `...76`\n• `` -&gt; `...77`\n• `` -&gt; `...78`\n• `` -&gt; `...79`\n• `` -&gt; `...80`\n• `` -&gt; `...81`\n• `` -&gt; `...82`\n• `` -&gt; `...83`\n• `` -&gt; `...84`\n• `` -&gt; `...85`\n• `` -&gt; `...86`\n• `` -&gt; `...87`\n• `` -&gt; `...88`\n• `` -&gt; `...89`\n• `` -&gt; `...90`\n• `` -&gt; `...91`\n• `` -&gt; `...92`\n• `` -&gt; `...93`\n• `` -&gt; `...94`\n• `` -&gt; `...95`\n• `` -&gt; `...96`\n• `` -&gt; `...97`\n• `` -&gt; `...98`\n• `` -&gt; `...99`\n• `` -&gt; `...100`\n• `` -&gt; `...101`\n• `` -&gt; `...102`\n• `` -&gt; `...103`\n• `` -&gt; `...104`\n• `` -&gt; `...105`\n• `` -&gt; `...106`\n• `` -&gt; `...107`\n• `` -&gt; `...108`\n• `` -&gt; `...109`\n• `` -&gt; `...110`\n• `` -&gt; `...111`\n• `` -&gt; `...112`\n• `` -&gt; `...113`\n• `` -&gt; `...114`\n• `` -&gt; `...115`\n• `` -&gt; `...116`\n• `` -&gt; `...117`\n• `` -&gt; `...118`\n• `` -&gt; `...119`\n• `` -&gt; `...120`\n• `` -&gt; `...121`\n• `` -&gt; `...122`\n• `` -&gt; `...123`\n• `` -&gt; `...124`\n• `` -&gt; `...125`\n• `` -&gt; `...126`\n• `` -&gt; `...127`\n• `` -&gt; `...128`\n• `` -&gt; `...129`\n• `` -&gt; `...130`\n• `` -&gt; `...131`\n• `` -&gt; `...132`\n• `` -&gt; `...133`\n• `` -&gt; `...134`\n• `` -&gt; `...135`\n• `` -&gt; `...136`\n• `` -&gt; `...137`\n• `` -&gt; `...138`\n• `` -&gt; `...139`\n• `` -&gt; `...140`\n• `` -&gt; `...141`\n• `` -&gt; `...142`\n• `` -&gt; `...143`\n• `` -&gt; `...144`\n• `` -&gt; `...145`\n• `` -&gt; `...146`\n• `` -&gt; `...147`\n• `` -&gt; `...148`\n• `` -&gt; `...149`\n• `` -&gt; `...150`\n• `` -&gt; `...151`\n• `` -&gt; `...152`\n• `` -&gt; `...153`\n• `` -&gt; `...154`\n• `` -&gt; `...155`\n• `` -&gt; `...156`\n• `` -&gt; `...157`\n• `` -&gt; `...158`\n• `` -&gt; `...159`\n• `` -&gt; `...160`\n• `` -&gt; `...161`\n• `` -&gt; `...162`\n• `` -&gt; `...163`\n• `` -&gt; `...164`\n• `` -&gt; `...165`\n• `` -&gt; `...166`\n• `` -&gt; `...167`\n• `` -&gt; `...168`\n• `` -&gt; `...169`\n• `` -&gt; `...170`\n• `` -&gt; `...171`\n• `` -&gt; `...172`\n• `` -&gt; `...173`\n• `` -&gt; `...174`\n• `` -&gt; `...175`\n• `` -&gt; `...176`\n• `` -&gt; `...177`\n• `` -&gt; `...178`\n• `` -&gt; `...179`\n• `` -&gt; `...180`\n• `` -&gt; `...181`\n• `` -&gt; `...182`\n• `` -&gt; `...183`\n• `` -&gt; `...184`\n• `` -&gt; `...185`\n• `` -&gt; `...186`\n• `` -&gt; `...187`\n• `` -&gt; `...188`\n• `` -&gt; `...189`\n• `` -&gt; `...190`\n• `` -&gt; `...191`\n• `` -&gt; `...192`\n• `` -&gt; `...193`\n• `` -&gt; `...194`\n• `` -&gt; `...195`\n• `` -&gt; `...196`\n• `` -&gt; `...197`\n• `` -&gt; `...198`\n• `` -&gt; `...199`\n• `` -&gt; `...200`\n• `` -&gt; `...201`\n• `` -&gt; `...202`\n• `` -&gt; `...203`\n• `` -&gt; `...204`\n• `` -&gt; `...205`\n• `` -&gt; `...206`\n• `` -&gt; `...207`\n• `` -&gt; `...208`\n• `` -&gt; `...209`\n• `` -&gt; `...210`\n• `` -&gt; `...211`\n• `` -&gt; `...212`\n• `` -&gt; `...213`\n• `` -&gt; `...214`\n• `` -&gt; `...215`\n• `` -&gt; `...216`\n• `` -&gt; `...217`\n• `` -&gt; `...218`\n• `` -&gt; `...219`\n• `` -&gt; `...220`\n• `` -&gt; `...221`\n• `` -&gt; `...222`\n• `` -&gt; `...223`\n• `` -&gt; `...224`\n• `` -&gt; `...225`\n• `` -&gt; `...226`\n• `` -&gt; `...227`\n• `` -&gt; `...228`\n• `` -&gt; `...229`\n• `` -&gt; `...230`\n• `` -&gt; `...231`\n• `` -&gt; `...232`\n• `` -&gt; `...233`\n• `` -&gt; `...234`\n• `` -&gt; `...235`\n• `` -&gt; `...236`\n• `` -&gt; `...237`\n• `` -&gt; `...238`\n• `` -&gt; `...239`\n• `` -&gt; `...240`\n• `` -&gt; `...241`\n• `` -&gt; `...242`\n• `` -&gt; `...243`\n• `` -&gt; `...244`\n• `` -&gt; `...245`\n• `` -&gt; `...246`\n• `` -&gt; `...247`\n• `` -&gt; `...248`\n• `` -&gt; `...249`\n• `` -&gt; `...250`\n• `` -&gt; `...251`\n• `` -&gt; `...252`\n• `` -&gt; `...253`\n• `` -&gt; `...254`\n• `` -&gt; `...255`\n• `` -&gt; `...256`\n• `` -&gt; `...257`\n• `` -&gt; `...258`\n• `` -&gt; `...259`\n• `` -&gt; `...260`\n• `` -&gt; `...261`\n• `` -&gt; `...262`\n• `` -&gt; `...263`\n• `` -&gt; `...264`\n• `` -&gt; `...265`\n• `` -&gt; `...266`\n• `` -&gt; `...267`\n• `` -&gt; `...268`\n• `` -&gt; `...269`\n• `` -&gt; `...270`\n• `` -&gt; `...271`\n• `` -&gt; `...272`\n• `` -&gt; `...273`\n• `` -&gt; `...274`\n• `` -&gt; `...275`\n• `` -&gt; `...276`\n• `` -&gt; `...277`\n• `` -&gt; `...278`\n• `` -&gt; `...279`\n• `` -&gt; `...280`\n• `` -&gt; `...281`\n• `` -&gt; `...282`\n• `` -&gt; `...283`\n• `` -&gt; `...284`\n• `` -&gt; `...285`\n• `` -&gt; `...286`\n• `` -&gt; `...287`\n• `` -&gt; `...288`\n• `` -&gt; `...289`\n• `` -&gt; `...290`\n• `` -&gt; `...291`\n• `` -&gt; `...292`\n• `` -&gt; `...293`\n• `` -&gt; `...294`\n• `` -&gt; `...295`\n• `` -&gt; `...296`\n• `` -&gt; `...297`\n• `` -&gt; `...298`\n• `` -&gt; `...299`\n• `` -&gt; `...300`\n• `` -&gt; `...301`\n• `` -&gt; `...302`\n• `` -&gt; `...303`\n• `` -&gt; `...304`\n• `` -&gt; `...305`\n• `` -&gt; `...306`\n• `` -&gt; `...307`\n• `` -&gt; `...308`\n• `` -&gt; `...309`\n• `` -&gt; `...310`\n• `` -&gt; `...311`\n• `` -&gt; `...312`\n• `` -&gt; `...313`\n• `` -&gt; `...314`\n• `` -&gt; `...315`\n• `` -&gt; `...316`\n• `` -&gt; `...317`\n• `` -&gt; `...318`\n• `` -&gt; `...319`\n• `` -&gt; `...320`\n• `` -&gt; `...321`\n• `` -&gt; `...322`\n• `` -&gt; `...323`\n• `` -&gt; `...324`\n• `` -&gt; `...325`\n• `` -&gt; `...326`\n• `` -&gt; `...327`\n• `` -&gt; `...328`\n• `` -&gt; `...329`\n• `` -&gt; `...330`\n• `` -&gt; `...331`\n• `` -&gt; `...332`\n• `` -&gt; `...333`\n• `` -&gt; `...334`\n• `` -&gt; `...335`\n• `` -&gt; `...336`\n• `` -&gt; `...337`\n• `` -&gt; `...338`\n• `` -&gt; `...339`\n• `` -&gt; `...340`\n• `` -&gt; `...341`\n• `` -&gt; `...342`\n• `` -&gt; `...343`\n• `` -&gt; `...344`\n• `` -&gt; `...345`\n• `` -&gt; `...346`\n• `` -&gt; `...347`\n• `` -&gt; `...348`\n• `` -&gt; `...349`\n• `` -&gt; `...350`\n• `` -&gt; `...351`\n• `` -&gt; `...352`\n• `` -&gt; `...353`\n• `` -&gt; `...354`\n• `` -&gt; `...355`\n• `` -&gt; `...356`\n• `` -&gt; `...357`\n• `` -&gt; `...358`\n• `` -&gt; `...359`\n• `` -&gt; `...360`\n• `` -&gt; `...361`\n• `` -&gt; `...362`\n• `` -&gt; `...363`\n• `` -&gt; `...364`\n• `` -&gt; `...365`\n• `` -&gt; `...366`\n• `` -&gt; `...367`\n• `` -&gt; `...368`\n• `` -&gt; `...369`\n• `` -&gt; `...370`\n• `` -&gt; `...371`\n• `` -&gt; `...372`\n• `` -&gt; `...373`\n• `` -&gt; `...374`\n• `` -&gt; `...375`\n• `` -&gt; `...376`\n• `` -&gt; `...377`\n• `` -&gt; `...378`\n• `` -&gt; `...379`\n• `` -&gt; `...380`\n• `` -&gt; `...381`\n• `` -&gt; `...382`\n• `` -&gt; `...383`\n• `` -&gt; `...384`\n• `` -&gt; `...385`\n• `` -&gt; `...386`\n• `` -&gt; `...387`\n• `` -&gt; `...388`\n• `` -&gt; `...389`\n• `` -&gt; `...390`\n• `` -&gt; `...391`\n• `` -&gt; `...392`\n• `` -&gt; `...393`\n• `` -&gt; `...394`\n• `` -&gt; `...395`\n• `` -&gt; `...396`\n• `` -&gt; `...397`\n• `` -&gt; `...398`\n• `` -&gt; `...399`\n• `` -&gt; `...400`\n• `` -&gt; `...401`\n• `` -&gt; `...402`\n• `` -&gt; `...403`\n• `` -&gt; `...404`\n• `` -&gt; `...405`\n• `` -&gt; `...406`\n• `` -&gt; `...407`\n• `` -&gt; `...408`\n• `` -&gt; `...409`\n• `` -&gt; `...410`\n• `` -&gt; `...411`\n• `` -&gt; `...412`\n• `` -&gt; `...413`\n• `` -&gt; `...414`\n• `` -&gt; `...415`\n• `` -&gt; `...416`\n• `` -&gt; `...417`\n• `` -&gt; `...418`\n• `` -&gt; `...419`\n• `` -&gt; `...420`\n• `` -&gt; `...421`\n• `` -&gt; `...422`\n• `` -&gt; `...423`\n• `` -&gt; `...424`\n• `` -&gt; `...425`\n• `` -&gt; `...426`\n• `` -&gt; `...427`\n• `` -&gt; `...428`\n• `` -&gt; `...429`\n• `` -&gt; `...430`\n• `` -&gt; `...431`\n• `` -&gt; `...432`\n• `` -&gt; `...433`\n• `` -&gt; `...434`\n• `` -&gt; `...435`\n• `` -&gt; `...436`\n• `` -&gt; `...437`\n• `` -&gt; `...438`\n• `` -&gt; `...439`\n• `` -&gt; `...440`\n• `` -&gt; `...441`\n• `` -&gt; `...442`\n• `` -&gt; `...443`\n• `` -&gt; `...444`\n• `` -&gt; `...445`\n• `` -&gt; `...446`\n• `` -&gt; `...447`\n• `` -&gt; `...448`\n• `` -&gt; `...449`\n• `` -&gt; `...450`\n• `` -&gt; `...451`\n• `` -&gt; `...452`\n• `` -&gt; `...453`\n• `` -&gt; `...454`\n• `` -&gt; `...455`\n• `` -&gt; `...456`\n• `` -&gt; `...457`\n• `` -&gt; `...458`\n• `` -&gt; `...459`\n• `` -&gt; `...460`\n• `` -&gt; `...461`\n• `` -&gt; `...462`\n• `` -&gt; `...463`\n• `` -&gt; `...464`\n• `` -&gt; `...465`\n• `` -&gt; `...466`\n• `` -&gt; `...467`\n• `` -&gt; `...468`\n• `` -&gt; `...469`\n• `` -&gt; `...470`\n• `` -&gt; `...471`\n• `` -&gt; `...472`\n• `` -&gt; `...473`\n• `` -&gt; `...474`\n• `` -&gt; `...475`\n• `` -&gt; `...476`\n• `` -&gt; `...477`\n• `` -&gt; `...478`\n• `` -&gt; `...479`\n• `` -&gt; `...480`\n• `` -&gt; `...481`\n• `` -&gt; `...482`\n• `` -&gt; `...483`\n• `` -&gt; `...484`\n• `` -&gt; `...485`\n• `` -&gt; `...486`\n• `` -&gt; `...487`\n• `` -&gt; `...488`\n• `` -&gt; `...489`\n• `` -&gt; `...490`\n• `` -&gt; `...491`\n• `` -&gt; `...492`\n• `` -&gt; `...493`\n• `` -&gt; `...494`\n• `` -&gt; `...495`\n• `` -&gt; `...496`\n• `` -&gt; `...497`\n• `` -&gt; `...498`\n• `` -&gt; `...499`\n• `` -&gt; `...500`\n• `` -&gt; `...501`\n• `` -&gt; `...502`\n• `` -&gt; `...503`\n• `` -&gt; `...504`\n• `` -&gt; `...505`\n• `` -&gt; `...506`\n• `` -&gt; `...507`\n• `` -&gt; `...508`\n• `` -&gt; `...509`\n• `` -&gt; `...510`\n• `` -&gt; `...511`\n• `` -&gt; `...512`\n• `` -&gt; `...513`\n• `` -&gt; `...514`\n• `` -&gt; `...515`\n• `` -&gt; `...516`\n• `` -&gt; `...517`\n• `` -&gt; `...518`\n• `` -&gt; `...519`\n• `` -&gt; `...520`\n• `` -&gt; `...521`\n• `` -&gt; `...522`\n• `` -&gt; `...523`\n• `` -&gt; `...524`\n• `` -&gt; `...525`\n• `` -&gt; `...526`\n• `` -&gt; `...527`\n• `` -&gt; `...528`\n• `` -&gt; `...529`\n• `` -&gt; `...530`\n• `` -&gt; `...531`\n• `` -&gt; `...532`\n• `` -&gt; `...533`\n• `` -&gt; `...534`\n• `` -&gt; `...535`\n• `` -&gt; `...536`\n• `` -&gt; `...537`\n• `` -&gt; `...538`\n• `` -&gt; `...539`\n• `` -&gt; `...540`\n• `` -&gt; `...541`\n• `` -&gt; `...542`\n• `` -&gt; `...543`\n• `` -&gt; `...544`\n• `` -&gt; `...545`\n• `` -&gt; `...546`\n• `` -&gt; `...547`\n• `` -&gt; `...548`\n• `` -&gt; `...549`\n• `` -&gt; `...550`\n• `` -&gt; `...551`\n• `` -&gt; `...552`\n• `` -&gt; `...553`\n• `` -&gt; `...554`\n• `` -&gt; `...555`\n• `` -&gt; `...556`\n• `` -&gt; `...557`\n• `` -&gt; `...558`\n• `` -&gt; `...559`\n• `` -&gt; `...560`\n• `` -&gt; `...561`\n• `` -&gt; `...562`\n• `` -&gt; `...563`\n• `` -&gt; `...564`\n• `` -&gt; `...565`\n• `` -&gt; `...566`\n• `` -&gt; `...567`\n• `` -&gt; `...568`\n• `` -&gt; `...569`\n• `` -&gt; `...570`\n• `` -&gt; `...571`\n• `` -&gt; `...572`\n• `` -&gt; `...573`\n• `` -&gt; `...574`\n• `` -&gt; `...575`\n• `` -&gt; `...576`\n• `` -&gt; `...577`\n• `` -&gt; `...578`\n• `` -&gt; `...579`\n• `` -&gt; `...580`\n• `` -&gt; `...581`\n• `` -&gt; `...582`\n• `` -&gt; `...583`\n• `` -&gt; `...584`\n• `` -&gt; `...585`\n• `` -&gt; `...586`\n• `` -&gt; `...587`\n• `` -&gt; `...588`\n• `` -&gt; `...589`\n• `` -&gt; `...590`\n• `` -&gt; `...591`\n• `` -&gt; `...592`\n• `` -&gt; `...593`\n• `` -&gt; `...594`\n• `` -&gt; `...595`\n• `` -&gt; `...596`\n• `` -&gt; `...597`\n• `` -&gt; `...598`\n• `` -&gt; `...599`\n• `` -&gt; `...600`\n• `` -&gt; `...601`\n• `` -&gt; `...602`\n• `` -&gt; `...603`\n• `` -&gt; `...604`\n• `` -&gt; `...605`\n• `` -&gt; `...606`\n• `` -&gt; `...607`\n• `` -&gt; `...608`\n• `` -&gt; `...609`\n• `` -&gt; `...610`\n• `` -&gt; `...611`\n• `` -&gt; `...612`\n• `` -&gt; `...613`\n• `` -&gt; `...614`\n• `` -&gt; `...615`\n• `` -&gt; `...616`\n• `` -&gt; `...617`\n• `` -&gt; `...618`\n• `` -&gt; `...619`\n• `` -&gt; `...620`\n• `` -&gt; `...621`\n• `` -&gt; `...622`\n• `` -&gt; `...623`\n• `` -&gt; `...624`\n• `` -&gt; `...625`\n• `` -&gt; `...626`\n• `` -&gt; `...627`\n• `` -&gt; `...628`\n• `` -&gt; `...629`\n• `` -&gt; `...630`\n• `` -&gt; `...631`\n• `` -&gt; `...632`\n• `` -&gt; `...633`\n• `` -&gt; `...634`\n• `` -&gt; `...635`\n• `` -&gt; `...636`\n• `` -&gt; `...637`\n• `` -&gt; `...638`\n• `` -&gt; `...639`\n• `` -&gt; `...640`\n• `` -&gt; `...641`\n• `` -&gt; `...642`\n• `` -&gt; `...643`\n• `` -&gt; `...644`\n• `` -&gt; `...645`\n• `` -&gt; `...646`\n• `` -&gt; `...647`\n• `` -&gt; `...648`\n• `` -&gt; `...649`\n• `` -&gt; `...650`\n• `` -&gt; `...651`\n• `` -&gt; `...652`\n• `` -&gt; `...653`\n• `` -&gt; `...654`\n• `` -&gt; `...655`\n• `` -&gt; `...656`\n• `` -&gt; `...657`\n• `` -&gt; `...658`\n• `` -&gt; `...659`\n• `` -&gt; `...660`\n• `` -&gt; `...661`\n• `` -&gt; `...662`\n• `` -&gt; `...663`\n• `` -&gt; `...664`\n• `` -&gt; `...665`\n• `` -&gt; `...666`\n• `` -&gt; `...667`\n• `` -&gt; `...668`\n• `` -&gt; `...669`\n• `` -&gt; `...670`\n• `` -&gt; `...671`\n• `` -&gt; `...672`\n• `` -&gt; `...673`\n• `` -&gt; `...674`\n• `` -&gt; `...675`\n• `` -&gt; `...676`\n• `` -&gt; `...677`\n• `` -&gt; `...678`\n• `` -&gt; `...679`\n• `` -&gt; `...680`\n• `` -&gt; `...681`\n• `` -&gt; `...682`\n• `` -&gt; `...683`\n• `` -&gt; `...684`\n• `` -&gt; `...685`\n• `` -&gt; `...686`\n• `` -&gt; `...687`\n• `` -&gt; `...688`\n• `` -&gt; `...689`\n• `` -&gt; `...690`\n• `` -&gt; `...691`\n• `` -&gt; `...692`\n• `` -&gt; `...693`\n• `` -&gt; `...694`\n• `` -&gt; `...695`\n• `` -&gt; `...696`\n• `` -&gt; `...697`\n• `` -&gt; `...698`\n• `` -&gt; `...699`\n• `` -&gt; `...700`\n• `` -&gt; `...701`\n• `` -&gt; `...702`\n• `` -&gt; `...703`\n• `` -&gt; `...704`\n• `` -&gt; `...705`\n• `` -&gt; `...706`\n• `` -&gt; `...707`\n• `` -&gt; `...708`\n• `` -&gt; `...709`\n• `` -&gt; `...710`\n• `` -&gt; `...711`\n• `` -&gt; `...712`\n• `` -&gt; `...713`\n• `` -&gt; `...714`\n• `` -&gt; `...715`\n• `` -&gt; `...716`\n• `` -&gt; `...717`\n• `` -&gt; `...718`\n• `` -&gt; `...719`\n• `` -&gt; `...720`\n• `` -&gt; `...721`\n• `` -&gt; `...722`\n• `` -&gt; `...723`\n• `` -&gt; `...724`\n• `` -&gt; `...725`\n• `` -&gt; `...726`\n• `` -&gt; `...727`\n• `` -&gt; `...728`\n• `` -&gt; `...729`\n• `` -&gt; `...730`\n• `` -&gt; `...731`\n• `` -&gt; `...732`\n• `` -&gt; `...733`\n• `` -&gt; `...734`\n\nhead(v1_data)\n\n# A tibble: 6 × 734\n  ...1   ...2  ...3  ...4  ...5  ...6  ...7  ...8  ...9  ...10 ...11 ...12 ...13\n  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n1 Theme… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n2 Subje… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n3 Topic… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n4 Table… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n5 &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n6 Data … Chec… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n# ℹ 721 more variables: ...14 &lt;chr&gt;, ...15 &lt;chr&gt;, ...16 &lt;chr&gt;, ...17 &lt;chr&gt;,\n#   ...18 &lt;chr&gt;, ...19 &lt;chr&gt;, ...20 &lt;chr&gt;, ...21 &lt;chr&gt;, ...22 &lt;chr&gt;,\n#   ...23 &lt;chr&gt;, ...24 &lt;chr&gt;, ...25 &lt;chr&gt;, ...26 &lt;chr&gt;, ...27 &lt;chr&gt;,\n#   ...28 &lt;chr&gt;, ...29 &lt;chr&gt;, ...30 &lt;chr&gt;, ...31 &lt;chr&gt;, ...32 &lt;chr&gt;,\n#   ...33 &lt;chr&gt;, ...34 &lt;chr&gt;, ...35 &lt;chr&gt;, ...36 &lt;chr&gt;, ...37 &lt;chr&gt;,\n#   ...38 &lt;chr&gt;, ...39 &lt;chr&gt;, ...40 &lt;chr&gt;, ...41 &lt;chr&gt;, ...42 &lt;chr&gt;,\n#   ...43 &lt;chr&gt;, ...44 &lt;chr&gt;, ...45 &lt;chr&gt;, ...46 &lt;chr&gt;, ...47 &lt;chr&gt;, …\n\nv1_subset &lt;- v1_data[c(10, 11),]\n\n\n\nShow the code\nv1_trans_matrix &lt;- t(v1_subset) #after transpose, the data is a matrix.\nv1_trans &lt;- as.data.frame(v1_trans_matrix) #now convert the matrix to df.\n\n# Correct the column name\nreal_column_names &lt;- as.character(v1_trans[1, ])\ncolnames(v1_trans) &lt;- real_column_names\n\n# remove the first row\nv1_trans &lt;- v1_trans[-1, ]\n\n# Extract year first\nv1_trans$Year &lt;- substr(v1_trans$`Data Series`, 1, 4)\nprint(v1_trans)\n\n\n       Data Series Total Merchandise Trade, (At Current Prices) Year\n...2      2025 Jan                                  114153979.9 2025\n...3      2024 Dec                                  116278793.1 2024\n...4      2024 Nov                                  110132324.5 2024\n...5      2024 Oct                                  107525959.8 2024\n...6      2024 Sep                                  103512459.9 2024\n...7      2024 Aug                                  105709528.1 2024\n...8      2024 Jul                                  112193161.2 2024\n...9      2024 Jun                                  100854308.9 2024\n...10     2024 May                                  109494399.7 2024\n...11     2024 Apr                                  108724422.7 2024\n...12     2024 Mar                                  108379073.7 2024\n...13     2024 Feb                                   96121143.1 2024\n...14     2024 Jan                                  106938892.7 2024\n...15     2023 Dec                                   97730166.2 2023\n...16     2023 Nov                                  104964764.1 2023\n...17     2023 Oct                                  109959513.4 2023\n...18     2023 Sep                                  103395782.6 2023\n...19     2023 Aug                                  102822761.5 2023\n...20     2023 Jul                                   98876159.7 2023\n...21     2023 Jun                                   99800672.3 2023\n...22     2023 May                                     96292627 2023\n...23     2023 Apr                                   94275864.7 2023\n...24     2023 Mar                                  110665037.4 2023\n...25     2023 Feb                                   93025120.2 2023\n...26     2023 Jan                                   93914081.9 2023\n...27     2022 Dec                                    104869854 2022\n...28     2022 Nov                                  104816687.4 2022\n...29     2022 Oct                                  109759290.9 2022\n...30     2022 Sep                                    118306444 2022\n...31     2022 Aug                                  121829757.2 2022\n...32     2022 Jul                                  125154364.8 2022\n...33     2022 Jun                                  123826212.3 2022\n...34     2022 May                                  117451686.9 2022\n...35     2022 Apr                                  116353344.9 2022\n...36     2022 Mar                                  121212560.9 2022\n...37     2022 Feb                                   96949830.4 2022\n...38     2022 Jan                                  104872484.8 2022\n...39     2021 Dec                                  113563150.5 2021\n...40     2021 Nov                                  107395038.7 2021\n...41     2021 Oct                                  101584554.8 2021\n...42     2021 Sep                                   98014412.4 2021\n...43     2021 Aug                                     96753013 2021\n...44     2021 Jul                                   95941798.1 2021\n...45     2021 Jun                                   94658839.2 2021\n...46     2021 May                                   88914921.6 2021\n...47     2021 Apr                                   95761442.6 2021\n...48     2021 Mar                                  103112519.2 2021\n...49     2021 Feb                                   80245891.3 2021\n...50     2021 Jan                                   84017449.2 2021\n...51     2020 Dec                                     86401426 2020\n...52     2020 Nov                                   81769816.3 2020\n...53     2020 Oct                                   82262179.1 2020\n...54     2020 Sep                                     82708848 2020\n...55     2020 Aug                                   80805918.9 2020\n...56     2020 Jul                                   80736330.3 2020\n...57     2020 Jun                                   75761657.7 2020\n...58     2020 May                                   67940497.1 2020\n...59     2020 Apr                                   75825423.9 2020\n...60     2020 Mar                                   86233047.8 2020\n...61     2020 Feb                                     82984957 2020\n...62     2020 Jan                                   85681880.8 2020\n...63     2019 Dec                                   86644318.8 2019\n...64     2019 Nov                                   88248629.3 2019\n...65     2019 Oct                                   89111010.5 2019\n...66     2019 Sep                                   82944944.7 2019\n...67     2019 Aug                                   86156104.5 2019\n...68     2019 Jul                                   87420995.7 2019\n...69     2019 Jun                                   80403917.6 2019\n...70     2019 May                                   89269126.2 2019\n...71     2019 Apr                                   85433686.5 2019\n...72     2019 Mar                                     84572200 2019\n...73     2019 Feb                                   75937043.3 2019\n...74     2019 Jan                                   86084504.8 2019\n...75     2018 Dec                                   86058910.3 2018\n...76     2018 Nov                                   93814550.4 2018\n...77     2018 Oct                                   98783433.4 2018\n...78     2018 Sep                                   87289929.6 2018\n...79     2018 Aug                                   94250763.9 2018\n...80     2018 Jul                                   93279293.5 2018\n...81     2018 Jun                                   86748323.6 2018\n...82     2018 May                                   91247498.4 2018\n...83     2018 Apr                                   82874846.6 2018\n...84     2018 Mar                                   85347638.7 2018\n...85     2018 Feb                                     73545913 2018\n...86     2018 Jan                                   82618004.4 2018\n...87     2017 Dec                                   84697494.7 2017\n...88     2017 Nov                                   87363139.7 2017\n...89     2017 Oct                                   83086700.1 2017\n...90     2017 Sep                                   76911014.7 2017\n...91     2017 Aug                                   83167698.8 2017\n...92     2017 Jul                                   79504111.4 2017\n...93     2017 Jun                                   78740858.7 2017\n...94     2017 May                                   83094746.9 2017\n...95     2017 Apr                                   74973091.6 2017\n...96     2017 Mar                                     86060240 2017\n...97     2017 Feb                                   72372935.7 2017\n...98     2017 Jan                                   77130382.4 2017\n...99     2016 Dec                                   83794770.7 2016\n...100    2016 Nov                                   79372049.5 2016\n...101    2016 Oct                                   73575640.3 2016\n...102    2016 Sep                                   72450494.6 2016\n...103    2016 Aug                                     72155962 2016\n...104    2016 Jul                                   70069579.1 2016\n...105    2016 Jun                                   73370914.2 2016\n...106    2016 May                                   71830063.6 2016\n...107    2016 Apr                                   71014960.5 2016\n...108    2016 Mar                                   72481976.9 2016\n...109    2016 Feb                                   63342636.3 2016\n...110    2016 Jan                                   66757163.4 2016\n...111    2015 Dec                                   75472970.5 2015\n...112    2015 Nov                                   72782687.7 2015\n...113    2015 Oct                                   79471169.3 2015\n...114    2015 Sep                                   75845721.2 2015\n...115    2015 Aug                                   73760090.3 2015\n...116    2015 Jul                                   80314624.8 2015\n...117    2015 Jun                                   77939565.4 2015\n...118    2015 May                                   72991940.3 2015\n...119    2015 Apr                                   79096446.2 2015\n...120    2015 Mar                                   85166186.1 2015\n...121    2015 Feb                                   64476544.2 2015\n...122    2015 Jan                                   77900845.3 2015\n...123    2014 Dec                                     80529402 2014\n...124    2014 Nov                                   77414200.7 2014\n...125    2014 Oct                                   86236478.1 2014\n...126    2014 Sep                                   85831628.1 2014\n...127    2014 Aug                                   80280884.5 2014\n...128    2014 Jul                                   84410904.3 2014\n...129    2014 Jun                                   81821835.1 2014\n...130    2014 May                                   85571038.1 2014\n...131    2014 Apr                                   89000350.8 2014\n...132    2014 Mar                                   89094505.9 2014\n...133    2014 Feb                                   78349170.8 2014\n...134    2014 Jan                                   86109609.4 2014\n...135    2013 Dec                                     81200008 2013\n...136    2013 Nov                                   82011098.6 2013\n...137    2013 Oct                                     92787692 2013\n...138    2013 Sep                                   86777870.7 2013\n...139    2013 Aug                                   84320793.5 2013\n...140    2013 Jul                                   90009610.8 2013\n...141    2013 Jun                                   82677399.9 2013\n...142    2013 May                                   87712430.7 2013\n...143    2013 Apr                                   87749589.3 2013\n...144    2013 Mar                                   80374024.3 2013\n...145    2013 Feb                                     72915521 2013\n...146    2013 Jan                                   82541864.9 2013\n...147    2012 Dec                                   77025317.8 2012\n...148    2012 Nov                                   82566343.6 2012\n...149    2012 Oct                                   85517037.3 2012\n...150    2012 Sep                                   79724773.8 2012\n...151    2012 Aug                                   80477594.7 2012\n...152    2012 Jul                                     81505716 2012\n...153    2012 Jun                                   85050940.9 2012\n...154    2012 May                                   87356484.1 2012\n...155    2012 Apr                                   84516566.8 2012\n...156    2012 Mar                                   89820321.3 2012\n...157    2012 Feb                                   85882277.9 2012\n...158    2012 Jan                                   82100595.1 2012\n...159    2011 Dec                                   83853527.9 2011\n...160    2011 Nov                                   85068675.9 2011\n...161    2011 Oct                                   84146679.4 2011\n...162    2011 Sep                                   84307189.4 2011\n...163    2011 Aug                                   87336076.5 2011\n...164    2011 Jul                                   79908645.1 2011\n...165    2011 Jun                                   83057330.8 2011\n...166    2011 May                                   82396879.4 2011\n...167    2011 Apr                                   81282034.2 2011\n...168    2011 Mar                                   89761340.1 2011\n...169    2011 Feb                                     69089869 2011\n...170    2011 Jan                                   81350559.3 2011\n...171    2010 Dec                                   77966152.5 2010\n...172    2010 Nov                                   75568476.6 2010\n...173    2010 Oct                                     78325836 2010\n...174    2010 Sep                                     77178033 2010\n...175    2010 Aug                                   79150240.7 2010\n...176    2010 Jul                                   79676629.1 2010\n...177    2010 Jun                                   78694903.3 2010\n...178    2010 May                                   72205358.8 2010\n...179    2010 Apr                                   77364598.8 2010\n...180    2010 Mar                                   77368439.8 2010\n...181    2010 Feb                                   63856067.1 2010\n...182    2010 Jan                                   69681291.3 2010\n...183    2009 Dec                                   71029541.6 2009\n...184    2009 Nov                                   67108157.6 2009\n...185    2009 Oct                                   68414179.7 2009\n...186    2009 Sep                                   68456728.5 2009\n...187    2009 Aug                                   64307849.4 2009\n...188    2009 Jul                                   66963504.1 2009\n...189    2009 Jun                                   61952063.4 2009\n...190    2009 May                                   57938152.1 2009\n...191    2009 Apr                                   59246226.4 2009\n...192    2009 Mar                                   59528603.3 2009\n...193    2009 Feb                                   54165921.4 2009\n...194    2009 Jan                                   52189843.3 2009\n...195    2008 Dec                                   59211487.9 2008\n...196    2008 Nov                                     67148353 2008\n...197    2008 Oct                                   78459916.4 2008\n...198    2008 Sep                                   85240482.8 2008\n...199    2008 Aug                                   81399600.3 2008\n...200    2008 Jul                                   88744688.6 2008\n...201    2008 Jun                                   83194163.9 2008\n...202    2008 May                                   79559914.9 2008\n...203    2008 Apr                                   83071447.7 2008\n...204    2008 Mar                                     79079467 2008\n...205    2008 Feb                                   69842221.4 2008\n...206    2008 Jan                                   81363940.9 2008\n...207    2007 Dec                                   72788487.2 2007\n...208    2007 Nov                                   75063525.9 2007\n...209    2007 Oct                                   78189401.5 2007\n...210    2007 Sep                                   71929205.2 2007\n...211    2007 Aug                                   72833825.3 2007\n...212    2007 Jul                                   73669127.1 2007\n...213    2007 Jun                                   72476997.6 2007\n...214    2007 May                                   68746903.3 2007\n...215    2007 Apr                                   68387572.3 2007\n...216    2007 Mar                                   71254516.6 2007\n...217    2007 Feb                                   58789691.4 2007\n...218    2007 Jan                                   68361570.6 2007\n...219    2006 Dec                                   68954969.8 2006\n...220    2006 Nov                                   69294697.5 2006\n...221    2006 Oct                                   68077663.5 2006\n...222    2006 Sep                                   71451021.8 2006\n...223    2006 Aug                                   72219142.2 2006\n...224    2006 Jul                                   69368770.5 2006\n...225    2006 Jun                                     71752930 2006\n...226    2006 May                                   68624261.8 2006\n...227    2006 Apr                                   62986337.8 2006\n...228    2006 Mar                                   69234700.5 2006\n...229    2006 Feb                                   62940701.9 2006\n...230    2006 Jan                                   59993900.3 2006\n...231    2005 Dec                                   67847663.9 2005\n...232    2005 Nov                                   63761309.4 2005\n...233    2005 Oct                                   67877583.9 2005\n...234    2005 Sep                                     63386556 2005\n...235    2005 Aug                                   63943439.9 2005\n...236    2005 Jul                                     59649731 2005\n...237    2005 Jun                                   59158726.2 2005\n...238    2005 May                                   56773896.3 2005\n...239    2005 Apr                                   56558394.8 2005\n...240    2005 Mar                                   59642108.4 2005\n...241    2005 Feb                                     46908115 2005\n...242    2005 Jan                                   52489280.4 2005\n...243    2004 Dec                                   55568760.6 2004\n...244    2004 Nov                                   53278515.2 2004\n...245    2004 Oct                                   56763878.5 2004\n...246    2004 Sep                                   56673275.2 2004\n...247    2004 Aug                                     54551785 2004\n...248    2004 Jul                                   55788184.1 2004\n...249    2004 Jun                                   53492814.7 2004\n...250    2004 May                                   51759425.7 2004\n...251    2004 Apr                                   50906345.4 2004\n...252    2004 Mar                                     53069273 2004\n...253    2004 Feb                                   44463508.5 2004\n...254    2004 Jan                                   44638368.7 2004\n...255    2003 Dec                                   48554997.7 2003\n...256    2003 Nov                                   43802442.5 2003\n...257    2003 Oct                                   48229423.3 2003\n...258    2003 Sep                                   45816601.9 2003\n...259    2003 Aug                                   42299447.4 2003\n...260    2003 Jul                                   43360466.4 2003\n...261    2003 Jun                                   42077944.4 2003\n...262    2003 May                                   40162535.8 2003\n...263    2003 Apr                                   42072883.2 2003\n...264    2003 Mar                                   43860167.9 2003\n...265    2003 Feb                                   36993870.9 2003\n...266    2003 Jan                                   41986698.9 2003\n...267    2002 Dec                                   35684824.8 2002\n...268    2002 Nov                                   38120539.9 2002\n...269    2002 Oct                                   39326285.3 2002\n...270    2002 Sep                                   35904949.8 2002\n...271    2002 Aug                                     37787583 2002\n...272    2002 Jul                                   38629707.1 2002\n...273    2002 Jun                                   36890597.7 2002\n...274    2002 May                                     36244503 2002\n...275    2002 Apr                                     37718249 2002\n...276    2002 Mar                                   35995455.7 2002\n...277    2002 Feb                                   29527038.2 2002\n...278    2002 Jan                                   33818023.3 2002\n...279    2001 Dec                                   32253624.2 2001\n...280    2001 Nov                                   34625528.7 2001\n...281    2001 Oct                                   37008944.9 2001\n...282    2001 Sep                                   32827412.9 2001\n...283    2001 Aug                                   34943647.4 2001\n...284    2001 Jul                                   34880396.6 2001\n...285    2001 Jun                                   35971403.7 2001\n...286    2001 May                                   35826204.1 2001\n...287    2001 Apr                                   35548433.9 2001\n...288    2001 Mar                                   39548517.5 2001\n...289    2001 Feb                                   36045003.3 2001\n...290    2001 Jan                                   36239283.3 2001\n...291    2000 Dec                                   41782301.1 2000\n...292    2000 Nov                                   43003500.4 2000\n...293    2000 Oct                                   44263702.1 2000\n...294    2000 Sep                                   42916026.1 2000\n...295    2000 Aug                                   42880027.8 2000\n...296    2000 Jul                                   40186659.3 2000\n...297    2000 Jun                                   39739278.5 2000\n...298    2000 May                                   38407734.5 2000\n...299    2000 Apr                                   35025776.7 2000\n...300    2000 Mar                                   38546733.9 2000\n...301    2000 Feb                                   31757734.3 2000\n...302    2000 Jan                                     31491949 2000\n...303    1999 Dec                                   36936214.6 1999\n...304    1999 Nov                                   35331910.5 1999\n...305    1999 Oct                                   34742341.1 1999\n...306    1999 Sep                                   34069719.6 1999\n...307    1999 Aug                                   32465146.8 1999\n...308    1999 Jul                                   32852660.8 1999\n...309    1999 Jun                                   32105547.7 1999\n...310    1999 May                                   30475820.5 1999\n...311    1999 Apr                                     31163897 1999\n...312    1999 Mar                                   31485379.3 1999\n...313    1999 Feb                                   24494581.9 1999\n...314    1999 Jan                                   26307956.1 1999\n...315    1998 Dec                                     29379108 1998\n...316    1998 Nov                                     27602867 1998\n...317    1998 Oct                                     28935515 1998\n...318    1998 Sep                                     30403223 1998\n...319    1998 Aug                                     29295320 1998\n...320    1998 Jul                                     30368195 1998\n...321    1998 Jun                                     30387660 1998\n...322    1998 May                                     27269816 1998\n...323    1998 Apr                                     29115338 1998\n...324    1998 Mar                                     33013823 1998\n...325    1998 Feb                                     29530419 1998\n...326    1998 Jan                                     28325521 1998\n...327    1997 Dec                                     34284272 1997\n...328    1997 Nov                                     32817829 1997\n...329    1997 Oct                                     34523630 1997\n...330    1997 Sep                                     34349004 1997\n...331    1997 Aug                                     31479244 1997\n...332    1997 Jul                                     33460102 1997\n...333    1997 Jun                                     30998743 1997\n...334    1997 May                                     31678874 1997\n...335    1997 Apr                                     31353836 1997\n...336    1997 Mar                                     32204410 1997\n...337    1997 Feb                                     24217362 1997\n...338    1997 Jan                                     30850383 1997\n...339    1996 Dec                                     31043702 1996\n...340    1996 Nov                                     30692970 1996\n...341    1996 Oct                                     32025621 1996\n...342    1996 Sep                                     29425608 1996\n...343    1996 Aug                                     28635705 1996\n...344    1996 Jul                                     30826321 1996\n...345    1996 Jun                                     29152742 1996\n...346    1996 May                                     30061642 1996\n...347    1996 Apr                                     30108289 1996\n...348    1996 Mar                                     32076758 1996\n...349    1996 Feb                                     26562292 1996\n...350    1996 Jan                                     30843672 1996\n...351    1995 Dec                                     30189911 1995\n...352    1995 Nov                                     31194891 1995\n...353    1995 Oct                                     31039678 1995\n...354    1995 Sep                                     29665051 1995\n...355    1995 Aug                                     30652877 1995\n...356    1995 Jul                                     29625194 1995\n...357    1995 Jun                                     29092975 1995\n...358    1995 May                                     28700250 1995\n...359    1995 Apr                                     26384942 1995\n...360    1995 Mar                                     28768453 1995\n...361    1995 Feb                                     23957862 1995\n...362    1995 Jan                                     24556086 1995\n...363    1994 Dec                                     27307893 1994\n...364    1994 Nov                                     26727765 1994\n...365    1994 Oct                                     26893921 1994\n...366    1994 Sep                                     27321176 1994\n...367    1994 Aug                                     27022867 1994\n...368    1994 Jul                                     26053223 1994\n...369    1994 Jun                                     26321588 1994\n...370    1994 May                                     25342975 1994\n...371    1994 Apr                                     25820372 1994\n...372    1994 Mar                                     23984139 1994\n...373    1994 Feb                                     18827899 1994\n...374    1994 Jan                                     22099165 1994\n...375    1993 Dec                                     23293955 1993\n...376    1993 Nov                                     21972021 1993\n...377    1993 Oct                                     21878085 1993\n...378    1993 Sep                                     23359027 1993\n...379    1993 Aug                                     21050175 1993\n...380    1993 Jul                                     22276134 1993\n...381    1993 Jun                                     21695902 1993\n...382    1993 May                                     21076420 1993\n...383    1993 Apr                                     21870039 1993\n...384    1993 Mar                                     22019533 1993\n...385    1993 Feb                                     18987631 1993\n...386    1993 Jan                                     17597466 1993\n...387    1992 Dec                                     21928057 1992\n...388    1992 Nov                                     19764917 1992\n...389    1992 Oct                                     19530943 1992\n...390    1992 Sep                                     18832282 1992\n...391    1992 Aug                                     17682603 1992\n...392    1992 Jul                                     19303469 1992\n...393    1992 Jun                                     19061391 1992\n...394    1992 May                                     16834013 1992\n...395    1992 Apr                                     17190434 1992\n...396    1992 Mar                                     18472025 1992\n...397    1992 Feb                                     15087414 1992\n...398    1992 Jan                                     17193165 1992\n...399    1991 Dec                                     16971151 1991\n...400    1991 Nov                                     17569101 1991\n...401    1991 Oct                                     17874179 1991\n...402    1991 Sep                                     17375152 1991\n...403    1991 Aug                                     17997204 1991\n...404    1991 Jul                                     19520375 1991\n...405    1991 Jun                                     18670555 1991\n...406    1991 May                                     18095221 1991\n...407    1991 Apr                                     17513364 1991\n...408    1991 Mar                                     18523113 1991\n...409    1991 Feb                                     16552644 1991\n...410    1991 Jan                                     19412377 1991\n...411    1990 Dec                                     18804435 1990\n...412    1990 Nov                                     18976108 1990\n...413    1990 Oct                                     19484208 1990\n...414    1990 Sep                                     16682825 1990\n...415    1990 Aug                                     17113546 1990\n...416    1990 Jul                                     16464565 1990\n...417    1990 Jun                                     16573325 1990\n...418    1990 May                                     16569564 1990\n...419    1990 Apr                                     15579206 1990\n...420    1990 Mar                                     17835810 1990\n...421    1990 Feb                                     14979340 1990\n...422    1990 Jan                                     15948701 1990\n...423    1989 Dec                                     16406934 1989\n...424    1989 Nov                                     16670958 1989\n...425    1989 Oct                                     16409717 1989\n...426    1989 Sep                                     16222652 1989\n...427    1989 Aug                                     16466064 1989\n...428    1989 Jul                                     14632640 1989\n...429    1989 Jun                                     15432765 1989\n...430    1989 May                                     15031724 1989\n...431    1989 Apr                                     15562849 1989\n...432    1989 Mar                                     15913503 1989\n...433    1989 Feb                                     12584527 1989\n...434    1989 Jan                                     12645836 1989\n...435    1988 Dec                                     15866441 1988\n...436    1988 Nov                                     14613743 1988\n...437    1988 Oct                                     15726208 1988\n...438    1988 Sep                                     14249424 1988\n...439    1988 Aug                                     14995639 1988\n...440    1988 Jul                                     14385386 1988\n...441    1988 Jun                                     14976565 1988\n...442    1988 May                                     13173838 1988\n...443    1988 Apr                                     13036559 1988\n...444    1988 Mar                                     11763728 1988\n...445    1988 Feb                                     12253885 1988\n...446    1988 Jan                                     12236559 1988\n...447    1987 Dec                                     12552949 1987\n...448    1987 Nov                                     12440399 1987\n...449    1987 Oct                                     11663744 1987\n...450    1987 Sep                                     12097303 1987\n...451    1987 Aug                                     10591657 1987\n...452    1987 Jul                                     11378341 1987\n...453    1987 Jun                                     10448346 1987\n...454    1987 May                                      9875454 1987\n...455    1987 Apr                                     10616755 1987\n...456    1987 Mar                                      9012296 1987\n...457    1987 Feb                                      8969979 1987\n...458    1987 Jan                                      9033736 1987\n...459    1986 Dec                                      9542443 1986\n...460    1986 Nov                                      9118847 1986\n...461    1986 Oct                                      9113454 1986\n...462    1986 Sep                                      8701368 1986\n...463    1986 Aug                                      9032949 1986\n...464    1986 Jul                                      8481929 1986\n...465    1986 Jun                                      8617548 1986\n...466    1986 May                                      8107353 1986\n...467    1986 Apr                                      8988669 1986\n...468    1986 Mar                                      8428895 1986\n...469    1986 Feb                                      8204219 1986\n...470    1986 Jan                                      8193201 1986\n...471    1985 Dec                                      8360460 1985\n...472    1985 Nov                                      8757073 1985\n...473    1985 Oct                                      9071069 1985\n...474    1985 Sep                                      8581385 1985\n...475    1985 Aug                                      8941592 1985\n...476    1985 Jul                                      8349893 1985\n...477    1985 Jun                                      8865169 1985\n...478    1985 May                                      8902682 1985\n...479    1985 Apr                                      9812541 1985\n...480    1985 Mar                                      9097469 1985\n...481    1985 Feb                                      8981734 1985\n...482    1985 Jan                                     10275331 1985\n...483    1984 Dec                                      8479924 1984\n...484    1984 Nov                                     10305601 1984\n...485    1984 Oct                                      9709161 1984\n...486    1984 Sep                                      8740987 1984\n...487    1984 Aug                                      9277161 1984\n...488    1984 Jul                                     10279572 1984\n...489    1984 Jun                                      9288434 1984\n...490    1984 May                                     10136467 1984\n...491    1984 Apr                                      8568871 1984\n...492    1984 Mar                                      9454289 1984\n...493    1984 Feb                                      8075635 1984\n...494    1984 Jan                                     10157540 1984\n...495    1983 Dec                                      9029214 1983\n...496    1983 Nov                                      8992828 1983\n...497    1983 Oct                                      8833662 1983\n...498    1983 Sep                                      8842977 1983\n...499    1983 Aug                                      9255958 1983\n...500    1983 Jul                                      8667411 1983\n...501    1983 Jun                                      9331520 1983\n...502    1983 May                                      8489857 1983\n...503    1983 Apr                                      9339807 1983\n...504    1983 Mar                                      8775155 1983\n...505    1983 Feb                                      7533919 1983\n...506    1983 Jan                                      8566793 1983\n...507    1982 Dec                                      8622975 1982\n...508    1982 Nov                                      8256747 1982\n...509    1982 Oct                                      9175781 1982\n...510    1982 Sep                                      8430238 1982\n...511    1982 Aug                                      8342091 1982\n...512    1982 Jul                                      9077975 1982\n...513    1982 Jun                                      8418490 1982\n...514    1982 May                                      9174856 1982\n...515    1982 Apr                                      9123512 1982\n...516    1982 Mar                                      9377611 1982\n...517    1982 Feb                                      8294753 1982\n...518    1982 Jan                                      8422338 1982\n...519    1981 Dec                                      8742796 1981\n...520    1981 Nov                                      7954451 1981\n...521    1981 Oct                                      8895568 1981\n...522    1981 Sep                                      8535093 1981\n...523    1981 Aug                                      8587580 1981\n...524    1981 Jul                                      9318592 1981\n...525    1981 Jun                                      8210811 1981\n...526    1981 May                                      8560171 1981\n...527    1981 Apr                                      8944270 1981\n...528    1981 Mar                                      8643079 1981\n...529    1981 Feb                                      6825379 1981\n...530    1981 Jan                                      9320982 1981\n...531    1980 Dec                                      7694598 1980\n...532    1980 Nov                                      8018408 1980\n...533    1980 Oct                                      8360759 1980\n...534    1980 Sep                                      7999543 1980\n...535    1980 Aug                                      7691056 1980\n...536    1980 Jul                                      8316149 1980\n...537    1980 Jun                                      7568582 1980\n...538    1980 May                                      7743877 1980\n...539    1980 Apr                                      7681468 1980\n...540    1980 Mar                                      7647141 1980\n...541    1980 Feb                                      6628180 1980\n...542    1980 Jan                                      7447353 1980\n...543    1979 Dec                                      6818578 1979\n...544    1979 Nov                                      6790714 1979\n...545    1979 Oct                                      6139854 1979\n...546    1979 Sep                                      6247485 1979\n...547    1979 Aug                                      6612035 1979\n...548    1979 Jul                                      5962679 1979\n...549    1979 Jun                                      5525664 1979\n...550    1979 May                                      5447369 1979\n...551    1979 Apr                                      5339240 1979\n...552    1979 Mar                                      5116645 1979\n...553    1979 Feb                                      4596062 1979\n...554    1979 Jan                                      4678197 1979\n...555    1978 Dec                                      4661898 1978\n...556    1978 Nov                                      4904315 1978\n...557    1978 Oct                                      4794022 1978\n...558    1978 Sep                                      4581372 1978\n...559    1978 Aug                                      4527776 1978\n...560    1978 Jul                                      4491517 1978\n...561    1978 Jun                                      4382352 1978\n...562    1978 May                                      3977730 1978\n...563    1978 Apr                                      4312686 1978\n...564    1978 Mar                                      4327432 1978\n...565    1978 Feb                                      3411896 1978\n...566    1978 Jan                                      4213726 1978\n...567    1977 Dec                                      4020278 1977\n...568    1977 Nov                                      4015654 1977\n...569    1977 Oct                                      3994065 1977\n...570    1977 Sep                                      4012879 1977\n...571    1977 Aug                                      4075178 1977\n...572    1977 Jul                                      3926665 1977\n...573    1977 Jun                                      3786276 1977\n...574    1977 May                                      3473583 1977\n...575    1977 Apr                                      3823531 1977\n...576    1977 Mar                                      3729916 1977\n...577    1977 Feb                                      3067312 1977\n...578    1977 Jan                                      3686934 1977\n...579    1976 Dec                                      3560030 1976\n...580    1976 Nov                                      3495886 1976\n...581    1976 Oct                                      3516256 1976\n...582    1976 Sep                                      3374302 1976\n...583    1976 Aug                                      3347979 1976\n...584    1976 Jul                                      3547263 1976\n...585    1976 Jun                                      2942772 1976\n...586    1976 May                                      2707964 1976\n...587    1976 Apr                                      3245711 1976\n...588    1976 Mar                                      3042929 1976\n...589    1976 Feb                                      2815720 1976\n...590    1976 Jan                                      3073525 1976\n...591    1975 Dec                                      2854600 1975\n...592    1975 Nov                                      2787700 1975\n...593    1975 Oct                                      2883300 1975\n...594    1975 Sep                                      2752600 1975\n...595    1975 Aug                                      2636600 1975\n...596    1975 Jul                                      2652500 1975\n...597    1975 Jun                                      2438000 1975\n...598    1975 May                                      2635800 1975\n...599    1975 Apr                                      2660500 1975\n...600    1975 Mar                                      2546700 1975\n...601    1975 Feb                                      2483900 1975\n...602    1975 Jan                                      2696000 1975\n...603    1974 Dec                                      2543100 1974\n...604    1974 Nov                                      2783300 1974\n...605    1974 Oct                                      2874900 1974\n...606    1974 Sep                                      2842800 1974\n...607    1974 Aug                                      3145900 1974\n...608    1974 Jul                                      2975700 1974\n...609    1974 Jun                                      3018700 1974\n...610    1974 May                                      3382000 1974\n...611    1974 Apr                                      2888400 1974\n...612    1974 Mar                                      3110500 1974\n...613    1974 Feb                                      2533200 1974\n...614    1974 Jan                                      2460900 1974\n...615    1973 Dec                                      2134200 1973\n...616    1973 Nov                                      2164800 1973\n...617    1973 Oct                                      1922300 1973\n...618    1973 Sep                                      1996000 1973\n...619    1973 Aug                                      1859700 1973\n...620    1973 Jul                                      1787100 1973\n...621    1973 Jun                                      1693900 1973\n...622    1973 May                                      1704800 1973\n...623    1973 Apr                                      1520300 1973\n...624    1973 Mar                                      1649900 1973\n...625    1973 Feb                                      1330700 1973\n...626    1973 Jan                                      1655900 1973\n...627    1972 Dec                                      1451400 1972\n...628    1972 Nov                                      1424700 1972\n...629    1972 Oct                                      1398800 1972\n...630    1972 Sep                                      1383500 1972\n...631    1972 Aug                                      1447000 1972\n...632    1972 Jul                                      1294700 1972\n...633    1972 Jun                                      1225900 1972\n...634    1972 May                                      1328700 1972\n...635    1972 Apr                                      1200200 1972\n...636    1972 Mar                                      1279200 1972\n...637    1972 Feb                                      1079400 1972\n...638    1972 Jan                                      1173800 1972\n...639    1971 Dec                                      1183500 1971\n...640    1971 Nov                                      1159000 1971\n...641    1971 Oct                                      1171800 1971\n...642    1971 Sep                                      1167100 1971\n...643    1971 Aug                                      1178900 1971\n...644    1971 Jul                                      1270300 1971\n...645    1971 Jun                                      1221000 1971\n...646    1971 May                                      1167900 1971\n...647    1971 Apr                                      1188100 1971\n...648    1971 Mar                                      1278800 1971\n...649    1971 Feb                                      1016800 1971\n...650    1971 Jan                                      1023000 1971\n...651    1970 Dec                                      1166500 1970\n...652    1970 Nov                                      1046600 1970\n...653    1970 Oct                                      1062200 1970\n...654    1970 Sep                                      1014200 1970\n...655    1970 Aug                                      1053300 1970\n...656    1970 Jul                                      1056400 1970\n...657    1970 Jun                                      1020100 1970\n...658    1970 May                                      1000900 1970\n...659    1970 Apr                                       964000 1970\n...660    1970 Mar                                      1002000 1970\n...661    1970 Feb                                       842100 1970\n...662    1970 Jan                                      1061300 1970\n...663    1969 Dec                                      1007000 1969\n...664    1969 Nov                                       969200 1969\n...665    1969 Oct                                      1056800 1969\n...666    1969 Sep                                      1004400 1969\n...667    1969 Aug                                       910200 1969\n...668    1969 Jul                                       952800 1969\n...669    1969 Jun                                       878500 1969\n...670    1969 May                                       866200 1969\n...671    1969 Apr                                       864600 1969\n...672    1969 Mar                                       864400 1969\n...673    1969 Feb                                       730000 1969\n...674    1969 Jan                                       880200 1969\n...675    1968 Dec                                       768600 1968\n...676    1968 Nov                                       781000 1968\n...677    1968 Oct                                       793000 1968\n...678    1968 Sep                                       772400 1968\n...679    1968 Aug                                       754900 1968\n...680    1968 Jul                                       789300 1968\n...681    1968 Jun                                       751300 1968\n...682    1968 May                                       809800 1968\n...683    1968 Apr                                       695700 1968\n...684    1968 Mar                                       733000 1968\n...685    1968 Feb                                       694700 1968\n...686    1968 Jan                                       631000 1968\n...687    1967 Dec                                       668200 1967\n...688    1967 Nov                                       666900 1967\n...689    1967 Oct                                       690900 1967\n...690    1967 Sep                                       668900 1967\n...691    1967 Aug                                       698400 1967\n...692    1967 Jul                                       629400 1967\n...693    1967 Jun                                       665500 1967\n...694    1967 May                                       689500 1967\n...695    1967 Apr                                       645700 1967\n...696    1967 Mar                                       655600 1967\n...697    1967 Feb                                       607200 1967\n...698    1967 Jan                                       610700 1967\n...699    1966 Dec                                       671800 1966\n...700    1966 Nov                                       629200 1966\n...701    1966 Oct                                       624900 1966\n...702    1966 Sep                                       638900 1966\n...703    1966 Aug                                       645800 1966\n...704    1966 Jul                                       622100 1966\n...705    1966 Jun                                       561200 1966\n...706    1966 May                                       648500 1966\n...707    1966 Apr                                       575200 1966\n...708    1966 Mar                                       642500 1966\n...709    1966 Feb                                       610000 1966\n...710    1966 Jan                                       569100 1966\n...711    1965 Dec                                       605600 1965\n...712    1965 Nov                                       599700 1965\n...713    1965 Oct                                       565400 1965\n...714    1965 Sep                                       573900 1965\n...715    1965 Aug                                       582500 1965\n...716    1965 Jul                                       554000 1965\n...717    1965 Jun                                       530200 1965\n...718    1965 May                                       575000 1965\n...719    1965 Apr                                       535700 1965\n...720    1965 Mar                                       611500 1965\n...721    1965 Feb                                       493200 1965\n...722    1965 Jan                                       584600 1965\n...723    1964 Dec                                       542200 1964\n...724    1964 Nov                                       498400 1964\n...725    1964 Oct                                       575000 1964\n...726    1964 Sep                                       542300 1964\n...727    1964 Aug                                       552300 1964\n...728    1964 Jul                                       466000 1964\n...729    1964 Jun                                       532800 1964\n...730    1964 May                                       513100 1964\n...731    1964 Apr                                       501800 1964\n...732    1964 Mar                                       499800 1964\n...733    1964 Feb                                       466900 1964\n...734    1964 Jan                                       564500 1964\n\n\nShow the code\nv1_trans$Year &lt;- as.numeric(v1_trans$Year)\n\n# Convert type\nv1_trans$`Total Merchandise Trade, (At Current Prices)` &lt;- \n  as.numeric(v1_trans$`Total Merchandise Trade, (At Current Prices)`)\n\n# This is the data frame for visual 1\nv1_year_sum &lt;- v1_trans %&gt;%\n  filter(Year &gt;= 2020 & Year &lt;= 2024) %&gt;%\n  group_by(Year) %&gt;%\n  summarise(\n    YearTotal = sum(`Total Merchandise Trade, (At Current Prices)`, na.rm = TRUE))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03.html#overview",
    "href": "Take-home_Ex/Take-home_Ex03.html#overview",
    "title": "Take-home_Ex03",
    "section": "1 Overview",
    "text": "1 Overview\nAs a visual analytics novice, I will apply newly acquired techniques to explore and analyse the changing trends and patterns of Singapore’s international trade since 2015. Using the data set from the Department of Statistics Singapore (DOS), I will re-create visualizations, offering critiques of the visualizations shared on the DOS website. In addition, I will analyze key time-series events to uncover insights from the data.\n\nTasks\nThere are 2 tasks I will complete in this assignment.\n\n1. Critiques & re-creation of visualisations\nI will select 3 visualisations from the Department of Statistics Singapore website that display the Singapore trading data. I will critique each visualisation, discuss their pros and cons. I will then provide sketches of improved versions. Using R packages, I will re-create the visualisations with clearer messaging.\n\n\n2. Data analysis\nI will perform time-series analysis using data visualisation techniques and R packages to uncover insights from the dataset."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03.html#visualisation-make-over",
    "href": "Take-home_Ex/Take-home_Ex03.html#visualisation-make-over",
    "title": "Take-home_Ex03",
    "section": "2 Visualisation Make-Over",
    "text": "2 Visualisation Make-Over\nThe Department of Statistics Singapore provides a series of visualizations on its website to illustrate Singapore’s international trade data. This assignment will critique three of the nine visualizations provided, highlighting their strengths and weaknesses, and then propose redesigned charts or graphics to better convey insights from the dataset.\nThe three visualizations selected for analysis are:\n\nComparison Bar Chart: Displays exports and imports from 2020 to 2024 at current prices.\nBubble Plot: Illustrates Singapore’s trade performance with major trading partners.\nMirror Bar Chart: Aims to compare imports and exports among top trading partners for the years 2019 and 2023, segmented by the top-performing trade partners.\n\nEach chart will be reviewed for aesthetics, effectiveness, and potential improvements.\n\n\n#1 Bar Chart\n\n\n#2 Bubble Plot\n\n\n#3 Mirror Bar Chart\n\n\n\n\n2.1 Visualisation #1 Bar Chart\n\n\n\n\n\nPROSCONSSKETCH\n\n\nThe visualisation has several strengths as follows:\n\nClear labeling for the bars: Each bar explicitly shows its exact value ($674.5 Bil, etc.), eliminating any guesswork about the precise figures represented.\nBalanced visual weight: The imports and exports are given equal visual prominence, avoiding biasing the viewer toward one trade direction over the other.\nComprehensive data presentation: The chart manages to show five years of data with two metrics per year plus totals (15 data points) in a single, compact visualization.\n\n\n\n\nUGLY\n\n🧶 Colours - The chart has several visual design issues that hinder its effectiveness. Primarily the colour scheme creates significant problems: each year uses a different color palette (red, yellow, blue, purple, teal), generating visual noise rather than facilitating cross-year comparisons. The colour coding makes temporal comparison difficult, while the subtle opacity differences between imports and exports provides insufficient visual distinction.\n🧶 Styling - The shipping container is appropriate to represent Trade data, but it does not enhance understanding of the data and is not recognisable at first glance.\n🧶 Labeling - system is also problematic. The Y axis labels for Imports and Exports use blue and green colouring. This introduces another colour dimension to an already chromatically overwhelming chart rather than clarifying the data.\n\nBAD\n\nThe chart’s structure impedes data interpretation. First, comparing the same metric across years is unnecessarily difficult as readers must visually jump between non-adjecent bars to track imports or exports over time. Second, the chart lacks clear visual hierarchy. The similar spacing between years and between categories within years, confuses their relationship. Third, the chosen format obscures temporal trends that would be immediately visible in a line chart or properly sequenced bar chart. Finally, displaying values to a decimal place (like $674.5 billion) creates an illusion of precision that adds no meaningful information at this scale and only contributes to visual clutter.\n\nWRONG\n\nThe “total” values, while mathematically correct, are conceptually flawed. Adding exports and imports creates a non-standard economic metric lacking clear meaning. If intended to show trade volume as an activity indicator, it should be explicitly labeled “Total Trade Volume” with context. Without this clarity, viewers might misinterpret the total as net economic benefit, when trade balance would be more meaningful.\n\n\n\nDESIGN RATIONALE\n\nDumbbell plot\nThe dumbbell plot effectively illustrates the comparison between imports and exports, highlighting the gap between the two for each year. It allows for clear observation of trends in trade values over time.\nColor scheme\nTwo distinct colors represent imports and exports, rather than using a different color for each year. This simplifies the visual presentation, as the years are clearly marked on the Y-axis and eliminate the need for color differentiation by year.\nWhat were removed\nThe cargo image, while thematically relevant, does not enhance comprehension and has been removed. Labels for trade amounts have been removed from the axes and are now placed next to the data points for better clarity.\n\n\n\n\n\n\n\n2.1.1 Data\nThe data set needed is the Merchandise Trade data from DOS website. Within the excel file Merchandise Trade By Commodity Section, (At Current Prices), Monthly, there are monthly trade volumes from 1964 Jan until 2025 Jan. The value for the amount is in thousand dollars.\nThis means some data wrangling is needed to derive the yearly sum of the trade amount for every year from 2020 ~ 2024.\nStep 1. Load and launch packages\n\n\nShow the code\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(knitr)\n\n\nStep 2. Import the data\n\nIMPORT EXCELMAKE SUBSET\n\n\n\n\nShow the code\nv1_data &lt;- read_xlsx(\"data/Mtrade_commodity.xlsx\", \"T1\")\nv1_data_import &lt;- read_xlsx(\"data/Mtrade_commodity.xlsx\", \"T3\")\nv1_data_export &lt;- read_xlsx(\"data/Mtrade_commodity.xlsx\", \"T5\")\nhead(v1_data)\n\n\n# A tibble: 6 × 734\n  ...1   ...2  ...3  ...4  ...5  ...6  ...7  ...8  ...9  ...10 ...11 ...12 ...13\n  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n1 Theme… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n2 Subje… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n3 Topic… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n4 Table… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n5 &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n6 Data … Chec… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n# ℹ 721 more variables: ...14 &lt;chr&gt;, ...15 &lt;chr&gt;, ...16 &lt;chr&gt;, ...17 &lt;chr&gt;,\n#   ...18 &lt;chr&gt;, ...19 &lt;chr&gt;, ...20 &lt;chr&gt;, ...21 &lt;chr&gt;, ...22 &lt;chr&gt;,\n#   ...23 &lt;chr&gt;, ...24 &lt;chr&gt;, ...25 &lt;chr&gt;, ...26 &lt;chr&gt;, ...27 &lt;chr&gt;,\n#   ...28 &lt;chr&gt;, ...29 &lt;chr&gt;, ...30 &lt;chr&gt;, ...31 &lt;chr&gt;, ...32 &lt;chr&gt;,\n#   ...33 &lt;chr&gt;, ...34 &lt;chr&gt;, ...35 &lt;chr&gt;, ...36 &lt;chr&gt;, ...37 &lt;chr&gt;,\n#   ...38 &lt;chr&gt;, ...39 &lt;chr&gt;, ...40 &lt;chr&gt;, ...41 &lt;chr&gt;, ...42 &lt;chr&gt;,\n#   ...43 &lt;chr&gt;, ...44 &lt;chr&gt;, ...45 &lt;chr&gt;, ...46 &lt;chr&gt;, ...47 &lt;chr&gt;, …\n\n\n\n\nObservation\n\n\n\nThe reading result shows that the fields are all in character type, which needs further conversion for computation later.\n\n\n\n\n\n\n\nShow the code\n# Make a subset of the data needed (just the total amount) - merch trade\nv1_subset &lt;- v1_data[c(10, 11),]\nv1_trans_matrix &lt;- t(v1_subset) #after transpose, the data is a matrix.\nv1_trans &lt;- as.data.frame(v1_trans_matrix) #now convert the matrix to df.\n\n# Make a subset of the data needed (just the total amount) - Imports\nv1_subset_import &lt;- v1_data_import[c(10, 11),]\nv1_trans_matrix_import &lt;- t(v1_subset_import) #after transpose, the data is a matrix.\nv1_trans_import &lt;- as.data.frame(v1_trans_matrix_import) #now convert the matrix to df.\n\n# Make a subset of the data needed (just the total amount) - Exports\nv1_subset_export &lt;- v1_data_export[c(10, 11),]\nv1_trans_matrix_export &lt;- t(v1_subset_export) #after transpose, the data is a matrix.\nv1_trans_export &lt;- as.data.frame(v1_trans_matrix_export) #now convert the matrix to df.\n\nkable(head(v1_trans))\n\n\n\n\n\n\nV1\nV2\n\n\n\n\n…1\nData Series\nTotal Merchandise Trade, (At Current Prices)\n\n\n…2\n2025 Jan\n114153979.9\n\n\n…3\n2024 Dec\n116278793.1\n\n\n…4\n2024 Nov\n110132324.5\n\n\n…5\n2024 Oct\n107525959.8\n\n\n…6\n2024 Sep\n103512459.9\n\n\n\n\n\nShow the code\nkable(head(v1_trans_import))\n\n\n\n\n\n\nV1\nV2\n\n\n\n\n…1\nData Series\nTotal Merchandise Imports\n\n\n…2\n2025 Jan\n54746366\n\n\n…3\n2024 Dec\n56135912\n\n\n…4\n2024 Nov\n51802132\n\n\n…5\n2024 Oct\n51415560\n\n\n…6\n2024 Sep\n49068356\n\n\n\n\n\nShow the code\nkable(head(v1_trans_export))\n\n\n\n\n\n\nV1\nV2\n\n\n\n\n…1\nData Series\nTotal Merchandise Exports\n\n\n…2\n2025 Jan\n59407614\n\n\n…3\n2024 Dec\n60142882\n\n\n…4\n2024 Nov\n58330193\n\n\n…5\n2024 Oct\n56110400\n\n\n…6\n2024 Sep\n54444104\n\n\n\n\n\n\n\nObservation\n\n\n\nThe subset data has new column names, so we will need to shift the first row up to be the column names.\n\n\n\n\n\n\nStep 3. Data wrangling\nIn this step, I will first correct the column names. Then I will extract the years from the 1st column so I can group them to sum up the trade values. I will also need to convert the data types to numeric from character type.\n\nMERCHANDISE TRADEIMPORTSEXPORTSCOMBINED\n\n\nBelow code is used to derive the data set for merchandise trade (import & export) yearly totals from 2020-2024.\n\n\nShow the code\n# Correct the column name\nreal_column_names &lt;- as.character(v1_trans[1, ])\ncolnames(v1_trans) &lt;- real_column_names\n\n# remove the first row\nv1_trans &lt;- v1_trans[-1, ]\n\n# Extract year first\nv1_trans$Year &lt;- substr(v1_trans$`Data Series`, 1, 4)\nv1_trans$Year &lt;- as.numeric(v1_trans$Year)\n\n# Convert type\nv1_trans$`Total Merchandise Trade, (At Current Prices)` &lt;- \n  as.numeric(v1_trans$`Total Merchandise Trade, (At Current Prices)`)\n\n# This is the data frame for visual 1\nv1_year_sum &lt;- v1_trans %&gt;%\n  filter(Year &gt;= 2020 & Year &lt;= 2024) %&gt;%\n  group_by(Year) %&gt;%\n  summarise(\n    YearTotal = sum(`Total Merchandise Trade, (At Current Prices)`, na.rm = TRUE))\n\nhead(v1_year_sum)\n\n\n# A tibble: 5 × 2\n   Year   YearTotal\n  &lt;dbl&gt;       &lt;dbl&gt;\n1  2020  969111983.\n2  2021 1159963031.\n3  2022 1365402518.\n4  2023 1205722551 \n5  2024 1285864467.\n\n\n\n\nBelow code is used to derive the data set for imports yearly totals from 2020-2024.\n\n\nShow the code\n# Correct the column name\nreal_column_names_im &lt;- as.character(v1_trans_import[1, ])\ncolnames(v1_trans_import) &lt;- real_column_names_im\n\n# remove the first row\nv1_trans_import &lt;- v1_trans_import[-1, ]\n\n# Extract year first\nv1_trans_import$Year &lt;- substr(v1_trans_import$`Data Series`, 1, 4)\nv1_trans_import$Year &lt;- as.numeric(v1_trans_import$Year)\n\n# Convert type\nv1_trans_import$`Total Merchandise Imports` &lt;- \n  as.numeric(v1_trans_import$`Total Merchandise Imports`)\n\n# This is the data frame for visual 1\nv1_year_sum_im &lt;- v1_trans_import %&gt;%\n  filter(Year &gt;= 2020 & Year &lt;= 2024) %&gt;%\n  group_by(Year) %&gt;%\n  summarise(\n    YearTotal_im = sum(`Total Merchandise Imports`, na.rm = TRUE))\n\nhead(v1_year_sum_im)\n\n\n# A tibble: 5 × 2\n   Year YearTotal_im\n  &lt;dbl&gt;        &lt;dbl&gt;\n1  2020    453467443\n2  2021    545881937\n3  2022    655435885\n4  2023    567319062\n5  2024    611359441\n\n\n\n\nBelow code is used to derive the data set for exports yearly totals from 2020-2024.\n\n\nShow the code\n# Correct the column name\nreal_column_names_ex &lt;- as.character(v1_trans_export[1, ])\ncolnames(v1_trans_export) &lt;- real_column_names_ex\n\n# remove the first row\nv1_trans_export &lt;- v1_trans_export[-1, ]\n\n# Extract year first\nv1_trans_export$Year &lt;- substr(v1_trans_export$`Data Series`, 1, 4)\nv1_trans_export$Year &lt;- as.numeric(v1_trans_export$Year)\n\n# Convert type\nv1_trans_export$`Total Merchandise Exports` &lt;- \n  as.numeric(v1_trans_export$`Total Merchandise Exports`)\n\n# This is the data frame for visual 1\nv1_year_sum_ex &lt;- v1_trans_export %&gt;%\n  filter(Year &gt;= 2020 & Year &lt;= 2024) %&gt;%\n  group_by(Year) %&gt;%\n  summarise(\n    YearTotal_ex = sum(`Total Merchandise Exports`, na.rm = TRUE))\n\nhead(v1_year_sum_ex)\n\n\n# A tibble: 5 × 2\n   Year YearTotal_ex\n  &lt;dbl&gt;        &lt;dbl&gt;\n1  2020    515644539\n2  2021    614081092\n3  2022    709966634\n4  2023    638403489\n5  2024    674505027\n\n\n\n\nI will combine Import and Export into one data frame for visualisation.\n\n\nShow the code\nv1_year_sum_im &lt;- v1_year_sum_im %&gt;%\n  rename(YearTotal = YearTotal_im) %&gt;%\n  mutate(ImEx = \"Import\")\n\nv1_year_sum_ex &lt;- v1_year_sum_ex %&gt;%\n  rename(YearTotal = YearTotal_ex) %&gt;%\n  mutate(ImEx = \"Export\")\n\nv1_combined &lt;- bind_rows(v1_year_sum_im, v1_year_sum_ex)\n\nv1_combined &lt;- v1_combined %&gt;%\n  arrange(Year, YearTotal, ImEx)\n\nhead(v1_combined)\n\n\n# A tibble: 6 × 3\n   Year YearTotal ImEx  \n  &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt; \n1  2020 453467443 Import\n2  2020 515644539 Export\n3  2021 545881937 Import\n4  2021 614081092 Export\n5  2022 655435885 Import\n6  2022 709966634 Export\n\n\n\n\n\n\n\n\n\n2.1.2 Visualisation make-over\nStep 1. Launch packages\n\n\nShow the code\nlibrary(tidyverse)\nlibrary(ggtext)\nlibrary(extrafont)\n\n\nStep 2. Code the visualisation\n\n\nShow the code\nmean_export &lt;- mean(v1_year_sum_ex$YearTotal, na.rm = TRUE)\nmean_import &lt;- mean(v1_year_sum_im$YearTotal, na.rm = TRUE)\n\np &lt;- ggplot(v1_combined)+\n  \n geom_segment(data = v1_year_sum_ex,\n              aes(x = YearTotal, y = Year,\n                  yend = v1_year_sum_im$Year, xend = v1_year_sum_im$YearTotal), \n              color = \"#aeb6bf\",\n              size = 4.5, #Note that I sized the segment to fit the points\n              alpha = .5) +\n  \n      # Add mean lines\n  geom_segment(aes(x = mean_export, \n                   y = min(v1_combined$Year),\n                   xend = mean_export, \n                   yend = 2024.5),  \n               color = \"#6A80B9\",  \n               linetype = \"solid\", \n               size = 0.2) +\n  \n  geom_segment(aes(x = mean_import, \n                   y = min(v1_combined$Year),\n                   xend = mean_import, \n                   yend = 2024.5), \n               color = \"#F37199\",  \n               linetype = \"solid\", \n               size = 0.2) +\n   # Add labels for the mean lines (display in billions)\n  annotate(\"text\", \n           x = mean_export + (max(v1_combined$YearTotal) - min(v1_combined$YearTotal))*0.05, \n           y = max(v1_combined$Year) + 0.7,\n           label = paste0(\"MEAN: \", round(mean_export/1000000, 1)),\n           color = \"#6A80B9\",\n           size = 3) +\n  \n  annotate(\"text\", \n           x = mean_import + (max(v1_combined$YearTotal) - min(v1_combined$YearTotal))*0.05,\n           y = max(v1_combined$Year) + 0.7,\n           label = paste0(\"MEAN: \", round(mean_import/1000000, 1)),\n           color = \"#F37199\",\n           size = 3) +\n  \n  geom_point(aes(x = YearTotal, y = Year, color = ImEx), \n             size = 4, \n             show.legend = TRUE) +\n  # Add text labels next to points\n  geom_text(data = v1_combined,\n            aes(x = YearTotal, y = Year, \n                label = paste0(round(YearTotal/1000000, 1)),\n                color = ImEx),\n            hjust = -0.3, # Position to the right of points\n            vjust = -2,  # Slight vertical adjustment\n            size = 2.5,   # Text size\n            show.legend = FALSE\n) +\n  \n  scale_color_manual(values = c(\"Import\" = \"#F37199\", \"Export\" = \"#6A80B9\")) +\n  labs(\n    x = \"Singapore Trade Volume (Billion S$)\",\n    y = \"Year\",\n    title = \"Total Merchandise Trade at Current Prices\",\n    subtitle = \"2020 - 2024\",\n    color = \"Import/Export\"\n  ) +\n    # Convert x-axis from thousands to billions\n  scale_x_continuous(labels = function(x) paste0(round(x/1000000, 1))) +\n  theme(\n    axis.title.x = element_text(\n      family = \"\",\n      size = 12,\n      face = \"bold\",\n      color = \"black\",\n      hjust = 1,\n      vjust = -1),\n    axis.title.y = element_text(\n      family = \"\",\n      size = 12,\n      face = \"bold\",\n      color = \"black\",\n      hjust = 0.5,\n      vjust = 2),\n    title = element_text(size = 15, face = \"bold\"),\n    legend.title = element_text(size = 12, face = \"bold\"),\n    legend.text = element_text(size = 10),\n    legend.position = \"right\",# Options: \"right\", \"left\", \"top\", \"bottom\", or c(x, y) coordinates\n    legend.background = element_blank(),\n    plot.background = element_rect(fill = \"#f1f4f5\"),\n    panel.background = element_blank()\n    ) \n\ndiff &lt;- v1_combined %&gt;%\n  tidyr::pivot_wider(\n    id_cols = Year,\n    names_from = ImEx,\n    values_from = YearTotal\n  ) \n\ndiff$Difference &lt;- diff$Export - diff$Import\ndiff$x_pos &lt;- diff$Import + (diff$Difference/2)\n\n\np +\n  geom_text(data = diff,\n            aes(label = paste(\"D: \", round(Difference/1000000, 1)),\n                x = x_pos, y = Year),\n            fill = \"white\",\n            color = \"black\",\n            size = 2,\n            show.legend = FALSE) -&gt; p_labelled\n\np_labelled\n\n\n\n\n\n\n\n\n\n\n\nMake-over\n\n\n\nColor - Used a focused two-color scheme to clearly distinguish between export and import values, enhancing data interpretation.\nTrends presentation - Viwers can easily tell the trends of Export and Import along the years 2020-2024 with an emphasis on the year-over-year trade patterns across the 2020-2024 period.\nMean score - Integrated mean value reference lines for both exports and imports.\nTrade surplus - Instead of showing the total volume of trade, the dumbbell format to highlight the gap between export and import values is utilised to easilty understand Surplus/Deficit amount. Utilized the dumbbell format to highlight the gap between export and import values\nX and Y axis - They are clearly defined with appropriate positions and labels, making the time progression and value comparisons intuitive\nData figures - Export and Import amounts for each year are annotated near the points, so it’s easy to refer to the actual amounts.\n\nThese improvements overall makes the plot more prominent in showing the trends of trade and Singapore’s trade balance position in these recent years.\n\n\n\n\n\n2.2 Visualisation #2 Bubble Plot\n\n\n\n\n\nPROSCONSSKETCH\n\n\n\nDual-color background (blue and green) - shows which trading relationship favour imports and exports.\nBubble size - The bubble size visually represent total trade volume, which makes it easy to identify Singapore’s most significant partner at a glance.\nLabeling - The labeling for each country provides the name and its total trade volume so viewers can easily retrieve the information.\nFootnote - It has also included an explanatory note to clarify how to interpret the bubble positions relative to the diagnol dividing line.\n\n\n\nUGLY\n\nColor - Similar to Visualisation #1, the color scheme lacks cohesion. Each country has a different color without any apparent system or logic. Although at first glance it looks colorful, it has added noise rather than enhaning understanding.\nLabeling - Although the labels provide useful information, they altogether make the chart unnecessary clutter looking. The positioning and spacing relative to their bubbles are inconsistent and look random.\n\nBAD\n\nThe explanatory text at the bottom is lengthy and could be simplified or converted to visual elements for quicker comprehension.\nThe footnote states that viewer can use the centre point (white circle) of the bubble to determine whether Singapore has deficit or surplus with the trading partner, but lacking coloring opacity made it hard to achieve this.\n\n\n\nWRONG\n\nLabeling - On the website, the lables for X axis and Y axis are in confusing positions where viewer might misunderstand the x axis as Imports and y as Exports, as it is against the normal axis labeling convention. This issue does not appear in the PDF file for download.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.2.1 Data\nFor this visualisation, the dataset Merchandise Trade by Region/Market from the Department of Statistics Singapore (DOS) will be used.\nThe dataset consists of three tabs: Imports, Domestic Exports, and Re-Exports. I will combine data from all three tabs to calculate the total trade volume for each country, which will be plotted in a bubble plot. The dataset contains monthly trade volumes from January 2003 to January 2025, with trade values expressed in millions of dollars. Data wrangling is required to aggregate the trade amounts by year for 2024.\nStep 1. Load and launch packages\n\n\nShow the code\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(knitr)\n\n\nStep 2. Import the data and make subsets\n\nIMPORT EXCELIMPORTEXPORTRE-EXPORT\n\n\n\n\nShow the code\nv2_data_im &lt;- read_xlsx(\"data/Mtrade_region.xlsx\", \"T1\")\nv2_data_ex &lt;- read_xlsx(\"data/Mtrade_region.xlsx\", \"T2\")\nv2_data_reex &lt;- read_xlsx(\"data/Mtrade_region.xlsx\", \"T3\")\nhead(v2_data_im)\n\n\n# A tibble: 6 × 266\n  ...1   ...2  ...3  ...4  ...5  ...6  ...7  ...8  ...9  ...10 ...11 ...12 ...13\n  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n1 Theme… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n2 Subje… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n3 Topic… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n4 Table… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n5 &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n6 Data … Chec… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n# ℹ 253 more variables: ...14 &lt;chr&gt;, ...15 &lt;chr&gt;, ...16 &lt;chr&gt;, ...17 &lt;chr&gt;,\n#   ...18 &lt;chr&gt;, ...19 &lt;chr&gt;, ...20 &lt;chr&gt;, ...21 &lt;chr&gt;, ...22 &lt;chr&gt;,\n#   ...23 &lt;chr&gt;, ...24 &lt;chr&gt;, ...25 &lt;chr&gt;, ...26 &lt;chr&gt;, ...27 &lt;chr&gt;,\n#   ...28 &lt;chr&gt;, ...29 &lt;chr&gt;, ...30 &lt;chr&gt;, ...31 &lt;chr&gt;, ...32 &lt;chr&gt;,\n#   ...33 &lt;chr&gt;, ...34 &lt;chr&gt;, ...35 &lt;chr&gt;, ...36 &lt;chr&gt;, ...37 &lt;chr&gt;,\n#   ...38 &lt;chr&gt;, ...39 &lt;chr&gt;, ...40 &lt;chr&gt;, ...41 &lt;chr&gt;, ...42 &lt;chr&gt;,\n#   ...43 &lt;chr&gt;, ...44 &lt;chr&gt;, ...45 &lt;chr&gt;, ...46 &lt;chr&gt;, ...47 &lt;chr&gt;, …\n\n\n\n\nObservation\n\n\n\nSimilar to the other set of data used in the previous section, the reading result shows that the fields are all in character type. The dataset also needs further conversion for computation later.\n\n\n\n\n\n\n\nShow the code\n# Make a subset of the total IMPORT amount for each country\nv2_subset_im &lt;- v2_data_im[c(10:170),]\nv2_trans_matrix_im &lt;- t(v2_subset_im) #after transpose, the data is a matrix.\nv2_trans_im &lt;- as.data.frame(v2_trans_matrix_im) #now convert the matrix to df.\nkable(head(v2_trans_im))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nV1\nV2\nV3\nV4\nV5\nV6\nV7\nV8\nV9\nV10\nV11\nV12\nV13\nV14\nV15\nV16\nV17\nV18\nV19\nV20\nV21\nV22\nV23\nV24\nV25\nV26\nV27\nV28\nV29\nV30\nV31\nV32\nV33\nV34\nV35\nV36\nV37\nV38\nV39\nV40\nV41\nV42\nV43\nV44\nV45\nV46\nV47\nV48\nV49\nV50\nV51\nV52\nV53\nV54\nV55\nV56\nV57\nV58\nV59\nV60\nV61\nV62\nV63\nV64\nV65\nV66\nV67\nV68\nV69\nV70\nV71\nV72\nV73\nV74\nV75\nV76\nV77\nV78\nV79\nV80\nV81\nV82\nV83\nV84\nV85\nV86\nV87\nV88\nV89\nV90\nV91\nV92\nV93\nV94\nV95\nV96\nV97\nV98\nV99\nV100\nV101\nV102\nV103\nV104\nV105\nV106\nV107\nV108\nV109\nV110\nV111\nV112\nV113\nV114\nV115\nV116\nV117\nV118\nV119\nV120\nV121\nV122\nV123\nV124\nV125\nV126\nV127\nV128\nV129\nV130\nV131\nV132\nV133\nV134\nV135\nV136\nV137\nV138\nV139\nV140\nV141\nV142\nV143\nV144\nV145\nV146\nV147\nV148\nV149\nV150\nV151\nV152\nV153\nV154\nV155\nV156\nV157\nV158\nV159\nV160\nV161\n\n\n\n\n…1\nData Series\nTotal All Markets\nAmerica\nAntigua And Barbuda\nArgentina\nBahamas\nBermuda\nBrazil\nCanada\nChile\nColombia\nCosta Rica\nCuba\nDominican Rep\nEcuador\nEl Salvador\nGuatemala\nGuyana\nHonduras\nJamaica\nMexico\nNetherlands Antilles\nPanama\nParaguay\nPeru\nPuerto Rico\nSt. Vincent And The Grenadines\nTrinidad And Tobago\nUnited States\nUnited States Virgin Islands\nUruguay\nVenezuela\nOther Markets America\nAsia\nAfghanistan\nBahrain\nBangladesh\nBrunei\nCambodia\nChina\nChristmas Island\nHong Kong\nIndia\nIndonesia\nIran\nIraq\nIsrael\nJapan\nJordan\nKazakhstan\nKorea, Dem Peo Rep Of\nKorea, Rep Of\nKuwait\nLao\nLebanon\nMacao\nMalaysia\nMaldives\nMongolia\nMyanmar\nNepal\nOman\nPakistan\nPhilippines\nQatar\nSaudi Arabia\nSri Lanka\nSyria\nTaiwan\nThailand\nTurkiye\nUnited Arab Emirates\nViet Nam\nYemen\nOther Markets Asia\nEurope\nAustria\nBelarus\nBelgium\nBulgaria\nCroatia\nCyprus\nCzech Rep\nDenmark\nEstonia\nFinland\nFrance\nGermany\nGreece\nHungary\nIreland\nItaly\nLatvia\nLithuania\nLuxembourg\nMalta\nNetherlands\nNorway\nPoland\nPortugal\nRomania\nRussia\nSlovakia\nSlovenia\nSpain\nSvalbard And Jan Mayen Islands\nSweden\nSwitzerland\nUkraine\nUnited Kingdom\nOther Markets Europe\nOceania\nAntarctica\nAustralia\nFiji\nFrench Polynesia\nGuam\nMarshall Islands\nNew Caledonia\nNew Zealand\nNorthern Mariana Islands\nPapua New Guinea\nSamoa\nSolomon Islands\nVanuatu\nOther Markets Oceania\nAfrica\nAlgeria\nAngola\nBenin\nCameroon\nCape Verde\nComoros\nCongo, Dem Rep Of\nCote D’ivoire\nDjibouti\nEgypt\nEthiopia\nGabon\nGhana\nGuinea\nKenya\nLiberia\nLibya\nMadagascar\nMauritius\nMorocco\nMozambique\nNigeria\nReunion\nSeychelles\nSierra Leone\nSomalia\nSouth Africa\nSudan\nSwaziland\nTanzania\nTunisia\nZambia\nZimbabwe\nOther Markets Africa\n\n\n…2\n2025 Jan\n54746.4\n6923.3\n0\n4\n0\n0\n870.2\n267.5\n12.6\n17.6\n40\n0.6\n5.7\n15.2\n1.2\n0.2\n0.3\n0.9\n0.1\n267.6\n0\n0.3\n0.3\n9.4\n15.9\n0\n1.3\n5388.6\n0\n2.7\n0\n0.8\n39520.8\n0\n86\n16.3\n205.5\n87.8\n6801.2\n0\n696\n1098.7\n1765.7\n1.6\n201.9\n64\n2600.1\n2.9\n12.8\n0\n3775\n100.3\n7.9\n0.3\n0.3\n6445.1\n0.1\n0\n4.3\n0.3\n140.6\n58.6\n539.6\n507.1\n658.1\n10\n0\n10152.7\n1139.7\n96.2\n1340.2\n794\n0\n109.7\n6931.2\n91.3\n3.1\n191.5\n5.1\n1.9\n3.1\n126.9\n134.6\n29.6\n41\n1248.2\n902.9\n21.3\n45.4\n327\n636\n1.4\n7.8\n3.4\n10.9\n294.2\n78.1\n80\n32.3\n31.3\n494.8\n10.6\n8.5\n113.3\n0\n132.8\n725.1\n3.2\n1086.5\n8.1\n666.1\n0\n574.5\n0.6\n0\n0\n0\n0\n80.3\n0\n10.1\n0\n0\n0\n0.4\n705.1\n0\n68.5\n0\n36.6\n0.3\n0\n20.2\n5.5\n0.8\n82.8\n8.2\n0\n18.2\n0\n1.6\n0\n0\n2.8\n0.6\n18.5\n14.4\n118.9\n0\n0.1\n0\n0\n103.5\n0\n0.1\n1.8\n12\n18.8\n1.5\n169.1\n\n\n…3\n2024 Dec\n56135.9\n7873.7\n0\n12.5\n8.1\n0\n586.8\n212.7\n5.7\n19.4\n72.5\n0.8\n6.1\n8.8\n2.5\n0.3\n0\n0.5\n0.1\n263.7\n0\n0.3\n0.7\n8.1\n10.2\n0\n0.1\n6651.8\n0\n0.7\n0\n1.4\n39721.8\n0\n81.4\n18.1\n94.7\n50.1\n7168\n0\n769.2\n857\n2006.9\n4\n459.2\n76.6\n2790.1\n5.4\n7.6\n0\n3675.7\n152.5\n6\n0.2\n0.4\n6569.9\n3.9\n0\n5.5\n0.1\n41.4\n17.3\n654.4\n507.5\n838.9\n11.2\n0\n8847.7\n1421.6\n67\n1659.5\n781.2\n0.1\n71.5\n7373.9\n77.4\n0.3\n134.9\n8.3\n2.6\n2.4\n133.3\n77.4\n5.6\n49.1\n1355.9\n1108.3\n43.7\n56.7\n449.3\n633.1\n2\n9.3\n3\n71\n331.4\n53.7\n71.6\n41\n19.8\n367.1\n11.5\n7.2\n179.5\n0\n172.8\n702.6\n14.1\n1166.6\n11.6\n751.8\n0\n671.1\n0.4\n2.5\n0\n0\n0.4\n60\n0\n15.5\n0\n0.1\n0.1\n1.7\n414.7\n19.7\n0\n0\n15\n0\n0\n5.5\n9.3\n0\n3.5\n4.8\n0\n12.8\n0\n1.3\n0\n0\n2.2\n1\n23.9\n89\n72.3\n0\n0.1\n0\n0\n40.1\n0\n0.4\n22.8\n11.2\n0.2\n0.1\n79.4\n\n\n…4\n2024 Nov\n51802.1\n7879.6\n0\n116.2\n0\n0\n942.4\n221.6\n8\n9.2\n70.2\n1.3\n5.9\n7.7\n1.2\n0.3\n0.1\n0.3\n0\n426.6\n0\n0.1\n0.4\n18.3\n9.8\n0\n49.6\n5988.7\n0\n0.9\n0\n0.7\n35194.8\n0\n2.1\n16.6\n93.7\n120.3\n6841.2\n0\n442.4\n909.9\n1940.8\n2.3\n164.8\n69.5\n2879.8\n4.9\n26.9\n0\n2793.8\n223.6\n1.1\n0.6\n1\n5778.2\n3.6\n0\n8.7\n0.5\n39.1\n6.4\n496\n441.7\n973.2\n12.9\n0\n7360\n1228.3\n41\n1538.8\n717.1\n0.3\n13.6\n7666.3\n104.5\n3.3\n132.9\n10.2\n2.2\n5.4\n100.8\n105.5\n26.4\n29.9\n1549.4\n1070.4\n12\n59.9\n494\n671.4\n1.9\n11.7\n3.2\n13.4\n274.5\n66.6\n75.8\n34.5\n24.8\n432.5\n12.1\n9.3\n351.7\n0\n123.9\n684.6\n11.4\n1146.9\n9.2\n404.5\n0\n338.7\n0.2\n0\n0\n0\n0\n55.7\n0\n9\n0\n0\n0\n0.9\n656.9\n47.6\n152.9\n0\n7.2\n0\n0\n1.5\n12.4\n0.5\n37.5\n11.8\n0\n24.7\n0\n1.3\n0\n0\n2\n0.9\n15.9\n59.8\n17.2\n0\n0\n0.2\n0\n51.2\n0\n0\n4.1\n12\n23.6\n1.2\n171.4\n\n\n…5\n2024 Oct\n51415.6\n8077.6\n0\n4.1\n0\n0\n639.9\n323.8\n7.1\n2.4\n58\n0.8\n7.4\n9.7\n1.4\n1.3\n0.3\n1\n0.1\n897.9\n0\n0.3\n0.4\n14.6\n9.7\n0\n0\n6092.8\n0\n2\n0.1\n2.3\n34284.1\n0\n115.9\n15.4\n94.7\n15\n6070.1\n0\n386.8\n989.6\n1973.1\n1\n203.8\n83.2\n2943.2\n4\n0\n0\n3000.3\n55.7\n0.7\n0.3\n1.9\n5574\n0.5\n0.1\n7\n0.8\n66.4\n56.5\n462.4\n551.2\n881.1\n9.4\n0\n6976.4\n1517.2\n50.2\n1371.3\n803.6\n0\n1.3\n7204.6\n100.8\n1.2\n208\n4.6\n2.7\n1.6\n114.2\n51.1\n4.1\n35.9\n1393.9\n1103.5\n13.3\n48.3\n199.9\n644.9\n3.8\n10.8\n1.4\n14.4\n537.3\n54.4\n83.3\n33.3\n31\n535.5\n8.4\n6.6\n124.2\n0\n131.2\n743.8\n7\n940.7\n9.6\n1097.3\n0\n1002.6\n0.3\n0\n1\n0\n0.5\n64.9\n0\n27.7\n0\n0\n0\n0.3\n751.9\n117.5\n0.5\n0\n16.5\n0.2\n0.3\n2.9\n18.9\n0.5\n1.7\n29.7\n0\n14\n0\n0.8\n0\n0\n0.5\n0.7\n15.3\n130.6\n183.7\n0.2\n0.1\n0\n0\n88.1\n42.4\n0\n0.5\n12\n0\n1.4\n72.8\n\n\n…6\n2024 Sep\n49068.4\n9112\n0\n8.1\n0\n0\n786.6\n236.5\n2.3\n3.3\n50.1\n1\n7.4\n3.7\n1.5\n0.9\n0.1\n0.3\n0.1\n1486.9\n0\n43.7\n0.7\n1.8\n7.4\n0\n1.9\n6449.3\n0\n17.4\n0\n1\n31828.7\n0\n23\n27.3\n83.9\n26.6\n5716.2\n0.1\n476.6\n774.4\n1650.2\n0\n133.3\n90.1\n2381.9\n2.2\n0.7\n0\n3041.7\n2.4\n0.5\n0.3\n0.1\n5462\n0.1\n0.2\n10.3\n0.6\n37.1\n19\n458\n460.4\n507.6\n8.7\n0\n7195.8\n1250.2\n98.4\n1193.1\n694.4\n0.3\n1.2\n6825.8\n104.3\n6.2\n101\n4.4\n3.2\n1.5\n228.1\n66.1\n31.9\n46.7\n1325.7\n1081.3\n134.6\n59.6\n502.2\n603.3\n2.1\n10.1\n4.2\n28.8\n270.6\n42.7\n78.9\n32.5\n26.4\n186.2\n10.6\n7.3\n153.5\n0\n147.8\n571.3\n3.2\n942.5\n6.9\n566.9\n0\n449.6\n0.8\n0.2\n0.1\n0\n0.1\n97.6\n0\n17.8\n0.1\n0\n0\n0.6\n735\n0\n217.8\n0\n11.1\n0\n1.2\n0.1\n12.4\n0\n24.8\n6.3\n0\n6\n0\n0.6\n0\n0\n2.6\n0.4\n19.6\n141.7\n160\n3.5\n0\n0\n0\n44.7\n0\n0.1\n1.2\n7.1\n0.2\n1.9\n71.4\n\n\n\n\n\n\n\n\n\nShow the code\nv2_subset_ex &lt;- v2_data_ex[c(10:170),]\nv2_trans_matrix_ex &lt;- t(v2_subset_ex) #after transpose, the data is a matrix.\nv2_trans_ex &lt;- as.data.frame(v2_trans_matrix_ex) #now convert the matrix to df.\nkable(head(v2_trans_ex))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nV1\nV2\nV3\nV4\nV5\nV6\nV7\nV8\nV9\nV10\nV11\nV12\nV13\nV14\nV15\nV16\nV17\nV18\nV19\nV20\nV21\nV22\nV23\nV24\nV25\nV26\nV27\nV28\nV29\nV30\nV31\nV32\nV33\nV34\nV35\nV36\nV37\nV38\nV39\nV40\nV41\nV42\nV43\nV44\nV45\nV46\nV47\nV48\nV49\nV50\nV51\nV52\nV53\nV54\nV55\nV56\nV57\nV58\nV59\nV60\nV61\nV62\nV63\nV64\nV65\nV66\nV67\nV68\nV69\nV70\nV71\nV72\nV73\nV74\nV75\nV76\nV77\nV78\nV79\nV80\nV81\nV82\nV83\nV84\nV85\nV86\nV87\nV88\nV89\nV90\nV91\nV92\nV93\nV94\nV95\nV96\nV97\nV98\nV99\nV100\nV101\nV102\nV103\nV104\nV105\nV106\nV107\nV108\nV109\nV110\nV111\nV112\nV113\nV114\nV115\nV116\nV117\nV118\nV119\nV120\nV121\nV122\nV123\nV124\nV125\nV126\nV127\nV128\nV129\nV130\nV131\nV132\nV133\nV134\nV135\nV136\nV137\nV138\nV139\nV140\nV141\nV142\nV143\nV144\nV145\nV146\nV147\nV148\nV149\nV150\nV151\nV152\nV153\nV154\nV155\nV156\nV157\nV158\nV159\nV160\nV161\n\n\n\n\n…1\nData Series\nTotal All Markets\nAmerica\nAntigua And Barbuda\nArgentina\nBahamas\nBermuda\nBrazil\nCanada\nChile\nColombia\nCosta Rica\nCuba\nDominican Rep\nEcuador\nEl Salvador\nGuatemala\nGuyana\nHonduras\nJamaica\nMexico\nNetherlands Antilles\nPanama\nParaguay\nPeru\nPuerto Rico\nSt. Vincent And The Grenadines\nTrinidad And Tobago\nUnited States\nUnited States Virgin Islands\nUruguay\nVenezuela\nOther Markets America\nAsia\nAfghanistan\nBahrain\nBangladesh\nBrunei\nCambodia\nChina\nChristmas Island\nHong Kong\nIndia\nIndonesia\nIran\nIraq\nIsrael\nJapan\nJordan\nKazakhstan\nKorea, Dem Peo Rep Of\nKorea, Rep Of\nKuwait\nLao\nLebanon\nMacao\nMalaysia\nMaldives\nMongolia\nMyanmar\nNepal\nOman\nPakistan\nPhilippines\nQatar\nSaudi Arabia\nSri Lanka\nSyria\nTaiwan\nThailand\nTurkiye\nUnited Arab Emirates\nViet Nam\nYemen\nOther Markets Asia\nEurope\nAustria\nBelarus\nBelgium\nBulgaria\nCroatia\nCyprus\nCzech Rep\nDenmark\nEstonia\nFinland\nFrance\nGermany\nGreece\nHungary\nIreland\nItaly\nLatvia\nLithuania\nLuxembourg\nMalta\nNetherlands\nNorway\nPoland\nPortugal\nRomania\nRussia\nSlovakia\nSlovenia\nSpain\nSvalbard And Jan Mayen Islands\nSweden\nSwitzerland\nUkraine\nUnited Kingdom\nOther Markets Europe\nOceania\nAntarctica\nAustralia\nFiji\nFrench Polynesia\nGuam\nMarshall Islands\nNew Caledonia\nNew Zealand\nNorthern Mariana Islands\nPapua New Guinea\nSamoa\nSolomon Islands\nVanuatu\nOther Markets Oceania\nAfrica\nAlgeria\nAngola\nBenin\nCameroon\nCape Verde\nComoros\nCongo, Dem Rep Of\nCote D’ivoire\nDjibouti\nEgypt\nEthiopia\nGabon\nGhana\nGuinea\nKenya\nLiberia\nLibya\nMadagascar\nMauritius\nMorocco\nMozambique\nNigeria\nReunion\nSeychelles\nSierra Leone\nSomalia\nSouth Africa\nSudan\nSwaziland\nTanzania\nTunisia\nZambia\nZimbabwe\nOther Markets Africa\n\n\n…2\n2025 Jan\n24672\n4263.1\n8.8\n5.3\n51.4\n2.7\n40.2\n33.7\n5.1\n4.3\n4.8\n0\n1.1\n2.9\n0.6\n0.3\n7.2\n0.9\n0\n48.2\n0\n532.6\n0.2\n3.7\n238.5\n0.7\n0.3\n3254.7\n0\n0.6\n0\n14.3\n15623.3\n0\n2.3\n194.6\n17.8\n103.9\n2257.3\n0\n1866.1\n638.1\n2002.7\n1.1\n8.4\n27.4\n830\n0.8\n5.7\n0\n1110.4\n16.2\n3.6\n0.7\n4.4\n2468.6\n9.1\n2.9\n273.4\n5.7\n91.8\n180.4\n566.1\n87.7\n73.6\n77.9\n0.2\n1099.7\n616.5\n30.6\n178\n759.2\n1\n9.6\n2123.3\n5.4\n0\n128.9\n0.2\n2.1\n46.1\n3.8\n36.4\n12.2\n5.9\n114.2\n189\n65.2\n44.2\n92.4\n55\n0.6\n0.1\n1.4\n189.6\n622.8\n65.5\n33.1\n70.3\n3.9\n9.8\n0.5\n1.8\n9.2\n0\n2.1\n137.8\n0.4\n134.3\n39.1\n1821.9\n0\n908\n21.3\n4.1\n24.1\n425.5\n16.3\n303.9\n4.5\n82.4\n0\n16.7\n1.3\n13.7\n840.3\n2\n21.6\n0\n2.1\n0.1\n0.1\n1.9\n4.4\n0.1\n16.2\n2.2\n1\n4\n2.5\n2.7\n669.5\n4\n0.1\n8.1\n19.6\n0.6\n21.2\n23.4\n0.6\n2.5\n0\n12.9\n0\n1.5\n7\n0.6\n0.3\n0.9\n6.6\n\n\n…3\n2024 Dec\n23684.7\n3607.9\n7.1\n6\n48.1\n7.7\n32.3\n35.6\n4.7\n7.8\n4\n0.4\n3.3\n2.1\n0.1\n0.5\n6.9\n0.5\n0.1\n52\n0\n493\n0.2\n4.8\n89.1\n0.9\n0.8\n2781.3\n0\n1.2\n0\n17.5\n15306\n0\n5\n168.9\n15.5\n87\n2871.4\n0\n1583.9\n544.9\n2068\n0.1\n7.1\n23.2\n828.6\n8\n3\n0\n944\n14.5\n3.3\n0.3\n5.6\n2276.5\n9.4\n3.2\n208.8\n5.8\n13.3\n83.2\n347.7\n72.8\n117.2\n105.3\n0\n1255\n684.7\n39.3\n195.9\n694.8\n0.1\n10.9\n2053\n9.1\n0.2\n206.7\n0.3\n1.9\n36\n3.6\n37.5\n16.3\n8.4\n93.3\n265.8\n79.2\n4.6\n74.3\n50.2\n1.6\n0.2\n8.7\n167.9\n420.5\n59.5\n21.4\n52\n3.1\n9.5\n0.6\n2.9\n17.5\n0\n2.4\n76.8\n0\n288.3\n32.6\n1885.4\n0\n928\n66.6\n0.6\n24.6\n393.9\n20.2\n344.8\n11.7\n61.2\n13.6\n7.4\n1.5\n11.4\n832.4\n4.9\n13.5\n0.2\n3.6\n0\n3.7\n1\n0.5\n0.2\n15.7\n1.9\n1.9\n25.6\n3.7\n10.9\n624.4\n1.6\n0.1\n2.4\n17.5\n3\n7.8\n51.2\n0.7\n2.2\n0.2\n16.7\n0\n2.1\n4.3\n1\n0.5\n0.3\n9\n\n\n…4\n2024 Nov\n23438.7\n3128.7\n8.3\n3.9\n60.5\n0.5\n37.8\n78.9\n4.4\n4.2\n4.5\n0\n1.2\n3.2\n0.8\n0.6\n4.1\n0.1\n0\n69.4\n0\n520.7\n0\n5.7\n122.4\n0.1\n0.3\n2179.1\n0\n0.4\n0.1\n17.3\n14697.1\n0\n13.6\n280.4\n20\n139.6\n2633.5\n0\n1538.5\n709\n1839.6\n1.2\n4.9\n22.3\n771.5\n1.8\n2.5\n0\n881.7\n16.3\n3.1\n0.7\n6.6\n2189.8\n4.9\n4.9\n189.3\n2.4\n14.3\n128.8\n424.9\n58.8\n85.5\n84.8\n0.1\n1101.6\n760.2\n41.6\n187.9\n520.2\n0.7\n9.6\n2268.5\n8.5\n0.1\n136.4\n0.1\n1.3\n63.2\n6.2\n38.3\n3.8\n4.7\n141.2\n184.6\n84.6\n18.8\n126.9\n75.2\n0.2\n0.8\n2.1\n186.8\n372.6\n51.1\n24.5\n59.5\n6.3\n10.3\n0.6\n3.8\n11.2\n0\n2\n93.1\n0\n521\n28.4\n2475.6\n0\n1234.7\n38.3\n3.3\n22.4\n680.8\n68.5\n300.2\n11\n80.1\n4.7\n15.8\n4.8\n10.9\n868.8\n2.6\n40.5\n0.1\n3.5\n0\n1.5\n1.6\n1.1\n0.1\n19\n2.8\n3.2\n4.1\n2.5\n7.5\n645.7\n3\n0\n2.4\n34.7\n1.1\n9.7\n45.3\n0.4\n2.6\n0.2\n16.6\n0\n2\n4.6\n0.1\n0.3\n1.1\n8.7\n\n\n…5\n2024 Oct\n22147.8\n2935.5\n7.7\n6.4\n36.1\n5.4\n62.2\n38.6\n6.9\n5.3\n4.3\n0\n1.7\n3.3\n0.5\n0.4\n2.9\n0.6\n0.1\n60.4\n0\n492.9\n0.2\n5.9\n49.4\n1.6\n0.6\n2126.5\n0\n0.4\n0.1\n15.2\n14497.3\n0\n2.3\n202.4\n19.7\n208.6\n2845\n0\n1060.3\n516.3\n1633.6\n0\n5.9\n27.4\n793.6\n9.7\n2\n0\n886.3\n20.5\n2.6\n0.4\n3.1\n2406.4\n4.2\n2.7\n223.3\n2.8\n17.5\n112.3\n488.2\n62.2\n121\n173.7\n0.1\n1146.6\n591.1\n26.7\n153.5\n714.9\n0.1\n10.3\n2258.1\n18.4\n0.1\n165.9\n0.6\n17.9\n38.1\n3\n33.8\n3.2\n2.8\n114\n166.5\n54.2\n44.8\n95.1\n94.5\n1.7\n0.2\n5.5\n164.3\n385.5\n47.4\n24.8\n49.1\n3.3\n4.4\n1\n4.5\n10.5\n0\n4.6\n87.1\n1.4\n572.6\n37.4\n1723.8\n0\n803.5\n72.6\n7.3\n8.1\n445.3\n17.9\n224.2\n2.2\n91.2\n12\n14.3\n2.7\n22.6\n733.2\n1.2\n7.4\n0\n4\n0.1\n1\n1.7\n1\n0.4\n14.9\n2\n10.6\n6.1\n1.2\n4.9\n548.1\n3.9\n0.2\n11.1\n38.3\n0.8\n5.1\n28.3\n0.8\n2.3\n0.1\n18.3\n0\n2.9\n3.6\n0.7\n0.1\n0.4\n11.9\n\n\n…6\n2024 Sep\n21966.7\n3294.2\n8.2\n3\n59.3\n0.7\n30\n33.5\n6.8\n7.4\n4.9\n1.6\n0.9\n3.7\n0.4\n0.8\n6.2\n0.8\n0\n214\n0\n533.5\n0\n3.9\n125.9\n1.9\n0.4\n2226.5\n0\n0.7\n0.1\n19.1\n13316.2\n0\n3.5\n217.8\n14.3\n127.5\n2789.3\n0\n1135.8\n566.7\n1527.4\n0.7\n4.2\n24.4\n712.8\n2.2\n1.8\n0\n865.7\n16.5\n2.7\n0.5\n6.1\n2160.4\n6\n2.6\n175.4\n2.2\n9.8\n77.5\n377.4\n42.4\n118.7\n102.5\n0\n1019.5\n567.1\n26.8\n166.4\n433.6\n0.8\n7\n2782.3\n24.2\n0.1\n779.3\n0.3\n0.2\n50.6\n3.9\n36.4\n0.1\n3.4\n138.2\n208.4\n89.5\n37\n93.9\n59.5\n0.5\n0.1\n9.3\n164.6\n397.5\n66\n23.6\n54.4\n3.8\n9.2\n1.1\n3.7\n58.6\n0\n3.8\n83.9\n1.1\n355.2\n20.7\n1689.4\n0\n837\n35.3\n4.9\n41.4\n424.1\n17.7\n186.9\n20.2\n85.5\n5.9\n10.7\n0.5\n19.2\n884.6\n2.6\n7.8\n0.1\n0.8\n0\n0\n1.5\n3.8\n1.3\n18.9\n1.4\n2.9\n4.8\n1.8\n6.3\n691\n2.6\n0.2\n9.5\n34.5\n1\n6.6\n54\n1.2\n1.9\n0\n18.2\n0\n0\n3.7\n0.2\n0\n1.4\n4.4\n\n\n\n\n\n\n\n\n\nShow the code\nv2_subset_reex &lt;- v2_data_reex[c(10:170),]\nv2_trans_matrix_reex &lt;- t(v2_subset_reex) #after transpose, the data is a matrix.\nv2_trans_reex &lt;- as.data.frame(v2_trans_matrix_reex) #now convert the matrix to df.\nkable(head(v2_trans_reex))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nV1\nV2\nV3\nV4\nV5\nV6\nV7\nV8\nV9\nV10\nV11\nV12\nV13\nV14\nV15\nV16\nV17\nV18\nV19\nV20\nV21\nV22\nV23\nV24\nV25\nV26\nV27\nV28\nV29\nV30\nV31\nV32\nV33\nV34\nV35\nV36\nV37\nV38\nV39\nV40\nV41\nV42\nV43\nV44\nV45\nV46\nV47\nV48\nV49\nV50\nV51\nV52\nV53\nV54\nV55\nV56\nV57\nV58\nV59\nV60\nV61\nV62\nV63\nV64\nV65\nV66\nV67\nV68\nV69\nV70\nV71\nV72\nV73\nV74\nV75\nV76\nV77\nV78\nV79\nV80\nV81\nV82\nV83\nV84\nV85\nV86\nV87\nV88\nV89\nV90\nV91\nV92\nV93\nV94\nV95\nV96\nV97\nV98\nV99\nV100\nV101\nV102\nV103\nV104\nV105\nV106\nV107\nV108\nV109\nV110\nV111\nV112\nV113\nV114\nV115\nV116\nV117\nV118\nV119\nV120\nV121\nV122\nV123\nV124\nV125\nV126\nV127\nV128\nV129\nV130\nV131\nV132\nV133\nV134\nV135\nV136\nV137\nV138\nV139\nV140\nV141\nV142\nV143\nV144\nV145\nV146\nV147\nV148\nV149\nV150\nV151\nV152\nV153\nV154\nV155\nV156\nV157\nV158\nV159\nV160\nV161\n\n\n\n\n…1\nData Series\nTotal All Markets\nAmerica\nAntigua And Barbuda\nArgentina\nBahamas\nBermuda\nBrazil\nCanada\nChile\nColombia\nCosta Rica\nCuba\nDominican Rep\nEcuador\nEl Salvador\nGuatemala\nGuyana\nHonduras\nJamaica\nMexico\nNetherlands Antilles\nPanama\nParaguay\nPeru\nPuerto Rico\nSt. Vincent And The Grenadines\nTrinidad And Tobago\nUnited States\nUnited States Virgin Islands\nUruguay\nVenezuela\nOther Markets America\nAsia\nAfghanistan\nBahrain\nBangladesh\nBrunei\nCambodia\nChina\nChristmas Island\nHong Kong\nIndia\nIndonesia\nIran\nIraq\nIsrael\nJapan\nJordan\nKazakhstan\nKorea, Dem Peo Rep Of\nKorea, Rep Of\nKuwait\nLao\nLebanon\nMacao\nMalaysia\nMaldives\nMongolia\nMyanmar\nNepal\nOman\nPakistan\nPhilippines\nQatar\nSaudi Arabia\nSri Lanka\nSyria\nTaiwan\nThailand\nTurkiye\nUnited Arab Emirates\nViet Nam\nYemen\nOther Markets Asia\nEurope\nAustria\nBelarus\nBelgium\nBulgaria\nCroatia\nCyprus\nCzech Rep\nDenmark\nEstonia\nFinland\nFrance\nGermany\nGreece\nHungary\nIreland\nItaly\nLatvia\nLithuania\nLuxembourg\nMalta\nNetherlands\nNorway\nPoland\nPortugal\nRomania\nRussia\nSlovakia\nSlovenia\nSpain\nSvalbard And Jan Mayen Islands\nSweden\nSwitzerland\nUkraine\nUnited Kingdom\nOther Markets Europe\nOceania\nAntarctica\nAustralia\nFiji\nFrench Polynesia\nGuam\nMarshall Islands\nNew Caledonia\nNew Zealand\nNorthern Mariana Islands\nPapua New Guinea\nSamoa\nSolomon Islands\nVanuatu\nOther Markets Oceania\nAfrica\nAlgeria\nAngola\nBenin\nCameroon\nCape Verde\nComoros\nCongo, Dem Rep Of\nCote D’ivoire\nDjibouti\nEgypt\nEthiopia\nGabon\nGhana\nGuinea\nKenya\nLiberia\nLibya\nMadagascar\nMauritius\nMorocco\nMozambique\nNigeria\nReunion\nSeychelles\nSierra Leone\nSomalia\nSouth Africa\nSudan\nSwaziland\nTanzania\nTunisia\nZambia\nZimbabwe\nOther Markets Africa\n\n\n…2\n2025 Jan\n34735.6\n3110.3\n1.9\n25.7\n9.8\n0.1\n203.7\n79.1\n8.9\n6.4\n1.3\n0\n0.6\n7.7\n0.6\n2.1\n1.5\n0.7\n0.6\n160.3\n0\n18\n0.1\n3.5\n2.1\n0\n0.9\n2572.1\n0\n0.5\n0.3\n1.8\n28465.5\n0\n15.7\n139.7\n47.7\n54\n3808.9\n0\n4719.1\n1162.4\n2553.4\n0.2\n3\n44.6\n1289.9\n8.8\n13.6\n0\n1628.5\n25.5\n2.3\n1.8\n17.8\n4287.6\n11.9\n32\n28.8\n17.6\n46.9\n88.5\n775.3\n42.1\n72.7\n43.5\n0.1\n3655.7\n1441.2\n70.8\n456.7\n1840.1\n0.1\n16.9\n2315.4\n11.8\n0\n60.2\n0.8\n1.7\n0.2\n47.1\n6.3\n0.4\n18.8\n170.6\n658.3\n15.6\n24.8\n13.8\n70.3\n1.2\n1.4\n2.2\n11.7\n294.7\n29.2\n43.5\n35.8\n8.3\n8.3\n2.1\n1\n28.9\n0\n5.1\n371.4\n0.3\n364.4\n5.1\n647.4\n0\n491.5\n4.2\n2.2\n1.4\n25.1\n1.3\n112.7\n0.1\n7.5\n0.1\n0\n0.8\n0.5\n197\n0.8\n7.4\n0.1\n0.6\n0\n0.4\n2.2\n2.3\n0.5\n15.9\n35.5\n2\n2\n0.1\n3.9\n15.1\n1.9\n0.4\n5.3\n9.7\n6.1\n15.4\n0.1\n0.8\n0\n0\n41.1\n0\n0.1\n12.7\n3.3\n0.1\n0.1\n11.1\n\n\n…3\n2024 Dec\n36458.2\n3893.4\n0.1\n22.3\n1.3\n0\n174.9\n67.6\n9\n8.6\n1.7\n0\n0.8\n3.9\n0.4\n2.4\n4.4\n0.4\n1\n850.1\n0\n17.4\n0\n5\n2.4\n0.5\n1.4\n2711.7\n0\n1.5\n0.1\n4.5\n29303.5\n0\n2.7\n162.8\n88.5\n53\n5812.2\n0\n5898.8\n1194.6\n2288.5\n0.2\n9.8\n50.9\n1380\n5.7\n5.3\n0\n1704\n21.1\n3.9\n2.9\n21.5\n3435.3\n11.9\n23.2\n26.7\n18.4\n28.6\n68.2\n571.6\n27\n57.7\n39.4\n0\n2828.5\n1420.6\n65.8\n366.8\n1591.9\n0.5\n14.8\n2314.1\n11.3\n0.1\n114.2\n3.7\n0.6\n2.9\n40\n5.1\n0.6\n33.7\n198.7\n608.9\n6.6\n23.2\n53.8\n61.5\n3.6\n2.9\n19.4\n6.5\n418.9\n6.9\n46.8\n88.7\n4.7\n10.8\n2.7\n3.3\n19.5\n0\n7.4\n201.7\n0.1\n299.4\n5.9\n760.1\n0\n579.1\n12.9\n0.6\n3.4\n39.2\n1.8\n112.2\n0\n8.7\n0.3\n0.4\n0.6\n0.8\n187.1\n2.8\n8.2\n2.5\n0.8\n0.1\n0.3\n2\n2\n1.5\n19.6\n38.6\n2.1\n18\n0.2\n14.3\n8.5\n2\n1.5\n3.8\n8.9\n1.3\n10.4\n0.6\n0.8\n0.1\n0.2\n20.2\n0\n0\n5.8\n1.8\n0\n0\n8.3\n\n\n…4\n2024 Nov\n34891.5\n3528.2\n0\n19.4\n3.7\n0\n149.1\n76\n6.3\n8.3\n1.4\n0\n1.1\n8.1\n0.5\n2.2\n1.4\n0.2\n1.2\n207.6\n0\n18.6\n0.1\n5.3\n1.6\n0\n1\n3011.7\n0\n0.8\n0.1\n2.3\n28020.9\n0.1\n17.3\n156\n1122.9\n93.1\n5292.4\n0\n5936.4\n979.5\n2430.1\n0.2\n18\n40.5\n1260.6\n7.8\n2.3\n0\n1525.5\n30.4\n4.5\n0.8\n21.5\n3253.9\n15.4\n28.4\n29.7\n32\n23\n64.3\n939.7\n40.4\n45.8\n43.4\n0\n1722.7\n1041.3\n80.1\n405.3\n1289.9\n0.1\n25.5\n2329\n9.9\n0.2\n90.1\n1.8\n2.2\n1.8\n56.1\n8.3\n1.4\n23.9\n201.8\n657.2\n14\n26.4\n61.6\n55.8\n1.7\n2.3\n13.3\n4.1\n374.9\n14.8\n34.3\n37.1\n9\n10\n2.9\n1.2\n17\n0\n47.1\n205.9\n0.2\n330.6\n10.3\n836.4\n0\n614.6\n11.8\n0.9\n6.4\n40.3\n5.2\n138.8\n1.5\n14.1\n0.3\n0.5\n1.1\n0.9\n176.9\n4\n8.9\n0.3\n0.3\n0\n0.3\n1.6\n3\n0.8\n9.3\n8.1\n0.4\n5.2\n0.1\n20.4\n15.5\n2.5\n1.1\n4.4\n7.4\n0.5\n8.6\n29\n0.6\n0.1\n0\n27.2\n0.2\n0\n6.8\n2.4\n0\n0\n8.1\n\n\n…5\n2024 Oct\n33962.6\n3388.8\n0.2\n23.8\n4.3\n0.1\n154.9\n58.6\n6.3\n8.8\n2.5\n0\n1.9\n4.1\n0.3\n1.2\n1.4\n0.8\n2.3\n547.6\n0\n12.6\n0.2\n4.8\n2.8\n0.9\n0.9\n2544.6\n0\n0.7\n0\n2.3\n27278.7\n0\n28\n128.8\n1184\n173.3\n5097.4\n0\n4493.7\n1048.4\n2321.3\n0.4\n17.2\n45.9\n1308.4\n9\n0.8\n0\n1496.7\n25.8\n3.8\n1.4\n26.1\n3358.9\n13\n29.6\n32.9\n26.4\n24\n103.2\n917.9\n71.5\n58.7\n51.9\n0\n1518.2\n1805.4\n112.2\n407.5\n1321.6\n0.5\n14.6\n2288\n10.9\n0\n70.5\n1.9\n3.9\n2.3\n92.6\n9.9\n2.3\n12.5\n228.7\n537\n14.3\n26.1\n174.2\n95.3\n3.9\n1.5\n12.1\n10.3\n331.3\n9\n28.7\n45.2\n11.1\n6.2\n1.3\n2.4\n23.1\n0\n10.6\n139.5\n0.5\n364.5\n4.3\n821.3\n0\n601.1\n9.7\n2.2\n2.3\n48.5\n1.7\n144.2\n0.1\n8.9\n0.3\n0.3\n0.3\n1.7\n185.7\n30.5\n4.7\n0\n0.6\n0\n0\n1.3\n1.3\n1.6\n19.9\n7.3\n1.6\n3.5\n0\n7.2\n20.7\n1.8\n0.7\n2.9\n16.8\n1.2\n7.8\n0.4\n1.1\n0.3\n0.1\n24.1\n0\n0\n9.4\n2.8\n0.1\n0.1\n16\n\n\n…6\n2024 Sep\n32477.4\n3196.7\n0\n27.1\n8.1\n0\n203.4\n107.8\n23\n6.2\n1.8\n0\n1.1\n3.6\n0.6\n2.5\n1\n0.4\n0.8\n395.4\n0\n22.8\n0.3\n6.4\n3.7\n0.5\n0.8\n2376.7\n0\n1.3\n0\n1.4\n26314.1\n0.1\n5\n138.8\n57.6\n71.1\n5439.6\n0\n4432.6\n1165.5\n2557.8\n0.5\n6.4\n48.6\n1314.9\n6.3\n2.1\n0\n1463.2\n53.5\n5.2\n1.8\n10.3\n4021.4\n10.9\n16\n27.9\n20.9\n7.2\n54.4\n566.7\n45.9\n65.1\n40.2\n0\n1641.1\n1534\n60.2\n352.1\n1062.3\n0.5\n6.5\n2127.5\n18.8\n0.2\n47.7\n43.8\n2.9\n1.1\n40.8\n16\n2.2\n30.5\n207.3\n597.2\n17.6\n20.8\n60.4\n56.2\n2.3\n2.6\n14\n5.9\n360\n6.8\n42.7\n45.9\n10.3\n7.7\n1.2\n1.1\n19.7\n0\n29.6\n129.4\n0.1\n281.3\n3.3\n711.9\n0\n513.3\n6.8\n1\n2\n27.2\n2\n146.9\n0.1\n10.4\n0.1\n0.3\n0.5\n1.3\n127.2\n1.1\n3.1\n0.3\n1\n0\n0.1\n1.3\n3.5\n0.1\n15.4\n2\n0.5\n2.9\n0.3\n3.6\n18.2\n0.9\n0.9\n3.1\n8.1\n1\n2.8\n0.2\n0.6\n0\n0\n29.7\n0\n0\n7.5\n2.1\n6.8\n0.1\n9.9\n\n\n\n\n\n\n\n\nStep 3. Data wrangling\nIn this step, I will process the total amount from the year 2024 for each country / region for each trade category.\n\nIMPORTEXPORTRE-EXPORTCOMBINED\n\n\n\n\nShow the code\n# 1. Settle the header\nv2_trans_im_original &lt;- v2_trans_im\n\nheader_row &lt;- as.character(v2_trans_im[1,])\n\n# Apply as col names\ncolnames(v2_trans_im) &lt;- header_row \n\n# Remove the first row\nv2_trans_im &lt;- v2_trans_im[-1,]\n\n# 2. Extract years from the first column\nyears &lt;- substr(v2_trans_im[[1]], 1, 4)\nyears &lt;- as.numeric(years)\n\n# Add as a new column (without modifying existing columns)\nv2_trans_im$Year &lt;- years\n\n\n# 3. Now convert country columns to numeric\ncountry_cols_im &lt;- 2:(ncol(v2_trans_im)-1)  \nv2_trans_im[, country_cols_im] &lt;- lapply(v2_trans_im[, country_cols_im], function(x) {\n  as.numeric(as.character(x))\n})\n\n\nv2_trans_im_2024 &lt;- v2_trans_im[v2_trans_im$Year == 2024, ]\n\n# 4. Sum for each country\nv2_trans_im_2024_sum &lt;- v2_trans_im_2024 %&gt;%\n  select(-1, -ncol(v2_trans_im)) %&gt;%  # Remove first column and Year column\n  summarise(across(everything(), ~sum(., na.rm = TRUE)))\n\nv2_long_im &lt;- v2_trans_im_2024_sum %&gt;%\n  pivot_longer(cols = everything(), \n               names_to = \"Country\", \n               values_to = \"Im2024\")\nprint(head(v2_long_im))\n\n\n# A tibble: 6 × 2\n  Country               Im2024\n  &lt;chr&gt;                  &lt;dbl&gt;\n1 Total All Markets   611360. \n2 America              95346. \n3 Antigua And Barbuda      0.2\n4 Argentina              327. \n5 Bahamas                 27.9\n6 Bermuda                  1.1\n\n\n\n\n\n\nShow the code\n# 1. Settle the header\nv2_trans_ex_original &lt;- v2_trans_ex\n\nheader_row_ex &lt;- as.character(v2_trans_ex[1,])\n\n# Apply as col names\ncolnames(v2_trans_ex) &lt;- header_row_ex \n\n# Remove the first row\nv2_trans_ex &lt;- v2_trans_ex[-1,]\n\n# 2. Extract years from the first column\nyears &lt;- substr(v2_trans_ex[[1]], 1, 4)\nyears &lt;- as.numeric(years)\n\n# Add as a new column (without modifying existing columns)\nv2_trans_ex$Year &lt;- years\n\n# 3. Now convert country columns to numeric\ncountry_cols_ex &lt;- 2:(ncol(v2_trans_ex)-1)  \nv2_trans_ex[, country_cols_ex] &lt;- lapply(v2_trans_ex[, country_cols_ex], function(x) {\n  as.numeric(as.character(x))\n})\n\nv2_trans_ex_2024 &lt;- v2_trans_ex[v2_trans_ex$Year == 2024, ]\n\n# 4. Sum for each country\nv2_trans_ex_2024_sum &lt;- v2_trans_ex_2024 %&gt;%\n  select(-1, -ncol(v2_trans_ex)) %&gt;%  # Remove first column and Year column\n  summarise(across(everything(), ~sum(., na.rm = TRUE)))\n\nv2_long_ex &lt;- v2_trans_ex_2024_sum %&gt;%\n  pivot_longer(cols = everything(), \n               names_to = \"Country\", \n               values_to = \"Ex2024\")\nprint(head(v2_long_ex))\n\n\n# A tibble: 6 × 2\n  Country               Ex2024\n  &lt;chr&gt;                  &lt;dbl&gt;\n1 Total All Markets   286598. \n2 America              43134  \n3 Antigua And Barbuda    127. \n4 Argentina               67.4\n5 Bahamas                849. \n6 Bermuda                 48.3\n\n\n\n\n\n\nShow the code\n# 1. Settle the header\nv2_trans_reex_original &lt;- v2_trans_reex\n\nheader_row_reex &lt;- as.character(v2_trans_reex[1,])\n\n# Apply as col names\ncolnames(v2_trans_reex) &lt;- header_row_reex \n\n# Remove the first row\nv2_trans_reex &lt;- v2_trans_reex[-1,]\n\n# 2. Extract years from the first column\nyears &lt;- substr(v2_trans_reex[[1]], 1, 4)\nyears &lt;- as.numeric(years)\n\n# Add as a new column (without modifying existing columns)\nv2_trans_reex$Year &lt;- years\n\n# 3. Now convert country columns to numeric\ncountry_cols_reex &lt;- 2:(ncol(v2_trans_reex)-1)  \nv2_trans_reex[, country_cols_reex] &lt;- lapply(v2_trans_reex[, country_cols_reex], function(x) {\n  as.numeric(as.character(x))\n})\n\nv2_trans_reex_2024 &lt;- v2_trans_reex[v2_trans_reex$Year == 2024, ]\n\n# 4. Sum for each country\nv2_trans_reex_2024_sum &lt;- v2_trans_reex_2024 %&gt;%\n  select(-1, -ncol(v2_trans_reex)) %&gt;%  # Remove first column and Year column\n  summarise(across(everything(), ~sum(., na.rm = TRUE)))\n\nv2_long_reex &lt;- v2_trans_reex_2024_sum %&gt;%\n  pivot_longer(cols = everything(), \n               names_to = \"Country\", \n               values_to = \"ReX2024\")\nprint(head(v2_long_reex))\n\n\n# A tibble: 6 × 2\n  Country              ReX2024\n  &lt;chr&gt;                  &lt;dbl&gt;\n1 Total All Markets   387907. \n2 America              35664. \n3 Antigua And Barbuda      2.1\n4 Argentina              253. \n5 Bahamas                 92.8\n6 Bermuda                  0.8\n\n\n\n\nNow I will combine the 3 data sets, and also sum up the Export values. I noticed that the original plot has EU together as a trade partner, so I will also combine the 27 EU countries into one new row “EU”.\n\n\nShow the code\n# First, join import and export data\nv2_ImEx &lt;- v2_long_im %&gt;%\n  full_join(v2_long_ex, \n            by = \"Country\")  # Join by country name\n\nv2_combine &lt;- v2_ImEx %&gt;%\n  full_join(v2_long_reex,\n            by = \"Country\")\n\n# Compute Export total\nv2_combine$Ex_total &lt;- v2_combine$Ex2024 + v2_combine$ReX2024\n\n# Compute Surplus/deficit\nv2_combine$Bal2024 &lt;- v2_combine$Ex_total - v2_combine$Im2024\nhead(v2_combine)\n\n\n# A tibble: 6 × 6\n  Country               Im2024   Ex2024  ReX2024 Ex_total   Bal2024\n  &lt;chr&gt;                  &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 Total All Markets   611360.  286598.  387907.  674505    63145.  \n2 America              95346.   43134    35664.   78798.  -16549.  \n3 Antigua And Barbuda      0.2    127.       2.1    130.     129.  \n4 Argentina              327.      67.4    253.     321.      -6.60\n5 Bahamas                 27.9    849.      92.8    942.     914.  \n6 Bermuda                  1.1     48.3      0.8     49.1     48   \n\n\nShow the code\n# Compute total trade volume\nv2_combine$Total2024 &lt;- v2_combine$Ex_total + v2_combine$Im2024\n\n# Add EU\neu_countries &lt;- c(\"Austria\", \"Belgium\", \"Bulgaria\", \"Croatia\", \"Cyprus\", \"Czech Rep\", \"Denmark\", \"Estonia\",\n                  \"Finland\", \"France\", \"Germany\", \"Greece\", \"Hungary\", \"Ireland\", \"Italy\", \"Latvia\",\n                  \"Lithuania\", \"Luxembourg\",  \"Malta\", \"Netherlands\", \"Poland\", \"Portugal\", \"Romania\",\n                  \"Slovakia\", \"Slovenia\", \"Spain\", \"Sweden\")\n\neu_values &lt;- v2_combine %&gt;%\n  filter(Country %in% eu_countries) %&gt;%\n  summarise(\n    Im2024 = sum(Im2024, na.rm = TRUE),\n    Ex2024 = sum(Ex2024, na.rm = TRUE),\n    ReX2024 = sum(ReX2024, na.rm = TRUE),\n    Ex_total = sum(Ex_total, na.rm = TRUE),\n    Bal2024 = sum(Bal2024, na.rm = TRUE),\n    Total2024 = sum(Total2024, na.rm = TRUE)\n  ) %&gt;%\n  mutate(Country = \"EU\")\n\nv2_con_eu &lt;- bind_rows(v2_combine, eu_values)\n\n\n\n\n\n\n\n2.2.4 Visualisation make-over\nLaunch packages\n\n\nShow the code\nlibrary(ggplot2)\nlibrary(scales)  # For formatting labels\nlibrary(plotly)\n\n\nPlot the visualisation\nThe plot will be a similar scatter plot with new color scheme and interactive tooltip showing more information of the country hovered over. This plot uses ggplot2 with ggplotly to show interactivity of the tooltips.\n\n\nShow the code\n# Filter data\nv2_filter &lt;- v2_con_eu %&gt;%\n  filter(!Country %in% c(\"Total All Markets\", \"America\", \"Asia\", \"Europe\", \"Oceania\", \"Africa\")) %&gt;%\n  arrange(desc(Total2024)) %&gt;%\n  head(10)  \n\n#legend breaks\nlegend_breaks &lt;- c(20, 40, 60, 80)\n\n# Create a dot plot\nv2_plot &lt;- ggplot(v2_filter, \n                  aes(x = Ex_total/1000, y = Im2024/1000)) + \n  # Create bubbles\n  geom_point(aes(size = Total2024/1000,  # Size by total trade \n                 color = Bal2024/1000,       # Color by trade balance \n                 alpha = 0.8)) +                 \n  # Custom color scale for surplus/deficit\n  scale_color_gradient2(\n    name = \"Trade Balance (S$ Bil.)\",\n    low = \"#690B22\",      \n    mid = \"white\",        \n    high = \"#1B4D3E\",    \n    midpoint = 0,        \n    labels = dollar_format(prefix = \"$\", suffix = \"B\")\n  ) +\n  \n  # Scale for bubble size\n  scale_size_continuous(\n    name = \"Total Trade (S$ Bil.)\",\n    range = c(5, 20), \n    breaks = legend_breaks,  \n    labels = dollar_format(prefix = \"$\", suffix = \"B\")\n  ) +\n  # Add country labels for bubbles\n#  geom_text(\n#    aes(label = Country),\n#    check_overlap = TRUE,\n#    vjust = 1,\n#    hjust = 1,\n#    size = 3\n#  ) +\n  # Add a diagonal reference line (imports = exports)\n  geom_abline(intercept = 0, slope = 1, linetype = \"solid\", \n              color = \"#73C7C7\", alpha = 0.5,\n              linewidth = 0.2) +\n  labs(\n    title = \"Singapore Merchandise Trade Relationships, 2024\",\n#    subtitle = \"Bubble size represents total trade volume, color indicates trade balance\",\n    x = \"Exports (S$ Bil.)\",\n    y = \"Imports (S$ Bil.)\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"right\",\n    plot.title = element_text(face = \"bold\", size = 17, family = \"Arial\"),\n    panel.grid.minor = element_blank(),\n    plot.background = element_rect(fill = \"#f1f4f5\", color = NA),\n    panel.background = element_rect(fill = \"#f1f4f5\", color = NA),\n    legend.background = element_rect(fill = \"#f1f4f5\", color = NA),\n    axis.title.x = element_text(size = 10, face = \"bold\", family = \"Arial\"),  \n    axis.title.y = element_text(size = 10, face = \"bold\", family = \"Arial\"), \n    axis.text.x = element_text(size = 8),  \n    axis.text.y = element_text(size = 8),\n    legend.text = element_text(size = 8, face = \"bold\", family = \"Arial\"),\n    legend.title = element_text(size = 10, face = \"bold\", family = \"Arial\")\n  ) +\n  # Format axis labels\n  scale_x_continuous( limits = c(0, 100)) +\n  scale_y_continuous( limits = c(0, 100)) +\n  guides(alpha = FALSE, fill = FALSE,\n         size = guide_legend(\n           override.aes = list(\n             color = \"grey90\",\n             alpha = 0.8\n           )\n         )) +\n  scale_alpha_identity() +  # Force alpha to be treated as fixed\n  scale_fill_identity() \n\n# Convert ggplot to plotly\np &lt;- ggplotly(v2_plot, tooltip = \"none\")\n\n# Set hover text\np$x$data[[1]]$text &lt;- paste(\n  \"Country:\", v2_filter$Country,\n  \"&lt;br&gt;Exports: $\", round(v2_filter$Ex_total/1000, 1), \"B\",\n  \"&lt;br&gt;Imports: $\", round(v2_filter$Im2024/1000, 1), \"B\",\n  \"&lt;br&gt;Balance: $\", round(v2_filter$Bal2024/1000, 1), \"B\",\n  \"&lt;br&gt;Total Trade: $\", round(v2_filter$Total2024/1000, 1), \"B\"\n)\np$x$data[[1]]$hoverinfo &lt;- \"text\"\np$layout$hovermode &lt;- \"closest\"\n\np &lt;- p %&gt;% add_annotations(\n  x = v2_filter$Ex_total/1000,\n  y = v2_filter$Im2024/1000,\n  text = v2_filter$Country,\n  showarrow = FALSE,\n  yshift = 15,  # Move 20 pixels up (similar to negative vjust)\n  xshift = 10,   # No horizontal shift\n  font = list(size = 12, color = \"black\", family = \"Arial\")\n)\n\np\n\n\n\n\n\n\n\n\nMake-over\n\n\n\nColor - The original plot assigns a color for each country, which makes no distinction for the countries. In the make-over, I scale down the color scheme to two, green and red. These colors are used to show whether the country is in Surplus or Deficit position to Singapore.\nInteractive tooltip - Instead of using a dotted line and label, a tooltip is applied so viewers can hover over the bubble to understand the details. This avoids overcorwding of the plot.\nTrade partner by Surplus/Deficit scale - Instead of using full color styling, the two color scheme is designed to show whether it is a surplus (Export &gt; Import) or deficit (Import &gt; Export). The color is gradient according to the amount of trade balance. If it is negative, the bubble truns red, and vice versa.\nTotal trade volume - Maintained total trade volume presentation in the form of bubble size.\n\nThese improvements make the trade relationships clearer and allow viewers to quickly identify key patterns while accessing detailed information on demand.\n\n\n\n\n\n2.3 Visualisation #3 Mirror Bar Chart\n\n\n\n\n\nPROSCONSSKETCH\n\n\n\nComprehensiveness - It clearly shows import/export data for major trading partners across two time periods (2019 and 2023)\nRanking systme - The ranking system (gold, silverm bronze medals) makes it easy to identify top trading partners.\nCountry flags - Helps with quick visual identification.\nTemporal comparison - The side-by-side comparison of 2019 and 2023 allows for easy temporal comparison.\n\n\n\nUGLY\n\nColor scheme - The visualization uses 30+ colors without a clear system. It creates visual noise and makes it difficult to focus on the most important information\nInconsistent color mapping - Colours don’t consistenly represent countries, time periods, or import/export categories.\n\nBAD\n\nFont size - The value annotations compete with the bars for visual attention.\nMulti-dimensional comparison - Trying to compare imports vs exports across multiple countries and two time periods creates high cognitive load and confusion.\nInconsistent entity classification - Mixing individual countries (US, Japan) with regional blocs (EU-27, ASEAN) without explanation.\nRanking methodology - There is no indication of what metric determines the gold/silver/bronze rankings.\n\nWRONG\n\nBar chart - It doesn’t effectively show the relationship between imports and exports for each entity.\nInconsistent period of comparison - While other visualisations on the website show data from 2020 to 2024, this chart displays 2019 vs 2023. The inconsistency disrupts the overall narrative and prevents viewers from making direct comparisons across different visualisations the holistic information of presenting the recent data.\n\n\n\n\n\n\n\n\n\n\n2.3.3 Data\nStep 1. Load and launch packages\n\n\nShow the code\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(tidyverse)  \nlibrary(stringr)\nlibrary(knitr)\nlibrary(ggflags)\nlibrary(countrycode)\nlibrary(ggiraph)\nlibrary(ggplot2)\n\n\nStep 2. Import data & make subsets\n\nIMPORT EXCELIMPORTEXPORT\n\n\n\n\nShow the code\nv3_data_import &lt;- read_xlsx(\"data/Mtrade_service.xlsx\", \"T7\")\nv3_data_export &lt;- read_xlsx(\"data/Mtrade_service.xlsx\", \"T3\")\n\nhead(v3_data_import)\n\n\n# A tibble: 6 × 25\n  ...1   ...2  ...3  ...4  ...5  ...6  ...7  ...8  ...9  ...10 ...11 ...12 ...13\n  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n1 Theme… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n2 Subje… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n3 Topic… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n4 Table… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n5 &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n6 Data … &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n# ℹ 12 more variables: ...14 &lt;chr&gt;, ...15 &lt;chr&gt;, ...16 &lt;chr&gt;, ...17 &lt;chr&gt;,\n#   ...18 &lt;chr&gt;, ...19 &lt;chr&gt;, ...20 &lt;chr&gt;, ...21 &lt;chr&gt;, ...22 &lt;chr&gt;,\n#   ...23 &lt;chr&gt;, ...24 &lt;chr&gt;, ...25 &lt;chr&gt;\n\n\n\n\nObservation\n\n\n\nThe dataset contains annual import data for services by country from 2000 to 2023.\nA key issue with the original visualization is the inconsistency in the data period. While other visualizations cover 2020-2024, this one compares 2019 to 2023. As the most recent data available in the DOS dataset is from 2023, I will use this period for the updated visualization.\nAdditionally, the dataset treats the European Union and ASEAN as single entities, so I will retain this grouping in the plot.\n\n\n\n\n\nMake a subset for data wrangling In this step, I will extrac the import data from 2019 and 2023 for all countries.\n\n\nShow the code\n# Select needed rows and change header.\nnew_header_im &lt;- as.character(unlist(v3_data_import[10,]))\nv3_subset_im &lt;- v3_data_import[11:78,]\nnames(v3_subset_im) &lt;- new_header_im\n\n# Select year 2019 and 2023\nv3_years_im &lt;- v3_subset_im %&gt;%\n  select(\"Data Series\", \"2023\", \"2019\")\n\nhead(v3_years_im)\n\n\n# A tibble: 6 × 3\n  `Data Series`     `2023`   `2019` \n  &lt;chr&gt;             &lt;chr&gt;    &lt;chr&gt;  \n1 Asia              139497.1 83242.3\n2 Bangladesh        468.8    380.9  \n3 Brunei Darussalam 196.8    49.2   \n4 Cambodia          121.2    217.9  \n5 Hong Kong         20255.7  13093.5\n6 India             13532.6  7813.9 \n\n\n\n\nMake a subset for data wrangling In this step, I will extrac the export data from 2019 and 2023 for all countries.\n\n\nShow the code\n# Select needed rows and change header.\nnew_header_ex &lt;- as.character(unlist(v3_data_export[10,]))\nv3_subset_ex &lt;- v3_data_export[11:78,]\nnames(v3_subset_ex) &lt;- new_header_ex\n\n# Select year 2019 and 2023\nv3_years_ex &lt;- v3_subset_ex %&gt;%\n  select(\"Data Series\", \"2023\", \"2019\")\n\nhead(v3_years_ex)\n\n\n# A tibble: 6 × 3\n  `Data Series`     `2023`   `2019`  \n  &lt;chr&gt;             &lt;chr&gt;    &lt;chr&gt;   \n1 Asia              170787.7 114573.1\n2 Bangladesh        985.7    642.4   \n3 Brunei Darussalam 960.1    556.4   \n4 Cambodia          475.6    259.1   \n5 Hong Kong         21686.1  11273.2 \n6 India             9909.4   6383.4  \n\n\n\n\n\nStep 3. Data Wrangling\nIn this step, I will combine the import and export data into one for ploting a slopegraphic plot.\n\n\nShow the code\n#Import set\nimport_long &lt;- v3_years_im %&gt;%\n  rename(Country = `Data Series`) %&gt;%\n  pivot_longer(\n    cols = -Country,\n    names_to = \"Year\",\n    values_to = \"Value\"\n  ) %&gt;%\n  \n  mutate(Type = \"Import\") %&gt;%\n  arrange(Country, Year)\n\n#Export set\nexport_long &lt;- v3_years_ex %&gt;%\n  rename(Country = `Data Series`) %&gt;%\n  pivot_longer(\n    cols = -Country,\n    names_to = \"Year\",\n    values_to = \"Value\"\n  ) %&gt;%\n  \n  mutate(Type = \"Export\") %&gt;%\n  arrange(Country, Year)\n\n# Combine datasets\nv3_combine &lt;- bind_rows(import_long, export_long) %&gt;%\n  arrange(Country, Year, Type)\n\n# Remove regions like Asia, North America\nregion_exclude &lt;- c(\"Asia\", \"Europe\", \"North America\", \"Africa\",\n                    \"South And Central America And The Caribbean\",\n                    \"Oceania\")\n\n# Covert Value to numeric type\nv3_convert &lt;- v3_combine %&gt;%\n  mutate(\n    Value = gsub(\"[^0-9.-]\", \"\", Value), #remove commas or non-numeric stuff\n    Value = as.numeric(Value),\n    Year = as.numeric(as.character(Year))\n    ) %&gt;%\n  filter(!Country %in% region_exclude)\n\n #Remove USA data\n#v3_convert &lt;- v3_convert %&gt;%\n#  filter(!grepl(\"United States Of America\", Country, ignore.case = TRUE)) %&gt;%\n#  filter(!grepl(\"United Kingdom\", Country, ignore.case = TRUE))\n\n#usa_data &lt;- tibble(\n#  Country = rep(c(\"U.S.\", \"U.K.\"), each = 4),\n#  Year = rep(c(2019, 2019, 2023, 2023), 2),\n#  Value = c(29277.2, 50735.4, 51122.8, 108025.0,\n#            13785, 8404.7, 20205.7, 16655.8\n#),\n#  Type = rep(c(\"Export\", \"Import\", \"Export\", \"Import\"), 2))\n\n#v3_usa &lt;- bind_rows(v3_convert, usa_data)\n\n# Filter top 10 countries by total value in 2023\ntop_countries &lt;- v3_convert %&gt;%\n  filter(Year == \"2023\") %&gt;%\n  group_by(Country) %&gt;%\n  summarize(TotalValue = sum(Value, na.rm = TRUE)) %&gt;%\n  arrange(desc(TotalValue)) %&gt;%\n  slice_head(n=10) %&gt;%\n  pull(Country)\n\n\n\n\n2.3.4 Visualisation make-over\n\n\nShow the code\nregional_groups &lt;- c(\"ASEAN\", \"European Union (EU-27)\")\n\nslope_data &lt;- v3_convert %&gt;%\n  filter(Year %in% c(2019, 2023)) %&gt;%\n  mutate(Year = as.factor(Year))\n\n\nslope_data_top &lt;- slope_data %&gt;%\n  filter(Country %in% top_countries) %&gt;%\n  mutate(\n    country_code = tolower(countrycode(Country, origin = \"country.name\", \n                                       destination = \"iso2c\")\n    )\n  )\n# Create the interactive plot\np &lt;- ggplot(slope_data_top, aes(x = Year, y = Value, \n                                group = interaction(Country, Type), color = Country)) +\n  geom_line_interactive(aes(data_id = Country), size = 1) +\n  \n  geom_flag(\n    data = subset(slope_data_top, Year == \"2023\"),\n    aes(country = country_code),\n    size = 6\n  ) +\n  \n  # Add interactive points with tooltips\n  geom_point_interactive(\n    data = subset(slope_data_top, Year == \"2019\"),\n    aes(data_id = Country, \n        tooltip = paste0(Country, \": S$\", round(Value/1000,1), \"B\")), \n    size = 2\n  ) +\n\n  geom_point_interactive(\n    data = subset(slope_data_top, Year == \"2023\"),\n    aes(data_id = Country, \n        tooltip = paste0(Country, \": S$\", round(Value/1000,1), \"B\")), \n    size = 0.1\n  ) +\n  \n  # Text labels for countries (positioned to account for flags)\n  geom_text_interactive(\n    data = subset(slope_data_top, Year == \"2023\"), \n    aes(label = Country, data_id = Country), \n    hjust = -0.2,\n    nudge_x = 0.02,\n    size = 2.5,\n    fontface = \"bold\"\n  ) +\n  #scale Y to bil.\n  scale_y_continuous(\n  \n  ) +\n  \n  # Side-by-side panels\n  facet_wrap(~Type, scales = \"free_x\") +\n  scale_color_manual(values = colorRampPalette(c(\"#A5BFCC\", \"#EFDCAB\", \"#C599B6\", \"#FFCFCF\", \"#C7DB9C\", \"#98D8EF\", \"#B6CBBD\", \"#FFCDB2\", \"#EABDE6\", \"#A9B5DF\"))(10)) +\n  scale_y_continuous(\n    name = \"Value (SGD$ Bil.)\",\n    labels = function(x) paste0(x/1000),  # Convert from millions to billions\n    limits = c(0, 109000)) +\n  labs(title = \"Major Trading Partners for Trade in Services\",\n  subtitle = \"2019 vs 2023\") +\n  geom_vline(xintercept = \"2019\", linetype = \"solid\", \n             color = \"#E3D2C3\", size = 0.7, alpha = 0.7) +\n  geom_vline(xintercept = \"2023\", linetype = \"solid\", \n             color = \"#E3D2C3\", size = 0.7, alpha = 0.7) +\n\n  theme_minimal() +\n  theme(legend.position = \"bottom\",\n        strip.text = element_text(size = 14, color = \"#F6D776\", face = \"bold\"),\n        plot.title = element_text(hjust = 0, size = 16, face = \"bold\", family = \"Arial\", color = \"white\"),\n        plot.subtitle = element_text(hjust = 0, size = 14, face = \"bold\", family = \"Arial\", color = \"white\"),\n        plot.background = element_rect(fill = \"#525E75\", color = \"#525E75\"),\n        axis.title.x = element_text(size = 12, face = \"bold\", family = \"Arial\", color = \"white\"),\n        axis.title.y = element_text(size = 12, face = \"bold\", family = \"Arial\", color = \"white\"),\n        axis.text.x = element_text(color = \"white\"),\n        axis.text.y = element_text(color = \"grey80\"),\n        panel.grid.major = element_line(color = \"gray60\", size = 0.4, linetype = \"dashed\"),\n        panel.grid.minor = element_line(color = \"grey50\", size = 0.25, linetype = \"dotted\"),\n        legend.text = element_text(color = \"grey80\"),\n        plot.margin = margin(t = 30, r = 20, b = 10, l = 20),\n        legend.title = element_text(color = \"grey80\")\n        ) \n\ngirafe(ggobj = p, width_svg = 7, height_svg = 10) %&gt;%\n  girafe_options(\n    opts_sizing(rescale = FALSE),\n    opts_hover(css = \"stroke-width:3px;\"),\n    opts_hover_inv(css = \"opacity:0.2;\")\n  )\n\n\n\n\n\n\n\n\nMake-over\n\n\n\nTitle - The title reflects the comparison between 2019 and 2023, not only 2023.\nTop 10 countries - In the original plot, it has India rather than Ireland. I took a guess that it meant top 10 total trade volume in 2023, because India is the 11th. The re-designed plot has Ireland rather than India in top 10, because it has filtered out the EU countries. Maybe it does not want to show individual countries, but I think it is better to show so viewers see the prominence and actual data insights.\nDivide Import and Export - The slopgraph has clearly defined Import and Export sections, so viewers can easily see the difference between the two trade categories.\nHover effect - With the interactive element, viewer can hover over the country slope, and it will emphasise the country while dehighlight the rest to compare how the trend is in both trade categories.\nTooltip - Tooltip is applied to show the actual Import and Export values if viewers with to know. The tool tip prevent the plot from being too crowded.\n\n\n\n\n\n\n2.4 Summary\nThe visualisations on the DOS website has a consistent theme and vibrant colors. This makes the website overall looks visually pleasant and inviting. The disadvantage is that it does not focus on enhancing understanding the data and insights quickly and meaningfully. The visualisation re-designs above took into consideration of data interpretation to ensure information is clearly conveyed to viewers. The themes together may not be coherent as it requires advanced levels of plotting with R packages. This can be the future work of the make-over task."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03.html#singapore-merchandise-trade-data-analysis",
    "href": "Take-home_Ex/Take-home_Ex03.html#singapore-merchandise-trade-data-analysis",
    "title": "Take-home_Ex03",
    "section": "3 Singapore Merchandise Trade Data Analysis",
    "text": "3 Singapore Merchandise Trade Data Analysis\nThis section analyses Singapore’s merchandise trade data, focusing on trading patterns and changes in partnerships over time. As a key global trading hub, Singapore facilitates significant cargo transit, influencing international trade flows. The data provides insights into Singapore’s trading relationships and the dynamics of its import and export activities.\n\n3.1 Objectives\nThis analysis aims to examine historical trading patterns and forecast future trends. The approach includes:\n\nTime-Series Analysis: Visualising Singapore’s monthly trade data from 1999 onwards to identify trends and patterns.\nTime-Series Forecasting: – Applying forecasting models to evaluate future trade dynamics and interpreting the results.\n\n\n\n3.2 Data\nThe main dataset is the Merchandise Trade Excel files downloaded from the Department of Statistics Singapore. The Excel file includes 3 sets of data: 1. Merchandise Trade By Region And Selected Market (Imports), Monthly 2. Merchandise Trade By Region And Selected Market (Domestic Exports), Monthly 3. Merchandise Trade By Region And Selected Market (Re-Exports), Monthly. The data spans from January 2003 to January 2025. However, for most analyses in this report, only data from 2015 to 2025 is used. The dataset covers 160 countries and regions, with some entries representing aggregated data.\nStep 1. Load and launch packages\n\npacman::p_load(fpp3, readxl, readr, ggplot2, patchwork, stringr, tidyr)\n\nStep 2. Import the data & make subsets\n\nMONTHLY TRADE INSTENSITYSEASONAL TRADE PATTERNSSINGAPORE RE-EXPORT ANALYSISMARKET SHARE TREND\n\n\nIn 3.3, a calendar heatmap will be plotted to show monthly merchandise trade intensity and by Import, Export, Re-Export categories. Therefore, data will be retrieved from 3 different tabs from the Merchandise Trade by REgion Excel files. The subset will be extracted to separate csv files, and will be read later in resepective data wrangling phase.\n\n\nShow the code\n# ---- Import by month\nim_region_month_data &lt;- read_xlsx(\"data/Mtrade_region.xlsx\", \"T1\")\nim_region_month_csv &lt;- im_region_month_data[c(10:170),]\n\n# After transpose, the data is a matrix.\nim_region_month_matrix &lt;- t(im_region_month_csv) \n#now convert the matrix to df.\nim_region_month &lt;- as.data.frame(im_region_month_matrix)\n\n# Correct the column name\nreal_column_names_im &lt;- as.character(im_region_month[1, ])\ncolnames(im_region_month) &lt;- real_column_names_im\n\n# remove the first row\nim_region_month &lt;- im_region_month[-1, ]\n\n\n# Turn the dataframe to a csv file for easy calling. Run only once. \n#write.csv(im_region_month, \"im_region_month.csv\") \n# Will move the file to data folder\n\n# ---- Export by month\nex_region_month_data &lt;- read_xlsx(\"data/Mtrade_region.xlsx\", \"T2\")\nex_region_month_csv &lt;- ex_region_month_data[c(10:170),]\n\n\n# After transpose, the data is a matrix.\nex_region_month_matrix &lt;- t(ex_region_month_csv) \n#now convert the matrix to df.\nex_region_month &lt;- as.data.frame(ex_region_month_matrix)\n\n# Correct the column name\nreal_column_names_ex &lt;- as.character(ex_region_month[1, ])\ncolnames(ex_region_month) &lt;- real_column_names_ex\n\n# remove the first row\nex_region_month &lt;- ex_region_month[-1, ]\n\n# Turn the dataframe to a csv file for easy calling. Run only once. \n#write.csv(ex_region_month, \"ex_region_month.csv\") \n# Will move the file to data folder\n\n\n# ---- ReExport by month\nrex_region_month_data &lt;- read_xlsx(\"data/Mtrade_region.xlsx\", \"T3\")\nrex_region_month_csv &lt;- rex_region_month_data[c(10:170),]\n#head(rex_by_month_csv)\n\n# After transpose, the data is a matrix.\nrex_region_month_matrix &lt;- t(rex_region_month_csv) \n#now convert the matrix to df.\nrex_region_month &lt;- as.data.frame(rex_region_month_matrix)\n\n# Correct the column name\nreal_column_names_rex &lt;- as.character(rex_region_month[1, ])\ncolnames(rex_region_month) &lt;- real_column_names_rex\n\n# remove the first row\nrex_region_month &lt;- rex_region_month[-1, ]\n\n# Turn the dataframe to a csv file for easy calling. Run only once. \n#write.csv(rex_region_month, \"rex_region_month.csv\") \n# Will move the file to data folder\n\n\n\n\nTo understand seasonal trade patterns by trading partner in 3.4, I will use the Merchandise Trade by Region/Market dataset from DOS. This data set has the merchandise trade by region and markets for Imports, Export and Re-export. I will combine the subsets into one csv file for the analysis. Similar to Monthly Trade Intensity Analysis, 3 tabs from this Excel file will be imported and make subsets into separate csv files.\n\n\nShow the code\n# ---- Import by region\nim_by_reg_data &lt;- read_xlsx(\"data/Mtrade_region.xlsx\", \"T1\")\nim_by_reg_csv &lt;- im_by_reg_data[c(10: 170),]\n\n# After transpose, the data is a matrix.\nim_by_reg_matrix &lt;- t(im_by_reg_csv) \n#now convert the matrix to df.\nim_by_reg &lt;- as.data.frame(im_by_reg_matrix)\n\n# Correct the column name\nreal_column_names_imreg &lt;- as.character(im_by_reg[1, ])\ncolnames(im_by_reg) &lt;- real_column_names_imreg\n\n# remove the first row\nim_by_reg &lt;- im_by_reg %&gt;%\n  slice(-1) \n\n\n# Turn the dataframe to a csv file for easy calling. Run only once. \n#write.csv(im_by_reg, \"im_by_reg.csv\") \n# Will move the file to data folder\n\n# ---- Export by region\nex_by_reg_data &lt;- read_xlsx(\"data/Mtrade_region.xlsx\", \"T2\")\nex_by_reg_csv &lt;- ex_by_reg_data[c(10: 170),]\n\n# After transpose, the data is a matrix.\nex_by_reg_matrix &lt;- t(ex_by_reg_csv) \n#now convert the matrix to df.\nex_by_reg &lt;- as.data.frame(ex_by_reg_matrix)\n\n# Correct the column name\nreal_column_names_exreg &lt;- as.character(ex_by_reg[1, ])\ncolnames(ex_by_reg) &lt;- real_column_names_exreg\n\n# remove the first row\nex_by_reg &lt;- ex_by_reg %&gt;%\n  slice(-1) \n\n# Turn the dataframe to a csv file for easy calling. Run only once. \n#write.csv(ex_by_reg, \"ex_by_reg.csv\") \n# Will move the file to data folder\n\n# ---- Re-Export by region\nrex_by_reg_data &lt;- read_xlsx(\"data/Mtrade_region.xlsx\", \"T3\")\nrex_by_reg_csv &lt;- rex_by_reg_data[c(10: 170),]\n\n# After transpose, the data is a matrix.\nrex_by_reg_matrix &lt;- t(rex_by_reg_csv) \n#now convert the matrix to df.\nrex_by_reg &lt;- as.data.frame(rex_by_reg_matrix)\n\n# Correct the column name\nreal_column_names_rexreg &lt;- as.character(rex_by_reg[1, ])\ncolnames(rex_by_reg) &lt;- real_column_names_rexreg\n\n# remove the first row\nrex_by_reg &lt;- rex_by_reg %&gt;%\n  slice(-1) \n\n# Turn the dataframe to a csv file for easy calling. Run only once. \n#write.csv(rex_by_reg, \"rex_by_reg.csv\") \n# Will move the file to data folder\n\n\n\n\nThe fact that Singapore being a pivotal trading hub, the Re-Export data is important to understand what goods have leveraged Singapore as its transition hub to see or forward to other place. 2 data sets from the Merchandise Trade by Commodity Section/Division Excel file will be used.\n\n\nShow the code\n# ---- ReX Commodity\nrex_by_com_data &lt;- read_xlsx(\"data/Mtrade_commodity.xlsx\", \"T9\")\nrex_by_com_csv &lt;- rex_by_com_data[c(10:37),]\n\n# After transpose, the data is a matrix.\nrex_by_com_matrix &lt;- t(rex_by_com_csv) \n#now convert the matrix to df.\nrex_by_com &lt;- as.data.frame(rex_by_com_matrix)\n\n# Correct the column name\nreal_column_names_rexcom &lt;- as.character(rex_by_com[1, ])\ncolnames(rex_by_com) &lt;- real_column_names_rexcom\n\n# remove the first row\nrex_by_com &lt;- rex_by_com %&gt;%\n  slice(-1) \n\n# Turn the dataframe to a csv file for easy calling. Run only once. \nwrite.csv(rex_by_com, \"rex_by_com.csv\") \n# Will move the file to data folder\n\n# ---- ReX Machinery\nrex_by_mac_data &lt;- read_xlsx(\"data/Mtrade_commodity.xlsx\", \"T10\")\nrex_by_mac_csv &lt;- rex_by_mac_data[c(10:22),]\n\n# After transpose, the data is a matrix.\nrex_by_mac_matrix &lt;- t(rex_by_mac_csv) \n#now convert the matrix to df.\nrex_by_mac &lt;- as.data.frame(rex_by_mac_matrix)\n\n# Correct the column name\nreal_column_names_rexmac &lt;- as.character(rex_by_mac[1, ])\ncolnames(rex_by_mac) &lt;- real_column_names_rexmac\n\n# remove the first row\nrex_by_mac &lt;- rex_by_mac %&gt;%\n  slice(-1) \n\n# Turn the dataframe to a csv file for easy calling. Run only once. \nwrite.csv(rex_by_mac, \"rex_by_mac.csv\") \n# Will move the file to data folder\n\n\n\n\nThe Market Share Trend Analysis in 3.6 aims to understand Singapore trade balance with its trading partners. For this analysis, the dataset derived for heatmaps will be reused for data wrangling.\n\n\n\n\n\n3.3 Monthly Trade Intensity Analysis\nIn this analysis, I will use the monthly trade data from the previously converted csv file trade_by_month.csv to plot a calendar heatmap. From the heatmap, I wish to observe the monthly intensity for the recent 25 years.\n\n3.3.1 Data wrangling\n\nIMPORTEXPORTRE-EXPORT\n\n\n\n\nShow the code\nim_mon &lt;- read_csv(\"data/im_region_month.csv\")\n\n# Prepare data for calendar heatmap\nregion_exlude_cal &lt;- c(\"Total All Markets\", \"America\", \"Asia\", \"Europe\", \"Oceania\", \"Africa\")\n\nim_mon_calendar &lt;- im_mon %&gt;%\n  select(-1) %&gt;%\n  rename(date_str = `Data Series`) %&gt;%\n  \n  pivot_longer(\n    -date_str,\n    names_to = \"Country\",\n    values_to = \"trade_value\"\n  ) %&gt;%\n  mutate(\n    year = as.numeric(str_extract(date_str, \"\\\\d{4}\")),\n    month_str = str_extract(date_str, \"[A-Za-z]{3}\"),\n    month = month_str,\n    month_num = match(month_str, month.abb),    \n    date = ymd(paste(year, month, \"01\", sep = \"-\")),\n    trade_value_mil = round(trade_value / 1000, 5),\n    yearmonth = floor_date(date, \"month\"),\n    year_factor = as.factor(year)\n  ) %&gt;%\n  \n  filter(year &gt;= 2015 & year &lt;= 2025) %&gt;%\n  \n  select(date, year, month, yearmonth, year_factor, trade_value_mil, Country) %&gt;%\n\n# Exclude regions\n  filter(!Country %in% region_exlude_cal)\n\n# Filter top 6\ntop6_calendar &lt;- im_mon_calendar %&gt;%\n  group_by(Country) %&gt;%\n  summarise(total_trade_value = sum(trade_value_mil, na.rm = TRUE)) %&gt;%\n  arrange(desc(total_trade_value)) %&gt;%\n  slice_head(n=6)\n\nim_mon_calendar_top6 &lt;- im_mon_calendar %&gt;%\n  filter(Country %in% top6_calendar$Country)\n\nhead(im_mon_calendar_top6)\n\n\n# A tibble: 6 × 7\n  date        year month yearmonth  year_factor trade_value_mil Country      \n  &lt;date&gt;     &lt;dbl&gt; &lt;chr&gt; &lt;date&gt;     &lt;fct&gt;                 &lt;dbl&gt; &lt;chr&gt;        \n1 2025-01-01  2025 Jan   2025-01-01 2025                   5.39 United States\n2 2025-01-01  2025 Jan   2025-01-01 2025                   6.80 China        \n3 2025-01-01  2025 Jan   2025-01-01 2025                   2.60 Japan        \n4 2025-01-01  2025 Jan   2025-01-01 2025                   3.78 Korea, Rep Of\n5 2025-01-01  2025 Jan   2025-01-01 2025                   6.45 Malaysia     \n6 2025-01-01  2025 Jan   2025-01-01 2025                  10.2  Taiwan       \n\n\n\n\n\n\nShow the code\nex_mon &lt;- read_csv(\"data/ex_region_month.csv\")\n\n# Prepare data for calendar heatmap\nex_mon_calendar &lt;- ex_mon %&gt;%\n  select(-1) %&gt;%\n  rename(date_str = `Data Series`) %&gt;%\n  \n  pivot_longer(\n    -date_str,\n    names_to = \"Country\",\n    values_to = \"trade_value\"\n  ) %&gt;%\n  mutate(\n    year = as.numeric(str_extract(date_str, \"\\\\d{4}\")),\n    month_str = str_extract(date_str, \"[A-Za-z]{3}\"),\n    month = month_str,\n    month_num = match(month_str, month.abb),    \n    date = ymd(paste(year, month, \"01\", sep = \"-\")),\n    trade_value_mil = round(trade_value / 1000, 5),\n    yearmonth = floor_date(date, \"month\"),\n    year_factor = as.factor(year)\n  ) %&gt;%\n  \n  filter(year &gt;= 2015 & year &lt;= 2025) %&gt;%\n  \n  select(date, year, month, yearmonth, year_factor, trade_value_mil, Country) %&gt;%\n\n# Exclude regions\n  filter(!Country %in% region_exlude_cal)\n\n# Filter top 6\ntop6_calendar_ex &lt;- ex_mon_calendar %&gt;%\n  group_by(Country) %&gt;%\n  summarise(total_trade_value = sum(trade_value_mil, na.rm = TRUE)) %&gt;%\n  arrange(desc(total_trade_value)) %&gt;%\n  slice_head(n=6)\n\nex_mon_calendar_top6 &lt;- ex_mon_calendar %&gt;%\n  filter(Country %in% top6_calendar_ex$Country)\n\nhead(ex_mon_calendar_top6)\n\n\n# A tibble: 6 × 7\n  date        year month yearmonth  year_factor trade_value_mil Country      \n  &lt;date&gt;     &lt;dbl&gt; &lt;chr&gt; &lt;date&gt;     &lt;fct&gt;                 &lt;dbl&gt; &lt;chr&gt;        \n1 2025-01-01  2025 Jan   2025-01-01 2025                   3.25 United States\n2 2025-01-01  2025 Jan   2025-01-01 2025                   2.26 China        \n3 2025-01-01  2025 Jan   2025-01-01 2025                   1.87 Hong Kong    \n4 2025-01-01  2025 Jan   2025-01-01 2025                   2.00 Indonesia    \n5 2025-01-01  2025 Jan   2025-01-01 2025                   2.47 Malaysia     \n6 2025-01-01  2025 Jan   2025-01-01 2025                   1.10 Taiwan       \n\n\n\n\n\n\nShow the code\nrex_mon &lt;- read_csv(\"data/rex_region_month.csv\")\n\n# Prepare data for calendar heatmap\nrex_mon_calendar &lt;- rex_mon %&gt;%\n  select(-1) %&gt;%\n  rename(date_str = `Data Series`) %&gt;%\n  \n  pivot_longer(\n    -date_str,\n    names_to = \"Country\",\n    values_to = \"trade_value\"\n  ) %&gt;%\n  mutate(\n    year = as.numeric(str_extract(date_str, \"\\\\d{4}\")),\n    month_str = str_extract(date_str, \"[A-Za-z]{3}\"),\n    month = month_str,\n    month_num = match(month_str, month.abb),    \n    date = ymd(paste(year, month, \"01\", sep = \"-\")),\n    trade_value_mil = round(trade_value / 1000, 5),\n    yearmonth = floor_date(date, \"month\"),\n    year_factor = as.factor(year)\n  ) %&gt;%\n  \n  filter(year &gt;= 2015 & year &lt;= 2025) %&gt;%\n  \n  select(date, year, month, yearmonth, year_factor, trade_value_mil, Country) %&gt;%\n\n# Exclude regions\n  filter(!Country %in% region_exlude_cal)\n\n# Filter top 6\ntop6_calendar_rex &lt;- rex_mon_calendar %&gt;%\n  group_by(Country) %&gt;%\n  summarise(total_trade_value = sum(trade_value_mil, na.rm = TRUE)) %&gt;%\n  arrange(desc(total_trade_value)) %&gt;%\n  slice_head(n=6)\n\nrex_mon_calendar_top6 &lt;- rex_mon_calendar %&gt;%\n  filter(Country %in% top6_calendar_ex$Country)\n\nhead(rex_mon_calendar_top6)\n\n\n# A tibble: 6 × 7\n  date        year month yearmonth  year_factor trade_value_mil Country      \n  &lt;date&gt;     &lt;dbl&gt; &lt;chr&gt; &lt;date&gt;     &lt;fct&gt;                 &lt;dbl&gt; &lt;chr&gt;        \n1 2025-01-01  2025 Jan   2025-01-01 2025                   2.57 United States\n2 2025-01-01  2025 Jan   2025-01-01 2025                   3.81 China        \n3 2025-01-01  2025 Jan   2025-01-01 2025                   4.72 Hong Kong    \n4 2025-01-01  2025 Jan   2025-01-01 2025                   2.55 Indonesia    \n5 2025-01-01  2025 Jan   2025-01-01 2025                   4.29 Malaysia     \n6 2025-01-01  2025 Jan   2025-01-01 2025                   3.66 Taiwan       \n\n\n\n\n\n\n\n3.3.2 Plot & Analysis\nLoad and launch packages\n\npacman::p_load(ggplot2, patchwork, ggthemes)\n\nPlot Heatmaps for top 6 markets\n\nIMPORTEXPORTRE-EXPORT\n\n\n\n\nShow the code\nggplot(im_mon_calendar_top6,\n       aes(\n         x = factor(month, levels = month.abb),\n         y = year_factor,\n         fill = trade_value_mil\n       )) +\n  geom_tile(color = \"white\") +  \n  coord_equal() +\n  scale_fill_gradient(name = \"Trade value (S$ Mil.)\",\n                      low = \"white\",\n                      high = \"#3D5300\") +\n  facet_wrap(~Country, ncol =3) +\n  labs(x = \"Month\", \n       y = \"Year\",\n       title = \"Import Monthly Merchandise Trade Intensity\",\n       subtitle = \"2015-2025\") +\n  coord_equal() +\n  theme(legend.position = \"right\",\n        legend.key.size = unit(0.7, \"cm\"),\n        title = element_text(size = 12, family = \"Arial\", face = \"bold\"),\n        axis.title.x = element_blank(),\n        axis.title.y = element_blank(),\n        axis.text.x = element_text(size = 6),\n        axis.text.y = element_text(size = 6),\n        legend.title = element_text(size = 7),\n        legend.text = element_text(size = 6),\n        axis.ticks = element_blank(),\n        plot.margin = margin( t = 20, r = 5, b = 10, l = 5))\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\nTop 6 markets - The top six markets by total trade value since 2015 are China, Japan, South Korea, Malaysia, Taiwan, and the United States.\nIncreasing intensity - Almost all of the top six markets show a significant increase in trade intensity starting from 2021, with Taiwan exhibiting the most remarkable rise.\nPeak import year - The highest trade intensity across all markets occurred in 2022, coinciding with Singapore’s border reopening post-COVID-19. Notably, Taiwan has seen a marked increase in imports from 2024 onwards.\nJapan - Despite being among the top six import markets, Japan demonstrates the lowest import intensity, even trailing behind South Korea.\n\n\n\n\n\n\n\nShow the code\nggplot(ex_mon_calendar_top6,\n       aes(\n         x = factor(month, levels = month.abb),\n         y = year_factor,\n         fill = trade_value_mil\n       )) +\n  geom_tile(color = \"white\") +  \n  coord_equal() +\n  scale_fill_gradient(name = \"Trade value (S$ Mil.)\",\n                      low = \"white\",\n                      high = \"#AC1754\") +\n  facet_wrap(~Country, ncol =3) +\n  labs(x = \"Month\", \n       y = \"Year\",\n       title = \"Export Monthly Merchandise Trade Intensity\",\n       subtitle = \"2015-2025\") +\n  coord_equal() +\n  theme(legend.position = \"right\",\n        legend.key.size = unit(0.7, \"cm\"),\n        title = element_text(size = 12, family = \"Arial\", face = \"bold\"),\n        axis.title.x = element_blank(),\n        axis.title.y = element_blank(),\n        axis.text.x = element_text(size = 6),\n        axis.text.y = element_text(size = 6),\n        legend.title = element_text(size = 7),\n        legend.text = element_text(size = 6),\n        axis.ticks = element_blank(),\n        plot.margin = margin( t = 20, r = 5, b = 10, l = 5))\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\nTop 6 markets - The top six markets by total export trade value since 2015 are China, Indonesia, Hong Kong, Malaysia, Taiwan, and the United States.\nIncreasing intensity - Among these markets, only the United States exhibits a clear upward trend in export trade intensity, while the others have remained relatively stable over the past decade.\nPeak export periods - No distinct peak year or month is observed. However, exports to the United States tend to show higher intensity in March, April, and July in certain years.\nTaiwan - While Taiwan ranks among the top six trading partners for both imports and exports, its export trade intensity is the lowest among them. This appears to be different from Import.\n\n\n\n\n\n\n\nShow the code\nggplot(ex_mon_calendar_top6,\n       aes(\n         x = factor(month, levels = month.abb),\n         y = year_factor,\n         fill = trade_value_mil\n       )) +\n  geom_tile(color = \"white\") +  \n  coord_equal() +\n  scale_fill_gradient(name = \"Trade value (S$ Mil.)\",\n                      low = \"white\",\n                      high = \"#640D5F\") +\n  facet_wrap(~Country, ncol =3) +\n  labs(x = \"Month\", \n       y = \"Year\",\n       title = \"Re-Export Monthly Merchandise Trade Intensity\",\n       subtitle = \"2015-2025\") +\n  coord_equal() +\n  theme(legend.position = \"right\",\n        legend.key.size = unit(0.7, \"cm\"),\n        title = element_text(size = 12, family = \"Arial\", face = \"bold\"),\n        axis.title.x = element_blank(),\n        axis.title.y = element_blank(),\n        axis.text.x = element_text(size = 6),\n        axis.text.y = element_text(size = 6),\n        legend.title = element_text(size = 7),\n        legend.text = element_text(size = 6),\n        axis.ticks = element_blank(),\n        plot.margin = margin( t = 20, r = 5, b = 10, l = 5))\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\nTop 6 markets - The top six markets by total re-export trade value since 2015 is the same as the top 6 for exports. They are China, Indonesia, Hong Kong, Malaysia, Taiwan, and the United States.\nIncreasing intensity - Only the United States and Indonesia have shown an obvious increasing trend of intensity, while the rest maintained similar intensity of export trade through the past 10 years.\nPeak re-export year - No distinct peak year or month is observed. However, exports to the United States tend to show higher intensity in March, April, and July in certain years. This is highly correlated to the domestic export trade volume.\n\n\n\n\n\n\n\n\n\n3.4 Seasonal Trade Pattern by Trading Partner\n\n\n3.4.1 Data wrangling\nIn this step, I will convert the tibble objects to tsibble object for all trade categories, using as_tsibble() from R package. In the analysis, only the top 25 partners will be analysed. I will also exclude some countries that are in fact regions, such as total markets, Asia, etc.\n\npacman::p_load(fpp3, feasts)\n\n\nIMPORTEXPORTRE-EXPORT\n\n\n\n\nShow the code\n# Import data (tibble frame)\nim_by_region &lt;- read_csv(\"data/im_by_reg.csv\")\nim_by_region &lt;- im_by_region %&gt;%\n  rename(`Date` = \"Data Series\")\n\n# Define regions to exclude\nregions_to_exclude &lt;- c(\"Asia\", \"Europe\", \"Africa\", \"America\", \n                        \"Oceania\", \"Total All Markets\")\n\n# Filter out columns that match regions to exclude\nim_by_region_filtered &lt;- im_by_region %&gt;%\n  select(-any_of(regions_to_exclude))\n\n# Calculate column sums to find top 10 countries (excluding Date column)\ncolumn_totals_im &lt;- im_by_region_filtered %&gt;%\n  select(-Date) %&gt;%\n  # Convert all columns to numeric\n  mutate(across(everything(), ~as.numeric(as.character(.)))) %&gt;%\n  summarise(across(everything(), ~sum(., na.rm = TRUE))) %&gt;%\n  pivot_longer(everything(), names_to = \"Country\", values_to = \"Total\") %&gt;%\n  arrange(desc(Total)) %&gt;%\n  slice_head(n = 10) %&gt;%\n  pull(Country)\n\n# Select only the top 10 countries plus Date\nim_by_region_top &lt;- im_by_region_filtered %&gt;%\n  select(Date, any_of(column_totals_im))\n\n\n# convert to tsibble\nim_by_region_tsb &lt;- im_by_region_top %&gt;%\n  mutate(Date = yearmonth(Date)) %&gt;%\n  as_tsibble(index = `Date`)\n\n# Pivot longer for visualisation\nim_by_region_long_data &lt;- im_by_region_tsb %&gt;%\n  pivot_longer(cols = c(2:ncol(im_by_region_tsb)),\n               names_to = \"Country\",\n               values_to = \"Value\")\n\nim_by_region_long &lt;- im_by_region_long_data %&gt;%\n  filter(year(Date) &gt;= 2015 & year(Date) &lt;= 2025)\n\n#tissible object now\nhead(im_by_region_long)\n\n\n# A tsibble: 6 x 3 [1M]\n# Key:       Country [6]\n      Date Country       Value\n     &lt;mth&gt; &lt;chr&gt;         &lt;dbl&gt;\n1 2015 Jan China         4951 \n2 2015 Jan Malaysia      3965.\n3 2015 Jan United States 3823.\n4 2015 Jan Taiwan        2586.\n5 2015 Jan Japan         2146.\n6 2015 Jan Korea, Rep Of 1631.\n\n\n\n\n\n\nShow the code\nex_by_region &lt;- read_csv(\"data/ex_by_reg.csv\")\nex_by_region &lt;- ex_by_region %&gt;%\n  rename(`Date` = \"Data Series\")\n# Filter out columns that match regions to exclude\nex_by_region_filtered &lt;- ex_by_region %&gt;%\n  select(-any_of(regions_to_exclude))\n\n# Calculate column sums to find top 10 countries (excluding Date column)\ncolumn_totals_ex &lt;- ex_by_region_filtered %&gt;%\n  select(-Date) %&gt;%\n  # Convert all columns to numeric\n  mutate(across(everything(), ~as.numeric(as.character(.)))) %&gt;%\n  summarise(across(everything(), ~sum(., na.rm = TRUE))) %&gt;%\n  pivot_longer(everything(), names_to = \"Country\", values_to = \"Total\") %&gt;%\n  arrange(desc(Total)) %&gt;%\n  slice_head(n = 10) %&gt;%\n  pull(Country)\n\n# Select only the top 10 countries plus Date\nex_by_region_top &lt;- ex_by_region_filtered %&gt;%\n  select(Date, any_of(column_totals_ex))\n\n\n# convert to tsibble\nex_by_region_tsb &lt;- ex_by_region_top %&gt;%\n  mutate(Date = yearmonth(Date)) %&gt;%\n  as_tsibble(index = `Date`)\n\n# Pivot longer for visualisation\nex_by_region_long_data &lt;- ex_by_region_tsb %&gt;%\n  pivot_longer(cols = c(2:ncol(ex_by_region_tsb)),\n               names_to = \"Country\",\n               values_to = \"Value\")\nex_by_region_long &lt;- ex_by_region_long_data %&gt;%\n  filter(year(Date) &gt;= 2015 & year(Date) &lt;= 2025)\n\n#tissible object now\nhead(ex_by_region_long)\n\n\n# A tsibble: 6 x 3 [1M]\n# Key:       Country [6]\n      Date Country       Value\n     &lt;mth&gt; &lt;chr&gt;         &lt;dbl&gt;\n1 2015 Jan China         2576.\n2 2015 Jan Malaysia      2135.\n3 2015 Jan United States 1248.\n4 2015 Jan Hong Kong     1532.\n5 2015 Jan Indonesia     1427.\n6 2015 Jan Japan          832.\n\n\n\n\n\n\nShow the code\nrex_by_region &lt;- read_csv(\"data/rex_by_reg.csv\")\nrex_by_region &lt;- rex_by_region %&gt;%\n  rename(Date = \"Data Series\")\n# Filter out columns that match regions to exclude\nrex_by_region_filtered &lt;- rex_by_region %&gt;%\n  select(-any_of(regions_to_exclude))\n\n# Calculate column sums to find top 25 countries (excluding Date column)\ncolumn_totals_rex &lt;- rex_by_region_filtered %&gt;%\n  select(-Date) %&gt;%\n  # Convert all columns to numeric\n  mutate(across(everything(), ~as.numeric(as.character(.)))) %&gt;%\n  summarise(across(everything(), ~sum(., na.rm = TRUE))) %&gt;%\n  pivot_longer(everything(), names_to = \"Country\", values_to = \"Total\") %&gt;%\n  arrange(desc(Total)) %&gt;%\n  slice_head(n = 10) %&gt;%\n  pull(Country)\n\n# Select only the top 10 countries plus Date\nrex_by_region_top &lt;- rex_by_region_filtered %&gt;%\n  select(Date, any_of(column_totals_rex))\n\n\n# convert to tsibble\nrex_by_region_tsb &lt;- rex_by_region_top %&gt;%\n  mutate(Date = yearmonth(Date)) %&gt;%\n  as_tsibble(index = `Date`)\n\n# Pivot longer for visualisation\nrex_by_region_long_data &lt;- rex_by_region_tsb %&gt;%\n  pivot_longer(cols = c(2:ncol(rex_by_region_tsb)),\n               names_to = \"Country\",\n               values_to = \"Value\")\n\nrex_by_region_long &lt;- rex_by_region_long_data %&gt;%\n  filter(year(Date) &gt;= 2015 & year(Date) &lt;= 2025)\n\n#tissible object now\nhead(rex_by_region_long)\n\n\n# A tsibble: 6 x 3 [1M]\n# Key:       Country [6]\n      Date Country       Value\n     &lt;mth&gt; &lt;chr&gt;         &lt;dbl&gt;\n1 2015 Jan Hong Kong     3689 \n2 2015 Jan China         3763.\n3 2015 Jan Malaysia      2407 \n4 2015 Jan Indonesia     1902.\n5 2015 Jan United States 1027.\n6 2015 Jan Korea, Rep Of 1148.\n\n\n\n\n\n\n\n3.4.2 Plot & Analysis\nBelow each tab shows the overall Time plot, Composite plot by country, as well as Seasonal subseries plots for a trade category, Import, Export or Re-Export. This helps observe the trend, seasonal and cyclic patterns for top 10 markets in each trade category during 2005 to 2025.\n\nIMPORTEXPORTRE-EXPORT\n\n\nThe top 10 trade markets for import include China, Japan, Malaysia, Taiwan, UAE, Indonesia, S. Korea, Saudi Arabia, Thailand and the US.\nOVERALL TIME PLOT\n\n\nShow the code\nautoplot(im_by_region_long) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\nCOMPOSITE PLOT BY COUNTRY\n\nCHINAINDONESIAJAPANKOREATAIWANMALAYSIASAUDI ARABIATHAILANDUSAUAE\n\n\n\n\nShow the code\nim_by_region_long %&gt;%\n  filter(`Country` == \"China\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nim_by_region_long %&gt;%\n  filter(`Country` == \"Indonesia\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nim_by_region_long %&gt;%\n  filter(`Country` == \"Japan\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nim_by_region_long %&gt;%\n  filter(`Country` == \"Korea, Rep Of\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nim_by_region_long %&gt;%\n  filter(`Country` == \"Taiwan\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nim_by_region_long %&gt;%\n  filter(`Country` == \"Malaysia\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nim_by_region_long %&gt;%\n  filter(`Country` == \"Saudi Arabia\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nim_by_region_long %&gt;%\n  filter(`Country` == \"Thailand\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nim_by_region_long %&gt;%\n  filter(`Country` == \"United States\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nim_by_region_long %&gt;%\n  filter(`Country` == \"United Arab Emirates\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\nSEASONAL SUBSERIES PLOTS\n\n\nShow the code\nim_by_region_long |&gt; gg_subseries(Value) +\n  theme(\n    axis.text.x = element_text(size = 5),\n    axis.text.y = element_text(size = 5)\n  )\n\n\n\n\n\n\n\n\n\n\n\nObservations | IMPORT\n\n\n\nWidening gap in strong trade markets - The time plot reveals four markets — Taiwan, China, the US, Malaysia - showing a consistent upward trend, creating a growing gap between them and other markets.\nSeasonal patterns - While most countries show little seasonality in imports, a dip in February is common, possibly due to fewer days. However, China and South Korea display a distinct spike in July, while the US shows dips in February and December, and a spike in August. Both China and the US also exhibit strong positive autocorrelation at lag 12, indicating a seasonal pattern. Indonesia shows sharp drops at lags 3 and 5, suggesting a cyclical pattern or seasonality every 3–5 months.\nTrend - Countries like China, South Korea, Taiwan, Malaysia, Thailand, USA, and UAE show an increasing trend, supported by slow decay in their ACF plots. In contrast, Saudi Arabia demonstrates a decreasing trend.\n\n\n\n\n\nOVERALL TIME PLOTS\n\n\nShow the code\nautoplot(ex_by_region_long) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\nCOMPOSITE PLOT BY COUNTRY\n\nAUSTRALIACHINAHONG KONGINDONESIAJAPANKOREATAIWANMALAYSIATHAILANDUSA\n\n\n\n\nShow the code\nex_by_region_long %&gt;%\n  filter(`Country` == \"Australia\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nex_by_region_long %&gt;%\n  filter(`Country` == \"China\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nex_by_region_long %&gt;%\n  filter(`Country` == \"Hong Kong\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nex_by_region_long %&gt;%\n  filter(`Country` == \"Indonesia\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nex_by_region_long %&gt;%\n  filter(`Country` == \"Japan\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nex_by_region_long %&gt;%\n  filter(`Country` == \"Korea, Rep Of\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nex_by_region_long %&gt;%\n  filter(`Country` == \"Taiwan\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nex_by_region_long %&gt;%\n  filter(`Country` == \"Malaysia\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nex_by_region_long %&gt;%\n  filter(`Country` == \"Thailand\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nex_by_region_long %&gt;%\n  filter(`Country` == \"United States\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\nSEASONAL SUBSERIES PLOTS\n\n\nShow the code\nex_by_region_long |&gt; gg_subseries(Value) +\n  theme(\n    axis.text.x = element_text(size = 5),\n    axis.text.y = element_text(size = 5)\n  )\n\n\n\n\n\n\n\n\n\n\n\nObservations | EXPORT\n\n\n\nConsistent gap in strong trade markets - Unlike Import, the stronger Export trade markets, including China, Malaysia, the US, and Indonesia maintains a consistent gap between them and other markets. Note that the gap isn’t as notable for Indonesia and Malaysia between year 2020-2022.\nCyclic behaviour - Hong Kong displays cyclical trade patterns with peaks at regular intervals (3, 6, 8, and 11 months), suggesting the influence of seasonality or external cyclical factors on trade. This cyclical behavior is not linked to specific months. Similarly, South Korea shows periodic peaks in the ACF plot at lags 3, 6, 9, and 12, indicating a cyclical pattern, with notable dips in February, May, and November, and peaks in March, October, and December. For Taiwan, a peak at lag 12 suggests annual seasonality, likely linked to the electronics manufacturing cycle, while Malaysia’s peak at lag 7 indicates a semi-annual rhythm, possibly driven by business or industry cycles.\nTrend - Countries such as Australia, Indonesia, South Korea, and the USA show an increasing trend, supported by slow decay in their ACF plots, indicating stable growth. In contrast, Hong Kong displays a declining trend, suggesting shifts in trade dynamics over time.\n\n\n\n\n\nOVERALL TIME PLOTS\n\n\nShow the code\nautoplot(rex_by_region_long) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\nCOMPOSITE PLOT BY COUNTRY\n\nCHINAHONG KONGINDONESIAJAPANKOREATAIWANMALAYSIATHAILANDUSAVIETNAM\n\n\n\n\nShow the code\nrex_by_region_long %&gt;%\n  filter(`Country` == \"China\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nrex_by_region_long %&gt;%\n  filter(`Country` == \"Hong Kong\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nrex_by_region_long %&gt;%\n  filter(`Country` == \"Indonesia\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nrex_by_region_long %&gt;%\n  filter(`Country` == \"Japan\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nrex_by_region_long %&gt;%\n  filter(`Country` == \"Korea, Rep Of\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nrex_by_region_long %&gt;%\n  filter(`Country` == \"Taiwan\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nrex_by_region_long %&gt;%\n  filter(`Country` == \"Malaysia\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nrex_by_region_long %&gt;%\n  filter(`Country` == \"Thailand\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nrex_by_region_long %&gt;%\n  filter(`Country` == \"United States\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nrex_by_region_long %&gt;%\n  filter(`Country` == \"Viet Nam\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\nSEASONAL SUBSERIES PLOTS\n\n\nShow the code\nrex_by_region_long |&gt; gg_subseries(Value) +\n  theme(\n    axis.text.x = element_text(size = 5),\n    axis.text.y = element_text(size = 5)\n  )\n\n\n\n\n\n\n\n\n\n\n\nObservations | RE_EXPORT\n\n\n\n3 distinct trade market bands - The time plot reveals three distinct bands of trade markets. The first band consists of Hong Kong and China, which have nearly identical trade values post-2023. With this, China stays as the largest Re-Export trade market. The second band evolves over time—before 2018, it includes Malaysia and Indonesia, but after 2019, the USA joins this group while Indonesia fell to band 3 until 2021. The third band consists of all remaining markets. The gaps between these bands remained stable before 2019 and after 2020, but post-2023, the distinction between bands 2 and 3 becomes less pronounced, while Malaysia pulls away from band 2, widening its gap.\nSeasonal patterns - Seasonal trends are evident across many markets. Most countries experience dips in February, likely due to fewer days in the month. China and Hong Kong show dips in February and June, with peaks in January, March, October, and December in recent years. Japan exhibits peaks in March, July, and December, with dips in May. South Korea has peaks in March, June, and December, and dips in February, May, and November. Malaysia peaks in March and October, while Thailand shows peaks in March, June, and October and dips in February and December. Vietnam experiences peaks in January, March, August, and December.\nCyclic behaviour - Many of the Re-export trade partners show cyclic behaviour. China, Hong Kong, Japan, Korea, Taiwan, Thailand, USA and Vietnam. Their ACF plots refelct the scallop effect at different lags. Notable patterns include China (lag 12), Hong Kong (lags 3, 6, 9, 12), and the USA (lags 8 and 12), that suggest periodic trade fluctuations.\nTrend - All top Re-Export trade markets show a consistent upward trend, indicating sustained growth in re-export activities.\n\n\n\n\n\n\n\n\n\n3.5 Trading Trend Analysis\n\n3.5.1 Data Wrangling\n\n\nShow the code\n# Add a trade type identifier to each dataset before stacking\nim_mon_trend &lt;- im_mon_calendar %&gt;% mutate(Type = \"Import\")\nex_mon_trend &lt;- ex_mon_calendar %&gt;% mutate(Type = \"Export\")\nrex_mon_trend &lt;- rex_mon_calendar %&gt;% mutate(Type = \"ReExport\")\n\n# Combine all datasets into one\nstacked_trend &lt;- bind_rows(im_mon_trend, ex_mon_trend, rex_mon_trend)\n\n# Create an adjusted trade value column where imports are negative and exports/re-exports are positive\nstacked_trend &lt;- stacked_trend %&gt;%\n  mutate(adjusted_trade_value = case_when(\n    Type == \"Export\" ~ trade_value_mil,\n    Type == \"ReExport\" ~ trade_value_mil,\n    Type == \"Import\" ~ -trade_value_mil,\n    TRUE ~ 0\n  ))\n\n# Compute (export + re-export - import) for each country by month\nnet_trade_df &lt;- stacked_trend %&gt;%\n  group_by(date, Country) %&gt;%\n  summarise(\n    net_trade_value_mil = sum(adjusted_trade_value, na.rm = TRUE)\n  ) %&gt;%\n  ungroup()\n\n# Convert trade values to thousands (if necessary)\nnet_trade_df$net_trade_value_mil &lt;- net_trade_df$net_trade_value_mil * 1000\n\nnet_trade_df &lt;- net_trade_df %&gt;%\n  rename(net_trade_value_k = \"net_trade_value_mil\")\n\n# View the resulting dataset\nhead(net_trade_df)\n\n\n# A tibble: 6 × 3\n  date       Country             net_trade_value_k\n  &lt;date&gt;     &lt;chr&gt;                           &lt;dbl&gt;\n1 2015-01-01 Afghanistan                       1.5\n2 2015-01-01 Algeria                           5.6\n3 2015-01-01 Angola                          117. \n4 2015-01-01 Antarctica                        0.2\n5 2015-01-01 Antigua And Barbuda              25.6\n6 2015-01-01 Argentina                         3.9\n\n\n\n\n3.5.2 Plot & Analaysis\nThe analyse the trade trends, a ggHoriPlot will be plotted to observed the trends among Singapore trade partners. This approach is employeed because I would like to see all countries in one view. To plot the ggHoriPlot, I will load and launch the following packages: ggHoriPlot, ggthemes and tidyverse.\n\npacman::p_load(ggHoriPlot, ggthemes, tidyverse)\n\nIn the HotiPlot below, the top and bottom Surplus and Deficit trade partners are plotted in one view. To have a full view of the historical changes of trade balance, all countries are included to the plot in tab 2 “ALL COUNTRIES”. All countries are ordered in alphebetical orders. Red dipicts net negative trade (Deficit) and blue means Surplus. Darker colors means larger trade deficit / surplus.\n\nTOP BOTTOM 30ALL COUNTRIES\n\n\n\n\nShow the code\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(ggHoriPlot)\n\n# Get total trade value per country\ncountry_trade_summary &lt;- net_trade_df %&gt;%\n  group_by(Country) %&gt;%\n  summarise(total_trade_value = sum(net_trade_value_k, na.rm = TRUE)) %&gt;%\n  ungroup()\n\n# Select the top 30 and bottom 30 countries\ntop_30_countries &lt;- country_trade_summary %&gt;%\n  arrange(desc(total_trade_value)) %&gt;%\n  slice_head(n = 30) %&gt;%\n  pull(Country)  # Extract country names as a vector\n\nbottom_30_countries &lt;- country_trade_summary %&gt;%\n  arrange(total_trade_value) %&gt;%\n  slice_head(n = 30) %&gt;%\n  pull(Country)  # Extract country names as a vector\n\n# Combine top and bottom 30 countries\nselected_countries &lt;- c(top_30_countries, bottom_30_countries)\n\n# Filter the original dataset for only these 60 countries\nfiltered_df &lt;- net_trade_df %&gt;%\n  filter(Country %in% selected_countries, date &gt;= \"2015-01-01\")\n\n# Plot the horizon graph for these countries\nggplot(filtered_df, aes(x = date, y = net_trade_value_k)) +\n  geom_horizon(origin = \"midpoint\", horizonscale = 6) +\n  facet_grid(Country ~ .) +\n  theme_few() +\n  scale_fill_hcl(palette = \"RdBu\") +\n  theme(\n    panel.spacing.y = unit(0, \"lines\"),\n    strip.text.y = element_text(size = 5, angle = 0, hjust = 0),\n    legend.position = \"none\",\n    axis.text.y = element_blank(),\n    axis.text.x = element_text(size = 5, angle = 45, hjust = 1),\n    axis.title.y = element_blank(),\n    axis.title.x = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.border = element_blank(),\n    plot.title = element_text(size = 12, family = \"Arial\", face = \"bold\"),\n    plot.margin = margin(t = 20, r = 15, b = 10, l = 15)\n  ) +\n  scale_x_date(expand = c(0, 0),\n               date_breaks = \"3 months\",\n               date_labels = \"%b%y\") +\n  labs(title = \"Trade Balance of Top & Bottom 30 Singapore Trading Partners \\n2015 Jan - 2025 Jan\")\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\nPersistent Trade Deficit Markets - Several markets have consistently remained in trade deficit, with occasional surplus periods. These include Bangladesh, Belgium, France, Germany, Guam, Myanmar, New Caledonia, New Zealand, Pakistan, Puerto Rico, and the UK.\nPersistent Trade Surplus Markets - Conversely, some markets have continuously maintained a trade surplus, with only brief deficit periods. Notable examples include Canada, Cyprus, Greece, Iraq, Libya, Poland, Sweden, and Venezuela.\nShifting to Surplus - Certain markets that were once in deficit have transitioned into surplus in recent years. This shift is particularly evident in Fiji, Hong Kong, India, Indonesia, Liberia, Malta, the Marshall Islands, Mexico, Papua New Guinea, and the Philippines, suggesting evolving trade dynamics.\nShifting to Deficit - A few key markets, including Brazil, Ireland, South Korea, Taiwan, and Vietnam, were historically surplus trade partners but have now become significant deficit markets or are trending in that direction.\n\n\n\n\n\n\n\nShow the code\nnet_trade_df %&gt;%\n  filter(date &gt;= \"2015-01-01\") %&gt;%\n  ggplot() +\n  geom_horizon(aes(\n    x = date, y = net_trade_value_k,\n    origin = \"midpoint\",\n    horizonscale = 6),\n    linewidth = 0.5) +\n      facet_grid(Country~.) +\n      theme_few() +\n      scale_fill_hcl(palette =\"RdBu\") +\n      theme(\n        panel.spacing.y=unit(0, \"lines\"), \n        strip.text.y = element_text(\n          size = 5, angle = 0, hjust = 0),\n        legend.position = 'none',\n        axis.text.y = element_blank(),\n        axis.text.x = element_text(size = 5, angle = 45, hjust = 1),\n        axis.title.y = element_blank(),\n        axis.title.x = element_blank(),\n        axis.ticks.y = element_blank(),\n        panel.border = element_blank(),\n        plot.title = element_text(size = 12, family = \"Arial\", face = \"bold\"),\n        plot.margin = margin(t = 20, r = 15, b = 10, l = 15)\n      ) +\n      scale_x_date(expand=c(0,0),\n                   date_breaks = \"3 months\",\n                   date_labels = \"%b%y\") +\n      labs(title = \"Trade Balance of Singapore Trading Partners \\n2015 Jan to 2025 Jan\")\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\nGenerally no obvious Surplus or Deficit trends are observed on the trading markets as a whole, but there are a few interesting patterns to pick up:\n\nDeficit Period (2020–2022) - A more pronounced trade deficit is observed during this period. This coincide with COVID-19 pandemic. This suggests the impact of external economic shocks or shifts in trade policies.\nStable Trade Positions - Most countries have maintained a consistent trade balance with Singapore, while some, as identified in previous analyses, exhibit a shifting trend towards either surplus or deficit.\n\n\n\n\n\n\n\n\n\n3.6 Trade time-series forecasting\nA time-series forecasting will be conducted for Singapore import trade daa by trade markets. The top 6 Import trade markets will be forecasted using ETS and ARIMA models, and results will be compared using plot visualisations.\nThe process is as below: Data Prep &gt; Exploratory data analysis (done in 3.4) &gt; model fitting &gt; diagnostic check &gt; forecasting &gt; forecasting check\n\npacman::p_load(dplyr, tidyr, tsibble, lubridate, forecast, fable)\n\n\n3.6.1 Time series data sampling\nThe data set I will be using is a tsibble frame derived from previous analysis v2_trans_im. This data frame contains monthly export data by trade markets (countries), from 2003 Jan to 2025 Jan. I am particularly interested in forecasting Imports from selected Singapore’s top trade partners from recent years.\nIn this analysis, I will use the last 12 months for hold-out and the rest for training.\n\n\n3.6.2 Data wrangling\n\n\nShow the code\n# Create a copy first\nim_region_df &lt;- v2_trans_im\n\nim_region_df &lt;- im_region_df %&gt;%\n  rename(Date = `Data Series`) %&gt;%\n  mutate(Date = as.Date(paste0(Date, \" 01\"), format = \"%Y %b %d\")) %&gt;%\n  slice(-1) %&gt;% \n  mutate(across(-Date, as.numeric)) %&gt;%\n  pivot_longer(-Date,\n               names_to = \"Country\",\n               values_to = \"Value\") \n\nim_region_df_top &lt;- im_region_df %&gt;%\n  filter(Country %in% c(\"Malaysia\", \"China\", \"Taiwan\", \"Japan\", \"Thailand\", \"Korea, Rep Of\", \"United States\")) %&gt;%\n  filter(Date &gt;= as.Date(\"2015-01-01\"))\n         \n# Convert tiblle to tsiblle\nim_by_region_tsb &lt;- im_region_df_top %&gt;%\n  mutate(Date = yearmonth(Date)) %&gt;%\n  as_tsibble(index = Date, key = Country)\n\nhead(im_by_region_tsb)\n\n\n# A tsibble: 6 x 3 [1M]\n# Key:       Country [1]\n      Date Country Value\n     &lt;mth&gt; &lt;chr&gt;   &lt;dbl&gt;\n1 2015 Jan China   4951 \n2 2015 Feb China   4084.\n3 2015 Mar China   4320.\n4 2015 Apr China   4987.\n5 2015 May China   4554.\n6 2015 Jun China   4686.\n\n\n\n\n3.6.3 Sampling\n\n\nShow the code\nim_top_train &lt;- im_by_region_tsb %&gt;%\n  mutate(Type = if_else(\n    `Date` &gt;= yearmonth(\"2024-01\"), \n    \"Hold-out\", \"Training\")) %&gt;%\n  filter(Type == \"Training\")\n\nhead(im_top_train)\n\n\n# A tsibble: 6 x 4 [1M]\n# Key:       Country [1]\n      Date Country Value Type    \n     &lt;mth&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;   \n1 2015 Jan China   4951  Training\n2 2015 Feb China   4084. Training\n3 2015 Mar China   4320. Training\n4 2015 Apr China   4987. Training\n5 2015 May China   4554. Training\n6 2015 Jun China   4686. Training\n\n\n\n\n3.6.4 Fit multiple time series\n\nFIT MODELSEXAMINE MODELSEXTRACT FITTED AND RESIDUAL VALUES\n\n\n\n\nShow the code\nim_top_fit &lt;- im_top_train %&gt;%\n  model(\n    ets = ETS(Value),\n    arima = ARIMA(Value)\n  )\n\n\n\n\n\nim_top_fit %&gt;%\n  glance()\n\n# A tibble: 14 × 12\n   Country      .model  sigma2 log_lik   AIC  AICc   BIC     MSE    AMSE     MAE\n   &lt;chr&gt;        &lt;chr&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1 China        ets    6.93e-3   -909. 1848. 1853. 1888. 231260. 296508.  0.0621\n 2 China        arima  3.44e+5   -834. 1679. 1680. 1696.     NA      NA  NA     \n 3 Japan        ets    8.28e-3   -826. 1683. 1688. 1723.  44688.  63564.  0.0704\n 4 Japan        arima  6.30e+4   -749. 1508. 1509. 1522.     NA      NA  NA     \n 5 Korea, Rep … ets    1.78e-2   -860. 1726. 1726. 1734.  82406. 111427.  0.107 \n 6 Korea, Rep … arima  8.16e+4   -756. 1517. 1517. 1522.     NA      NA  NA     \n 7 Malaysia     ets    9.58e-3   -917. 1839. 1839. 1847. 245189. 298955.  0.0743\n 8 Malaysia     arima  2.48e+5   -816. 1636. 1636. 1641.     NA      NA  NA     \n 9 Taiwan       ets    8.00e-3   -879. 1788. 1793. 1828. 149726. 223555.  0.0682\n10 Taiwan       arima  2.00e+5   -804. 1614. 1614. 1622.     NA      NA  NA     \n11 Thailand     ets    3.92e-2   -824. 1655. 1655. 1663.  46044.  51467.  0.138 \n12 Thailand     arima  4.68e+4   -727. 1458. 1458. 1463.     NA      NA  NA     \n13 United Stat… ets    7.91e-3   -892. 1814. 1819. 1854. 156055. 202325.  0.0656\n14 United Stat… arima  2.33e+5   -813. 1631. 1631. 1639.     NA      NA  NA     \n# ℹ 2 more variables: ar_roots &lt;list&gt;, ma_roots &lt;list&gt;\n\n\n\n\n\nim_top_fit %&gt;%\n  augment()\n\n# A tsibble: 1,512 x 7 [1M]\n# Key:       Country, .model [14]\n   Country .model     Date Value .fitted .resid   .innov\n   &lt;chr&gt;   &lt;chr&gt;     &lt;mth&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n 1 China   ets    2015 Jan 4951    5457. -506.  -0.0928 \n 2 China   ets    2015 Feb 4084.   3874.  210.   0.0543 \n 3 China   ets    2015 Mar 4320.   5137. -817.  -0.159  \n 4 China   ets    2015 Apr 4987.   4501.  486.   0.108  \n 5 China   ets    2015 May 4554.   4847. -293.  -0.0605 \n 6 China   ets    2015 Jun 4686.   4696.  -10.8 -0.00230\n 7 China   ets    2015 Jul 4996.   4799.  196.   0.0409 \n 8 China   ets    2015 Aug 4830.   4765.   65.2  0.0137 \n 9 China   ets    2015 Sep 5005.   4875.  130.   0.0266 \n10 China   ets    2015 Oct 5363.   5191.  171.   0.0330 \n# ℹ 1,502 more rows\n\n\n\n\n\n\n\n3.6.5 Compare fit models Use accuracy() to compare the performance of models\n\n\nShow the code\nim_top_fit %&gt;%\n  accuracy() %&gt;%\n  arrange(Country) %&gt;%\n  kable(digits = 4, caption = \"Forecast Accuracy Metrics for Each Country\")\n\n\n\nForecast Accuracy Metrics for Each Country\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCountry\n.model\n.type\nME\nRMSE\nMAE\nMPE\nMAPE\nMASE\nRMSSE\nACF1\n\n\n\n\nChina\nets\nTraining\n11.9574\n480.8950\n366.4509\n-0.1939\n6.2506\n0.5564\n0.5529\n0.0562\n\n\nChina\narima\nTraining\n57.8184\n569.9843\n439.2390\n0.1868\n7.6637\n0.6669\n0.6554\n-0.0147\n\n\nJapan\nets\nTraining\n-0.6291\n211.3943\n171.1785\n-0.4698\n7.0199\n0.4371\n0.4221\n-0.0621\n\n\nJapan\narima\nTraining\n4.3188\n246.3921\n190.8210\n-0.7639\n7.9715\n0.4872\n0.4920\n-0.0195\n\n\nKorea, Rep Of\nets\nTraining\n22.2084\n287.0644\n227.6461\n-0.3782\n10.6173\n0.4683\n0.4241\n0.1565\n\n\nKorea, Rep Of\narima\nTraining\n22.2147\n282.9792\n223.6307\n-0.1773\n10.4052\n0.4600\n0.4181\n0.0217\n\n\nMalaysia\nets\nTraining\n34.5795\n495.1653\n366.1790\n0.0009\n7.4907\n0.4898\n0.5004\n0.0665\n\n\nMalaysia\narima\nTraining\n26.2860\n493.0780\n359.3030\n-0.1482\n7.3579\n0.4806\n0.4983\n-0.0114\n\n\nTaiwan\nets\nTraining\n36.2225\n386.9443\n289.8459\n0.4252\n6.7591\n0.3609\n0.3660\n0.0537\n\n\nTaiwan\narima\nTraining\n33.3608\n440.6971\n322.4981\n0.2547\n7.6050\n0.4016\n0.4169\n0.0023\n\n\nThailand\nets\nTraining\n11.4115\n214.5793\n145.1930\n-1.5209\n13.2531\n0.5862\n0.6048\n-0.0085\n\n\nThailand\narima\nTraining\n11.6179\n214.2205\n143.8310\n-1.5881\n13.1478\n0.5807\n0.6038\n0.0342\n\n\nUnited States\nets\nTraining\n35.4632\n395.0378\n303.1292\n0.2329\n6.4715\n0.4084\n0.4299\n-0.0533\n\n\nUnited States\narima\nTraining\n34.1356\n475.5440\n375.5570\n-0.0171\n8.0521\n0.5060\n0.5175\n-0.0436\n\n\n\n\n\n\n\n3.6.6 Forecast future values\n\n\nShow the code\nim_top_fc &lt;- im_top_fit %&gt;%\n  forecast(h = \"12 months\")\n\n\n\n\n3.6.7 Visualisation\n\n\nShow the code\nim_top_fc %&gt;%\n  autoplot(im_by_region_tsb)\n\n\n\n\n\n\n\n\n\n\n\nAnalysis\n\n\nBased on the accuracy comparison, the ARIMA model provides the best fit for Korea, Malaysia, and Thailand, as indicated by the lowest RMSE and MAPE values. However, for China, Japan, Taiwan, and the USA, the ETS model performs better. They show lower MASE and RMSSE, which suggests improved predictive accuracy.\nThe ACF1 values are close to zero, indicating minimal autocorrelation in residuals— a desirable property for reliable forecasts. Given that different models perform optimally for different markets, a hybrid approach using both ETS and ARIMA would enhance forecast accuracy.\nThe visualisations also reveal high uncertainty, likely due to volatile trade patterns or model sensitivity. This may suggest that external factors, such as policy changes or global economic shifts, may be influencing trade fluctuations. The models generally falls in the ranges, except for the model for Taiwan, which forecasts lower than the actual.\n\n\n\n\n\n3.7 Comparative Analysis of Singapore’s Re-export (2019 vs 2024)\nSingapore, as a focal point for international trading, hsa goods come and go. I am curious to find out what goods have been imported and re-exported. Do they change over time? In this section, I will use slopegraph to display the changes for individual commodity categories between 2019 and 2024.\n\n3.7.1 Data Wrangling\nLoad pakcage\n\npacman::p_load(CGPfunctions, ggthemes)\n\nImport data & Data wrangling\n\nCOMMODITYMACHINERY & EQUIPMENT\n\n\n\n\nShow the code\nrex_com_data &lt;- read_csv(\"data/rex_by_com.csv\")\nrex_com_slope &lt;- rex_com_data %&gt;%\n  select(-1) %&gt;%  # Remove the first unwanted column\n  mutate(\n    # Extract year from the 'Data Series' column\n    Year = as.numeric(format(as.Date(paste0(`Data Series`, \"-01\"), format = \"%Y %b-%d\"), \"%Y\"))\n  ) %&gt;%\n    #shortern some item names\n  rename(`Fish, Seafood` = \"Fish, Seafood (Excl Marine Mammals) & Preparations\",\n         `Coffee, Tea, Cocoa, Spices` = \"Coffee, Tea, Cocoa, Spices & Manufactures\",\n         `Crude Fertilizers & Minerals` = \"Crude Fertilizers & Minerals (Excl Division 56 Coal Petroleum & Precious Stones)\",\n         `Animal/Veg Fats & Oils (Processed)` = \"Animal Or Vegetable Fats & Oils Processed Waxes Of Animal Or Vegetable Origin Inedible Mixtures Or Preparations Of Animal Or Vegetable Fats Or Oils Nes\",\n         `Essential Oils & Perfume` = \"Essential Oils & Resinoids & Perfume Materials; Toilet Polishing & Cleansing Preparations\",\n         `Paper & Paperboard Products` = \"Paper, Paperboard & Articles Of Paper Pulp Of Paper Or Of Paperboard\",\n         `Scientific Instruments` = \"Professional Scientific & Controlling Instruments & Apparatus Nes\",\n         `Photo & Optical Goods` = \"Photographic Apparatus Equipment & Supplies & Optical Goods Nes; Watches & Clocks\",\n         `Textile Yarns & Fabrics` = \"Textile, Yarn, Fabrics Made-Up Articles Nes & Related Products\",\n         `Vegetable Fats & Oils` = \"Fixed Vegetable Fats & Oils Crude Refined Or Fractionated\"\n  ) %&gt;% \n  # Convert columns to numeric, coercing non-numeric values to NA\n  mutate(across(\n    .cols = where(is.character) & !matches(\"Data Series\"),\n    .fns = ~as.numeric(gsub(\",\", \"\", .x)),\n    .names = \"{col}\"\n  )) %&gt;%\n  \npivot_longer(\n    cols = -c(Year, `Data Series`),\n    names_to = \"Item\",\n    values_to = \"Value\"\n  ) %&gt;%\n  group_by(Year, Item) %&gt;%\n  summarise(Value = sum(Value, na.rm = TRUE)) %&gt;%\n  ungroup()  \nhead(rex_com_slope)\n\n\n# A tibble: 6 × 3\n   Year Item                                        Value\n  &lt;dbl&gt; &lt;chr&gt;                                       &lt;dbl&gt;\n1  1976 Animal/Veg Fats & Oils (Processed)          18382\n2  1976 Articles Of Apparel & Clothing Accessories  75804\n3  1976 Beverages                                   13778\n4  1976 Coffee, Tea, Cocoa, Spices                 358866\n5  1976 Crude Animal & Vegetable Materials Nes      88581\n6  1976 Crude Fertilizers & Minerals                30984\n\n\n\n\n\n\nShow the code\nrex_mac_data &lt;- read_csv(\"data/rex_by_mac.csv\")\n\n# Remove 2 rows - total electronic and non-electronic products\n\nrex_mac_slope &lt;- rex_mac_data %&gt;%\n  select(-1) %&gt;% \n  select(-c(`Total Electronic Products`, `Non-Electronic Products`)) %&gt;%\n  mutate(\n    # Extract year from the 'Data Series' column\n    Year = as.numeric(format(as.Date(paste0(`Data Series`, \"-01\"), format = \"%Y %b-%d\"), \"%Y\"))\n  ) %&gt;%\n  # Convert columns to numeric, coercing non-numeric values to NA\n  mutate(across(\n    .cols = where(is.character) & !matches(\"Data Series\"),\n    .fns = ~as.numeric(gsub(\",\", \"\", .x)),\n    .names = \"{col}\"\n  )) %&gt;%\n  \npivot_longer(\n    cols = -c(Year, `Data Series`),\n    names_to = \"Item\",\n    values_to = \"Value\"\n  ) %&gt;%\n  group_by(Year, Item) %&gt;%\n  summarise(Value = sum(Value, na.rm = TRUE)) %&gt;%\n  ungroup()  \n\nhead(rex_mac_slope)\n\n\n# A tibble: 6 × 3\n   Year Item                                     Value\n  &lt;dbl&gt; &lt;chr&gt;                                    &lt;dbl&gt;\n1  1999 Consumer Electronics                  5014687.\n2  1999 Diodes And Transistors                3449509.\n3  1999 Disk Drives                           3902195.\n4  1999 Electrical Circuit Apparatus          1309027.\n5  1999 Electrical Machinery & Apparatus Nes  1248792.\n6  1999 Integrated Circuits                  15477220.\n\n\n\n\n\n\n\n3.7.2 Plot & Analysis\n\nMACHINERY & EQUIPMENTCOMMODITY\n\n\n\n\nShow the code\nrex_mac_slope %&gt;% \n  mutate(Year = factor(Year),\n         Value = round(Value/100000, 1)) %&gt;%\n  filter(Year %in% c(2019, 2024)) %&gt;%\n  newggslopegraph(Year, Value, Item,\n                  Title = \"Commodity Trade Evolution\",\n                  SubTitle = \"2019 vs 2024\",\n                  Caption = \"Value in S$ Bil. \\nSource of Data: Singapore Department of Statistics\",\n                  YTextSize = 3,\n                  DataLabelLineSize = 0.2,\n                  DataLabelFillColor = \"#EFDCAB\") +\n  theme_wsj() +\n  theme(plot.title = element_text(size = 15),\n        plot.subtitle = element_text(size = 11),\n        plot.caption = element_text(size = 9),\n        legend.text = element_text(size = 7),\n        legend.title = element_text(size = 8),\n        legend.position = \"bottom\",\n        axis.text.y = element_text(size = 6, color = \"grey70\"),\n        axis.text.x = element_text(size = 7))\n\n\n\n\n\n\n\n\n\n\n\nAnalysis | Re-export Machinery\n\n\n\nIntegrated circuits re-export - The analysis of Singapore’s RE-exports reveals that integrated circuits have dominated the machinery and equipment category since 2019, with values reaching 1,373.6 billion Singapore dollars. This represents approximately six times the value of Telecommunications Equipment, the second-largest export category. These re-exported integrated circuits primarily consist of semiconductor chips used in electronic devices such as computers, smartphones, and televisions. In addition, Telecommunications equipment and Personal computers are also growing. The strong upward trend in the data indicates growing international reliance on Singapore’s transshipment capabilities for distributing these critical technology components.\nFocal point for trade - What makes this data particularly significant is that it reflects re-exports rather than domestic exports. This highlights Singapore’s strategic role as a transshipment hub in the global semiconductor supply chain. The timing of this growth in semiconductor re-exports aligns with increased global demand for specialized processing chips, including those used for AI applications. While the data doesn’t explicitly categorize AI-specific chips within the broader integrated circuits category, the substantial volumes flowing through Singapore suggest it serves as a key node in the distribution network for advanced computing hardware.\n\n\n\n\n\n\n\nShow the code\nrex_com_slope %&gt;% \n  mutate(Year = factor(Year),\n         Value = round(Value/100000, 1)) %&gt;%\n  filter(Year %in% c(2019, 2024)) %&gt;%\n  newggslopegraph(Year, Value, Item,\n                  Title = \"Commodity Trade Evolution\",\n                  SubTitle = \"2019 vs 2024\",\n                  Caption = \"Value in S$ Bil. \\nSource of Data: Singapore Department of Statistics\",\n                  YTextSize = 3,\n                  DataLabelLineSize = 0.2,\n                  DataLabelFillColor = \"#EFDCAB\") +\n  theme_wsj() +\n  theme(plot.title = element_text(size = 15),\n        plot.subtitle = element_text(size = 11),\n        plot.caption = element_text(size = 9),\n        legend.text = element_text(size = 7),\n        legend.title = element_text(size = 8),\n        legend.position = \"bottom\",\n        axis.text.y = element_text(size = 6, color = \"grey70\"),\n        axis.title.x = element_text(size = 7))\n\n\n\n\n\n\n\n\n\n\n\nAnalysis | Re-export Commodity\n\n\n\nHigh-tech and healthcare-related categories — Scientific instruments (10% increase), Miscellaneous manufactured articles (22% increase), and Medicinal & pharmaceutical products (100% increase) — show consistent upward trajectories. This growth indicates Singapore’s strengthening role as a transshipment hub for these high-value goods, likely reflecting increased regional and global demand for advanced technologies and healthcare solutions.\nTraditional commodity - Conversely, several traditional commodity categories in Singapore’s re-export portfolio have declined during this period. Essential oils & perfume products (10% decrease) and plastics experienced the most pronounced decreases, followed by non-metallic mineral manufactures, crude rubber, apparel & clothing accessories, and organic chemicals.\n\nThis divergence in re-export patterns suggests a potential reconfiguration of regional supply chains, with Singapore’s transshipment activities increasingly concentrated in higher-value, specialized product categories while seeing reduced volumes in more basic industrial inputs and consumer goods. The trend may reflect changing manufacturing locations in the region, shifts in consumption patterns, or evolving trade routes that may be bypassing Singapore for certain commodity categories."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03.html#conclusion",
    "href": "Take-home_Ex/Take-home_Ex03.html#conclusion",
    "title": "Take-home_Ex03",
    "section": "4 Conclusion",
    "text": "4 Conclusion\n\n\n\n\n\nThe goal of this assignment was to critique and redesign three visualizations of Singapore’s trade market data, followed by a detailed time-series analysis to uncover trends and patterns in trade over time.\n\nVisualisation redesigns: The 3 visualisation make-over present more ways to show audience the same set of data and more insightful information.\n\n\n\nVisualisation & insights: Analysis revealed an upward trend for Singapore’s geographically proximate trade partners, including China, Hong Kong, Taiwan, Japan, Korea, Thailand, and the US. Time series decomposition identified distinct seasonality and cyclical patterns in several trading relationships that warrant further investigation.\nCOVID-19 period: The pandemic significantly disrupted global trade flows, clearly visible in the visualizations. Trade volumes decreased across most markets and goods during this period, with varying recovery patterns afterward.\nTime series forecasting: The ARIMA and ETS models employed demonstrated the challenges in accurately forecasting trade volumes, largely due to the complex interplay of economic conditions, policy changes, and external shocks affecting international trade.\nLimitations: This analysis did not incorporate historical policy decisions or economic events that could provide contextual explanation for the patterns observed in the data.\nRecommendation for future analysis: Future work should include statistical significance testing of the observed patterns and changes. More sophisticated machine learning techniques could be explored for more accurate trade flow predictions. Additionally, incorporating complementary datasets such as GDP, inflation rates would provide a more comprehensive view of Singapore’s trade dynamics.\n\nMy eyes soar, and feel the more I learn, the more I do not know. Working with these visualization and analysis techniques has been eye-opening! I’m amazed at how much I’ve learned, but also how much more there is to discover. Time series analysis is deeper and more complex than I initially thought, and I’m excited to keep exploring new approaches in the future."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03.html#reference",
    "href": "Take-home_Ex/Take-home_Ex03.html#reference",
    "title": "Take-home_Ex03",
    "section": "Reference",
    "text": "Reference\nKam, T. S. (2023, December 4). R for Visual Analytics. https://r4va.netlify.app/\nHyndman, R.J., & Athanasopoulos, G. (2021) Forecasting: principles and practice, 3rd edition, OTexts: Melbourne, Australia. OTexts.com/fpp3. Accessed on 8 Mar 2025.\nStalder, T., Holtz, Y. (2021): Extended Dumbbell Plot in R with ggplot2. R graph gallery. Access: r-graph-gallery.com/web-extended-dumbbell-plot-ggplot2.html. Date: 08-03-2015.\nDepartment of Statistics Singapore. Singapore’s International Trade. Singapore Government, https://www.singstat.gov.sg/modules/infographics/singapore-international-trade. Accessed 8 Mar. 2025.\nDepartment of Statistics Singapore. Merchandise Trade – Latest Data. Singapore Government, https://www.singstat.gov.sg/find-data/search-by-theme/trade-and-investment/merchandise-trade/latest-data. Accessed 8 Mar. 2025."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Cathy C.",
    "section": "",
    "text": "My name is Cathy.\nCreating cute illustrations in my spare time is one of my favourite hobbies.",
    "crumbs": [
      "![](/images/house.svg)",
      "About"
    ]
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "Cathy C.",
    "section": "Education",
    "text": "Education\nSingapore Management University | Masters of IT in Business | Expected Dec 2025",
    "crumbs": [
      "![](/images/house.svg)",
      "About"
    ]
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "Cathy C.",
    "section": "Experience",
    "text": "Experience\nMultiple MNCs | Program Manager, Training instructor | Singapore",
    "crumbs": [
      "![](/images/house.svg)",
      "About"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#getting-started",
    "title": "Hands-on_Ex01",
    "section": "1.2 Getting started",
    "text": "1.2 Getting started\n\n1.2.1 Installing and loading the required libraries\n🔑 pacman package has been installed in the workshop, using the following code.\n\npacman::p_load(tidyverse)\n\n\n\n1.2.2 Importing data\nread_csv is a function of readr package, which is from the tidyverse package.\nThe dataset Exam_data.csv, containing exam grades of P3 students from a Singapore local school is imported into R environment.\n🔑 The code chunk below was used to import the dataset.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nID\nCLASS\nGENDER\nRACE\nMATHS\nENGLISH\nSCIENCE\n\n\nStudent321\n3I\nMale\nMalay\n21\n9\n15\n\n\nStudent305\n3I\nFemale\nMalay\n24\n22\n1",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 1"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#introducing-ggplot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#introducing-ggplot",
    "title": "Hands-on_Ex01",
    "section": "1.3 Introducing ggplot",
    "text": "1.3 Introducing ggplot\nggplot2 is part of the tidyverse family specially designed for visual exploration and communication. It creates graphics based on The Grammar of Graphics.\n\n\n\n\n\n\nCheatsheet for ggplot2 (Learn more)\n\n\n\n\n\n\n\n\n\n\n\n1.3.1 R Graphics vs. ggplot\n🔑 Observe how R Graphics and ggplot are different when plotting a simple histogram. An example below:\n\nR Graphicsggplot2\n\n\n\nhist(exam_data$MATHS)\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, aes(x = MATHS)) + \n  geom_histogram(bins=10,\n                 boundary=100,\n                 color=\"snow4\",\n                 fill=\"mistyrose\") +\n  ggtitle(\"Distribution of Math Scores\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n🦖 PRACTICE\nPractice plotting the different charts for English.\n\nG graphicshistogramboxplot\n\n\n\nhist(exam_data$ENGLISH)\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x = ENGLISH)) +\n  geom_histogram(bins = 10,\n                 boundary = 100,\n                 color = \"black\",\n                 fill = \"skyblue\") +\n  ggtitle(\"Distribution of English Scores\")\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x = GENDER,\n           y = ENGLISH)) +\n  geom_boxplot(outlier.colour = \"skyblue\",\n               outlier.fill = \"skyblue\",) +\n  ggtitle(\"Distribution of English Scores\")",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 1"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#grammar-of-graphics",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#grammar-of-graphics",
    "title": "Hands-on_Ex01",
    "section": "1.4 Grammar of Graphics",
    "text": "1.4 Grammar of Graphics\n❓ What is a statistical graphic?\nUnderstanding the principles of grammar of graphics: a general scheme for data visualisation which breaks up graphs into semantic components such as scales and layers.\nIt was introduced by Leland Wlkinson (1999). It defines the rules of structural mathematical and aesthetic elements into a meaningful graph.\n\n\n\n\n\n\nNote\n\n\n\nTwo principles in grammar of graphics are:\n\nGraphics = distinct layers of grammatical elements\nMeaningful plots through aesthetic mapping\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nA good grammar of graphics has the following characters:\n\nAllows us to gain insights into the composition of complicated graphics.\nReveals unexpected connections between seemingly different graphics (Cox 1978).\nProvides a strong foundation for understanding a diverse range of graphics.\nMay also help guide us on what a well-formed or correct graphic looks like, but there will still be many grammatically correct but nonsensical graphics.\n\n\n\n\n1.4.1 A Layered Grammar of Graphics\nggplot2 is an implementation of Leland Wilkinson’s Grammar of Graphics. Figure below shows the seven grammars of ggplot2.\n\n\n\n\n\nReference: Hadley Wickham (2010) “A layered grammar of graphics.” Journal of Computational and Graphical Statistics, vol. 19, no. 1, pp. 3–28.\n\n\n\n\n\n\nImportant\n\n\n\nA short description of each building blocks:\n\nData: the dataset being plotted.\nAesthetic: takes attributes of the data and use them to influence visual characteristics, such as position, colours, size, shape, or transparency.\nGeometrics: the visual elements used for our data, such as point, bar or line.\nFacets: split the data into subsets to create multiple variations of the same graph (paneling, multiple plots).\nStatistics: statistical transformations that summarise data (e.g. mean, confidence intervals).\nCoordinate systems: define the plan on which data are mapped on the graphic.\nThemes: modify all non-data components of a plot, such as main title, sub-title, y-axis title, or legend background.",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 1"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-data",
    "title": "Hands-on_Ex01",
    "section": "1.5 Essential Grammatical Elements in ggplot2: data",
    "text": "1.5 Essential Grammatical Elements in ggplot2: data\n🔑 Calling the ggplot() function, using the code chunk below:\n\nggplot(data=exam_data)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nA blank canvas appears.\nggplot initializes a ggplot object.\nThe data argument defines the dataset to be used for plotting.\nIf the dataset is not aleady a data.frame, it will be converted to one by fortify().",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 1"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-aesthetic-mappings",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-aesthetic-mappings",
    "title": "Hands-on_Ex01",
    "section": "1.6 Essential Grammatical Elements in ggplot2: Aesthetic mappings",
    "text": "1.6 Essential Grammatical Elements in ggplot2: Aesthetic mappings\nThe aesthetic mappings take attributes of the data and use them to influence visual characteristics, such as position, colour, size, shape, or transparency. Each visual characteristic can this encode an aspect of the data and be used to convey information.\n\nAll aesthetic of a plot are specified in the aes() function call.\n\n\n\n🚀 Usage aes(x,y,…)\nThe names for x and y aesthetics are typically omitted because they are so common; all other aesthetics must be named.\n\nEach geom layer can have its own aes specification.\n\n🔑 Code chunk below adds the aesthetic element into the plot.\n\n\n🚀 To display line numbers alongside the code block, can use the code-line-numbers attribute.\nFor example, {.r code-line-numbers=\"true\"}\nggplot(data=exam_data,\n       aes(x = MATHS))\n\n\n\n\n\n\nNote\n\n\n\n\nggplot includes the x-axis and the axis’s label.\n\n\n\n\n\n\n\n\n\nAesthetic specifications\n\n\n\nResources",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 1"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-geom",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-geom",
    "title": "Hands-on_Ex01",
    "section": "1.7 Essential Grammatical Elements in ggplot2: geom",
    "text": "1.7 Essential Grammatical Elements in ggplot2: geom\nGeometric objects are the actual marks we put on a plot. Examples include:\n\ngeom_point for drawing individual points (e.g., a scatter plot)\ngeom_line for drawing lines (e.g., for a line charts)\ngeom_smooth for drawing smoothed lines (e.g., for simple trends or approximations)\ngeom_bar for drawing bars (e.g., for bar charts)\ngeom_histogram for drawing binned values (e.g., a histogram)\ngeom_polygon for drawing arbitrary shapes\ngeom_map for drawing polygons in the shape of a map! (data can be accessed for these maps by using the map_data() function).\nA plot must have one geom, but there is no limit. Add a geom to a plot using the + operator.\n\n\n\n🦄 Complete list of geom layers\n\n\n\n\n\n\n\nR colors\n\n\n\nColor codes for R as a resource. \n\ncl &lt;- colors()\nlength(cl); cl[1:20] #display 1-20\n\n[1] 657\n\n\n [1] \"white\"         \"aliceblue\"     \"antiquewhite\"  \"antiquewhite1\"\n [5] \"antiquewhite2\" \"antiquewhite3\" \"antiquewhite4\" \"aquamarine\"   \n [9] \"aquamarine1\"   \"aquamarine2\"   \"aquamarine3\"   \"aquamarine4\"  \n[13] \"azure\"         \"azure1\"        \"azure2\"        \"azure3\"       \n[17] \"azure4\"        \"beige\"         \"bisque\"        \"bisque1\"      \n\n\n\n\n\n1.7.1 Geometric Objects: geom_bar\n🔑 Code chunk below to plot a bar chart using geom_bar()\n\nggplot(data=exam_data,\n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n❓ Code won’t run when using {r code-line-numbers=\"true\"}\n\n\n1.7.2 Geometric Objects: geom_dotplot\nIn a dot plot, the width of a dot corresponds to the bin width (or maximum width, depending on the binning algorithm), and dots are stacked, with each dot representing one observation.\n🔑 geom_dotplot() of ggplot2 is used to plot a dot plot with the code chunk below.\n\nggplot(data=exam_data,\n       aes(x = MATHS)) +\n  geom_dotplot(dotsize = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBe warned\n\n\n\nThe y scale could be misleading, so isn’t useful.\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe code chunk below performs the following 2 steps:\n\nscale_y_continuous() is sued to turn off the y-axis, and\nbinwidth argument is used to change the binwidth to 2.5.\n\n\n\n\nggplot(data=exam_data,\n       aes(x = MATHS)) +\n  geom_dotplot(binwidth = 2.5,\n               dotsize = 0.5) +\n  scale_y_continuous(NULL,\n                     breaks = NULL)\n\n\n\n\n\n\n\n\n\n\n1.7.3 Geometric Objects: geom_histogram()\n🔑 In the code chunk below, geom_histogram() is used to create a simple histogram by using values in MATHS field of exam_data.\n\n\n🚀 Histograms (geom_histogram()) display the counts with bars; frequency polygons (geom_freqpoly()) display the counts with lines.\nFrequency polygons are more suitable when you want to compare the distribution across the levels of a categorical variable.\n\nggplot(data = exam_data,\n       aes(x = MATHS)) +\n  geom_histogram()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote that the default bin is 30.\n\n\n\n\n1.7.4 Modify a geometric object by changing geom()\nIn the code chunk below,\n\nbins argument is used to change the number of of bins to 20,\nfill argument is used to shade the histogram with light blue color, and\ncolor argument is used to change the outline colour of the bars in black.\n\nggplot(data=exam_data,\n       aes(x = MATHS)) + \n  geom_histogram(bins=20,\n                 color=\"black\",\n                 fill=\"light blue\")\n\n\n\n\n\n\n\n\n\n\n\n1.7.5 Modify a geometric object by changing aes()\nThe code chunk below changes the interior colour of t he histogram (i.e. fill) by using sub-group of aesthetic().\nggplot(data=exam_data,\n       aes(x = MATHS,\n           fill = GENDER)) +\n  geom_histogram(bins=20,\n                 color=\"grey30\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe approach can be used to colour, fill and alpha of the geometric.\n\n\n\n\n1.7.6 Geometric Objects: geom_density()\ngeom_density() computes and plots kernel density estimate, which is a smoothed version of the histogram.\n\n\n🦄 geom-density() understands the following aesthetics: x, y, alpha, colour, fill, group, linetype, linewidth, weight.\nIt is a useful alternative to the histogram for continuous data that comes from an underlying smooth distribution.\n🔑 The code below plots the distribution of Maths scores in a kernel density estimate plot.\nggplot(data=exam_data,\n       aes(x = MATHS)) + \n  geom_density()\n\n\n\n\n\n\n\n\n\n🔑 The code chunk below plots two kernel density lines by using colour or fill arguments of aes()\nggplot(data=exam_data,\n       aes(x = MATHS,\n           colour = GENDER)) +\n  geom_density()\n\n\n\n\n\n\n\n\n\n\n\n1.7.7 Geometric Objects: geom_boxplot\ngeom_boxplot() displays continuous value list. It visualises five summary statistics (the median, two hinges and two whiskers), and all “outlying” points individually.\n\n\n🦄 geom_boxplot() understands the following aesthetics:\nx or y, lower or xlower, upper or xupper, middle or xmiddle, ymin or xmin, ymax or xmax, alpha, colour, fill, group, linetype, linewidth, shape, size, weight.\n🔑 The code chunk below plots boxplots by using geom_boxplot()\nggplot(data=exam_data,\n       aes(y = MATHS,\n           x = GENDER)) + \n  geom_boxplot()\n\n\n\n\n\n\n\n\n\nNotches are used in box plots to help visually assess whether the medians of distributions differ. If the notches do not overlap, this is evidence that the medians are different.\n🔑 The code chunk below plots the distribution of Maths scores by gender in notched plot instead of boxplot.\nggplot(data=exam_data,\n       aes(y = MATHS,\n           x = GENDER)) +\n  geom_boxplot(notch=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n1.7.8 Geometric Objects: geom_violin\ngeom_violin() is designed for creating violin plot. Violin plots are a way of comparing multiple data distributions. With ordinary density curves, it is difficult to compare more than just a few distributions because the lines visually interfere with each other. With a violin plot, it’s easier to compare several distributions since they’re placed side by side.\n\n\ngeom_violin() understands the following aesthetics:\nx, y, alpha, colour, fill, group, linetype, linewidth,weight.\n🔑 The code below plot the distribution of Maths score by gender in violin plot.\nggplot(data=exam_data,\n       aes(y = MATHS,\n           x = GENDER)) +\n  geom_violin()\n\n\n\n\n\n\n\n\n\n\n\n1.7.9 Geometric Objects: geom_point()\ngeom_point() is especially useful for creating scatterplot. The scatterplot is most useful for displaying the relationship between two continuous variables.\n\n\n🦄 geom_point() can be used to compare one continuous and one categorical variable, or two categorical variables, but a variation like geom_jitter(), geom_count(), or geom_bin_2d() is usually more appropriate.\nA bubblechart is a scatterplot with a third variable mapped to the size of points.\n🔑 The code chunk below plots a scatterplot showing that Maths and English grades of pupils by using geom_point().\nggplot(data=exam_data,\n       aes(x= MATHS,\n           y= ENGLISH)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\n1.7.10 Geometric objects can be combined\n\n\n🐳 AMAZING\n🔑 The code chunk below plots the data points on the boxplots by using both geom_boxplot() and geom_point().\nggplot(data=exam_data,\n       aes(y = MATHS,\n           x = GENDER)) +\n  geom_boxplot() +\n  geom_point(position = \"jitter\",\n             size = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n💊 Point size in actual figure = 0.3",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 1"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-stat",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-stat",
    "title": "Hands-on_Ex01",
    "section": "1.8 Essential Grammatical Elements in ggplot2: stat",
    "text": "1.8 Essential Grammatical Elements in ggplot2: stat\nThe Statistics functions statistically transform data, usually as some form of summary. For example:\n\nFrequencey of values of a variable (bar graph)\n\na mean\na confidence limit\n\nThere are two ways to use these functions:\n\nadd a stat_() function and override the default geom, or\nadd a geom_() function and override the default stat.\n\n\n\n1.8.1 Working with stat()\nThe boxplots below are incomplete because the positions of the means were not shown.\n\nggplot(data=exam_data,\n       aes(y = MATHS, x = GENDER)) + \n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n1.8.2 Working with stat - the stat_summary() method\nThe code chunk below adds mean values by using stat_summary() function and overriding the default geom.\nstat_summary() operates on unique x or y; stat_summary_bin() operates on binned x or y. They are more flexible versions of stat_bin(): instead of just counting, they can compute any aggregate.\n\nggplot(data=exam_data,\n       aes(y = MATHS, x = GENDER)) + \n  geom_boxplot() +\n  stat_summary(geom = \"point\",\n               fun = \"mean\",\n               colour = \"red\",\n               size = 4)\n\n\n\n\n\n\n\n\n\n\n1.8.3 Working with the stat - the geom() method\nThe code chunk below adds mean values by using geom_() function and overriding the default stat.\n\nggplot(data=exam_data,\n       aes(y = MATHS, x = GENDER)) + \n  geom_boxplot() +\n  geom_point(stat = \"summary\",\n             fun = \"mean\",\n             colour = \"red\",\n             size = 4)\n\n\n\n\n\n\n\n\n\n\n1.8.4 Adding a best fit curve on a scatterplot?\nThe scatterplot below shows the relationship of Maths and English grades of pupils. The interpretability of this graph can be improved by adding a best fit curve.\n\n\n❓ Unable to adjust scale\n\n\n\n\n\n\n\n\n\n🔑 In the code chunk below, geom_smooth() is used to plot a best fit curve on the scatterplot.\nggplot(data=exam_data,\n       aes(x = MATHS, y = ENGLISH)) +\n  geom_point() +\n  geom_smooth(linewidth = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe default method used is loess.\ngeom_smooth(method = \"loess\")\n\n\n🔑 The default smoothing method can be overridden as shown below.\nggplot(data=exam_data,\n       aes(x = MATHS, y = ENGLISH)) +\n  geom_point() +\n  geom_smooth(method = lm,\n              linewidth = 0.5)",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 1"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-facets",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-facets",
    "title": "Hands-on_Ex01",
    "section": "1.9 Essential Grammatical Elements in ggplot2: Facets",
    "text": "1.9 Essential Grammatical Elements in ggplot2: Facets\nFacetting generates small multiples (sometimes also called treillis plot), each displaying a different subset of the data. They are an alternative to aesthetics for displaying additional discrete variables. ggplot suppoorts two types of facets, namely: facet_grid() and facet_wrap().\n\n1.9.1 Working with facet_wrap()\nfacet_wrap() wraps a 1d sequence of panels into 2d. This is generally a better use of screen space than facet_grid because most displays are roughly rectangular.\n🔑 The code chunk below plots a trellis plot using facet_wrap().\nggplot(data=exam_data,\n       aes(x = MATHS)) +\n  geom_histogram(bins=20) + \n  facet_wrap(~ CLASS)\n\n\n\n\n\n\n\n\n\n\n\n1.9.2 facet_grid() function\nfacet_grid() forms a matrix of panels defined by row and columns facetting variables. It is most useful when you have two discrete variables, and all combinations of the variables exist in the data.\n🔑 The code chunk below plots a trellis plot using facet_grid() .\n\n\n🦄 If you have only one variable with many levels, try facet_wrap().\nggplot(data=exam_data,\n       aes(x = MATHS)) +\n  geom_histogram(bins=20) +\n  facet_grid(~ CLASS)\n\n\n\n\n\n\n\n\n\n\n\n🦖 PRACTICE\n\nggplot(data=exam_data,\n       aes(x = MATHS, y = ENGLISH)) +\n  geom_point(size=0.8, colour=\"skyblue\") +\n  facet_wrap(~ CLASS)",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 1"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-coordinates",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-coordinates",
    "title": "Hands-on_Ex01",
    "section": "1.10 Essential Grammatical Elements in ggplot2: Coordinates",
    "text": "1.10 Essential Grammatical Elements in ggplot2: Coordinates\nThe Coordinates functions map the position of objects onto the plane of the plot. There are a number of different possible coordinate systems to use, they are:\n\ncoord_cartesian(): the default cartesian coordinate systems, where you specify x and y values (e.g. allows you to zoom in or out.)\ncoord_flip(): a cartesian system with the x and y flipped.\ncoord_fixed(): a cartesian system with a “fixed” aspect ratio (e.g. 1.78 for a “widescreen” plot).\ncoord_quickmap(): a coordinate system that approximates a good aspect ratio for maps.\n\n\n1.10.1 Working with Coordinate\nBy the default, the bar chart of ggplot2 is in vertical form.\n\nggplot(data=exam_data,\n       aes(x = RACE)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n🔑 The code chunk below flips the horizontal bar chart into vertical bar chart by using coord_flip().\n\nggplot(data=exam_data,\n       aes(x = RACE)) +\n  geom_bar(color=\"gray\",fill=\"skyblue\") +\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\n1.10.2 Changing the y- and x-axis range\nThe scatterplot on the right is slightly misleading because the y-axis range are not equal.\n\nggplot(data=exam_data,\n       aes(x = MATHS, y = ENGLISH)) +\n  geom_point(size = 1) +\n  geom_smooth(method = lm, size = 0.5)",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 1"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-themes",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-themes",
    "title": "Hands-on_Ex01",
    "section": "1.11 Essential Grammatical Elements in ggplot2: themes",
    "text": "1.11 Essential Grammatical Elements in ggplot2: themes\nThemes control elements of the graph not related to the data. For example:\n\nbackground colour\nsize fnts\ngridlines\ncolour of labels\n\nBuilt-in themes include -theme_gray()(default)-theme_bw()-theme_classic()\nA list of theme can be found at this link. Each theme element can be conceived f as either a line (e.g. x-axis), a rectangle (e.g. graph background), or text (e.g. axis title).\n\n1.11.1 Working with theme\n🔑 The code chunk below plot a horizontal bar chart using theme_gray().\nggplot(data=exam_data,\n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_gray()\n\n\n\n\n\n\n\n\n\n🔑 A horizontal bar chart plotted using theme_classic().\nggplot(data=exam_data,\n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_classic()\n\n\n\n\n\n\n\n\n\n🔑 A horizontal bar chart plotted using theme_minimal().\nggplot(data=exam_data,\n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_minimal()\n\nggplot(data=exam_data,\n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_minimal()",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 1"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#reference",
    "title": "Hands-on_Ex01",
    "section": "1.12 Reference",
    "text": "1.12 Reference\n\nHadley Wickham (2023) ggplot2: Elegant Graphics for Data Analysis. Online 3rd edition.\nWinston Chang (2013) R Graphics Cookbook 2nd edition. Online version.\nHealy, Kieran (2019) Data Visualization: A practical introduction. Online version\nLearning ggplot2 on Paper – Components\nLearning ggplot2 on Paper – Layer\nLearning ggplot2 on Paper – Scale",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 1"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_1.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_1.html",
    "title": "Hands-on_Ex08_1",
    "section": "",
    "text": "Choropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors.\nFor example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nWe will learn how to plot functional and truthful choropleth maps by using an R package called tmap package.\n\n\nTips\n\n\nRead each functional description before use.\n\n\n\n\n\nIn this hands-on exercise, the key R package use is tmap package in R. Besides tmap package, four other R packages will be used. They are:\n\nreadr for importing delimited text file\ntidyr for tidying data\ndplyr for wrangling data\nsf for handling geospatial data\n\nAmong the four packages, readr, tidyr and dplyr are part of tidyverse package.\nThe code chunk below will be used to install and load these packages in RStudio.\n\npacman::p_load(sf, tmap, tidyverse)\n\n\n\nTips\n\n\n\nOnly need to install tidyverse instead of readr, tidyr and dplyr individually.\nsf - simple feature: allows us to do data exchange.\n\n\n\n\n\n\n\n\nTwo data set will be used to create the choropleth map. They are:\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format. It can be downloaded at data.gov.sg This is a geospatial data. It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on URA Master Plan 2014.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv). This is an aspatial data fie. It can be downloaded at Department of Statistics, Singapore. Although it does not contain any coordinates values, its PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile.\n\n\n\n\nThe code chunk below uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame called mpsz.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\",\n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/cathyc/Documents/cathyschu/ISSS608_new/Hands-on_Ex/Hands-on_Ex08/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nTo examine the data:\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\n\nWhy only 10 records are displayed?\n\n\nThis is a default behavior in R, particularly for spatial data frames and sf (simple features) objects.\nA few ways to view more rows:\n\nUse print(mpsz, n = 20) to show more rows (20 in this example)\nUse View(mpsz) to open the data in R’s data viewer window\nUse head(mpsz, 30) to see the first 30 rows\nUse str(mpsz) to see the structure of the entire object\nUse summary(mpsz) to get a statistical summary\n\n\n\n\n\n\nNext, we will import respopagsex2011to2020.csv file into RStudio and save the file into an R dataframe called popagsex.\nThe task will be performed by using *read_csv()* function of readr package as shown in the code chunk below.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\n\n\n\nBefore a thematic map can be prepared, it is required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24\nECONOMY ACTIVE: age group 25-29 until age group 60-64\nAGED: age group 65 and above\nTOTAL: all age group\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n\n\nThe following data wrangling and transformation functions will be used: - pivot_wider() of tidyr package - mutate(), filter(), group_by() and select() of dplyr package\n\n\nShow the code\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from=AG,\n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%\nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`,\n       `ECONOMY ACTIVE`, `AGED`,\n       `TOTAL`, `DEPENDENCY`)\n\n\n\n\n\nBefore we can perform the georelational join, one extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper- and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ),\n          .funs = funs(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nThing to learn from the code chunk above:\nleft_join() of dplyr package is used with mpsz simple feature data frame as the left data table is to ensure that the output will be a simple features data frame.\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")\n\n\n\n\n\nTwo approaches can be used to prepare thematic map using tmap, they are:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\n\nThe easiest and quickest to draw a choropleth map using **tmap** is using *qtm()*. It is concise and provides a good default visualisation in many cases.\nThe code chunk below will draw a cartographic standard choropleth map as shown below.\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020,\n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\ntmap_mode(\"view\")\nqtm(mpsz_pop2020,\n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\nLearn from code chunk\n\n\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\nfill argument is used to map the attribute (i.e. DEPENDENCY)\n\n\n\n\ntmap_mode(\"plot\")\n\n\n\n\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of qtm() is that it makes aesthetics of individual layers harder to control. To draw a high quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\n\nShow the code\ntm_shape(mpsz_pop2020)+\n  tm_polygons(fill = \"DEPENDENCY\",\n          fill.scale = tm_scale_intervals( #variability\n            style = \"quantile\",\n            n = 5, #classes\n            values = \"brewer.blues\"), #colour\n          fill.legend = tm_legend(\n          title = \"Dependency ratio\"  \n          )) +\n  tm_title (\"Distribution of Dependency Ratio by planning subzone\") +\n  tm_layout(legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(fill_alpha = 0.3) +\n  tm_compass(type=\"8star\", size = 2) +\n#  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\\\n and Population data from Department of Statistics DOS\",\n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\nIn the following sub-section, we will learn the tmap functions that used to plot these elements.\n\n\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_fill() and tm_polygons().\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\n\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\n\nLearn from tm_polygons()\n\n\n\nThe default interval binning used to draw the choropleth map is called “pretty”. A detailed discussion of the data classification methods supported by tmap will be provided in sub-section 4.3.\nThe default colour scheme used is YlOrRd of ColorBrewer. We will learn more about the color scheme in sub-section 4.4.\nBy default, Missing value will be shaded in grey.\n\n\n\n\n\n\ntm_polygons() = tm_fill() + tm_border()\ntm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\nThe code chunk below draws a choropleth map by using tm_fill() alone.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nNotice that the planning subzones are shared according to the respective dependecy values.\nTo add the boundary of the planning subzones, tm_borders will be used as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  fill_alpha = 1)\n\n\n\n\n\n\n\n\n\n\nLearning\n\n\n\nLight-gray border lines have been added on the choropleth map.\nThe alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nBeside alpha argument, there are three other arguments for tm_borders(), they are:\n\ncol = border colour\nlwd = border line width. The default is 1\nlty = border line type. The default is “solid”\n\n\n\n\n\n\n\n\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\n\n\nThe code chunk below shows a quantile data classification that used 5 classes.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nIn the code chunk below, equal data classification method is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nNote that the distribution of quantile data classification method are more evenly distributed than equal data classification method.\n\n\n\nUsing what you had learned, prepare choropleth maps by using different classification methods supported by tmap and compare their differences.\n\nprettysdn=2n=6n=10\n\n\nCreates “pretty” breaks that are easy to understand.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"pretty\",\n          palette = \"Greens\") +\n  tm_borders(alpha = 0.3)\n\n\n\n\n\n\n\n\n\n\nCreates classes based on standard deviation from the mean.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"sd\",\n          palette = \"Greens\") +\n  tm_borders(alpha = 0.3)\n\n\n\n\n\n\n\n\n\n\nPreparing choropleth maps by using similar classification method but with different numbers of classes (i.e. 2, 6, 10, 20). Compare the output maps, what observation can you draw?\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 2,\n          style = \"jenks\",\n          palette = \"Oranges\") +\n  tm_borders(alpha = 0.3)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"jenks\",\n          palette = \"Oranges\") +\n  tm_borders(alpha = 0.3)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 10,\n          style = \"jenks\",\n          palette = \"Oranges\") +\n  tm_borders(alpha = 0.3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaks argument to the tm_fill(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nBefore we get started, it is always a good practice to get some descriptive statistics on the variable before setting the break points. Code chunk below will be used to compute and display the descriptive statistics of DEPENDENCY field.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00)\nNow, we will plot the choropleth map by using the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n\nTo change the colour, we assign the preferred colour to palette argument of tm_fill() as shown in the code chunk below.\n\nReds-Reds\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"brewer.Oranges\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nTo reverse the colour sharing, add a ‘-’ prefix.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"-brewer.Oranges\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nNow the colour scheme has been reversed!\n\n\n\n\n\n\n\nMap layout refers to the combination of all map elements into a cohensive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\n\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\n\nShow the code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          values = \"brewer.YlOrRd\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style is used.\n\n\nShow the code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n\n\n\n\n\n\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\n\nShow the code\ntm_shape(mpsz_pop2020)+\n  tm_polygons(fill = \"DEPENDENCY\", \n              fill.scale = tm_scale_intervals(\n                style = \"quantile\",\n                n = 5,\n                values = \"brewer.blues\"),\n                fill.legend = tm_legend(\n                title = \"Dependency ratio\"),\n              col = \"#f1f4f5\") +\n  tm_title(\"Distribution of Dependency Ratio by planning subzone\") +\n  tm_layout(frame = TRUE,\n            bg.color = \"#f1f4f5\") +\n  tm_borders(fill_alpha = 0.5) +\n  tm_basemap(server = NULL) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA) and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\nTo reset the default style, we will use:\n\ntmap_style(\"white\")\n\n\n\n\n\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\n\nSmall multiple choropleth maps are created by defining ncols in tm_fill()\n\n\nShow the code\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"brewer.blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"),\n            legend.width = 5, \n            legend.height = 6,        \n            legend.text.size = 0.7,      \n            legend.title.size = 0.5,\n            legend.frame = FALSE,\n            frame.col = \"grey\",\n            bg.color = \"#f1f4f5\") + \n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\n\n\n\n\n\nsmall multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments.\nBelow maps are plotted using different versions of tmap. For some reason, v4 isn’t able to show another color, other than blue.\n\nv4v3\n\n\n\n\nShow the code\nmap1 &lt;- tm_shape(mpsz_pop2020) + \n  tm_polygons(\"DEPENDENCY\", \n          style = \"equal\", \n          values = \"matplotlib.Blues\",\n          title = \"Dependency\") +\n  tm_borders() +\n  tm_layout(legend.position = c(\"right\", \"bottom\"),\n            legend.frame = FALSE,\n            frame.lwd = 0.5,\n            frame.col = \"grey\")\n\nmap2 &lt;- tm_shape(mpsz_pop2020) + \n  tm_polygons(\"AGED\", \n          style = \"quantile\", \n          values = \"matplotlib.Greens\",\n          title = \"Aged\") +\n  tm_borders() +\n  tm_layout(legend.position = c(\"right\", \"bottom\"),\n            legend.frame = FALSE,\n            frame.lwd = 0.5,\n            frame.col = \"grey\")\n\ntmap_arrange(map1, map2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nmap1 &lt;- tm_shape(mpsz_pop2020) + \n  tm_fill(\"DEPENDENCY\", \n          style = \"equal\", \n          palette = \"matplotlib.Blues\",\n          title = \"Dependency\") +\n  tm_borders() +\n  tm_layout(legend.position = c(\"right\", \"bottom\"),\n            legend.frame = FALSE,\n            frame.lwd = 0.5,\n            frame.col = \"grey\")\n\nmap2 &lt;- tm_shape(mpsz_pop2020) + \n  tm_fill(\"AGED\", \n          style = \"quantile\", \n          palette = \"matplotlib.Greens\",\n          title = \"Aged\") +\n  tm_borders() +\n  tm_layout(legend.position = c(\"right\", \"bottom\"),\n            legend.frame = FALSE,\n            frame.lwd = 0.5,\n            frame.col = \"grey\")\n\ntmap_arrange(map1, map2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBelow multiple small choropleth maps are created by using tm_facets().\n\n\nShow the code\n# Try explicitly creating a list of maps by region\nlibrary(dplyr)\n\nregions &lt;- unique(mpsz_pop2020$REGION_N)\nmap_list &lt;- lapply(regions, function(region) {\n  region_data &lt;- mpsz_pop2020 %&gt;% filter(REGION_N == region)\n  tm_shape(region_data) +\n    tm_fill(\"DEPENDENCY\",\n            style = \"quantile\",\n            palette = \"matplotlib.Blues\",\n            na.value = \"grey\") +\n    tm_layout(title = region,\n              legend.show = FALSE,\n              title.size = 0.5,\n              title.color = \"#205781\") +\n    tm_borders(alpha = 0.5)\n})\n\n# Combine the maps\ntmap_arrange(map_list)\n\n\n\n\n\n\n\n\n\n\n\n\nIn this example, multiple small choropleth maps are created by creating multiple stand-alone maps with tmap_arrange().\n\n\nShow the code\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"matplotlib.Blues\") +\n    tm_layout(legend.position = c(\"right\", \"bottom\"),\n              legend.frame = FALSE) \n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"matplotlib.Blues\") +\n    tm_layout(legend.position = c(\"right\", \"bottom\"),\n              legend.frame = FALSE) \n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nInstead of creating small multiple choropleth map, you can also use selection funtion to map spatial objects meeting the selection criterion.\n\n\nShow the code\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ]) +\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"matplotlib.Blues\",\n          title = \"Dependency\",\n          legend.hist = TRUE) +  \n  tm_borders(alpha = 0.5) +\n  tm_layout(frame = FALSE,\n            legend.format = list(scientific = FALSE, format = \"f\"),  \n            legend.position = c(\"right\", \"bottom\"),\n            legend.frame = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\n\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 8-1"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_1.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_1.html#overview",
    "title": "Hands-on_Ex08_1",
    "section": "",
    "text": "Choropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors.\nFor example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nWe will learn how to plot functional and truthful choropleth maps by using an R package called tmap package.\n\n\nTips\n\n\nRead each functional description before use.",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 8-1"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_1.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_1.html#getting-started",
    "title": "Hands-on_Ex08_1",
    "section": "",
    "text": "In this hands-on exercise, the key R package use is tmap package in R. Besides tmap package, four other R packages will be used. They are:\n\nreadr for importing delimited text file\ntidyr for tidying data\ndplyr for wrangling data\nsf for handling geospatial data\n\nAmong the four packages, readr, tidyr and dplyr are part of tidyverse package.\nThe code chunk below will be used to install and load these packages in RStudio.\n\npacman::p_load(sf, tmap, tidyverse)\n\n\n\nTips\n\n\n\nOnly need to install tidyverse instead of readr, tidyr and dplyr individually.\nsf - simple feature: allows us to do data exchange.",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 8-1"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_1.html#import-data",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_1.html#import-data",
    "title": "Hands-on_Ex08_1",
    "section": "",
    "text": "Two data set will be used to create the choropleth map. They are:\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format. It can be downloaded at data.gov.sg This is a geospatial data. It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on URA Master Plan 2014.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv). This is an aspatial data fie. It can be downloaded at Department of Statistics, Singapore. Although it does not contain any coordinates values, its PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile.\n\n\n\n\nThe code chunk below uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame called mpsz.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\",\n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/cathyc/Documents/cathyschu/ISSS608_new/Hands-on_Ex/Hands-on_Ex08/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nTo examine the data:\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\n\nWhy only 10 records are displayed?\n\n\nThis is a default behavior in R, particularly for spatial data frames and sf (simple features) objects.\nA few ways to view more rows:\n\nUse print(mpsz, n = 20) to show more rows (20 in this example)\nUse View(mpsz) to open the data in R’s data viewer window\nUse head(mpsz, 30) to see the first 30 rows\nUse str(mpsz) to see the structure of the entire object\nUse summary(mpsz) to get a statistical summary\n\n\n\n\n\n\nNext, we will import respopagsex2011to2020.csv file into RStudio and save the file into an R dataframe called popagsex.\nThe task will be performed by using *read_csv()* function of readr package as shown in the code chunk below.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\n\n\n\nBefore a thematic map can be prepared, it is required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24\nECONOMY ACTIVE: age group 25-29 until age group 60-64\nAGED: age group 65 and above\nTOTAL: all age group\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n\n\nThe following data wrangling and transformation functions will be used: - pivot_wider() of tidyr package - mutate(), filter(), group_by() and select() of dplyr package\n\n\nShow the code\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from=AG,\n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%\nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`,\n       `ECONOMY ACTIVE`, `AGED`,\n       `TOTAL`, `DEPENDENCY`)\n\n\n\n\n\nBefore we can perform the georelational join, one extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper- and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ),\n          .funs = funs(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nThing to learn from the code chunk above:\nleft_join() of dplyr package is used with mpsz simple feature data frame as the left data table is to ensure that the output will be a simple features data frame.\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 8-1"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_1.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_1.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Hands-on_Ex08_1",
    "section": "",
    "text": "Two approaches can be used to prepare thematic map using tmap, they are:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\n\nThe easiest and quickest to draw a choropleth map using **tmap** is using *qtm()*. It is concise and provides a good default visualisation in many cases.\nThe code chunk below will draw a cartographic standard choropleth map as shown below.\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020,\n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\ntmap_mode(\"view\")\nqtm(mpsz_pop2020,\n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\nLearn from code chunk\n\n\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\nfill argument is used to map the attribute (i.e. DEPENDENCY)\n\n\n\n\ntmap_mode(\"plot\")\n\n\n\n\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of qtm() is that it makes aesthetics of individual layers harder to control. To draw a high quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\n\nShow the code\ntm_shape(mpsz_pop2020)+\n  tm_polygons(fill = \"DEPENDENCY\",\n          fill.scale = tm_scale_intervals( #variability\n            style = \"quantile\",\n            n = 5, #classes\n            values = \"brewer.blues\"), #colour\n          fill.legend = tm_legend(\n          title = \"Dependency ratio\"  \n          )) +\n  tm_title (\"Distribution of Dependency Ratio by planning subzone\") +\n  tm_layout(legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(fill_alpha = 0.3) +\n  tm_compass(type=\"8star\", size = 2) +\n#  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\\\n and Population data from Department of Statistics DOS\",\n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\nIn the following sub-section, we will learn the tmap functions that used to plot these elements.\n\n\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_fill() and tm_polygons().\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\n\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\n\nLearn from tm_polygons()\n\n\n\nThe default interval binning used to draw the choropleth map is called “pretty”. A detailed discussion of the data classification methods supported by tmap will be provided in sub-section 4.3.\nThe default colour scheme used is YlOrRd of ColorBrewer. We will learn more about the color scheme in sub-section 4.4.\nBy default, Missing value will be shaded in grey.\n\n\n\n\n\n\ntm_polygons() = tm_fill() + tm_border()\ntm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\nThe code chunk below draws a choropleth map by using tm_fill() alone.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nNotice that the planning subzones are shared according to the respective dependecy values.\nTo add the boundary of the planning subzones, tm_borders will be used as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  fill_alpha = 1)\n\n\n\n\n\n\n\n\n\n\nLearning\n\n\n\nLight-gray border lines have been added on the choropleth map.\nThe alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nBeside alpha argument, there are three other arguments for tm_borders(), they are:\n\ncol = border colour\nlwd = border line width. The default is 1\nlty = border line type. The default is “solid”\n\n\n\n\n\n\n\n\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\n\n\nThe code chunk below shows a quantile data classification that used 5 classes.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nIn the code chunk below, equal data classification method is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nNote that the distribution of quantile data classification method are more evenly distributed than equal data classification method.\n\n\n\nUsing what you had learned, prepare choropleth maps by using different classification methods supported by tmap and compare their differences.\n\nprettysdn=2n=6n=10\n\n\nCreates “pretty” breaks that are easy to understand.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"pretty\",\n          palette = \"Greens\") +\n  tm_borders(alpha = 0.3)\n\n\n\n\n\n\n\n\n\n\nCreates classes based on standard deviation from the mean.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"sd\",\n          palette = \"Greens\") +\n  tm_borders(alpha = 0.3)\n\n\n\n\n\n\n\n\n\n\nPreparing choropleth maps by using similar classification method but with different numbers of classes (i.e. 2, 6, 10, 20). Compare the output maps, what observation can you draw?\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 2,\n          style = \"jenks\",\n          palette = \"Oranges\") +\n  tm_borders(alpha = 0.3)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"jenks\",\n          palette = \"Oranges\") +\n  tm_borders(alpha = 0.3)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 10,\n          style = \"jenks\",\n          palette = \"Oranges\") +\n  tm_borders(alpha = 0.3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaks argument to the tm_fill(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nBefore we get started, it is always a good practice to get some descriptive statistics on the variable before setting the break points. Code chunk below will be used to compute and display the descriptive statistics of DEPENDENCY field.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00)\nNow, we will plot the choropleth map by using the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n\nTo change the colour, we assign the preferred colour to palette argument of tm_fill() as shown in the code chunk below.\n\nReds-Reds\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"brewer.Oranges\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nTo reverse the colour sharing, add a ‘-’ prefix.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"-brewer.Oranges\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nNow the colour scheme has been reversed!\n\n\n\n\n\n\n\nMap layout refers to the combination of all map elements into a cohensive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\n\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\n\nShow the code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          values = \"brewer.YlOrRd\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style is used.\n\n\nShow the code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n\n\n\n\n\n\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\n\nShow the code\ntm_shape(mpsz_pop2020)+\n  tm_polygons(fill = \"DEPENDENCY\", \n              fill.scale = tm_scale_intervals(\n                style = \"quantile\",\n                n = 5,\n                values = \"brewer.blues\"),\n                fill.legend = tm_legend(\n                title = \"Dependency ratio\"),\n              col = \"#f1f4f5\") +\n  tm_title(\"Distribution of Dependency Ratio by planning subzone\") +\n  tm_layout(frame = TRUE,\n            bg.color = \"#f1f4f5\") +\n  tm_borders(fill_alpha = 0.5) +\n  tm_basemap(server = NULL) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA) and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\nTo reset the default style, we will use:\n\ntmap_style(\"white\")\n\n\n\n\n\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\n\nSmall multiple choropleth maps are created by defining ncols in tm_fill()\n\n\nShow the code\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"brewer.blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"),\n            legend.width = 5, \n            legend.height = 6,        \n            legend.text.size = 0.7,      \n            legend.title.size = 0.5,\n            legend.frame = FALSE,\n            frame.col = \"grey\",\n            bg.color = \"#f1f4f5\") + \n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\n\n\n\n\n\nsmall multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments.\nBelow maps are plotted using different versions of tmap. For some reason, v4 isn’t able to show another color, other than blue.\n\nv4v3\n\n\n\n\nShow the code\nmap1 &lt;- tm_shape(mpsz_pop2020) + \n  tm_polygons(\"DEPENDENCY\", \n          style = \"equal\", \n          values = \"matplotlib.Blues\",\n          title = \"Dependency\") +\n  tm_borders() +\n  tm_layout(legend.position = c(\"right\", \"bottom\"),\n            legend.frame = FALSE,\n            frame.lwd = 0.5,\n            frame.col = \"grey\")\n\nmap2 &lt;- tm_shape(mpsz_pop2020) + \n  tm_polygons(\"AGED\", \n          style = \"quantile\", \n          values = \"matplotlib.Greens\",\n          title = \"Aged\") +\n  tm_borders() +\n  tm_layout(legend.position = c(\"right\", \"bottom\"),\n            legend.frame = FALSE,\n            frame.lwd = 0.5,\n            frame.col = \"grey\")\n\ntmap_arrange(map1, map2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nmap1 &lt;- tm_shape(mpsz_pop2020) + \n  tm_fill(\"DEPENDENCY\", \n          style = \"equal\", \n          palette = \"matplotlib.Blues\",\n          title = \"Dependency\") +\n  tm_borders() +\n  tm_layout(legend.position = c(\"right\", \"bottom\"),\n            legend.frame = FALSE,\n            frame.lwd = 0.5,\n            frame.col = \"grey\")\n\nmap2 &lt;- tm_shape(mpsz_pop2020) + \n  tm_fill(\"AGED\", \n          style = \"quantile\", \n          palette = \"matplotlib.Greens\",\n          title = \"Aged\") +\n  tm_borders() +\n  tm_layout(legend.position = c(\"right\", \"bottom\"),\n            legend.frame = FALSE,\n            frame.lwd = 0.5,\n            frame.col = \"grey\")\n\ntmap_arrange(map1, map2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBelow multiple small choropleth maps are created by using tm_facets().\n\n\nShow the code\n# Try explicitly creating a list of maps by region\nlibrary(dplyr)\n\nregions &lt;- unique(mpsz_pop2020$REGION_N)\nmap_list &lt;- lapply(regions, function(region) {\n  region_data &lt;- mpsz_pop2020 %&gt;% filter(REGION_N == region)\n  tm_shape(region_data) +\n    tm_fill(\"DEPENDENCY\",\n            style = \"quantile\",\n            palette = \"matplotlib.Blues\",\n            na.value = \"grey\") +\n    tm_layout(title = region,\n              legend.show = FALSE,\n              title.size = 0.5,\n              title.color = \"#205781\") +\n    tm_borders(alpha = 0.5)\n})\n\n# Combine the maps\ntmap_arrange(map_list)\n\n\n\n\n\n\n\n\n\n\n\n\nIn this example, multiple small choropleth maps are created by creating multiple stand-alone maps with tmap_arrange().\n\n\nShow the code\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"matplotlib.Blues\") +\n    tm_layout(legend.position = c(\"right\", \"bottom\"),\n              legend.frame = FALSE) \n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"matplotlib.Blues\") +\n    tm_layout(legend.position = c(\"right\", \"bottom\"),\n              legend.frame = FALSE) \n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nInstead of creating small multiple choropleth map, you can also use selection funtion to map spatial objects meeting the selection criterion.\n\n\nShow the code\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ]) +\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"matplotlib.Blues\",\n          title = \"Dependency\",\n          legend.hist = TRUE) +  \n  tm_borders(alpha = 0.5) +\n  tm_layout(frame = FALSE,\n            legend.format = list(scientific = FALSE, format = \"f\"),  \n            legend.position = c(\"right\", \"bottom\"),\n            legend.frame = FALSE)",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 8-1"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_1.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_1.html#reference",
    "title": "Hands-on_Ex08_1",
    "section": "",
    "text": "tmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\n\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 8-1"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "title": "Hands-on_Ex07",
    "section": "",
    "text": "In this chapter, we will learn to plot the following visualisations:\n\na calender heatmap (ggplot2 functions)\na cycle plot (ggplot2 functions)\na slopegraph\na horizon chart\n\n\n\n\nTo install and launch the following R packages:\nscales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table and tidyverse.\n\npacman::p_load(scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, \n               data.table, tidyverse, CGPfunctions, ggHoriPlot)\n\n\n\n\nWithin this section, we will do the following:\n\nplot a calendar heatmap by using ggplot2 functions and extension\nwrite function using R programming\nderive specific date and time related field by using base R and libridate packages\nperform data preparation task by using tidyr and dplyr packages\n\n\n\neventlog.csv file will be used for this exercise. This data file consists of 199,999 rows of time-series cyber attack records by country.\n\n1-Import data2-Exam data structure3-Data prep\n\n\nTo import eventlog.csv into R environment and call this data frame as attacks.\n\nattacks &lt;- read_csv(\"data/eventlog.csv\")\n\n\n\nWe will use kable() to review the structure of the imported data frame.\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nWe see 3 columns: timestamp, source_country, and tz.\n\ntimestamp: stores data-time values in POSIXct format.\nsource_country: stores the source of attack. It is in ISO3166-1 alpha-2 country code.\ntz: stores timezone of source IP address.\n\n\n\nStep 1. Deriving weekday and hour of day fields\nTwo new fields need to be derived: wkday and hour before we plot the calendar heatmap.\n\n\nShow the code\nmake_hr_wkday &lt;- function(ts, sc, tz) {\n  real_times &lt;- ymd_hms(ts,\n                        tz = tz[1],\n                        quiet = TRUE)\n  dt &lt;- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n}\n\n\n\n\nLearning from the code\n\n\n\nymd_hms() and hour() are from lubridate package.\nweekdays() is a base R function.\n\n\n\nStep 2. Deriving the attacks tibble data frame\n\n\nShow the code\nwkday_levels &lt;- c('Saturday', 'Friday', 'Thursday',\n                  'Wednesday', 'Tuesday', 'Monday',\n                  'Sunday')\nattacks &lt;- attacks %&gt;%\n  group_by(tz) %&gt;%\n  do(make_hr_wkday(.$timestamp,\n                   .$source_country,\n                   .$tz)) %&gt;%\n  ungroup() %&gt;%\n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour = factor(\n      hour, levels = 0:23\n    )\n  )\n\n\n\n\nLearning from the code\n\n\nmutate() of dplyr package is used to convert wkday and hour fields into factor so they will be ordered when plotting.\n\n\nStep 3. Check the tibble table:\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\n\n\n\n\nWe can simply group the count by hour and wkday and plot it, since we know that we have values for every combination. Use the code below to build the calendar heatmaps:\n\n\nShow the code\ngrouped &lt;- attacks %&gt;%\n  count(wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  na.omit()\n\nggplot(grouped,\n       aes(hour,\n           wkday,\n           fill = n)) +\n  geom_tile(color = \"#f1f4f5\",\n            size = 0.1) +\n  theme_tufte(base_family = \"Helvetica\") +\n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                      low = \"#faf1f0\",\n                      high = \"dark red\") +\n  labs(x = NULL,\n       y = NULL,\n       title = \"Attacks by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6))\n\n\n\n\n\n\n\n\n\n\n\nLearning from the code\n\n\n\na tibble data table called grouped is derived by aggregating the attack by wkday and hour fields.\na new field called n is derived by using group_by() and count() functions.\nna.omit() is used to exclude missing value.\ngeom_tile() is used to plot tiles (grids) at each x and y position. color and size arguments are used to specify the border color and line size of the tiles.\ntheme_tufte() of ggthemes package is used to remove unnecessary chart junk. [there is a dashed line around the plot removed by this theme]\ncoord_equal() is used to ensure the plot will have an aspect ratio of 1:1.\nscale_fill_gradient() function is used to create a two colour gradient (low-high).\n\n\n\n\n\n\nChallenge: Build multiple heatmaps for the top four countries with the highest number of attacks.\nStep 1. Derive attack numbers by country object\nTo identify the top 4 countries with the highest attack numbers, we need to do the following:\n\ncount the number of attacks by country\ncalculate the percentage of attacks by country\nsave the result in a tibble data frame\n\n\n\nShow the code\nattacks_by_country &lt;- count(\n  attacks, source_country) %&gt;%\n  mutate(percent = percent(n/sum(n))) %&gt;%\n  arrange(desc(n))\n\n\nStep 2. Prepare the tidy data frame\nNow, we will extract the top 4 countries from attacks data frame, and save the data in a new tibble data frame top4_attacks.\n\n\nShow the code\ntop4 &lt;- attacks_by_country$source_country[1:4]\ntop4_attacks &lt;- attacks %&gt;%\n  filter(source_country %in% top4) %&gt;%\n  count(source_country, wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  mutate(source_country = factor(\n    source_country, levels = top4\n  )) %&gt;%\n  na.omit()\n\n\nStep 3. Plot the multiple calendar heatmap with ggplot2\n\n\nShow the code\nggplot(top4_attacks,\n       aes(hour,\n           wkday,\n           fill = n)) +\n  geom_tile(color = \"#f1f4f5\", size = 0.1) +\n  theme_tufte(base_family = \"Helvetica\") +\n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                      low = \"#faf1f0\",\n                      high = \"dark red\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL,\n       title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 4),\n        axis.text.y = element_text(size = 4),\n        plot.title = element_text(size = 10, hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6))\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo show time-series patterns and trend of visitor arrivals from Vietnam, we will use Cycle plot to visualise it with ggplot2.\n\n\n\n1 Data import2 Deriving M and Y fields3 Extract target country4 Compute year avg arrival by month\n\n\nWe will use dataset from arrivals_by_air.xlsx. Since it’s in .xlsx format, read_excel() will be used to the read the file.\n\nair &lt;- read_excel(\"data/arrivals_by_air.xlsx\")\n\n\n\nHere 2 new fields called month and year are derived from Month-Year field.\n\nair$month &lt;- factor(month(air$'Month-Year'),\n                    levels = 1:12,\n                    labels = month.abb,\n                    ordered = TRUE)\nair$year &lt;- year(ymd(air$'Month-Year'))\n\n\n\nNow, we will extract data for the target country - Vietnam\n\nvietnam &lt;- air %&gt;%\n  select(`Vietnam`,\n         month,\n         year) %&gt;%\n  filter(year &gt;= 2010)\n\n\n\nThen we use group_by() and summarise() of dplyr to compute year average arrivals by month.\n\nhline.data &lt;- vietnam %&gt;%\n  group_by(month) %&gt;%\n  summarise(avgvalue = mean(`Vietnam`))\n\n\n\n\n\n\n\nNow plot the Cycle plot.\n\n\nShow the code\nggplot() +\n  geom_line(data = vietnam,\n            aes(x = year,\n                y = `Vietnam`,\n                group = month),\n            colour = \"black\") +\n  geom_hline(aes(yintercept = avgvalue),\n             data = hline.data,\n             linetype = 6,\n             colour = \"red\",\n             size = 0.5) +\n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from VN by air, Jan 2010 - Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"# of Visitors\") +\n  theme_tufte(base_family = \"Helvetica\") +\n  theme(axis.text.x = element_text(size = 3))\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnsure CGPfunctions has been installed and loaded onto R environment before plot a slopegraph. Refer to Using newggslopegraph to learn more about the function, and read more about newggslopegraph() and its arguments in this link.\nSlopegraphs are not the best choice for categorical data when there’s no real connection between the selected categories.\n\n\nLet’s import the data first:\n\nrice &lt;- read_csv(\"data/rice.csv\")\n\nTake a look at the data structure:\n\nkable(head(rice))\n\n\n\n\nCountry\nYear\nYield\nProduction\n\n\n\n\nChina\n1961\n20787\n56217601\n\n\nChina\n1962\n23700\n65675288\n\n\nChina\n1963\n26833\n76439280\n\n\nChina\n1964\n28289\n85853780\n\n\nChina\n1965\n29667\n90705630\n\n\nChina\n1966\n31445\n98403990\n\n\n\n\n\n\n\n\n\nRiceArrivals\n\n\nNow, we will plot the slopegraph to know the ups and down of the 11 Asian countries.\n\n\nShow the code\nrice %&gt;%\n  mutate(Year = factor(Year)) %&gt;%\n  filter(Year %in% c(1961, 1980)) %&gt;%\n  newggslopegraph(Year, Yield, Country,\n                  Title = \"Rice Yield of Top 11 Asian Countries\",\n                  SubTitle = \"1961-1980\",\n                  Caption = \"Prepared by Cathy C.\",\n                  DataLabelLineSize = 0.2,\n                  DataLabelFillColor = \"#EFDCAB\") +\n  theme_wsj() +\n  theme(plot.title = element_text(size = 15),\n        plot.subtitle = element_text(size = 11),\n        plot.caption = element_text(size = 11),\n        legend.text = element_text(size = 8),\n        legend.title = element_text(size = 8),\n        axis.text.y = element_text(size = 8, color = \"grey70\"))\n\n\n\n\n\n\n\n\n\n\n\nLearning from the code\n\n\n\nThe first letter of Title SubTitle Caption need to have upper case letter.\nFor effective data visualisation design, factor() is used to convert the value type of Year field from numeric to factor.\n\n\n\n\n\n\n\nShow the code\narrival &lt;- read_xlsx(\"data/arrivals_by_air.xlsx\")\nkable(head(arrival))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMonth-Year\nRepublic of South Africa\nCanada\nUSA\nBangladesh\nBrunei\nChina\nHong Kong SAR (China)\nIndia\nIndonesia\nJapan\nSouth Korea\nKuwait\nMalaysia\nMyanmar\nPakistan\nPhilippines\nSaudi Arabia\nSri Lanka\nTaiwan\nThailand\nUnited Arab Emirates\nVietnam\nBelgium & Luxembourg\nCIS\nFinland\nFrance\nGermany\nIreland\nItaly\nNetherlands\nSpain\nSwitzerland\nUnited Kingdom\nAustralia\nNew Zealand\n\n\n\n\n2000-01-01\n3291\n5545\n25906\n2883\n3749\n33895\n13692\n19235\n65151\n59288\n21457\n507\n27472\n1177\n2150\n8404\n1312\n3922\n15766\n12048\n1318\n1527\n1434\n2703\n1634\n4752\n12739\n1292\n3544\n4962\n925\n3731\n28986\n34616\n5034\n\n\n2000-02-01\n2357\n6120\n28262\n2469\n3236\n34344\n19870\n18975\n37105\n58188\n19634\n199\n29084\n1161\n2496\n9128\n623\n3988\n24861\n12745\n899\n2269\n1596\n1182\n1297\n6391\n13093\n1200\n2897\n5054\n747\n3980\n35148\n26030\n3938\n\n\n2000-03-01\n4036\n6255\n30439\n2904\n3342\n27053\n17086\n21049\n44205\n74426\n20719\n386\n30504\n1355\n2429\n11691\n1578\n4259\n18767\n16971\n1474\n2034\n1548\n1088\n1220\n5528\n13645\n1368\n2717\n4950\n935\n3576\n36117\n31119\n4668\n\n\n2000-04-01\n4241\n4521\n25378\n2843\n5117\n30464\n22346\n26160\n45480\n49985\n17489\n221\n34478\n1593\n2711\n14141\n705\n6579\n22735\n20397\n1284\n2420\n1592\n1012\n1208\n5544\n13366\n1345\n2512\n4149\n941\n3850\n33792\n34824\n6890\n\n\n2000-05-01\n2841\n3914\n26163\n2793\n4152\n30775\n16357\n35869\n38350\n48937\n19398\n164\n34795\n1397\n2594\n13305\n679\n4625\n18399\n15769\n1042\n1833\n1167\n660\n743\n4225\n10878\n1067\n2205\n3643\n764\n3025\n23377\n33139\n7006\n\n\n2000-06-01\n2776\n3487\n28179\n3146\n5018\n26720\n18133\n31314\n47982\n53798\n17522\n440\n34660\n1715\n2924\n10555\n2749\n4740\n21042\n17217\n1545\n2480\n1170\n712\n982\n4047\n9054\n1363\n2196\n3544\n855\n2580\n21769\n35731\n7634\n\n\n\n\n\nShow the code\narrival_trans &lt;- arrival %&gt;%\n  mutate(year = year(`Month-Year`)) %&gt;%\n  group_by(year) %&gt;%\n  summarise(across(where(is.numeric), sum, na.rm = TRUE))\n\n#head(arrival_trans)\narrival_long &lt;- arrival_trans %&gt;%\n  mutate(year = as.ordered(year)) %&gt;%\n  pivot_longer(\n    cols = -year,\n    names_to = \"Country\",\n    values_to = \"Count\"\n  ) %&gt;%\n  filter(year %in% c(2000, 2005))  %&gt;%\n  group_by(Country) %&gt;%\n  ungroup()\n\n\nggplot_obj &lt;- newggslopegraph(\n  dataframe = arrival_long,\n  Times = year,\n  Measurement = Count,\n  Grouping = Country,\n  Title = \"Arrival Times by Country\",\n  SubTitle = \"2000-2025\",\n  Caption = \"Prepared by Cathy C.\",)\n\nggplot_obj \n\n\n\n\n\n\n\n\n\n\n\nLearning from the code\n\n\n\nnewggslopegraph() prefers an ordered sequence for its Times variable to ensure the correct chronological display of data points.\n\n\n\n\n\n\n\n\n\n\n\nKam, T. S. (2025). R for Visual Analytics. Retrieved February 24, 2025, from [https://r4va.netlify.app/chap17]\nPowell, C. (2025). Slopegraph in ggplot2. Retrieved February 24, 2025, from https://r-charts.com/evolution/newggslopegraph/",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 7"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#learning-objectives",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#learning-objectives",
    "title": "Hands-on_Ex07",
    "section": "",
    "text": "In this chapter, we will learn to plot the following visualisations:\n\na calender heatmap (ggplot2 functions)\na cycle plot (ggplot2 functions)\na slopegraph\na horizon chart",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 7"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#getting-started",
    "title": "Hands-on_Ex07",
    "section": "",
    "text": "To install and launch the following R packages:\nscales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table and tidyverse.\n\npacman::p_load(scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, \n               data.table, tidyverse, CGPfunctions, ggHoriPlot)",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 7"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-calendar-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-calendar-heatmap",
    "title": "Hands-on_Ex07",
    "section": "",
    "text": "Within this section, we will do the following:\n\nplot a calendar heatmap by using ggplot2 functions and extension\nwrite function using R programming\nderive specific date and time related field by using base R and libridate packages\nperform data preparation task by using tidyr and dplyr packages\n\n\n\neventlog.csv file will be used for this exercise. This data file consists of 199,999 rows of time-series cyber attack records by country.\n\n1-Import data2-Exam data structure3-Data prep\n\n\nTo import eventlog.csv into R environment and call this data frame as attacks.\n\nattacks &lt;- read_csv(\"data/eventlog.csv\")\n\n\n\nWe will use kable() to review the structure of the imported data frame.\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nWe see 3 columns: timestamp, source_country, and tz.\n\ntimestamp: stores data-time values in POSIXct format.\nsource_country: stores the source of attack. It is in ISO3166-1 alpha-2 country code.\ntz: stores timezone of source IP address.\n\n\n\nStep 1. Deriving weekday and hour of day fields\nTwo new fields need to be derived: wkday and hour before we plot the calendar heatmap.\n\n\nShow the code\nmake_hr_wkday &lt;- function(ts, sc, tz) {\n  real_times &lt;- ymd_hms(ts,\n                        tz = tz[1],\n                        quiet = TRUE)\n  dt &lt;- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n}\n\n\n\n\nLearning from the code\n\n\n\nymd_hms() and hour() are from lubridate package.\nweekdays() is a base R function.\n\n\n\nStep 2. Deriving the attacks tibble data frame\n\n\nShow the code\nwkday_levels &lt;- c('Saturday', 'Friday', 'Thursday',\n                  'Wednesday', 'Tuesday', 'Monday',\n                  'Sunday')\nattacks &lt;- attacks %&gt;%\n  group_by(tz) %&gt;%\n  do(make_hr_wkday(.$timestamp,\n                   .$source_country,\n                   .$tz)) %&gt;%\n  ungroup() %&gt;%\n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour = factor(\n      hour, levels = 0:23\n    )\n  )\n\n\n\n\nLearning from the code\n\n\nmutate() of dplyr package is used to convert wkday and hour fields into factor so they will be ordered when plotting.\n\n\nStep 3. Check the tibble table:\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\n\n\n\n\nWe can simply group the count by hour and wkday and plot it, since we know that we have values for every combination. Use the code below to build the calendar heatmaps:\n\n\nShow the code\ngrouped &lt;- attacks %&gt;%\n  count(wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  na.omit()\n\nggplot(grouped,\n       aes(hour,\n           wkday,\n           fill = n)) +\n  geom_tile(color = \"#f1f4f5\",\n            size = 0.1) +\n  theme_tufte(base_family = \"Helvetica\") +\n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                      low = \"#faf1f0\",\n                      high = \"dark red\") +\n  labs(x = NULL,\n       y = NULL,\n       title = \"Attacks by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6))\n\n\n\n\n\n\n\n\n\n\n\nLearning from the code\n\n\n\na tibble data table called grouped is derived by aggregating the attack by wkday and hour fields.\na new field called n is derived by using group_by() and count() functions.\nna.omit() is used to exclude missing value.\ngeom_tile() is used to plot tiles (grids) at each x and y position. color and size arguments are used to specify the border color and line size of the tiles.\ntheme_tufte() of ggthemes package is used to remove unnecessary chart junk. [there is a dashed line around the plot removed by this theme]\ncoord_equal() is used to ensure the plot will have an aspect ratio of 1:1.\nscale_fill_gradient() function is used to create a two colour gradient (low-high).\n\n\n\n\n\n\nChallenge: Build multiple heatmaps for the top four countries with the highest number of attacks.\nStep 1. Derive attack numbers by country object\nTo identify the top 4 countries with the highest attack numbers, we need to do the following:\n\ncount the number of attacks by country\ncalculate the percentage of attacks by country\nsave the result in a tibble data frame\n\n\n\nShow the code\nattacks_by_country &lt;- count(\n  attacks, source_country) %&gt;%\n  mutate(percent = percent(n/sum(n))) %&gt;%\n  arrange(desc(n))\n\n\nStep 2. Prepare the tidy data frame\nNow, we will extract the top 4 countries from attacks data frame, and save the data in a new tibble data frame top4_attacks.\n\n\nShow the code\ntop4 &lt;- attacks_by_country$source_country[1:4]\ntop4_attacks &lt;- attacks %&gt;%\n  filter(source_country %in% top4) %&gt;%\n  count(source_country, wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  mutate(source_country = factor(\n    source_country, levels = top4\n  )) %&gt;%\n  na.omit()\n\n\nStep 3. Plot the multiple calendar heatmap with ggplot2\n\n\nShow the code\nggplot(top4_attacks,\n       aes(hour,\n           wkday,\n           fill = n)) +\n  geom_tile(color = \"#f1f4f5\", size = 0.1) +\n  theme_tufte(base_family = \"Helvetica\") +\n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                      low = \"#faf1f0\",\n                      high = \"dark red\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL,\n       title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 4),\n        axis.text.y = element_text(size = 4),\n        plot.title = element_text(size = 10, hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6))",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 7"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-cycle-plot",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-cycle-plot",
    "title": "Hands-on_Ex07",
    "section": "",
    "text": "To show time-series patterns and trend of visitor arrivals from Vietnam, we will use Cycle plot to visualise it with ggplot2.\n\n\n\n1 Data import2 Deriving M and Y fields3 Extract target country4 Compute year avg arrival by month\n\n\nWe will use dataset from arrivals_by_air.xlsx. Since it’s in .xlsx format, read_excel() will be used to the read the file.\n\nair &lt;- read_excel(\"data/arrivals_by_air.xlsx\")\n\n\n\nHere 2 new fields called month and year are derived from Month-Year field.\n\nair$month &lt;- factor(month(air$'Month-Year'),\n                    levels = 1:12,\n                    labels = month.abb,\n                    ordered = TRUE)\nair$year &lt;- year(ymd(air$'Month-Year'))\n\n\n\nNow, we will extract data for the target country - Vietnam\n\nvietnam &lt;- air %&gt;%\n  select(`Vietnam`,\n         month,\n         year) %&gt;%\n  filter(year &gt;= 2010)\n\n\n\nThen we use group_by() and summarise() of dplyr to compute year average arrivals by month.\n\nhline.data &lt;- vietnam %&gt;%\n  group_by(month) %&gt;%\n  summarise(avgvalue = mean(`Vietnam`))\n\n\n\n\n\n\n\nNow plot the Cycle plot.\n\n\nShow the code\nggplot() +\n  geom_line(data = vietnam,\n            aes(x = year,\n                y = `Vietnam`,\n                group = month),\n            colour = \"black\") +\n  geom_hline(aes(yintercept = avgvalue),\n             data = hline.data,\n             linetype = 6,\n             colour = \"red\",\n             size = 0.5) +\n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from VN by air, Jan 2010 - Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"# of Visitors\") +\n  theme_tufte(base_family = \"Helvetica\") +\n  theme(axis.text.x = element_text(size = 3))",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 7"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-slopegraph",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-slopegraph",
    "title": "Hands-on_Ex07",
    "section": "",
    "text": "Ensure CGPfunctions has been installed and loaded onto R environment before plot a slopegraph. Refer to Using newggslopegraph to learn more about the function, and read more about newggslopegraph() and its arguments in this link.\nSlopegraphs are not the best choice for categorical data when there’s no real connection between the selected categories.\n\n\nLet’s import the data first:\n\nrice &lt;- read_csv(\"data/rice.csv\")\n\nTake a look at the data structure:\n\nkable(head(rice))\n\n\n\n\nCountry\nYear\nYield\nProduction\n\n\n\n\nChina\n1961\n20787\n56217601\n\n\nChina\n1962\n23700\n65675288\n\n\nChina\n1963\n26833\n76439280\n\n\nChina\n1964\n28289\n85853780\n\n\nChina\n1965\n29667\n90705630\n\n\nChina\n1966\n31445\n98403990\n\n\n\n\n\n\n\n\n\nRiceArrivals\n\n\nNow, we will plot the slopegraph to know the ups and down of the 11 Asian countries.\n\n\nShow the code\nrice %&gt;%\n  mutate(Year = factor(Year)) %&gt;%\n  filter(Year %in% c(1961, 1980)) %&gt;%\n  newggslopegraph(Year, Yield, Country,\n                  Title = \"Rice Yield of Top 11 Asian Countries\",\n                  SubTitle = \"1961-1980\",\n                  Caption = \"Prepared by Cathy C.\",\n                  DataLabelLineSize = 0.2,\n                  DataLabelFillColor = \"#EFDCAB\") +\n  theme_wsj() +\n  theme(plot.title = element_text(size = 15),\n        plot.subtitle = element_text(size = 11),\n        plot.caption = element_text(size = 11),\n        legend.text = element_text(size = 8),\n        legend.title = element_text(size = 8),\n        axis.text.y = element_text(size = 8, color = \"grey70\"))\n\n\n\n\n\n\n\n\n\n\n\nLearning from the code\n\n\n\nThe first letter of Title SubTitle Caption need to have upper case letter.\nFor effective data visualisation design, factor() is used to convert the value type of Year field from numeric to factor.\n\n\n\n\n\n\n\nShow the code\narrival &lt;- read_xlsx(\"data/arrivals_by_air.xlsx\")\nkable(head(arrival))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMonth-Year\nRepublic of South Africa\nCanada\nUSA\nBangladesh\nBrunei\nChina\nHong Kong SAR (China)\nIndia\nIndonesia\nJapan\nSouth Korea\nKuwait\nMalaysia\nMyanmar\nPakistan\nPhilippines\nSaudi Arabia\nSri Lanka\nTaiwan\nThailand\nUnited Arab Emirates\nVietnam\nBelgium & Luxembourg\nCIS\nFinland\nFrance\nGermany\nIreland\nItaly\nNetherlands\nSpain\nSwitzerland\nUnited Kingdom\nAustralia\nNew Zealand\n\n\n\n\n2000-01-01\n3291\n5545\n25906\n2883\n3749\n33895\n13692\n19235\n65151\n59288\n21457\n507\n27472\n1177\n2150\n8404\n1312\n3922\n15766\n12048\n1318\n1527\n1434\n2703\n1634\n4752\n12739\n1292\n3544\n4962\n925\n3731\n28986\n34616\n5034\n\n\n2000-02-01\n2357\n6120\n28262\n2469\n3236\n34344\n19870\n18975\n37105\n58188\n19634\n199\n29084\n1161\n2496\n9128\n623\n3988\n24861\n12745\n899\n2269\n1596\n1182\n1297\n6391\n13093\n1200\n2897\n5054\n747\n3980\n35148\n26030\n3938\n\n\n2000-03-01\n4036\n6255\n30439\n2904\n3342\n27053\n17086\n21049\n44205\n74426\n20719\n386\n30504\n1355\n2429\n11691\n1578\n4259\n18767\n16971\n1474\n2034\n1548\n1088\n1220\n5528\n13645\n1368\n2717\n4950\n935\n3576\n36117\n31119\n4668\n\n\n2000-04-01\n4241\n4521\n25378\n2843\n5117\n30464\n22346\n26160\n45480\n49985\n17489\n221\n34478\n1593\n2711\n14141\n705\n6579\n22735\n20397\n1284\n2420\n1592\n1012\n1208\n5544\n13366\n1345\n2512\n4149\n941\n3850\n33792\n34824\n6890\n\n\n2000-05-01\n2841\n3914\n26163\n2793\n4152\n30775\n16357\n35869\n38350\n48937\n19398\n164\n34795\n1397\n2594\n13305\n679\n4625\n18399\n15769\n1042\n1833\n1167\n660\n743\n4225\n10878\n1067\n2205\n3643\n764\n3025\n23377\n33139\n7006\n\n\n2000-06-01\n2776\n3487\n28179\n3146\n5018\n26720\n18133\n31314\n47982\n53798\n17522\n440\n34660\n1715\n2924\n10555\n2749\n4740\n21042\n17217\n1545\n2480\n1170\n712\n982\n4047\n9054\n1363\n2196\n3544\n855\n2580\n21769\n35731\n7634\n\n\n\n\n\nShow the code\narrival_trans &lt;- arrival %&gt;%\n  mutate(year = year(`Month-Year`)) %&gt;%\n  group_by(year) %&gt;%\n  summarise(across(where(is.numeric), sum, na.rm = TRUE))\n\n#head(arrival_trans)\narrival_long &lt;- arrival_trans %&gt;%\n  mutate(year = as.ordered(year)) %&gt;%\n  pivot_longer(\n    cols = -year,\n    names_to = \"Country\",\n    values_to = \"Count\"\n  ) %&gt;%\n  filter(year %in% c(2000, 2005))  %&gt;%\n  group_by(Country) %&gt;%\n  ungroup()\n\n\nggplot_obj &lt;- newggslopegraph(\n  dataframe = arrival_long,\n  Times = year,\n  Measurement = Count,\n  Grouping = Country,\n  Title = \"Arrival Times by Country\",\n  SubTitle = \"2000-2025\",\n  Caption = \"Prepared by Cathy C.\",)\n\nggplot_obj \n\n\n\n\n\n\n\n\n\n\n\nLearning from the code\n\n\n\nnewggslopegraph() prefers an ordered sequence for its Times variable to ensure the correct chronological display of data points.",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 7"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#reference",
    "title": "Hands-on_Ex07",
    "section": "",
    "text": "Kam, T. S. (2025). R for Visual Analytics. Retrieved February 24, 2025, from [https://r4va.netlify.app/chap17]\nPowell, C. (2025). Slopegraph in ggplot2. Retrieved February 24, 2025, from https://r-charts.com/evolution/newggslopegraph/",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 7"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex00/Hands-on_Ex00.html",
    "href": "Hands-on_Ex/Hands-on_Ex00/Hands-on_Ex00.html",
    "title": "Hands-on Exercise 00: working with tidyverse",
    "section": "",
    "text": "Loading tidyverse onto r environment by using the code chunk below.\n\npacman::p_load(tidyverse)",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex00/Hands-on_Ex00.html#getting-started.",
    "href": "Hands-on_Ex/Hands-on_Ex00/Hands-on_Ex00.html#getting-started.",
    "title": "Hands-on Exercise 00: working with tidyverse",
    "section": "",
    "text": "Loading tidyverse onto r environment by using the code chunk below.\n\npacman::p_load(tidyverse)",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex00/Hands-on_Ex00.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex00/Hands-on_Ex00.html#importing-data",
    "title": "Hands-on Exercise 00: working with tidyverse",
    "section": "Importing data",
    "text": "Importing data\nCode chunk below uses read_csv() of readr to import REALIS2019.csv into r environment as a tibble data.frame.\n\nrealis_csv &lt;- read.csv(\"data/REALIS2019.csv\") #old way - utility &gt; avoid using this.\n\n\nrealis2019 &lt;- read_csv(\"data/REALIS2019.csv\")\n\n\npopdata_fat &lt;- read_csv(\"data/PopData2019_fat.csv\")",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex00/Hands-on_Ex00.html#pivoting-data",
    "href": "Hands-on_Ex/Hands-on_Ex00/Hands-on_Ex00.html#pivoting-data",
    "title": "Hands-on Exercise 00: working with tidyverse",
    "section": "Pivoting data",
    "text": "Pivoting data\n\npopdata_long &lt;- popdata_fat %&gt;% \n  #what is %&gt;%? allows to combine functions together. e.g. call this file and do pivot_longer.\n  pivot_longer(c(3:21),\n               names_to = \"Age Group\",\n               values_to = \"Population\") \n\nCreate rds file\n\nwrite_rds(popdata_long, \"data/rds/popdata_long.rds\") #reading rds is faster.",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex00/Hands-on_Ex00.html#working-with-dplyr",
    "href": "Hands-on_Ex/Hands-on_Ex00/Hands-on_Ex00.html#working-with-dplyr",
    "title": "Hands-on Exercise 00: working with tidyverse",
    "section": "Working with dplyr",
    "text": "Working with dplyr\nselect, filter, arrange, mutate (compute), group_by, summarise, join.\n\nrealis2019_selected &lt;- realis2019 %&gt;%\n  select(`Project Name`,\n         `Transacted Price ($)`,\n         `Type of Sale`,\n         `Unit Price ($ psm)`,\n         `Property Type`)\nrealis2019_selected\n\n# A tibble: 19,515 × 5\n   `Project Name`     `Transacted Price ($)` `Type of Sale` `Unit Price ($ psm)`\n   &lt;chr&gt;                               &lt;dbl&gt; &lt;chr&gt;                         &lt;dbl&gt;\n 1 PEIRCE VIEW                        840000 Resale                         7434\n 2 FLORIDA PARK                      3040000 Resale                         9737\n 3 BULLION PARK                       860000 Resale                        11467\n 4 CASTLE GREEN                      1000000 Resale                         9346\n 5 HAPPY ESTATE                      7000000 Resale                        10183\n 6 TEACHER'S HOUSING…                2880000 Resale                        12659\n 7 THE PANORAMA                      1510000 Resale                        16064\n 8 THE PANORAMA                       710000 Resale                        16905\n 9 CHIP THYE GARDEN                  2800000 Resale                        13500\n10 TEACHER'S HOUSING…                2300000 Resale                         9935\n# ℹ 19,505 more rows\n# ℹ 1 more variable: `Property Type` &lt;chr&gt;\n\n\n\nrealis2019_filtered &lt;- realis2019_selected %&gt;%\n  filter(`Property Type` == \"Condominium\" | \n           `Property Type` == \"Apartment\") %&gt;%\n  filter(`Type of Sale` == \"New Sale\") %&gt;%\n  filter(`Unit Price ($ psm)` &lt;= 13000)\n\n\nPutting all together",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_3.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_3.html",
    "title": "Hands-on_Ex05-3",
    "section": "",
    "text": "Heatmaps visualise data through variations in colouring. When applied to a tabular format, heatmaps are useful for cross-examining multivariate data, through placing variables in the columns and observation (or records) in rows and colouring the cells within the table.\nHeatmaps are good for showing variance across multiple variables, revealing any patterns, displaying whether any variables are similar to each other, and for detecting if any correlations exist in-between them.\nIn this chapter, we will use R to plot static and interactive heatmap for visualising and analysing multivariate data.\n\n\n\nWe shall install and launch seriation, heatmaply, dendextend and tidyverse in RStudio.\n\npacman::p_load(seriation, dendextend, heatmaply, tidyverse)\n\n\n\n\n\n1 Import data2 Prep data3 Transform data frame to matrix\n\n\nThe data of World Happines 2018 report called WHData-2018.csv will be used.\n\nwh &lt;- read_csv(\"data/WHData-2018.csv\")\n\n\nglimpse(wh)\n\nRows: 156\nColumns: 12\n$ Country                        &lt;chr&gt; \"Albania\", \"Bosnia and Herzegovina\", \"B…\n$ Region                         &lt;chr&gt; \"Central and Eastern Europe\", \"Central …\n$ `Happiness score`              &lt;dbl&gt; 4.586, 5.129, 4.933, 5.321, 6.711, 5.73…\n$ `Whisker-high`                 &lt;dbl&gt; 4.695, 5.224, 5.022, 5.398, 6.783, 5.81…\n$ `Whisker-low`                  &lt;dbl&gt; 4.477, 5.035, 4.844, 5.244, 6.639, 5.66…\n$ Dystopia                       &lt;dbl&gt; 1.462, 1.883, 1.219, 1.769, 2.494, 1.45…\n$ `GDP per capita`               &lt;dbl&gt; 0.916, 0.915, 1.054, 1.115, 1.233, 1.20…\n$ `Social support`               &lt;dbl&gt; 0.817, 1.078, 1.515, 1.161, 1.489, 1.53…\n$ `Healthy life expectancy`      &lt;dbl&gt; 0.790, 0.758, 0.712, 0.737, 0.854, 0.73…\n$ `Freedom to make life choices` &lt;dbl&gt; 0.419, 0.280, 0.359, 0.380, 0.543, 0.55…\n$ Generosity                     &lt;dbl&gt; 0.149, 0.216, 0.064, 0.120, 0.064, 0.08…\n$ `Perceptions of corruption`    &lt;dbl&gt; 0.032, 0.000, 0.009, 0.039, 0.034, 0.17…\n\n\n\n\nChange the rows by country name instead of row number.\n\nrow.names(wh) &lt;- wh$Country\n\n\n\nThe data was loaded into a data frame, but it has to be a data matrix to make a heatmap. The code chunk below will be used to transform wh data frame into a data matrix.\n\nwh1 &lt;- dplyr::select(wh, c(3, 7:12))\nwh_matrix &lt;- data.matrix(wh)\n\nNote that wh_matrix is in R matrix format.\n\n\n\n\n\n\nThere are many R packages and functions can be used to drawing static heatmaps, they are:\n\nheatmap() of R stats package. It draws a simple heatmap.\nheatmap.2() of gplots R package. It draws an enhanced heatmap compared to the R base function.\npheatmap() of pheatmap R package. pheatmap package also known as Pretty Heatmap. The package provides functions to draws pretty heatmaps and provides more control to change the appearance of heatmaps.\nComplexHeatmap package of R/Bioconductor package. The package draws, annotates and arranges complex heatmaps (very useful for genomic data analysis). The full reference guide of the package is available here.\nsuperheat package: A Graphical Tool for Exploring Complex Datasets Using Heatmaps. A system for generating extendable and customizable heatmaps for exploring complex datasets, including big data and data with multiple data types. The full reference guide of the package is available here.\n\nWe will plot static heatmaps by using heatmap() of R Stats package.\n\n\n\nBase plotCluster heatmapNormalised heatmap\n\n\nLet’s plot a heatmap by using heatmap() of Base Stats.\n\n\nShow the code\npar(bg = \"#f1f4f5\")\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      Rowv = NA, Colv = NA)\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nBy default, heatmap() plots a cluster heatmap. The arguments Rowv=NA and Colv=NA are used to switch off the option of plotting the row and column dendrograms.\n\n\n\n\n\nTo plot a cluster heatmap, we just have to use the default code.\n\n\nShow the code\npar(bg = \"#f1f4f5\")\nwh_heatmap &lt;- heatmap(wh_matrix)\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe order of both rows and columns is different compare to the native wh_matrix.\n\nThis is because heatmap do a reordering using clusterisation: it calculates the distance between each pair of rows and columns and try to order them by similarity. Moreover, the corresponding dendrogram are provided beside the heatmap.\n\nWhen the Happiness Score variable have relatively higher values, it makes all other variables small and hard to interpret. Thus, we need to normalize this matrix.\n\n\n\n\n\n\n\nShow the code\npar(bg = \"#f1f4f5\")\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      scale=\"column\",\n                      cexRow = 0.6, \n                      cexCol = 0.8,\n                      margins = c(10, 4))\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe values are scaled now and the margins argument is used to ensure that the entire x-axis labels are displayed completely and, cexRow and cexCol arguments are used to define the font size used for y-axis and x-axis labels respectively.\n\n\n\n\n\n\n\n\n\n\nheatmaply is an R package for building interactive cluster heatmap that can be shared online as a stand-alone HTML file. It is designed and maintained by Tal Galili.\nResource: Introduction to Heatmaply & user manual\nBelow we will use heatmaply to design an interactive cluster heatmap. We will still use the wh_matrix as the input data.\n\n\n\nheatmaply(mtcars)\n\n\n\n\n\nWith basic syntax for interactive heatmap creation, using heatmaply package.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)])\n\n\n\n\n\n\n\nNote\n\n\n\nDifferent from heatmap(), for heatmaply() the default horizontal dendrogram is placed on the left hand side of the heatmap. The text label of each raw, on the other hand, is placed on the right hand side of the heat map.\nWhen the x-axis marker labels are too long, they will be rotated by 135 degree from the north.\n\n\n\n\n\n\nWhen analysing multivariate data set, it is very common that the variables in the data sets includes values that reflect different types of measurement. In general, these variables’ values have their own range. In order to ensure that all the variables have comparable values, data transformation are commonly used before clustering.\nThree main data transformation methods are supported by heatmaply(); namely, scale, normalise and percentilse.\n\nScaling methodNormalising methodPercentising method\n\n\n\nWhen all variables come from or assumed to come from some normal distribution, then scaling (i.e.: subtract the mean and divide by the standard deviation) would bring them all close to the standard normal distribution.\nIn such a case, each value would reflect the distance from the mean in units of standard deviation.\nThe scale argument in heatmaply() supports column and row scaling. Below the code scales variable values columewise.\n\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)],\n          scale = \"column\")\n\n\n\n\n\n\n\n\nWhen variables in the data come from possibly different (and non-normal) distributions, the normalize function can be used to bring data to the 0 to 1 scale by subtracting the minimum and dividing by the maximum of all observations.\nThis preserves the shape of each variable’s distribution while making them easily comparable on the same “scale”.\n\nDifferent from Scaling, the normalise method is performed on the input data set; i.e., wh_matrix as shown in the code chunk below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n\nThis is similar to ranking the variables, but instead of keeping the rank values, divide them by the maximal rank.\nThis is done by using the ecdf of the variables on their own values, bringing each value to its empirical percentile.\nThe benefit of the percentize function is that each value has a relatively clear interpretation, it is the percent of observations that got that value or below it.\n\nPercentize method is also performed on the input data set. See below:\n\nheatmaply(percentize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n\n\n\n\nheatmaply supports a variety of hierarchical clustering algorithm. The main arguments provided are:\n\ndistfun: function used to compute the distance (dissimilarity) between both rows and columns. Defaults to dist. The options “pearson”, “spearman” and “kendall” can be used to use correlation-based clustering, which uses as.dist(1 - cor(t(x))) as the distance metric (using the specified correlation method).\nhclustfun: function used to compute the hierarchical clustering when Rowv or Colv are not dendrograms. Defaults to hclust.\ndist_method default is NULL, which results in “euclidean” to be used. It can accept alternative character strings indicating the method to be passed to distfun. By default distfun is “dist”” hence this can be one of “euclidean”, “maximum”, “manhattan”, “canberra”, “binary” or “minkowski”.\nhclust_method default is NULL, which results in “complete” method to be used. It can accept alternative character strings indicating the method to be passed to hclustfun. By default hclustfun is hclust hence this can be one of “ward.D”, “ward.D2”, “single”, “complete”, “average” (= UPGMA), “mcquitty” (= WPGMA), “median” (= WPGMC) or “centroid” (= UPGMC).\n\nIn general, a clustering model can be calibrated either manually or statistically.\n\nManual approachStatistical approach\n\n\nIn the code chunk below, the heatmap is plotted by using hierachical clustering algorithm with “Euclidean distance” and “ward.D” method.\n\npar(bg = \"#f1f4f5\")\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")\n\n\n\n\n\n\n\nIn order to determine the best clustering method and number of cluster the dend_expend() and find_k() functions of dendextend package will be used.\nFirst, the dend_expend() will be used to determine the recommended clustering method to be used.\n\n\nShow the code\npar(bg = \"#f1f4f5\")\nwh_d &lt;- dist(normalize(wh_matrix[, -c(1, 2, 4, 5)]), method = \"euclidean\")\ndend_expend(wh_d)[[3]]\n\n\n  dist_methods hclust_methods     optim\n1      unknown         ward.D 0.6137851\n2      unknown        ward.D2 0.6289186\n3      unknown         single 0.4774362\n4      unknown       complete 0.6434009\n5      unknown        average 0.6701688\n6      unknown       mcquitty 0.5020102\n7      unknown         median 0.5901833\n8      unknown       centroid 0.6338734\n\n\nNext, find_k() is used to determine the optimal number of cluster.\n\n\nShow the code\npar(bg = \"#f1f4f5\")\nwh_clust &lt;- hclust(wh_d, method = \"average\")\nnum_k &lt;- find_k(wh_clust)\nplot(num_k)\n\n\n\n\n\n\n\n\n\nFigure above shows that K = 3 would be good.\nWith reference to the statistical analysis results, we can prepare the code chunk as shown below:\n\n\nShow the code\npar(bg = \"#f1f4f5\")\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"average\",\n          k_row = 3)\n\n\n\n\n\n\n\n\n\n\n\n\nProblems to tackle: with hierarchical clustering is that it doesn’t actually place the rows in a definite order.\nIt merely constrains the space of possible orderings. Take three items A, B and C. If you ignore reflections, there are three possible orderings: ABC, ACB, BAC. If clustering them gives you ((A+B)+C) as a tree, you know that C can’t end up between A and B, but it doesn’t tell you which way to flip the A+B cluster. It doesn’t tell you if the ABC ordering will lead to a clearer-looking heatmap than the BAC ordering.\nSolution: heatmaply uses the seriation package to find an optimal ordering of rows and columns.\nOptimal means to optimize the Hamiltonian path length that is restricted by the dendrogram structure. This, in other words, means to rotate the branches so that the sum of distances between each adjacent leaf (label) will be minimized. This is related to a restricted version of the travelling salesman problem.\n\nOLOGWmeannone\n\n\nSeriation algorithm #1: Optimal Leaf Ordering (OLO)\nThis algorithm starts with the output of an agglomerative clustering algorithm and produces a unique ordering, one that flips the various branches of the dendrogram around so as to minimize the sum of dissimilarities between adjacent leaves. Here is the result of applying Optimal Leaf Ordering to the same clustering result as the heatmap above.\nThe default options is “OLO” (Optimal leaf ordering) which optimizes the above criterion (in O(n^4)).\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"OLO\")\n\n\n\n\n\n\n\n“GW” (Gruvaeus and Wainer) aims for the same goal but uses a potentially faster heuristic.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"GW\")\n\n\n\n\n\n\n\nThe option “mean” gives the output we would get by default from heatmap functions in other packages such as gplots::heatmap.2.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"mean\")\n\n\n\n\n\n\n\nThe option “none” gives us the dendrograms without any rotation that is based on the data matrix.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\")\n\n\n\n\n\n\n\n\n\n\n\nThe default colour palette uses by heatmaply is viridis. heatmaply users, however, can use other colour palettes in order to improve the aestheticness and visual friendliness of the heatmap.\nThe Purple colour palette of rColorBrewer is used.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\",\n          k_row = 3,\n          seriate = \"GW\",\n          fontsize_col = 7,\n          fontsize_row = 4,\n          colors = Purples)\n\n\n\n\n\n\n\n\nheatmaply has a wide collection of arguments to meet the statistical analysis needs. Italso provides many plotting features to ensure cartographic quality heatmap can be produced.\nIn the code chunk below the following arguments are used:\n\nk_row is used to produce 5 groups.\nmargins is used to change the top margin to 60 and row margin to 200.\nfontsizw_row and fontsize_col are used to change the font size for row and column labels to 4.\nmain is used to write the main title of the plot.\nxlab and ylab are used to write the x-axis and y-axis labels respectively.\n\n\n\nShow the code\npar(bg = \"#f1f4f5\")\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Greens,\n          k_row = 5,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 7,\n          main=\"World Happiness Score and Variables by Country, 2018 \\nDataTransformation using Normalise Method\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )\n\n\n\n\n\n\n\n\n\nR for Visual Analytics: https://r4va.netlify.app/chap14#overview",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 5-3"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_3.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_3.html#overview",
    "title": "Hands-on_Ex05-3",
    "section": "",
    "text": "Heatmaps visualise data through variations in colouring. When applied to a tabular format, heatmaps are useful for cross-examining multivariate data, through placing variables in the columns and observation (or records) in rows and colouring the cells within the table.\nHeatmaps are good for showing variance across multiple variables, revealing any patterns, displaying whether any variables are similar to each other, and for detecting if any correlations exist in-between them.\nIn this chapter, we will use R to plot static and interactive heatmap for visualising and analysing multivariate data.",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 5-3"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_3.html#install-and-launch-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_3.html#install-and-launch-r-packages",
    "title": "Hands-on_Ex05-3",
    "section": "",
    "text": "We shall install and launch seriation, heatmaply, dendextend and tidyverse in RStudio.\n\npacman::p_load(seriation, dendextend, heatmaply, tidyverse)",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 5-3"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_3.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_3.html#data-preparation",
    "title": "Hands-on_Ex05-3",
    "section": "",
    "text": "1 Import data2 Prep data3 Transform data frame to matrix\n\n\nThe data of World Happines 2018 report called WHData-2018.csv will be used.\n\nwh &lt;- read_csv(\"data/WHData-2018.csv\")\n\n\nglimpse(wh)\n\nRows: 156\nColumns: 12\n$ Country                        &lt;chr&gt; \"Albania\", \"Bosnia and Herzegovina\", \"B…\n$ Region                         &lt;chr&gt; \"Central and Eastern Europe\", \"Central …\n$ `Happiness score`              &lt;dbl&gt; 4.586, 5.129, 4.933, 5.321, 6.711, 5.73…\n$ `Whisker-high`                 &lt;dbl&gt; 4.695, 5.224, 5.022, 5.398, 6.783, 5.81…\n$ `Whisker-low`                  &lt;dbl&gt; 4.477, 5.035, 4.844, 5.244, 6.639, 5.66…\n$ Dystopia                       &lt;dbl&gt; 1.462, 1.883, 1.219, 1.769, 2.494, 1.45…\n$ `GDP per capita`               &lt;dbl&gt; 0.916, 0.915, 1.054, 1.115, 1.233, 1.20…\n$ `Social support`               &lt;dbl&gt; 0.817, 1.078, 1.515, 1.161, 1.489, 1.53…\n$ `Healthy life expectancy`      &lt;dbl&gt; 0.790, 0.758, 0.712, 0.737, 0.854, 0.73…\n$ `Freedom to make life choices` &lt;dbl&gt; 0.419, 0.280, 0.359, 0.380, 0.543, 0.55…\n$ Generosity                     &lt;dbl&gt; 0.149, 0.216, 0.064, 0.120, 0.064, 0.08…\n$ `Perceptions of corruption`    &lt;dbl&gt; 0.032, 0.000, 0.009, 0.039, 0.034, 0.17…\n\n\n\n\nChange the rows by country name instead of row number.\n\nrow.names(wh) &lt;- wh$Country\n\n\n\nThe data was loaded into a data frame, but it has to be a data matrix to make a heatmap. The code chunk below will be used to transform wh data frame into a data matrix.\n\nwh1 &lt;- dplyr::select(wh, c(3, 7:12))\nwh_matrix &lt;- data.matrix(wh)\n\nNote that wh_matrix is in R matrix format.",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 5-3"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_3.html#static-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_3.html#static-heatmap",
    "title": "Hands-on_Ex05-3",
    "section": "",
    "text": "There are many R packages and functions can be used to drawing static heatmaps, they are:\n\nheatmap() of R stats package. It draws a simple heatmap.\nheatmap.2() of gplots R package. It draws an enhanced heatmap compared to the R base function.\npheatmap() of pheatmap R package. pheatmap package also known as Pretty Heatmap. The package provides functions to draws pretty heatmaps and provides more control to change the appearance of heatmaps.\nComplexHeatmap package of R/Bioconductor package. The package draws, annotates and arranges complex heatmaps (very useful for genomic data analysis). The full reference guide of the package is available here.\nsuperheat package: A Graphical Tool for Exploring Complex Datasets Using Heatmaps. A system for generating extendable and customizable heatmaps for exploring complex datasets, including big data and data with multiple data types. The full reference guide of the package is available here.\n\nWe will plot static heatmaps by using heatmap() of R Stats package.\n\n\n\nBase plotCluster heatmapNormalised heatmap\n\n\nLet’s plot a heatmap by using heatmap() of Base Stats.\n\n\nShow the code\npar(bg = \"#f1f4f5\")\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      Rowv = NA, Colv = NA)\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nBy default, heatmap() plots a cluster heatmap. The arguments Rowv=NA and Colv=NA are used to switch off the option of plotting the row and column dendrograms.\n\n\n\n\n\nTo plot a cluster heatmap, we just have to use the default code.\n\n\nShow the code\npar(bg = \"#f1f4f5\")\nwh_heatmap &lt;- heatmap(wh_matrix)\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe order of both rows and columns is different compare to the native wh_matrix.\n\nThis is because heatmap do a reordering using clusterisation: it calculates the distance between each pair of rows and columns and try to order them by similarity. Moreover, the corresponding dendrogram are provided beside the heatmap.\n\nWhen the Happiness Score variable have relatively higher values, it makes all other variables small and hard to interpret. Thus, we need to normalize this matrix.\n\n\n\n\n\n\n\nShow the code\npar(bg = \"#f1f4f5\")\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      scale=\"column\",\n                      cexRow = 0.6, \n                      cexCol = 0.8,\n                      margins = c(10, 4))\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe values are scaled now and the margins argument is used to ensure that the entire x-axis labels are displayed completely and, cexRow and cexCol arguments are used to define the font size used for y-axis and x-axis labels respectively.",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 5-3"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_3.html#create-interactive-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_3.html#create-interactive-heatmap",
    "title": "Hands-on_Ex05-3",
    "section": "",
    "text": "heatmaply is an R package for building interactive cluster heatmap that can be shared online as a stand-alone HTML file. It is designed and maintained by Tal Galili.\nResource: Introduction to Heatmaply & user manual\nBelow we will use heatmaply to design an interactive cluster heatmap. We will still use the wh_matrix as the input data.\n\n\n\nheatmaply(mtcars)\n\n\n\n\n\nWith basic syntax for interactive heatmap creation, using heatmaply package.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)])\n\n\n\n\n\n\n\nNote\n\n\n\nDifferent from heatmap(), for heatmaply() the default horizontal dendrogram is placed on the left hand side of the heatmap. The text label of each raw, on the other hand, is placed on the right hand side of the heat map.\nWhen the x-axis marker labels are too long, they will be rotated by 135 degree from the north.\n\n\n\n\n\n\nWhen analysing multivariate data set, it is very common that the variables in the data sets includes values that reflect different types of measurement. In general, these variables’ values have their own range. In order to ensure that all the variables have comparable values, data transformation are commonly used before clustering.\nThree main data transformation methods are supported by heatmaply(); namely, scale, normalise and percentilse.\n\nScaling methodNormalising methodPercentising method\n\n\n\nWhen all variables come from or assumed to come from some normal distribution, then scaling (i.e.: subtract the mean and divide by the standard deviation) would bring them all close to the standard normal distribution.\nIn such a case, each value would reflect the distance from the mean in units of standard deviation.\nThe scale argument in heatmaply() supports column and row scaling. Below the code scales variable values columewise.\n\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)],\n          scale = \"column\")\n\n\n\n\n\n\n\n\nWhen variables in the data come from possibly different (and non-normal) distributions, the normalize function can be used to bring data to the 0 to 1 scale by subtracting the minimum and dividing by the maximum of all observations.\nThis preserves the shape of each variable’s distribution while making them easily comparable on the same “scale”.\n\nDifferent from Scaling, the normalise method is performed on the input data set; i.e., wh_matrix as shown in the code chunk below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n\nThis is similar to ranking the variables, but instead of keeping the rank values, divide them by the maximal rank.\nThis is done by using the ecdf of the variables on their own values, bringing each value to its empirical percentile.\nThe benefit of the percentize function is that each value has a relatively clear interpretation, it is the percent of observations that got that value or below it.\n\nPercentize method is also performed on the input data set. See below:\n\nheatmaply(percentize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n\n\n\n\nheatmaply supports a variety of hierarchical clustering algorithm. The main arguments provided are:\n\ndistfun: function used to compute the distance (dissimilarity) between both rows and columns. Defaults to dist. The options “pearson”, “spearman” and “kendall” can be used to use correlation-based clustering, which uses as.dist(1 - cor(t(x))) as the distance metric (using the specified correlation method).\nhclustfun: function used to compute the hierarchical clustering when Rowv or Colv are not dendrograms. Defaults to hclust.\ndist_method default is NULL, which results in “euclidean” to be used. It can accept alternative character strings indicating the method to be passed to distfun. By default distfun is “dist”” hence this can be one of “euclidean”, “maximum”, “manhattan”, “canberra”, “binary” or “minkowski”.\nhclust_method default is NULL, which results in “complete” method to be used. It can accept alternative character strings indicating the method to be passed to hclustfun. By default hclustfun is hclust hence this can be one of “ward.D”, “ward.D2”, “single”, “complete”, “average” (= UPGMA), “mcquitty” (= WPGMA), “median” (= WPGMC) or “centroid” (= UPGMC).\n\nIn general, a clustering model can be calibrated either manually or statistically.\n\nManual approachStatistical approach\n\n\nIn the code chunk below, the heatmap is plotted by using hierachical clustering algorithm with “Euclidean distance” and “ward.D” method.\n\npar(bg = \"#f1f4f5\")\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")\n\n\n\n\n\n\n\nIn order to determine the best clustering method and number of cluster the dend_expend() and find_k() functions of dendextend package will be used.\nFirst, the dend_expend() will be used to determine the recommended clustering method to be used.\n\n\nShow the code\npar(bg = \"#f1f4f5\")\nwh_d &lt;- dist(normalize(wh_matrix[, -c(1, 2, 4, 5)]), method = \"euclidean\")\ndend_expend(wh_d)[[3]]\n\n\n  dist_methods hclust_methods     optim\n1      unknown         ward.D 0.6137851\n2      unknown        ward.D2 0.6289186\n3      unknown         single 0.4774362\n4      unknown       complete 0.6434009\n5      unknown        average 0.6701688\n6      unknown       mcquitty 0.5020102\n7      unknown         median 0.5901833\n8      unknown       centroid 0.6338734\n\n\nNext, find_k() is used to determine the optimal number of cluster.\n\n\nShow the code\npar(bg = \"#f1f4f5\")\nwh_clust &lt;- hclust(wh_d, method = \"average\")\nnum_k &lt;- find_k(wh_clust)\nplot(num_k)\n\n\n\n\n\n\n\n\n\nFigure above shows that K = 3 would be good.\nWith reference to the statistical analysis results, we can prepare the code chunk as shown below:\n\n\nShow the code\npar(bg = \"#f1f4f5\")\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"average\",\n          k_row = 3)\n\n\n\n\n\n\n\n\n\n\n\n\nProblems to tackle: with hierarchical clustering is that it doesn’t actually place the rows in a definite order.\nIt merely constrains the space of possible orderings. Take three items A, B and C. If you ignore reflections, there are three possible orderings: ABC, ACB, BAC. If clustering them gives you ((A+B)+C) as a tree, you know that C can’t end up between A and B, but it doesn’t tell you which way to flip the A+B cluster. It doesn’t tell you if the ABC ordering will lead to a clearer-looking heatmap than the BAC ordering.\nSolution: heatmaply uses the seriation package to find an optimal ordering of rows and columns.\nOptimal means to optimize the Hamiltonian path length that is restricted by the dendrogram structure. This, in other words, means to rotate the branches so that the sum of distances between each adjacent leaf (label) will be minimized. This is related to a restricted version of the travelling salesman problem.\n\nOLOGWmeannone\n\n\nSeriation algorithm #1: Optimal Leaf Ordering (OLO)\nThis algorithm starts with the output of an agglomerative clustering algorithm and produces a unique ordering, one that flips the various branches of the dendrogram around so as to minimize the sum of dissimilarities between adjacent leaves. Here is the result of applying Optimal Leaf Ordering to the same clustering result as the heatmap above.\nThe default options is “OLO” (Optimal leaf ordering) which optimizes the above criterion (in O(n^4)).\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"OLO\")\n\n\n\n\n\n\n\n“GW” (Gruvaeus and Wainer) aims for the same goal but uses a potentially faster heuristic.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"GW\")\n\n\n\n\n\n\n\nThe option “mean” gives the output we would get by default from heatmap functions in other packages such as gplots::heatmap.2.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"mean\")\n\n\n\n\n\n\n\nThe option “none” gives us the dendrograms without any rotation that is based on the data matrix.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\")\n\n\n\n\n\n\n\n\n\n\n\nThe default colour palette uses by heatmaply is viridis. heatmaply users, however, can use other colour palettes in order to improve the aestheticness and visual friendliness of the heatmap.\nThe Purple colour palette of rColorBrewer is used.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\",\n          k_row = 3,\n          seriate = \"GW\",\n          fontsize_col = 7,\n          fontsize_row = 4,\n          colors = Purples)\n\n\n\n\n\n\n\n\nheatmaply has a wide collection of arguments to meet the statistical analysis needs. Italso provides many plotting features to ensure cartographic quality heatmap can be produced.\nIn the code chunk below the following arguments are used:\n\nk_row is used to produce 5 groups.\nmargins is used to change the top margin to 60 and row margin to 200.\nfontsizw_row and fontsize_col are used to change the font size for row and column labels to 4.\nmain is used to write the main title of the plot.\nxlab and ylab are used to write the x-axis and y-axis labels respectively.\n\n\n\nShow the code\npar(bg = \"#f1f4f5\")\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Greens,\n          k_row = 5,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 7,\n          main=\"World Happiness Score and Variables by Country, 2018 \\nDataTransformation using Normalise Method\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )\n\n\n\n\n\n\n\n\n\nR for Visual Analytics: https://r4va.netlify.app/chap14#overview",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 5-3"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_4.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_4.html",
    "title": "Hands-on_Ex05-4",
    "section": "",
    "text": "Parallel coordinates plot is a data visualisation specially designed for visualising and analysing multivariate, numerical data. It is ideal for comparing multiple variables together and seeing the relationships between them. For example, parallel coordinates plot can be used to characterise clusters detected during customer segmentation.\n\n\n\n\nInstall and launch R packagesData preparation\n\n\nGGally, parcoords, parallelPlot and tidyverse packages will be used.\n\npacman::p_load(GGally, parallelPlot, tidyverse)\n\n\n\nhe World Happinees 2018 (http://worldhappiness.report/ed/2018/) data will be used. The data set is download at https://s3.amazonaws.com/happiness-report/2018/WHR2018Chapter2OnlineData.xls. The original data set is in Microsoft Excel format. It has been extracted and saved in csv file called WHData-2018.csv.\nIn the code chunk below, read_csv() of readr package is used to import WHData-2018.csv into R and save it into a tibble data frame object called wh.\n\nwh &lt;- read_csv(\"data/WHData-2018.csv\")\n\nHave a look at the data.\n\nhead(wh)\n\n# A tibble: 6 × 12\n  Country         Region `Happiness score` `Whisker-high` `Whisker-low` Dystopia\n  &lt;chr&gt;           &lt;chr&gt;              &lt;dbl&gt;          &lt;dbl&gt;         &lt;dbl&gt;    &lt;dbl&gt;\n1 Albania         Centr…              4.59           4.70          4.48     1.46\n2 Bosnia and Her… Centr…              5.13           5.22          5.04     1.88\n3 Bulgaria        Centr…              4.93           5.02          4.84     1.22\n4 Croatia         Centr…              5.32           5.40          5.24     1.77\n5 Czech Republic  Centr…              6.71           6.78          6.64     2.49\n6 Estonia         Centr…              5.74           5.82          5.66     1.46\n# ℹ 6 more variables: `GDP per capita` &lt;dbl&gt;, `Social support` &lt;dbl&gt;,\n#   `Healthy life expectancy` &lt;dbl&gt;, `Freedom to make life choices` &lt;dbl&gt;,\n#   Generosity &lt;dbl&gt;, `Perceptions of corruption` &lt;dbl&gt;\n\n\n\n\n\n\n\n\nIn this section, we will learn to plot static parallel coordinates plot by using ggparcoord() of GGally package.\n\n\nCode chunk below shows a typical syntax used to plot a basic static parallel coordinates plot by using ggparcoord().\n\nhead(wh)\n\n# A tibble: 6 × 12\n  Country         Region `Happiness score` `Whisker-high` `Whisker-low` Dystopia\n  &lt;chr&gt;           &lt;chr&gt;              &lt;dbl&gt;          &lt;dbl&gt;         &lt;dbl&gt;    &lt;dbl&gt;\n1 Albania         Centr…              4.59           4.70          4.48     1.46\n2 Bosnia and Her… Centr…              5.13           5.22          5.04     1.88\n3 Bulgaria        Centr…              4.93           5.02          4.84     1.22\n4 Croatia         Centr…              5.32           5.40          5.24     1.77\n5 Czech Republic  Centr…              6.71           6.78          6.64     2.49\n6 Estonia         Centr…              5.74           5.82          5.66     1.46\n# ℹ 6 more variables: `GDP per capita` &lt;dbl&gt;, `Social support` &lt;dbl&gt;,\n#   `Healthy life expectancy` &lt;dbl&gt;, `Freedom to make life choices` &lt;dbl&gt;,\n#   Generosity &lt;dbl&gt;, `Perceptions of corruption` &lt;dbl&gt;\n\n\n\n\nShow the code\nggparcoord(data = wh, \n           columns = c(7:12)) +\n  labs(title = \"Basic parellel plot\") +\n  geom_line(size = 0.01) +\n  theme(\n    plot.title = element_text(hjust = 0),\n    axis.title.x = element_text(size = 0.7),\n    axis.title.y = element_text(hjust=1, angle=0),\n    plot.background = element_rect(fill = \"#f1f4f5\", color = \"#f1f4f5\"),\n    legend.background = element_rect(fill=\"#f1f4f5\"),\n    panel.background = element_rect(fill=\"#f1f4f5\"))\n\n\n\n\n\n\n\n\n\nNotice that only two argument namely data and columns is used. Data argument is used to map the data object (i.e. wh) and columns is used to select the columns for preparing the parallel coordinates plot.\nUse groupColumn() to group column ‘Region’:\n\n\nShow the code\nggparcoord(data = wh, \n           columns = c(7:12),\n           groupColumn = \"Region\",\n           scale = \"robust\") +\n  labs(title = \"Basic parellel plot grouped by Region\") +\n  geom_line(size = 0.01) +\n  theme(\n    plot.title = element_text(hjust = 0),\n    axis.title.x = element_text(size = 0.7),\n    axis.title.y = element_text(hjust=1, angle=0),\n    plot.background = element_rect(fill = \"#f1f4f5\", color = \"#f1f4f5\"),\n    legend.background = element_rect(fill=\"#f1f4f5\"),\n    panel.background = element_rect(fill=\"#f1f4f5\"))\n\n\n\n\n\n\n\n\n\nCan assign a color to specific group, but assigning the former columns may have the colors blocked by the rest.\n\n\nShow the code\nggparcoord(data = wh, \n           columns = c(7:12),\n           groupColumn = \"Region\",\n           scale = \"robust\") +\n  labs(title = \"Basic parellel plot grouped by Region with color\") +\n  geom_line(size = 0.01) +\n  theme(\n    plot.title = element_text(hjust = 0),\n    axis.title.x = element_text(size = 0.7),\n    axis.title.y = element_text(hjust=1, angle=0),\n    plot.background = element_rect(fill = \"#f1f4f5\", color = \"#f1f4f5\"),\n    legend.background = element_rect(fill=\"#f1f4f5\"),\n    legend.position = \"left\",\n    panel.background = element_rect(fill=\"#f1f4f5\")) +\n  scale_x_discrete(guide = guide_axis(n.dodge = 2))+\n  scale_color_manual(values=c(\"grey70\", \"grey70\", \"grey70\", \"grey70\", \"grey70\", \"grey70\", \"grey70\", \"grey70\", \"skyblue\", \"grey70\") )\n\n\n\n\n\n\n\n\n\n\n\n\nIt is hard to decipher the Parallel Coordinates Plot alone. We will complement it with boxplot. The arguments are provided in ggparcoord().\n\n\nShow the code\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Parallel Coordinates Plot of World Happines Variables\") +\n  theme(\n    plot.title = element_text(hjust = 0),\n    axis.title.x = element_text(size = 0.7),\n    axis.title.y = element_text(hjust=1, angle=0),\n    plot.background = element_rect(fill = \"#f1f4f5\", color = \"#f1f4f5\"),\n    legend.background = element_rect(fill=\"#f1f4f5\"),\n    legend.position = \"left\",\n    panel.background = element_rect(fill=\"#f1f4f5\")) +\n  scale_x_discrete(guide = guide_axis(n.dodge = 2))\n\n\n\n\n\n\n\n\n\n\n\nLearning from the code\n\n\n\ngroupColumn argument is used to group the observations (i.e. parallel lines) by using a single variable (i.e. Region) and colour the parallel coordinates lines by region name.\nscale argument is used to scale the variables in the parallel coordinate plot by using uniminmax method. The method univariately scale each variable so the minimum of the variable is zero and the maximum is one.\nalphaLines argument is used to reduce the intensity of the line colour to 0.2. The permissible value range is between 0 to 1.\nboxplot argument is used to turn on the boxplot by using logical TRUE. The default is FALSE.\ntitle argument is used to provide the parallel coordinates plot a title.\n\n\n\n\n\n\nSince ggparcoord() is developed by extending ggplot2 package, we can combie some of the ggplot2 function when plotting a parallel coordinates plot.\nIn the code chunk below, facet_wrap() of ggplot2 is used to plot 10 small multiple parallel coordinates plots. Each plot represent one geographical region.\n\nBase plotRoate X-axis text labelAdjust label position\n\n\nOne of the aesthetic defect of the current design is that some of the variable names overlap on x-axis.\n\n\nShow the code\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) +\n  theme(\n    plot.title = element_text(hjust = 0, size = 8),\n    axis.title.x = element_text(size = 0.2),\n    axis.title.y = element_text(hjust=1, angle=0),\n    axis.text.x = element_text(size = 6),\n    plot.background = element_rect(fill = \"#f1f4f5\", color = \"#f1f4f5\"),\n    legend.background = element_rect(fill=\"#f1f4f5\"),\n    legend.position = \"bottom\",\n    panel.background = element_rect(fill=\"#f1f4f5\")) \n\n\n\n\n\n\n\n\n\n\n\nTo make the x-axis text label easy to read, we will rotate the labels. We can rotate axis text labels using theme() function in ggplot2.\n\n\nShow the code\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) +\n  theme(\n    plot.title = element_text(hjust = 0, size = 8),\n    axis.title.x = element_text(size = 10, hjust = 1),\n    axis.title.y = element_text(hjust=1, angle=0),\n    axis.text.x = element_text(size = 7, angle = 30),\n    plot.background = element_rect(fill = \"#f1f4f5\", color = \"#f1f4f5\"),\n    legend.background = element_rect(fill=\"#f1f4f5\"),\n    legend.position = \"bottom\",\n    panel.background = element_rect(fill=\"#f1f4f5\")) \n\n\n\n\n\n\n\n\n\n\n\nLearning from the code\n\n\n\nWe use axis.text.x as argument to theme() function. And we specify element_text(angle = 30) to rotate the x-axis text by an angle 30 degrees.\n\n\n\n\n\nSome text labels after rotation are overlapping the plot. We can use hjust to adjust the position of the labels in theme().\n\n\nShow the code\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) +\n  theme(\n    plot.title = element_text(hjust = 0, size = 8),\n    axis.title.x = element_text(size = 10, hjust = 1),\n    axis.title.y = element_text(hjust=1, angle=0),\n    axis.text.x = element_text(size = 7, angle = 30, hjust = 1.1),\n    plot.background = element_rect(fill = \"#f1f4f5\", color = \"#f1f4f5\"),\n    legend.background = element_rect(fill=\"#f1f4f5\"),\n    legend.position = \"bottom\",\n    panel.background = element_rect(fill=\"#f1f4f5\")) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nparallelPlot is an R package specially designed to plot a parallel coordinates plot by using ‘htmlwidgets’ package and d3.js. We will learn how to use functions provided in parallelPlot package to build interactive parallel coordinates plot.\n\nBase plotRotate axis labelChange colour schemeParallel coordinates plot with histogram\n\n\nThe code chunk below plot an interactive parallel coordinates plot by using parallelPlot().\nNote that some labels are long and overlapping.\n\n\nShow the code\nwh &lt;- wh %&gt;%\n  select(\"Happiness score\", c(7:12))\nparallelPlot(wh,\n             width = 320,\n             height = 250)\n\n\n\n\n\n\n\n\nTo solve the issue in the basee plot, we use rotateTitle argument is used to avoid overlapping axis labels.\n\n\nShow the code\nparallelPlot(wh,\n             rotateTitle = TRUE)\n\n\n\n\n\n\n\n\nColor can be customised using continuousCS.\n\nparallelPlot(wh,\n             continuousCS = \"YlOrRd\",\n             rotateTitle = TRUE)\n\n\n\n\n\n\n\nhistoVisibility argument is used to plot histogram along the axis of each variables.\n\nhistoVisibility &lt;- rep(TRUE, ncol(wh))\nparallelPlot(wh,\n             rotateTitle = TRUE,\n             histoVisibility = histoVisibility)\n\n\n\n\n\n\n\n\nWhen clicking on a variable, the lines often change colour based on how that variable scales or groups the data.\n\n\n\n\nR for Visual Analytics\nggparcoord() of GGally package\nparcoords user guide\nparallelPlot",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 5-4"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_4.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_4.html#overview",
    "title": "Hands-on_Ex05-4",
    "section": "",
    "text": "Parallel coordinates plot is a data visualisation specially designed for visualising and analysing multivariate, numerical data. It is ideal for comparing multiple variables together and seeing the relationships between them. For example, parallel coordinates plot can be used to characterise clusters detected during customer segmentation.",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 5-4"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_4.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_4.html#getting-started",
    "title": "Hands-on_Ex05-4",
    "section": "",
    "text": "Install and launch R packagesData preparation\n\n\nGGally, parcoords, parallelPlot and tidyverse packages will be used.\n\npacman::p_load(GGally, parallelPlot, tidyverse)\n\n\n\nhe World Happinees 2018 (http://worldhappiness.report/ed/2018/) data will be used. The data set is download at https://s3.amazonaws.com/happiness-report/2018/WHR2018Chapter2OnlineData.xls. The original data set is in Microsoft Excel format. It has been extracted and saved in csv file called WHData-2018.csv.\nIn the code chunk below, read_csv() of readr package is used to import WHData-2018.csv into R and save it into a tibble data frame object called wh.\n\nwh &lt;- read_csv(\"data/WHData-2018.csv\")\n\nHave a look at the data.\n\nhead(wh)\n\n# A tibble: 6 × 12\n  Country         Region `Happiness score` `Whisker-high` `Whisker-low` Dystopia\n  &lt;chr&gt;           &lt;chr&gt;              &lt;dbl&gt;          &lt;dbl&gt;         &lt;dbl&gt;    &lt;dbl&gt;\n1 Albania         Centr…              4.59           4.70          4.48     1.46\n2 Bosnia and Her… Centr…              5.13           5.22          5.04     1.88\n3 Bulgaria        Centr…              4.93           5.02          4.84     1.22\n4 Croatia         Centr…              5.32           5.40          5.24     1.77\n5 Czech Republic  Centr…              6.71           6.78          6.64     2.49\n6 Estonia         Centr…              5.74           5.82          5.66     1.46\n# ℹ 6 more variables: `GDP per capita` &lt;dbl&gt;, `Social support` &lt;dbl&gt;,\n#   `Healthy life expectancy` &lt;dbl&gt;, `Freedom to make life choices` &lt;dbl&gt;,\n#   Generosity &lt;dbl&gt;, `Perceptions of corruption` &lt;dbl&gt;",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 5-4"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_4.html#plot-static-parallel-coordinates-plot",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_4.html#plot-static-parallel-coordinates-plot",
    "title": "Hands-on_Ex05-4",
    "section": "",
    "text": "In this section, we will learn to plot static parallel coordinates plot by using ggparcoord() of GGally package.\n\n\nCode chunk below shows a typical syntax used to plot a basic static parallel coordinates plot by using ggparcoord().\n\nhead(wh)\n\n# A tibble: 6 × 12\n  Country         Region `Happiness score` `Whisker-high` `Whisker-low` Dystopia\n  &lt;chr&gt;           &lt;chr&gt;              &lt;dbl&gt;          &lt;dbl&gt;         &lt;dbl&gt;    &lt;dbl&gt;\n1 Albania         Centr…              4.59           4.70          4.48     1.46\n2 Bosnia and Her… Centr…              5.13           5.22          5.04     1.88\n3 Bulgaria        Centr…              4.93           5.02          4.84     1.22\n4 Croatia         Centr…              5.32           5.40          5.24     1.77\n5 Czech Republic  Centr…              6.71           6.78          6.64     2.49\n6 Estonia         Centr…              5.74           5.82          5.66     1.46\n# ℹ 6 more variables: `GDP per capita` &lt;dbl&gt;, `Social support` &lt;dbl&gt;,\n#   `Healthy life expectancy` &lt;dbl&gt;, `Freedom to make life choices` &lt;dbl&gt;,\n#   Generosity &lt;dbl&gt;, `Perceptions of corruption` &lt;dbl&gt;\n\n\n\n\nShow the code\nggparcoord(data = wh, \n           columns = c(7:12)) +\n  labs(title = \"Basic parellel plot\") +\n  geom_line(size = 0.01) +\n  theme(\n    plot.title = element_text(hjust = 0),\n    axis.title.x = element_text(size = 0.7),\n    axis.title.y = element_text(hjust=1, angle=0),\n    plot.background = element_rect(fill = \"#f1f4f5\", color = \"#f1f4f5\"),\n    legend.background = element_rect(fill=\"#f1f4f5\"),\n    panel.background = element_rect(fill=\"#f1f4f5\"))\n\n\n\n\n\n\n\n\n\nNotice that only two argument namely data and columns is used. Data argument is used to map the data object (i.e. wh) and columns is used to select the columns for preparing the parallel coordinates plot.\nUse groupColumn() to group column ‘Region’:\n\n\nShow the code\nggparcoord(data = wh, \n           columns = c(7:12),\n           groupColumn = \"Region\",\n           scale = \"robust\") +\n  labs(title = \"Basic parellel plot grouped by Region\") +\n  geom_line(size = 0.01) +\n  theme(\n    plot.title = element_text(hjust = 0),\n    axis.title.x = element_text(size = 0.7),\n    axis.title.y = element_text(hjust=1, angle=0),\n    plot.background = element_rect(fill = \"#f1f4f5\", color = \"#f1f4f5\"),\n    legend.background = element_rect(fill=\"#f1f4f5\"),\n    panel.background = element_rect(fill=\"#f1f4f5\"))\n\n\n\n\n\n\n\n\n\nCan assign a color to specific group, but assigning the former columns may have the colors blocked by the rest.\n\n\nShow the code\nggparcoord(data = wh, \n           columns = c(7:12),\n           groupColumn = \"Region\",\n           scale = \"robust\") +\n  labs(title = \"Basic parellel plot grouped by Region with color\") +\n  geom_line(size = 0.01) +\n  theme(\n    plot.title = element_text(hjust = 0),\n    axis.title.x = element_text(size = 0.7),\n    axis.title.y = element_text(hjust=1, angle=0),\n    plot.background = element_rect(fill = \"#f1f4f5\", color = \"#f1f4f5\"),\n    legend.background = element_rect(fill=\"#f1f4f5\"),\n    legend.position = \"left\",\n    panel.background = element_rect(fill=\"#f1f4f5\")) +\n  scale_x_discrete(guide = guide_axis(n.dodge = 2))+\n  scale_color_manual(values=c(\"grey70\", \"grey70\", \"grey70\", \"grey70\", \"grey70\", \"grey70\", \"grey70\", \"grey70\", \"skyblue\", \"grey70\") )\n\n\n\n\n\n\n\n\n\n\n\n\nIt is hard to decipher the Parallel Coordinates Plot alone. We will complement it with boxplot. The arguments are provided in ggparcoord().\n\n\nShow the code\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Parallel Coordinates Plot of World Happines Variables\") +\n  theme(\n    plot.title = element_text(hjust = 0),\n    axis.title.x = element_text(size = 0.7),\n    axis.title.y = element_text(hjust=1, angle=0),\n    plot.background = element_rect(fill = \"#f1f4f5\", color = \"#f1f4f5\"),\n    legend.background = element_rect(fill=\"#f1f4f5\"),\n    legend.position = \"left\",\n    panel.background = element_rect(fill=\"#f1f4f5\")) +\n  scale_x_discrete(guide = guide_axis(n.dodge = 2))\n\n\n\n\n\n\n\n\n\n\n\nLearning from the code\n\n\n\ngroupColumn argument is used to group the observations (i.e. parallel lines) by using a single variable (i.e. Region) and colour the parallel coordinates lines by region name.\nscale argument is used to scale the variables in the parallel coordinate plot by using uniminmax method. The method univariately scale each variable so the minimum of the variable is zero and the maximum is one.\nalphaLines argument is used to reduce the intensity of the line colour to 0.2. The permissible value range is between 0 to 1.\nboxplot argument is used to turn on the boxplot by using logical TRUE. The default is FALSE.\ntitle argument is used to provide the parallel coordinates plot a title.\n\n\n\n\n\n\nSince ggparcoord() is developed by extending ggplot2 package, we can combie some of the ggplot2 function when plotting a parallel coordinates plot.\nIn the code chunk below, facet_wrap() of ggplot2 is used to plot 10 small multiple parallel coordinates plots. Each plot represent one geographical region.\n\nBase plotRoate X-axis text labelAdjust label position\n\n\nOne of the aesthetic defect of the current design is that some of the variable names overlap on x-axis.\n\n\nShow the code\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) +\n  theme(\n    plot.title = element_text(hjust = 0, size = 8),\n    axis.title.x = element_text(size = 0.2),\n    axis.title.y = element_text(hjust=1, angle=0),\n    axis.text.x = element_text(size = 6),\n    plot.background = element_rect(fill = \"#f1f4f5\", color = \"#f1f4f5\"),\n    legend.background = element_rect(fill=\"#f1f4f5\"),\n    legend.position = \"bottom\",\n    panel.background = element_rect(fill=\"#f1f4f5\")) \n\n\n\n\n\n\n\n\n\n\n\nTo make the x-axis text label easy to read, we will rotate the labels. We can rotate axis text labels using theme() function in ggplot2.\n\n\nShow the code\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) +\n  theme(\n    plot.title = element_text(hjust = 0, size = 8),\n    axis.title.x = element_text(size = 10, hjust = 1),\n    axis.title.y = element_text(hjust=1, angle=0),\n    axis.text.x = element_text(size = 7, angle = 30),\n    plot.background = element_rect(fill = \"#f1f4f5\", color = \"#f1f4f5\"),\n    legend.background = element_rect(fill=\"#f1f4f5\"),\n    legend.position = \"bottom\",\n    panel.background = element_rect(fill=\"#f1f4f5\")) \n\n\n\n\n\n\n\n\n\n\n\nLearning from the code\n\n\n\nWe use axis.text.x as argument to theme() function. And we specify element_text(angle = 30) to rotate the x-axis text by an angle 30 degrees.\n\n\n\n\n\nSome text labels after rotation are overlapping the plot. We can use hjust to adjust the position of the labels in theme().\n\n\nShow the code\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) +\n  theme(\n    plot.title = element_text(hjust = 0, size = 8),\n    axis.title.x = element_text(size = 10, hjust = 1),\n    axis.title.y = element_text(hjust=1, angle=0),\n    axis.text.x = element_text(size = 7, angle = 30, hjust = 1.1),\n    plot.background = element_rect(fill = \"#f1f4f5\", color = \"#f1f4f5\"),\n    legend.background = element_rect(fill=\"#f1f4f5\"),\n    legend.position = \"bottom\",\n    panel.background = element_rect(fill=\"#f1f4f5\"))",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 5-4"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_4.html#plot-interactive-parallel-coordinates-plot-parallelplot-methods",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_4.html#plot-interactive-parallel-coordinates-plot-parallelplot-methods",
    "title": "Hands-on_Ex05-4",
    "section": "",
    "text": "parallelPlot is an R package specially designed to plot a parallel coordinates plot by using ‘htmlwidgets’ package and d3.js. We will learn how to use functions provided in parallelPlot package to build interactive parallel coordinates plot.\n\nBase plotRotate axis labelChange colour schemeParallel coordinates plot with histogram\n\n\nThe code chunk below plot an interactive parallel coordinates plot by using parallelPlot().\nNote that some labels are long and overlapping.\n\n\nShow the code\nwh &lt;- wh %&gt;%\n  select(\"Happiness score\", c(7:12))\nparallelPlot(wh,\n             width = 320,\n             height = 250)\n\n\n\n\n\n\n\n\nTo solve the issue in the basee plot, we use rotateTitle argument is used to avoid overlapping axis labels.\n\n\nShow the code\nparallelPlot(wh,\n             rotateTitle = TRUE)\n\n\n\n\n\n\n\n\nColor can be customised using continuousCS.\n\nparallelPlot(wh,\n             continuousCS = \"YlOrRd\",\n             rotateTitle = TRUE)\n\n\n\n\n\n\n\nhistoVisibility argument is used to plot histogram along the axis of each variables.\n\nhistoVisibility &lt;- rep(TRUE, ncol(wh))\nparallelPlot(wh,\n             rotateTitle = TRUE,\n             histoVisibility = histoVisibility)\n\n\n\n\n\n\n\n\nWhen clicking on a variable, the lines often change colour based on how that variable scales or groups the data.",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 5-4"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_4.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_4.html#references",
    "title": "Hands-on_Ex05-4",
    "section": "",
    "text": "R for Visual Analytics\nggparcoord() of GGally package\nparcoords user guide\nparallelPlot",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 5-4"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-on_Ex02",
    "section": "",
    "text": "Several ggplot2 extensions for creating more elegant and effective statistical graphics. By the end of this exercise, one will be able to:\n\ncontrol the placement of annotation on a graph by using functions provided in ggrepel package.\ncreate professional publication quality figure by using functions provided in ggthemes and hrbrthemes packages; and\nplot composite figure by combing ggplot2 graphs by using patchwork package.\n\n\n\n\n\n\nIn this exercise, besides tidyverse, four R packages will be used.\nThey are:\n\nggrepel: a R package provides geoms for ggplot2 to repel overlapping text labels.\nggthemes: a R package provides some extra themes, geoms, and scales for ggplot.\nhrbrthemes: a R package provides typographu-centric themes and theme components for ggplot2.\npatchwork: a R package for preparing composite figure created using ggplot2.\n\nCode chunk below will be used to check if these packages have been installed and also load them onto the working R environment.\n\npacman::p_load(ggrepel, patchwork,\n               ggthemes, hrbrthemes,\n               tidyverse) #all packages are then installed.\n\n\n\n\nFor the purpose of this exercise, a data file called Exam_data will be used. It consists of year end examination grades of a cohort of primary 3 students from a local school. It is in csv file format.\nThe code chunk below imports exam_data.csv into R environment by using read_csv() function of readr package. readr is one of the tidyversepackage.\n\nlibrary(readr)\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nThere are a total of seven attributes in the exam_data tibble data frame. Four of them are categorical data type and the other three are in continuous data type.\n\nThe categorical attributes are ID, CLASS, GENDER and RACE.\nThe continuous attributes are MATHS, ENGLISH and SCIENCE.\n\n\n\n\n\nOne of the challenge in plotting statistical graph is annotation, especially with large number of data points.\n\n🦖 PracticePlotCode\n\n\n🦖 Used colours to differentiate genders.\n\nggplot(data=exam_data,\n       aes(x = MATHS,\n           y = ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm,\n              linewidth=0.5) +\n  geom_label(aes(label = ID,\n                 colour = GENDER), #added colours\n             hjust = .5,\n             vjust = -.5) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x = MATHS,\n           y = ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm,\n              linewidth=0.5) +\n  geom_label(aes(label = ID),\n             hjust = .5,\n             vjust = -.5) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\nggrepel  is an extension of ggplot2 package which provides geoms for ggplot2 to repel overlapping text as in the examples below.\n\n\n\n\n\nWe simply replace geom_text() by geom_text_repel() and geom_label() with geom_label_repel().\n\n\n\n🦖 PracticePlotCode\n\n\n🦖 Applied colours to differentiate genders.\n\nggplot(data=exam_data,\n       aes(x = MATHS,\n           y = ENGLISH)) +\n  geom_point() +\n  geom_smooth(method = lm,\n              size = 0.5) +\n  geom_label_repel(aes(label = ID,\n                       colour = GENDER), #colour for gender\n                   fontface = \"bold\") +\n  coord_cartesian(xlim = c(0,100),\n                  ylim = c(0,100)) +\n  ggtitle(\"English scores vs Maths scores for P3\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x = MATHS,\n           y = ENGLISH)) +\n  geom_point() +\n  geom_smooth(method = lm,\n              size = 0.5) +\n  geom_label_repel(aes(label = ID),\n                   fontface = \"bold\") +\n  coord_cartesian(xlim = c(0,100),\n                  ylim = c(0,100)) +\n  ggtitle(\"English scores vs Maths scores for P3\")\n\n\n\n\n\n\n\nggplot2 comes with eight built-in themes. They are:\ntheme_gray(), theme_bw(), theme_classic(), theme_dark(), theme_light(), theme_linedraw(), theme_minimal(), theme_void().\n\n🦖 Practice I🦖 Practice IIPlotCode\n\n\n🦖 Applied theme_light() and different colors for fill and color.\n\nggplot(data=exam_data,\n       aes(x = MATHS)) +\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 color = \"grey90\",\n                 fill = \"pink\") +\n  theme_light() +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n\n\n\n\n\n🦖 Applied theme_dark() and different colors for fill and color.\n\nggplot(data=exam_data,\n       aes(x = MATHS)) +\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 color = \"grey90\",\n                 fill = \"skyblue\") +\n  theme_dark() +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x = MATHS)) +\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 color = \"grey25\",\n                 fill = \"grey90\") +\n  theme_gray() +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n🦄 Refer to this link to learn more about ggplot2 Themes\n\n\nggthemes provides ggplot2 themes that replicate the look of plots by Edward Tuffe, Stephen Few, Fivethirtyeight, The Economist, ‘Stata’, ‘Excel’, and The Wall Street Journal, among others.\nIn the example below, The Economist theme is used.\n\n🦖 PracticePlotCode\n\n\n🦖 Used theme_stata()\n\nggplot(data=exam_data,\n       aes(x = MATHS)) +\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 color = \"grey25\",\n                 fill = \"grey90\",\n                 linewidth = 0.3) +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_stata()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x = MATHS)) +\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 color = \"grey25\",\n                 fill = \"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_economist()\n\n\n\nIt also provides some extra geoms and scales fpr ggplot2. Consult this vignette to learn more. *Link is broken as of Jan 19.\n\n\n\nhrbrthemes package provides a base theme that focuses on typographic elements, including where various labels are placed as well as the fonts that are used.\n\n🦖 PracticePlotCode\n\n\n\nggplot(data=exam_data,\n       aes(x = MATHS)) +\n  geom_histogram(bins=20,\n                 boundary=100,\n                 color=\"grey25\",\n                 fill=\"pink\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x = MATHS)) +\n  geom_histogram(bins=20,\n                 boundary=100,\n                 color=\"grey25\",\n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum()\n\n\n\n\n🦖 PracticePlotCode\n\n\n🦖 Display English scores.\n\nggplot(data=exam_data,\n       aes(x = ENGLISH)) +\n  geom_histogram(bins=20,\n                 boundary=100,\n                 color=\"grey25\",\n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of English scores\") +\n  theme_ipsum(axis_text_size = 18,\n              base_size = 15,\n              grid = \"Y\") \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x = MATHS)) +\n  geom_histogram(bins=20,\n                 boundary=100,\n                 color=\"grey25\",\n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum(axis_text_size = 18,\n              base_size = 15,\n              grid = \"Y\")\n              \n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\naxis_title_size argument is used to increase the font size of the axis title to 18.\nbase_size argument is used to increase the default axis label to 15.\ngrid argument is used to remove the x-axis grid lines.\n\n\n\n\n\n\n\nIt is not unusual that multiple graphs are required to tell a compelling visual story. There are several ggplot2 extensions provide functions to compose figure with multiple graphs. In this section, learn how to create composite plot by combining multiple graphs. First, let us create three statistical graphics by using the code chunk below.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\np1 &lt;- ggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") + \n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\np1\n\n\n\nNext -\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np2 &lt;- ggplot(data=exam_data, \n             aes(x = ENGLISH)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") + \n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of English scores\")\np2\n\n\n\n\n\n\n\n\n\n\n\nLastly, we will draw a scatterplot for English score vs Maths score by the plot below:\n\n🦖 PracticePlotCode\n\n\n🦖 Used theme_economist().\n\np100 &lt;- ggplot(data=exam_data,\n             aes(x = MATHS,\n                 y = ENGLISH)) +\n  geom_point() +\n  geom_smooth(method = lm,\n              size = 0.5) +\n  coord_cartesian(xlim=c(0,100),\n                 ylim=c(0,100)) +\n  ggtitle(\"English scores vs Maths scores for P3\") +\n  theme_economist() +\n    theme(plot.title = element_text(size = 10, face = \"bold\"))\np100\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np99 &lt;- ggplot(data=exam_data,\n             aes(x = MATHS,\n                 y = ENGLISH)) +\n  geom_point() +\n  geom_smooth(method = lm,\n              size = 0.5) +\n  coord_cartesian(xlim=c(0,100),\n                 ylim=c(0,100)) +\n  ggtitle(\"English scores vs Maths scores for P3\") \np99\n\n\n\n\n\nThere are several ggplot2 extension’s functions support the needs to prepare composite figure by combining several graphs such as grid.arrange() of gridExtra package and plot_grid() of cowplot package . The extension called patchwork is specially designed for combining separate ggplot 2 graphs into a single figure.\nPatchwork package has a very simple syntax where we can create layouts super easily. Here is the general syntax that combines:\n\nTwo-column layout using the Plus sign +.\nParenthesis () to create a subplot group.\nTwo-row layout using the Division design /\n\n\n\n\nFigure in the tabset below shows a a composite of two histograms created using patchwork. Code is pretty simple.\n\n🦖 PracticePlotCode\n\n\n\npatchwork &lt;- p1 + p2\npatchwork & theme_stata()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np1 + p2\n\n\n\n\n\n\nWe can plot more complex composite by using appropriate operators. For example, the composite figure below is plotted by using: - “/” operator to stack two ggplot2 graphs - “|” operator to place the plots beside each other - “()” operator to define the sequence of the plotting.\n\n🦖 Practice I🦖 Practice IIPlotCode\n\n\n🦖 Changed the layout.\n\np3 | ( p2 / p1)\n\n\n\n\n\n\n\n\n\n\n🦖 Used theme_economist()\n\npatchwork &lt;- p3 | (p2 / p1)\npatchwork & theme_economist() +\n  theme(axis.title = element_text(size = rel(1)),\n        axis.text = element_text(size = 8))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(p1 / p2) | p3\n\n\n\n\n\n🦄 Learn more with Plot Assembly.\n\n\n\nIn order to identify subplots in text, patchwork also provides auto-tagging capabilities as shown in the figure below.\n\n🦖 PracticePlotCode\n\n\n🦖 Changed level tag and used a new theme theme_stata()\n\n((p1 / p2) | p3) +\n  plot_annotation(tag_levels = 'A') + \n  theme_stata()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n((p1 / p2) | p3) +\n  plot_annotation(tag_levels = 'I')\n\n\n\n\n\n\nBeside providing functions to place plots next to each other based on the provided layout. With inset_element() of patchwork, we can place one or several plots or graphic elements freely on top or below another plot.\n\n🦖 PracticePlotCode\n\n\n🦖 Used theme_economist() and altered the position of the top layer plot.\n\np3 + theme_economist() +\n  inset_element(p1,\n                   left = 0.5,\n                   bottom = 0,\n                   right = 1,\n                   top = 0.3) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np3 + inset_element(p2,\n                   left = 0.02,\n                   bottom = 0.7,\n                   right = 0.5,\n                   top = 1)\n\n\n\n\n\n\nFigure below is created by combining patchwork and theme_economist() of ggthemes package discussed earlier.\n\n🦖 PracticePlotCode\n\n\nUsed theme_stata() and changed layout.\n\npatchwork &lt;- p3 | (p1 / p2) \npatchwork & theme_stata()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npatchwork &lt;- (p1 / p2) | p3 \npatchwork & theme_economist()\n\n\n\n\n\n\n\n\nPatchwork R package goes nerd viral\nggrepel\nggthemes\nhrbrthemes\nggplot tips: Arranging plots\nggplot2 Theme Elements Demonstration\nggplot2 Theme Elements Reference Sheet",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 2"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#overview",
    "title": "Hands-on_Ex02",
    "section": "",
    "text": "Several ggplot2 extensions for creating more elegant and effective statistical graphics. By the end of this exercise, one will be able to:\n\ncontrol the placement of annotation on a graph by using functions provided in ggrepel package.\ncreate professional publication quality figure by using functions provided in ggthemes and hrbrthemes packages; and\nplot composite figure by combing ggplot2 graphs by using patchwork package.",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 2"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#getting-started",
    "title": "Hands-on_Ex02",
    "section": "",
    "text": "In this exercise, besides tidyverse, four R packages will be used.\nThey are:\n\nggrepel: a R package provides geoms for ggplot2 to repel overlapping text labels.\nggthemes: a R package provides some extra themes, geoms, and scales for ggplot.\nhrbrthemes: a R package provides typographu-centric themes and theme components for ggplot2.\npatchwork: a R package for preparing composite figure created using ggplot2.\n\nCode chunk below will be used to check if these packages have been installed and also load them onto the working R environment.\n\npacman::p_load(ggrepel, patchwork,\n               ggthemes, hrbrthemes,\n               tidyverse) #all packages are then installed.\n\n\n\n\nFor the purpose of this exercise, a data file called Exam_data will be used. It consists of year end examination grades of a cohort of primary 3 students from a local school. It is in csv file format.\nThe code chunk below imports exam_data.csv into R environment by using read_csv() function of readr package. readr is one of the tidyversepackage.\n\nlibrary(readr)\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nThere are a total of seven attributes in the exam_data tibble data frame. Four of them are categorical data type and the other three are in continuous data type.\n\nThe categorical attributes are ID, CLASS, GENDER and RACE.\nThe continuous attributes are MATHS, ENGLISH and SCIENCE.",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 2"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot-annotation-ggrepel",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot-annotation-ggrepel",
    "title": "Hands-on_Ex02",
    "section": "",
    "text": "One of the challenge in plotting statistical graph is annotation, especially with large number of data points.\n\n🦖 PracticePlotCode\n\n\n🦖 Used colours to differentiate genders.\n\nggplot(data=exam_data,\n       aes(x = MATHS,\n           y = ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm,\n              linewidth=0.5) +\n  geom_label(aes(label = ID,\n                 colour = GENDER), #added colours\n             hjust = .5,\n             vjust = -.5) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x = MATHS,\n           y = ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm,\n              linewidth=0.5) +\n  geom_label(aes(label = ID),\n             hjust = .5,\n             vjust = -.5) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\nggrepel  is an extension of ggplot2 package which provides geoms for ggplot2 to repel overlapping text as in the examples below.\n\n\n\n\n\nWe simply replace geom_text() by geom_text_repel() and geom_label() with geom_label_repel().\n\n\n\n🦖 PracticePlotCode\n\n\n🦖 Applied colours to differentiate genders.\n\nggplot(data=exam_data,\n       aes(x = MATHS,\n           y = ENGLISH)) +\n  geom_point() +\n  geom_smooth(method = lm,\n              size = 0.5) +\n  geom_label_repel(aes(label = ID,\n                       colour = GENDER), #colour for gender\n                   fontface = \"bold\") +\n  coord_cartesian(xlim = c(0,100),\n                  ylim = c(0,100)) +\n  ggtitle(\"English scores vs Maths scores for P3\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x = MATHS,\n           y = ENGLISH)) +\n  geom_point() +\n  geom_smooth(method = lm,\n              size = 0.5) +\n  geom_label_repel(aes(label = ID),\n                   fontface = \"bold\") +\n  coord_cartesian(xlim = c(0,100),\n                  ylim = c(0,100)) +\n  ggtitle(\"English scores vs Maths scores for P3\")",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 2"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-themes",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-themes",
    "title": "Hands-on_Ex02",
    "section": "",
    "text": "ggplot2 comes with eight built-in themes. They are:\ntheme_gray(), theme_bw(), theme_classic(), theme_dark(), theme_light(), theme_linedraw(), theme_minimal(), theme_void().\n\n🦖 Practice I🦖 Practice IIPlotCode\n\n\n🦖 Applied theme_light() and different colors for fill and color.\n\nggplot(data=exam_data,\n       aes(x = MATHS)) +\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 color = \"grey90\",\n                 fill = \"pink\") +\n  theme_light() +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n\n\n\n\n\n🦖 Applied theme_dark() and different colors for fill and color.\n\nggplot(data=exam_data,\n       aes(x = MATHS)) +\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 color = \"grey90\",\n                 fill = \"skyblue\") +\n  theme_dark() +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x = MATHS)) +\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 color = \"grey25\",\n                 fill = \"grey90\") +\n  theme_gray() +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n🦄 Refer to this link to learn more about ggplot2 Themes\n\n\nggthemes provides ggplot2 themes that replicate the look of plots by Edward Tuffe, Stephen Few, Fivethirtyeight, The Economist, ‘Stata’, ‘Excel’, and The Wall Street Journal, among others.\nIn the example below, The Economist theme is used.\n\n🦖 PracticePlotCode\n\n\n🦖 Used theme_stata()\n\nggplot(data=exam_data,\n       aes(x = MATHS)) +\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 color = \"grey25\",\n                 fill = \"grey90\",\n                 linewidth = 0.3) +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_stata()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x = MATHS)) +\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 color = \"grey25\",\n                 fill = \"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_economist()\n\n\n\nIt also provides some extra geoms and scales fpr ggplot2. Consult this vignette to learn more. *Link is broken as of Jan 19.\n\n\n\nhrbrthemes package provides a base theme that focuses on typographic elements, including where various labels are placed as well as the fonts that are used.\n\n🦖 PracticePlotCode\n\n\n\nggplot(data=exam_data,\n       aes(x = MATHS)) +\n  geom_histogram(bins=20,\n                 boundary=100,\n                 color=\"grey25\",\n                 fill=\"pink\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x = MATHS)) +\n  geom_histogram(bins=20,\n                 boundary=100,\n                 color=\"grey25\",\n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum()\n\n\n\n\n🦖 PracticePlotCode\n\n\n🦖 Display English scores.\n\nggplot(data=exam_data,\n       aes(x = ENGLISH)) +\n  geom_histogram(bins=20,\n                 boundary=100,\n                 color=\"grey25\",\n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of English scores\") +\n  theme_ipsum(axis_text_size = 18,\n              base_size = 15,\n              grid = \"Y\") \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x = MATHS)) +\n  geom_histogram(bins=20,\n                 boundary=100,\n                 color=\"grey25\",\n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum(axis_text_size = 18,\n              base_size = 15,\n              grid = \"Y\")\n              \n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\naxis_title_size argument is used to increase the font size of the axis title to 18.\nbase_size argument is used to increase the default axis label to 15.\ngrid argument is used to remove the x-axis grid lines.",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 2"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-single-graph",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-single-graph",
    "title": "Hands-on_Ex02",
    "section": "",
    "text": "It is not unusual that multiple graphs are required to tell a compelling visual story. There are several ggplot2 extensions provide functions to compose figure with multiple graphs. In this section, learn how to create composite plot by combining multiple graphs. First, let us create three statistical graphics by using the code chunk below.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\np1 &lt;- ggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") + \n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\np1\n\n\n\nNext -\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np2 &lt;- ggplot(data=exam_data, \n             aes(x = ENGLISH)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") + \n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of English scores\")\np2\n\n\n\n\n\n\n\n\n\n\n\nLastly, we will draw a scatterplot for English score vs Maths score by the plot below:\n\n🦖 PracticePlotCode\n\n\n🦖 Used theme_economist().\n\np100 &lt;- ggplot(data=exam_data,\n             aes(x = MATHS,\n                 y = ENGLISH)) +\n  geom_point() +\n  geom_smooth(method = lm,\n              size = 0.5) +\n  coord_cartesian(xlim=c(0,100),\n                 ylim=c(0,100)) +\n  ggtitle(\"English scores vs Maths scores for P3\") +\n  theme_economist() +\n    theme(plot.title = element_text(size = 10, face = \"bold\"))\np100\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np99 &lt;- ggplot(data=exam_data,\n             aes(x = MATHS,\n                 y = ENGLISH)) +\n  geom_point() +\n  geom_smooth(method = lm,\n              size = 0.5) +\n  coord_cartesian(xlim=c(0,100),\n                 ylim=c(0,100)) +\n  ggtitle(\"English scores vs Maths scores for P3\") \np99\n\n\n\n\n\nThere are several ggplot2 extension’s functions support the needs to prepare composite figure by combining several graphs such as grid.arrange() of gridExtra package and plot_grid() of cowplot package . The extension called patchwork is specially designed for combining separate ggplot 2 graphs into a single figure.\nPatchwork package has a very simple syntax where we can create layouts super easily. Here is the general syntax that combines:\n\nTwo-column layout using the Plus sign +.\nParenthesis () to create a subplot group.\nTwo-row layout using the Division design /\n\n\n\n\nFigure in the tabset below shows a a composite of two histograms created using patchwork. Code is pretty simple.\n\n🦖 PracticePlotCode\n\n\n\npatchwork &lt;- p1 + p2\npatchwork & theme_stata()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np1 + p2\n\n\n\n\n\n\nWe can plot more complex composite by using appropriate operators. For example, the composite figure below is plotted by using: - “/” operator to stack two ggplot2 graphs - “|” operator to place the plots beside each other - “()” operator to define the sequence of the plotting.\n\n🦖 Practice I🦖 Practice IIPlotCode\n\n\n🦖 Changed the layout.\n\np3 | ( p2 / p1)\n\n\n\n\n\n\n\n\n\n\n🦖 Used theme_economist()\n\npatchwork &lt;- p3 | (p2 / p1)\npatchwork & theme_economist() +\n  theme(axis.title = element_text(size = rel(1)),\n        axis.text = element_text(size = 8))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(p1 / p2) | p3\n\n\n\n\n\n🦄 Learn more with Plot Assembly.\n\n\n\nIn order to identify subplots in text, patchwork also provides auto-tagging capabilities as shown in the figure below.\n\n🦖 PracticePlotCode\n\n\n🦖 Changed level tag and used a new theme theme_stata()\n\n((p1 / p2) | p3) +\n  plot_annotation(tag_levels = 'A') + \n  theme_stata()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n((p1 / p2) | p3) +\n  plot_annotation(tag_levels = 'I')\n\n\n\n\n\n\nBeside providing functions to place plots next to each other based on the provided layout. With inset_element() of patchwork, we can place one or several plots or graphic elements freely on top or below another plot.\n\n🦖 PracticePlotCode\n\n\n🦖 Used theme_economist() and altered the position of the top layer plot.\n\np3 + theme_economist() +\n  inset_element(p1,\n                   left = 0.5,\n                   bottom = 0,\n                   right = 1,\n                   top = 0.3) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np3 + inset_element(p2,\n                   left = 0.02,\n                   bottom = 0.7,\n                   right = 0.5,\n                   top = 1)\n\n\n\n\n\n\nFigure below is created by combining patchwork and theme_economist() of ggthemes package discussed earlier.\n\n🦖 PracticePlotCode\n\n\nUsed theme_stata() and changed layout.\n\npatchwork &lt;- p3 | (p1 / p2) \npatchwork & theme_stata()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npatchwork &lt;- (p1 / p2) | p3 \npatchwork & theme_economist()",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 2"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#reference",
    "title": "Hands-on_Ex02",
    "section": "",
    "text": "Patchwork R package goes nerd viral\nggrepel\nggthemes\nhrbrthemes\nggplot tips: Arranging plots\nggplot2 Theme Elements Demonstration\nggplot2 Theme Elements Reference Sheet",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 2"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#learning-outcome",
    "title": "Hands-on_Ex03_1",
    "section": "3.1 Learning Outcome",
    "text": "3.1 Learning Outcome\nIn this hands-on exercise, you will learn how to create interactive data cisualisation by using functions provided by ggiraph and plotlyr packages.",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 3-1"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#getting-started",
    "title": "Hands-on_Ex03_1",
    "section": "3.2 Getting Started",
    "text": "3.2 Getting Started\nFirst, write a code chunk to check, install and launch t he following R packages:\n\nggiraph for making ‘ggplot’ graphics interactive.\nplotly, R library for plotting interactive statistical graphs\nDT provides an R interface to the JavaScript library DataTables that create interactive table on html page.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\npatchwork for combining multiple ggplot2 graphs into one figure.\n\n🔑 The code chunk below will be used to accomplish the task.",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 3-1"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#importing-data",
    "title": "Hands-on_Ex03_1",
    "section": "3.3 Importing Data",
    "text": "3.3 Importing Data\nIn this section, Exam_data.csv provided will be used. Using read_csv() of readr package, import Exam_data.csv into R.\nThe code chunk below read_csv() of readr package is used to import Exam_data.csv data file into R and save it as an tibble data frame called exam_data.\n\nlibrary(readr)\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 3-1"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#interactive-data-visualisation---ggiraph-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#interactive-data-visualisation---ggiraph-methods",
    "title": "Hands-on_Ex03_1",
    "section": "3.4 Interactive Data Visualisation - ggiraph methods",
    "text": "3.4 Interactive Data Visualisation - ggiraph methods\nggiraph  is an htmlwidget and a ggplot2 extension. It allows ggplot graphics to be interactive.\nInteractive is made with ggplot geometries that can understand three arguments:\n\nTooltip: a column of data-sets that contain tooltips to be displayed when the mouse is over elements.\nOnclick: a column of data-sets that contain a JavaScript function to be executed when elements are clicked.\nData_id: a column of data-sets that contain an id to be associated with elements.\n\n\n\n🎯 Onclick, Data_id\nIf it is used within a shiny application, elements associated with an id(data_id) can be selected and manipulated on client and server sides. Refer to this article for more detail explanation.\n\n\n❗article not found.\n\n3.4.1 Tooltip effect with tooltip aesthetic\nBelow shows a typical code chunk to plot an interactive statistical graph by using ggiraph package. Notice that the code chunk consists of two parts. First, a ggplot object will be created. Next, girafe() of ggiraph will be used to create an interactive svg object.\n\np &lt;- ggplot(data=exam_data,\n            aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,\n                     breaks = NULL\n  )\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\n\n\n\n\nNotice that two steps are involved.\nFirst, an interactive vrsion of ggplot2 geom (i.e. geom_dotplot_interactive()) will be used to create the basic graph. Then, girafe() will be used to generate an svg object to be displayed on an html page.",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 3-1"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#interactivity",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#interactivity",
    "title": "Hands-on_Ex03_1",
    "section": "3.5 Interactivity",
    "text": "3.5 Interactivity\nBy hovering the mouse pointer on an data point of interest, the student’s ID will be displayed.\n\n\n\n\n\n\n\n3.5.1 Displaying multiple information on tooltip\n🔑 The content of the tooltip can be customised by including a list object as shown in the code chunk below.\n\nexam_data$tooltip &lt;- c(paste0(\n  \"Name = \", exam_data$ID,\n  \"\\n Class =\", exam_data$CLASS))\n\np &lt;- ggplot(data=exam_data,\n            aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,\n                     breaks=NULL)\n\ngirafe(\n  ggobj = p,\n  width_svg = 8,\n  height_svg = 8*0.618\n)\n\n\n\n\n\nThe first three lines of codes in the code chunk create a new field called tooltip. At the same time, it populates text in ID and CLASS fields into the newly created field. Next, this newly created field is used as tooltip field as shown in the code of line 7.",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 3-1"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#interactivity---customisation",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#interactivity---customisation",
    "title": "Hands-on_Ex03_1",
    "section": "3.6 Interactivity - customisation",
    "text": "3.6 Interactivity - customisation\nBy hovering the mouse pointer on a data point of interest, the student’s ID and CLASS are displayed.\n\n\n\n\n\n\n\n3.7.1 Customising Tooltip style\n🔑 Code chunk below uses opts_tooltip() of ggiraph to customise tooltip rendering by adding css declarations.\ntooltip_css &lt;- \"background-color: pink;  #&lt;&lt;\nfront-style:bold; color: #fff;\" #&lt;&lt;\n\np &lt;- ggplot(data = exam_data,\n            aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,\n                     breaks = NULL)\n\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618,\n  options = list(    #&lt;&lt;\n    opts_tooltip(    #&lt;&lt;\n      css = tooltip_css)) #&lt;&lt;\n)\nNotice that the background colour of the tooltip is pink and the font colour is white and bold.\n\n\n\n\n\n\n\n\n❓ How to change tooltip fonts?\n❓ Text to appear between code chunk and charts\nRefer to Customizing girafe objects to learn more about how to customise ggriaph objects. (link is not working as of Jan 16 2025)\n\n\n3.6.2 Displaying statistics on tooltip\n🔑 Code chunk below shows an advanced way to customise tooltip. In this example, a function is used to compute 90% confident interval of the mean. The derived statistics are then displayed in the tooltip.\n\ntooltip &lt;- function(y, ymax, accuracy = .01) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores: \", mean, \"+/-\", sem)\n}\n\ngg_point &lt;- ggplot(data=exam_data,\n                  aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS,\n                   tooltip = after_stat(\n                     tooltip(y, ymax))),\n               fun.data = mean_se,\n               geom = GeomInteractiveCol,\n               fill = \"light blue\"\n              ) + \n              stat_summary(aes(y = MATHS),\n                fun.data = mean_se,\n                geom = \"errorbar\", width = 0.2, size = 0.2\n              )\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\n\n\n3.6.3 Hover effect with data_id aesthetic\n🔑 Code chunk below shows the second interactive feature of ggiraph, namely data_id.\np &lt;- ggplot(data=exam_data,\n            aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(data_id = CLASS),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,\n                     breaks = NULL\n  )\n\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\nInteractivity: Elements associated with a data_id (i.e. CLASS) will be highlighted upon mouse over.\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote that the default value of the hover css is hover_css = “fill:orange;”\n\n\n\n\n3.6.4 Styling hover effect\nIn the code chunk below, css codes are used to change the highlighting effect.\n\np &lt;- ggplot(data=exam_data,\n            aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(data_id=CLASS),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,\n                     breaks = NULL\n  )\n\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618,\n  options = list(\n    opts_hover(css = \"fill:#202020;\"),\n    opts_hover_inv(css = \"opacity:0.2;\")\n  )\n)\n\n\n\n\n\nInteractivity: Elements associated with a data_id (i.e. CLASS) will be highlighted upon mouse hover.\n\n\n\n\n\n\nNote\n\n\n\nDifferent from previous example, in this example the css customisation request are encoded directly.\n\n\n\n\n3.6.5 Combining tooltip and hover effect\n🔑 There are time when we want to combine tooltip and hover effect on the interactive statistical graph as shown in the code chunk below.\n\np &lt;- ggplot(data=exam_data,\n            aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = CLASS, #tooltip here\n        data_id = CLASS),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,\n                     breaks = NULL)\n\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618,\n  options = list(\n    opts_hover(css = \"fill: #2020202;\"),\n    opts_hover_inv(css = \"opacity:0.2\")\n  )\n)\n\n\n\n\n\nInteractivity: Elements associated with a data_id (i.e. CLASS) will be highlighted upon mouse over. At the same time, the tooltip will show the CLASS.\n\n\n3.6.6 Click effect with onclick\nonclick argument of ggiraph provides hotlink interactivity on the web.\n🔑 The code chunk below shown an example of onclick.\n\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID)) #onclic link here\n\np &lt;- ggplot(data=exam_data,\n            aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(onclick = onclick),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,\n                     breaks = NULL\n  )\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nNote that click actions must be a string column in the dataset containing valid JavaScript instructions.\n\n\n\n\n❓ string column in the dataset\n\n\n3.6.7 Coordinated Multiple Views with ggiraph\nCoordinated multiple views methods has been implemented in the data visualisation below.\n\n\n\n\n\n\n🐳 Note that when a data point of one of the dotplot is selected, the corresponding data point ID on the second data visualisation will be highlighted too.\nIn order to build a coordinated multiple views as shown in the example above, the following programming strategy will be used:\n\nAppropriate interactive functions of ggiraph will be used to create the multiple views.\npatchwork function of patchwork package will be used inside girafe function to create the interactive coordinated multiple views.\n\n\n\n🦄 The goal of patchwork is to make it ridiculously simple to combine separate ggplots into the same graphic. As such it tries to solve the same problem as gridExtra::grid.arrange() and cowplot::plot_grid but using an API that incites exploration and iteration, and scales to arbitrarily complex layouts.\np1 &lt;- ggplot(data=exam_data,\n             aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(data_id = ID,),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  coord_cartesian(xlim = c(0,100)) +\n  scale_y_continuous(NULL,\n                     breaks = NULL)\n\np2 &lt;- ggplot(data=exam_data,\n             aes(x = ENGLISH)) +\n  geom_dotplot_interactive(\n    aes(data_id = ID),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  coord_cartesian(xlim = c(0,100)) + #patchwork here\n  scale_y_continuous(NULL,\n                     breaks = NULL)\n\ngirafe(code = print(p1 + p2),\n       width_svg = 6,\n       height_svg = 3,\n       options = list(\n         opts_hover(css = \"fill:#202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n       ))\nThe data_id aesthetic is critical to link observations between plots and the tooltip aesthetic is optional but nice to have when mouse over a point.",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 3-1"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#interactive-data-visualisation---plotly-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#interactive-data-visualisation---plotly-methods",
    "title": "Hands-on_Ex03_1",
    "section": "3.7 Interactive Data Visualisation - plotly methods!",
    "text": "3.7 Interactive Data Visualisation - plotly methods!\nPlotly’s R graphing library create interactive web graphics from ggplot2 graphs and/or a custom interface to the (MIT-licensed) JavaScript library plotly.js inspired by the grammar of graphics. Different from other plotly platform, plot.R is free and open source.\n\nThere are two ways to create interactive graph by using plotly, they are:\n\nby using plot_ly(), and\nby using ggplotly()\n\n\n3.7.1 Creating an interactive scatter plot: plot_ly() method\n🔑 The tabset below shows an example of a basic interactive plot created with plot_ly().\n\nPlotCode chunk\n\n\n\n\n\n\n\n\n\n\nplot_ly(\n  data=exam_data,\n  x = ~MATHS,\n  y = ~ENGLISH\n)\n\n\n\n\n\n3.7.2 Working with visual variable: plot_ly() method\nIn the code chunk below, color argument is mapped to a qualitative visual variable (i.e. RACE).\n\nPlotCode chunk\n\n\n\n\n\n\n\n\n\n\nplot_ly(data=exam_data,\n        x = ~ENGLISH,\n        y = ~MATHS,\n        color = ~RACE)\n\n\n\n\n\n3.7.3 Creating an interactive scatter plot: ggplotly() method\nThe code chunk below plots an interactive scatter plot by using ggplot().\n\nPlotCode chunk🦖 Practice\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nggplotly(p)\nNotice that the only extra line needed in the code chunk is ggplotly()\n\n\n\np &lt;- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH,\n                color = RACE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nggplotly(p)\n\n\n\n\n\n\n\n\n\n\n3.7.4 Coordinated multiple views with plotly\nThe creation of a coordinated linked plot by using plotly involves three steps:\n\nhighlight_key() of plotly package is used as shared data.\ntwo scatter plots will be created by using ggplot2 functions.\nlastly, subplot() of plotly package is used to place them next to each other side-by-side.\n\n\n\n\n🦄 highlight_key(): This function simply creates an object of class crosstalk::SharedData. The reason it exists is to make it easier to teach others how to leverage its functionality in plotly. It also makes it more discoverable if one is already aware of highlight.\n🎯 Read more on subplot()\n\n\nPlotCode chunk🦖 Practice I🦖 Practice II\n\n\n\n\n\n\n\n\n\nHover over on a data point in one of the scatterplots. A tooltip will appear and show its scores.\nClick on a data point in one of the scatterplots, and the corresponding point in the other plot will appear.\n\n\n\nd &lt;- highlight_key(exam_data)\np1 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nsubplot(ggplotly(p1),\n        ggplotly(p2))\n\n\n\nd &lt;- highlight_key(exam_data)\np1 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = ENGLISH,\n                color = GENDER)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = SCIENCE,\n                color = GENDER)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nsubplot(ggplotly(p1),\n        ggplotly(p2))\n\n\n\n\n\n\n\n\nd &lt;- highlight_key(exam_data)\np1 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = ENGLISH,\n                color = RACE)) +\n  geom_point(size=0.5) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = SCIENCE,\n                color = RACE)) +\n  geom_point(size=0.5) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nsubplot(ggplotly(p1),\n        ggplotly(p2))\n\n\n\n\n\n\n\n\nThings to learn from the code chunk:\n\nhighlight_key() simply creates object of class crosstalk::SharedData.\nLearn more about crosswalk.",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 3-1"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#interactive-data-visualisation---crosstalk-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#interactive-data-visualisation---crosstalk-methods",
    "title": "Hands-on_Ex03_1",
    "section": "3.8 Interactive Data Visualisation - crosstalk methods!",
    "text": "3.8 Interactive Data Visualisation - crosstalk methods!\nCrosstalk is an add-on to the htmlwidgets package. It extends htmlwidgets with a set of classes, functions, and conventions for implementing cross-widget interactions (currently, linked brushing and filtering).\n\n3.8.1 Interactive Data Table: DT package\n\nA wrapper of the JavaScript Library DataTables\nData objects in R can be rendered as HTML tables using the JavaScript Library ‘DataTables’ (typically via R Markdown or Shiny).\n\n\nDT::datatable(exam_data, class = \"compact\")\n\n\n\n\n\n\n\n3.8.2 Linked brushing: crosstalk method\n\nPlotCode chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nd &lt;- highlight_key(exam_data)\np &lt;- ggplot(d,\n            aes(ENGLISH,\n                MATHS)) +\n  geom_point(size = 1) +\n  coord_cartesian(xlim = c(0,100),\n                  ylim = c(0,100))\n\ngg &lt;- highlight(ggplotly(p),\n                \"plotly_selected\")\n\ncrosstalk::bscols(gg,\n                  DT::datatable(d),\n                  widths = 5)",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 3-1"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#reference",
    "title": "Hands-on_Ex03_1",
    "section": "3.9 Reference",
    "text": "3.9 Reference\n\n3.9.1 ggiraph\nThis link provides online version of the reference gude and several useful articles. Use this link to download the PDF version of the reference guide.\n\nHow to plot with ggiraph\nInteractive map of France with ggiraph\nCustom interactive sunbursts with ggplot in R\nThis link provides code example on how ggiraph is used to create interactive graphs for Swiss Olympians - the solo specialists.\n\n\n\n3.9.2 plotly for R\n\nGetting started with Plotly in R\nA collection of plotly R graphs are available via this [link]\nCarson Sievert (2020) Interactive web-based data visualization with R, plotly, and shiny, Chapman and Hall/CRC is the best resource to learn plotly for R. The online version is available via this [link]\nPlotly R Figure Reference provides a comprehensive discussion of each visual representations.\nPlotly R Library Fundamentals is a good place to learn the fundamental features of Plotly’s R API.\nGetting Started\nA interesting implementation of gganimate by SMU senior: How has Singapore changed since 2011?\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 3-1"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html",
    "title": "Hands-on Ex04-2",
    "section": "",
    "text": "In this hands-on exercise, we will gain hands-on experience on using:\n\nggstatsplot package to create visual graphics with rich statistical information.\nperformance package to visualise model diagnostics.\nparameters package to visualise model parameters.\n\n\n\n\nggstatsplot is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves.\n- to provide alternative statistical inference methods by default.\n- to follow best practices for statistical reporting. For all statistical tests reported in the plots, the default template abides by the [APA](https://my.ilstu.edu/~jhkahn/apastats.html) gold standard for statistical reporting. \nFor example, here are results from a robust t-test:\n\n\n\n\n\n\nIn this exercise, ggstatsplot and tidyverse will be used.\n\npacman::p_load(ggstatsplot, tidyverse)\n\n\n\n\n\n\n\n\n\n\nDIY\n\n\n\nImport Exam-csv data by using appropriate tidyverse package.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\n\n\n\nIn the code chunk below, gghistostats() is used to build an visual of one-sample test on English scores.\n\n\nShow the code\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\n\n\n\n\n\nDefault information:\nstatistical details / Bayes Factor / sample sizes / distribution summary\n\n\n\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favour of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favour of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favour of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes factor is often written as B10. It can be defined mathematically as:\n\\[\n\\frac{likelihood-of-data-given-H_1}{likelihood-of-data-given-H_0} = \\frac{P(D|H_1)}{P(D/H_0)}\n\\]\nThe Schwarz criterion is one of the easiest ways to calculate rough estimation of the Bayes factor.\n\n\n\n\nA Bayes Factor can be any positive number.\nOne of the most common interpretation is this one - first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagemakers in 2013.\n\nBayes Factor\n\n\nIF B10 IS…\nTHEN YOU HAVE\n\n\n\n\n&gt;100\nExtreme evidence for H1\n\n\n30 - 100\nVery strong evidence for H1\n\n\n10 - 30\nStrong evidence for H1\n\n\n3 - 10\nModerate evidence for H1\n\n\n1 - 3\nAnecdotal evidence for H1\n\n\n1\nNo evidence\n\n\n1/3 - 1\nAnecdotal evidence for H1\n\n\n1/3 - 1/10\nModerate evidence for H1\n\n\n1/10 - 1/30\nStrong evidence for H1\n\n\n1/30 - 1/100\nVery Strong evidence for H1\n\n\n&lt;1/100\nExtreme evidence for H1\n\n\n\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\n\nShow the code\nggbetweenstats(\n  data = exam,\n  x = GENDER,\n  y = MATHS,\n  type = \"np\",\n  message = FALSE\n)\n\n\n\n\n\n\n\n\n\nDefault information: statistical details / Bayes factor / samples sizes / distribution summary\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English scores by race.\n\n\nShow the code\nggbetweenstats(\n  data = exam,\n  x = RACE,\n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE,\n  pariwise.comparisons = TRUE,\n  pairwise.display = \"s\",\n  p.adjust.methods = \"fdr\",\n  message = FALSE\n)\n\n\n\n\n\n\n\n\n\n\n“na” -&gt; only non-significant\n“s” -&gt; only significant\n“all” -&gt; everything\n\n\n\n\nTestCISummary\n\n\nFollowing (between-subjects) tests are carried out for each type of analyses.\n\n\n\nTYPE\nNO. OF GROUPS\nTEST\n\n\n\n\nParametric\n&gt;2\nFisher’s or Welch’s one-way ANOVA\n\n\nNon-Parametric\n&gt;2\nKruskal-Wallis one-way ANOVA\n\n\nRobust\n&gt;2\nHeteroscedastic one-way ANOVA for trimmed means\n\n\nBayes Factor\n&gt;2\nFisher’s ANOVA\n\n\nParametric\n2\nStudent’s or Welch’s t-test\n\n\nNon-Parametric\n2\nMann-Whitney U test\n\n\nRobust\n2\nYuen’s test for trimmed means\n\n\nBayes Factor\n2\nStudent’s t-test\n\n\n\n\n\nThe following effect sizes (and confidence intervals) are available for each type of test\n\n\n\nSummary of multiple pairwise comparison tests supported in ggbetweenstats()\n\n\n\n\n\n\n\n\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores. Practice using various subjects from the data and labeling functions.\n\n🦖 Practice I🦖 Practice IIExample\n\n\nMaths x Science; use labels to indicate races scoring 90 for both subjects.\n\n\nShow the code\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = SCIENCE,\n  label.var = RACE,\n  label.expression = MATHS &gt;= 90 & SCIENCE &gt;= 90,\n  marginal = FALSE\n)\n\n\n\n\n\n\n\n\n\n\n\nEnglish x Science; use labels to indicate genders scoring 90 for both subjects.\n\n\nShow the code\nggscatterstats(\n  data = exam,\n  x = ENGLISH,\n  y = SCIENCE,\n  label.var = GENDER,\n  label.expression = ENGLISH &gt;= 90 & SCIENCE &gt;= 90,\n  marginal = FALSE\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode chunk below, the Maths scores are binned into a 4-class variable with cut()\n\n#load library\nlibrary(dplyr)\n\nexam1 &lt;- exam |&gt;\n  mutate(MATHS_bins = \n           cut(MATHS,\n               breaks = c(0,60,75,85,100)))\n\nggbarstats() is used to build a visual for Significant Test of Association in the code below.\n\n\nUsage\nggbarstats(\n  data,\n  x,\n  y,\n  counts = NULL,\n  type = \"parametric\",\n  paired = FALSE,\n  results.subtitle = TRUE,\n  label = \"percentage\",\n  label.args = list(alpha = 1, fill = \"white\"),\n  sample.size.label.args = list(size = 4),\n  digits = 2L,\n  proportion.test = results.subtitle,\n  digits.perc = 0L,\n  bf.message = TRUE,\n  ratio = NULL,\n  conf.level = 0.95,\n  sampling.plan = \"indepMulti\",\n  fixed.margin = \"rows\",\n  prior.concentration = 1,\n  title = NULL,\n  subtitle = NULL,\n  caption = NULL,\n  legend.title = NULL,\n  xlab = NULL,\n  ylab = NULL,\n  ggtheme = ggstatsplot::theme_ggstatsplot(),\n  package = \"RColorBrewer\",\n  palette = \"Dark2\",\n  ggplot.component = NULL,\n  ...\n)\n\n🦖 English by GENDER🦖 Science by RACEExample\n\n\nTo see English scores by genders.\n\n\nShow the code\nexam_E &lt;- exam |&gt;\n  mutate(ENGLISH_bins = \n           cut(ENGLISH,\n               breaks = c(0,60,75,85,100)))\n\nggbarstats(exam_E,\n           x = ENGLISH_bins,\n           y = GENDER)\n\n\n\n\n\n\n\n\n\n\n\nTo see Science scores by races.\n\n\nShow the code\nexam_S &lt;- exam |&gt;\n  mutate(SCIENCE_bins = \n           cut(SCIENCE,\n               breaks = c(0,60,75,85,100)))\n\nggbarstats(exam_S,\n           x = SCIENCE_bins,\n           y = RACE)\n\n\n\n\n\n\n\n\n\n\n\n\nggbarstats(exam1,\n           x = MATHS_bins,\n           y = GENDER)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLearn how to visualise model diagnostic and model parameters by using parameters package.\n🚙 🚙 🚙 🚙 🚙 Toyota Corolla case study will be used to build a model to discover factor affecting practices of used-cars by taking into consideration of a set of explanatory variables.\n\n\n\n\n\n\n\npacman::p_load(readxl, performance, parameters, see)\n\n\n\nread_xls() of readxl package is used to import the data worksheet of ToyotaCorolla.xls worksbook into R.\n\n\nread_xls() Usage\nread_excel(\n  path,\n  sheet = NULL,\n  range = NULL,\n  col_names = TRUE,\n  col_types = NULL,\n  na = \"\",\n  trim_ws = TRUE,\n  skip = 0,\n  n_max = Inf,\n  guess_max = min(1000, n_max),\n  progress = readxl_progress(),\n  .name_repair = \"unique\"\n)\n\nread_xls(\n  path,\n  sheet = NULL,\n  range = NULL,\n  col_names = TRUE,\n  col_types = NULL,\n  na = \"\",\n  trim_ws = TRUE,\n  skip = 0,\n  n_max = Inf,\n  guess_max = min(1000, n_max),\n  progress = readxl_progress(),\n  .name_repair = \"unique\"\n)\n\nread_xlsx(\n  path,\n  sheet = NULL,\n  range = NULL,\n  col_names = TRUE,\n  col_types = NULL,\n  na = \"\",\n  trim_ws = TRUE,\n  skip = 0,\n  n_max = Inf,\n  guess_max = min(1000, n_max),\n  progress = readxl_progress(),\n  .name_repair = \"unique\"\n)\n\ncar_resale &lt;- read_xls(\"data/ToyotaCorolla.xls\",\n                       \"data\")\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model    Price Age_08_04 Mfg_Month Mfg_Year     KM Quarterly_Tax Weight\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n 1    81 TOYOTA … 18950        25         8     2002  20019           100   1180\n 2     1 TOYOTA … 13500        23        10     2002  46986           210   1165\n 3     2 TOYOTA … 13750        23        10     2002  72937           210   1165\n 4     3  TOYOTA… 13950        24         9     2002  41711           210   1165\n 5     4 TOYOTA … 14950        26         7     2002  48000           210   1165\n 6     5 TOYOTA … 13750        30         3     2002  38500           210   1170\n 7     6 TOYOTA … 12950        32         1     2002  61000           210   1170\n 8     7  TOYOTA… 16900        27         6     2002  94612           210   1245\n 9     8 TOYOTA … 18600        30         3     2002  75889           210   1245\n10    44 TOYOTA … 16950        27         6     2002 110404           234   1255\n# ℹ 1,426 more rows\n# ℹ 29 more variables: Guarantee_Period &lt;dbl&gt;, HP_Bin &lt;chr&gt;, CC_bin &lt;chr&gt;,\n#   Doors &lt;dbl&gt;, Gears &lt;dbl&gt;, Cylinders &lt;dbl&gt;, Fuel_Type &lt;chr&gt;, Color &lt;chr&gt;,\n#   Met_Color &lt;dbl&gt;, Automatic &lt;dbl&gt;, Mfr_Guarantee &lt;dbl&gt;,\n#   BOVAG_Guarantee &lt;dbl&gt;, ABS &lt;dbl&gt;, Airbag_1 &lt;dbl&gt;, Airbag_2 &lt;dbl&gt;,\n#   Airco &lt;dbl&gt;, Automatic_airco &lt;dbl&gt;, Boardcomputer &lt;dbl&gt;, CD_Player &lt;dbl&gt;,\n#   Central_Lock &lt;dbl&gt;, Powered_Windows &lt;dbl&gt;, Power_Steering &lt;dbl&gt;, …\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe output object car_resale is a tibble data frame.\nTibble is a modern data frame that is similar to data frames in R Programming Language but with some enhancements to make them easier to use and more consistent. Tibble is a part of the tidyverse package in R. Using tibbles we can view and understand the data very easily especially when working with large datasets\n\n\n\n\n\nCode chunk below is used to calibrate a multiple linear regression model by using lm() of Base Stats of R.\n\nmodel &lt;- lm(Price~Age_08_04 + Mfg_Year + KM +\n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n🦄 Can see how the variables affecting price positively or negatively.\n\n\n\nCode below checks for Multicollinearity using check_collinearity() of performance package.\n\n\ncheck_collinearity() Usage\ncheck_collinearity(x, ...)\n\nmulticollinearity(x, ...)\n\n# Default S3 method\ncheck_collinearity(x, ci = 0.95, verbose = TRUE, ...)\n\n# S3 method for class 'glmmTMB'\ncheck_collinearity(\n  x,\n  component = c(\"all\", \"conditional\", \"count\", \"zi\", \"zero_inflated\"),\n  ci = 0.95,\n  verbose = TRUE,\n  ...\n)\n\ncheck_concurvity(x, ...)\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n               KM 1.46 [ 1.37,  1.57]         1.21      0.68     [0.64, 0.73]\n           Weight 1.41 [ 1.32,  1.51]         1.19      0.71     [0.66, 0.76]\n Guarantee_Period 1.04 [ 1.01,  1.17]         1.02      0.97     [0.86, 0.99]\n\nHigh Correlation\n\n      Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n  Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\n\nNext to plot the result:\n\n#install.packages(\"bayestestR\", repos = \"https://easystats.r-universe.dev\")\n#remotes::install_github(\"easystats/see\")\n#install.packages(\"performance\")\nlibrary(performance)\nlibrary(\"bayestestR\")\nlibrary(\"see\")\n\ncheck_c &lt;- check_collinearity(model)\nplot(check_c)\n\n\n\n\n\n\n\n\n\n\n\nChecking normality using check_normality() from the performance package.\n\n\ncheck_normality()usage\ncheck_normality(x, ...)\n\n# S3 method for class 'merMod'\ncheck_normality(x, effects = \n                  c(\"fixed\", \"random\"), ...)\n\n\nShow the code\nmodel1 &lt;- lm(Price ~ Age_08_04 + KM +\n               Weight + Guarantee_Period, \n             data = car_resale)\n\n#check normality\ncheck_n &lt;- check_normality(model1)\n\nplot(check_n)\n\n\n\n\n\n\n\n\n\n\n\n🐠 The Performance workflow\n\n\n\n\n\n\n\n\nCheck model for constant error variance using check_heteroscedasticity() from the performance package.\n\n\ncheck_heteroscedasticity() usage\ncheck_heteroscedasticity(x, ...)\n\ncheck_heteroskedasticity(x, ...)\n\ncheck_h &lt;- check_heteroscedasticity(model1)\n\nplot(check_h)\n\n\n\n\n\n\n\n\n\n\n\nUse check_model() to perform a complete model check.\nVisual check of various model assumptions (normality of residuals, normality of random effects, linear relationship, homogeneity of variance, multicollinearity).\nIf check_model() doesn’t work as expected, try setting verbose = TRUE to get hints about possible problems.\n\n\ncheck_model(x, ...)\n\n# Default S3 method\ncheck_model(\n  x,\n  panel = TRUE,\n  check = \"all\",\n  detrend = TRUE,\n  bandwidth = \"nrd\",\n  type = \"density\",\n  residual_type = NULL,\n  show_dots = NULL,\n  size_dot = 2,\n  size_line = 0.8,\n  size_title = 12,\n  size_axis_title = base_size,\n  base_size = 10,\n  alpha = 0.2,\n  alpha_dot = 0.8,\n  colors = c(\"#3aaf85\", \"#1b6ca8\", \"#cd201f\"),\n  theme = \"see::theme_lucid\",\n  verbose = FALSE,\n  ...\n)\n\n\nShow the code\ncheck_model(model1)\n\n\n\n\n\n\n\n\n\n\n\n\nUse plot() from the see package and parameters() from the parameters package to visualise the parameters of a regression model.\n\nplot(parameters(model1))\n\n\n\n\n\n\n\n\n\n\n\nUse ggcoefstats() from ggstatsplot package to visualise the parameters of a regression model.\n\n\nShow the code\nggcoefstats(model1,\n            output = \"plot\")",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 4-2"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html#learning-outcome",
    "title": "Hands-on Ex04-2",
    "section": "",
    "text": "In this hands-on exercise, we will gain hands-on experience on using:\n\nggstatsplot package to create visual graphics with rich statistical information.\nperformance package to visualise model diagnostics.\nparameters package to visualise model parameters.",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 4-2"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html#visual-statistical-analysis-with-ggstatsplot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html#visual-statistical-analysis-with-ggstatsplot",
    "title": "Hands-on Ex04-2",
    "section": "",
    "text": "ggstatsplot is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves.\n- to provide alternative statistical inference methods by default.\n- to follow best practices for statistical reporting. For all statistical tests reported in the plots, the default template abides by the [APA](https://my.ilstu.edu/~jhkahn/apastats.html) gold standard for statistical reporting. \nFor example, here are results from a robust t-test:",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 4-2"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html#getting-started",
    "title": "Hands-on Ex04-2",
    "section": "",
    "text": "In this exercise, ggstatsplot and tidyverse will be used.\n\npacman::p_load(ggstatsplot, tidyverse)\n\n\n\n\n\n\n\n\n\n\nDIY\n\n\n\nImport Exam-csv data by using appropriate tidyverse package.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\n\n\n\nIn the code chunk below, gghistostats() is used to build an visual of one-sample test on English scores.\n\n\nShow the code\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\n\n\n\n\n\nDefault information:\nstatistical details / Bayes Factor / sample sizes / distribution summary\n\n\n\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favour of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favour of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favour of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes factor is often written as B10. It can be defined mathematically as:\n\\[\n\\frac{likelihood-of-data-given-H_1}{likelihood-of-data-given-H_0} = \\frac{P(D|H_1)}{P(D/H_0)}\n\\]\nThe Schwarz criterion is one of the easiest ways to calculate rough estimation of the Bayes factor.\n\n\n\n\nA Bayes Factor can be any positive number.\nOne of the most common interpretation is this one - first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagemakers in 2013.\n\nBayes Factor\n\n\nIF B10 IS…\nTHEN YOU HAVE\n\n\n\n\n&gt;100\nExtreme evidence for H1\n\n\n30 - 100\nVery strong evidence for H1\n\n\n10 - 30\nStrong evidence for H1\n\n\n3 - 10\nModerate evidence for H1\n\n\n1 - 3\nAnecdotal evidence for H1\n\n\n1\nNo evidence\n\n\n1/3 - 1\nAnecdotal evidence for H1\n\n\n1/3 - 1/10\nModerate evidence for H1\n\n\n1/10 - 1/30\nStrong evidence for H1\n\n\n1/30 - 1/100\nVery Strong evidence for H1\n\n\n&lt;1/100\nExtreme evidence for H1\n\n\n\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\n\nShow the code\nggbetweenstats(\n  data = exam,\n  x = GENDER,\n  y = MATHS,\n  type = \"np\",\n  message = FALSE\n)\n\n\n\n\n\n\n\n\n\nDefault information: statistical details / Bayes factor / samples sizes / distribution summary\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English scores by race.\n\n\nShow the code\nggbetweenstats(\n  data = exam,\n  x = RACE,\n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE,\n  pariwise.comparisons = TRUE,\n  pairwise.display = \"s\",\n  p.adjust.methods = \"fdr\",\n  message = FALSE\n)\n\n\n\n\n\n\n\n\n\n\n“na” -&gt; only non-significant\n“s” -&gt; only significant\n“all” -&gt; everything\n\n\n\n\nTestCISummary\n\n\nFollowing (between-subjects) tests are carried out for each type of analyses.\n\n\n\nTYPE\nNO. OF GROUPS\nTEST\n\n\n\n\nParametric\n&gt;2\nFisher’s or Welch’s one-way ANOVA\n\n\nNon-Parametric\n&gt;2\nKruskal-Wallis one-way ANOVA\n\n\nRobust\n&gt;2\nHeteroscedastic one-way ANOVA for trimmed means\n\n\nBayes Factor\n&gt;2\nFisher’s ANOVA\n\n\nParametric\n2\nStudent’s or Welch’s t-test\n\n\nNon-Parametric\n2\nMann-Whitney U test\n\n\nRobust\n2\nYuen’s test for trimmed means\n\n\nBayes Factor\n2\nStudent’s t-test\n\n\n\n\n\nThe following effect sizes (and confidence intervals) are available for each type of test\n\n\n\nSummary of multiple pairwise comparison tests supported in ggbetweenstats()\n\n\n\n\n\n\n\n\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores. Practice using various subjects from the data and labeling functions.\n\n🦖 Practice I🦖 Practice IIExample\n\n\nMaths x Science; use labels to indicate races scoring 90 for both subjects.\n\n\nShow the code\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = SCIENCE,\n  label.var = RACE,\n  label.expression = MATHS &gt;= 90 & SCIENCE &gt;= 90,\n  marginal = FALSE\n)\n\n\n\n\n\n\n\n\n\n\n\nEnglish x Science; use labels to indicate genders scoring 90 for both subjects.\n\n\nShow the code\nggscatterstats(\n  data = exam,\n  x = ENGLISH,\n  y = SCIENCE,\n  label.var = GENDER,\n  label.expression = ENGLISH &gt;= 90 & SCIENCE &gt;= 90,\n  marginal = FALSE\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode chunk below, the Maths scores are binned into a 4-class variable with cut()\n\n#load library\nlibrary(dplyr)\n\nexam1 &lt;- exam |&gt;\n  mutate(MATHS_bins = \n           cut(MATHS,\n               breaks = c(0,60,75,85,100)))\n\nggbarstats() is used to build a visual for Significant Test of Association in the code below.\n\n\nUsage\nggbarstats(\n  data,\n  x,\n  y,\n  counts = NULL,\n  type = \"parametric\",\n  paired = FALSE,\n  results.subtitle = TRUE,\n  label = \"percentage\",\n  label.args = list(alpha = 1, fill = \"white\"),\n  sample.size.label.args = list(size = 4),\n  digits = 2L,\n  proportion.test = results.subtitle,\n  digits.perc = 0L,\n  bf.message = TRUE,\n  ratio = NULL,\n  conf.level = 0.95,\n  sampling.plan = \"indepMulti\",\n  fixed.margin = \"rows\",\n  prior.concentration = 1,\n  title = NULL,\n  subtitle = NULL,\n  caption = NULL,\n  legend.title = NULL,\n  xlab = NULL,\n  ylab = NULL,\n  ggtheme = ggstatsplot::theme_ggstatsplot(),\n  package = \"RColorBrewer\",\n  palette = \"Dark2\",\n  ggplot.component = NULL,\n  ...\n)\n\n🦖 English by GENDER🦖 Science by RACEExample\n\n\nTo see English scores by genders.\n\n\nShow the code\nexam_E &lt;- exam |&gt;\n  mutate(ENGLISH_bins = \n           cut(ENGLISH,\n               breaks = c(0,60,75,85,100)))\n\nggbarstats(exam_E,\n           x = ENGLISH_bins,\n           y = GENDER)\n\n\n\n\n\n\n\n\n\n\n\nTo see Science scores by races.\n\n\nShow the code\nexam_S &lt;- exam |&gt;\n  mutate(SCIENCE_bins = \n           cut(SCIENCE,\n               breaks = c(0,60,75,85,100)))\n\nggbarstats(exam_S,\n           x = SCIENCE_bins,\n           y = RACE)\n\n\n\n\n\n\n\n\n\n\n\n\nggbarstats(exam1,\n           x = MATHS_bins,\n           y = GENDER)",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 4-2"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html#visualsing-models",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html#visualsing-models",
    "title": "Hands-on Ex04-2",
    "section": "",
    "text": "Learn how to visualise model diagnostic and model parameters by using parameters package.\n🚙 🚙 🚙 🚙 🚙 Toyota Corolla case study will be used to build a model to discover factor affecting practices of used-cars by taking into consideration of a set of explanatory variables.",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 4-2"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html#installing-and-loading-the-required-libraries",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html#installing-and-loading-the-required-libraries",
    "title": "Hands-on Ex04-2",
    "section": "",
    "text": "pacman::p_load(readxl, performance, parameters, see)\n\n\n\nread_xls() of readxl package is used to import the data worksheet of ToyotaCorolla.xls worksbook into R.\n\n\nread_xls() Usage\nread_excel(\n  path,\n  sheet = NULL,\n  range = NULL,\n  col_names = TRUE,\n  col_types = NULL,\n  na = \"\",\n  trim_ws = TRUE,\n  skip = 0,\n  n_max = Inf,\n  guess_max = min(1000, n_max),\n  progress = readxl_progress(),\n  .name_repair = \"unique\"\n)\n\nread_xls(\n  path,\n  sheet = NULL,\n  range = NULL,\n  col_names = TRUE,\n  col_types = NULL,\n  na = \"\",\n  trim_ws = TRUE,\n  skip = 0,\n  n_max = Inf,\n  guess_max = min(1000, n_max),\n  progress = readxl_progress(),\n  .name_repair = \"unique\"\n)\n\nread_xlsx(\n  path,\n  sheet = NULL,\n  range = NULL,\n  col_names = TRUE,\n  col_types = NULL,\n  na = \"\",\n  trim_ws = TRUE,\n  skip = 0,\n  n_max = Inf,\n  guess_max = min(1000, n_max),\n  progress = readxl_progress(),\n  .name_repair = \"unique\"\n)\n\ncar_resale &lt;- read_xls(\"data/ToyotaCorolla.xls\",\n                       \"data\")\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model    Price Age_08_04 Mfg_Month Mfg_Year     KM Quarterly_Tax Weight\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n 1    81 TOYOTA … 18950        25         8     2002  20019           100   1180\n 2     1 TOYOTA … 13500        23        10     2002  46986           210   1165\n 3     2 TOYOTA … 13750        23        10     2002  72937           210   1165\n 4     3  TOYOTA… 13950        24         9     2002  41711           210   1165\n 5     4 TOYOTA … 14950        26         7     2002  48000           210   1165\n 6     5 TOYOTA … 13750        30         3     2002  38500           210   1170\n 7     6 TOYOTA … 12950        32         1     2002  61000           210   1170\n 8     7  TOYOTA… 16900        27         6     2002  94612           210   1245\n 9     8 TOYOTA … 18600        30         3     2002  75889           210   1245\n10    44 TOYOTA … 16950        27         6     2002 110404           234   1255\n# ℹ 1,426 more rows\n# ℹ 29 more variables: Guarantee_Period &lt;dbl&gt;, HP_Bin &lt;chr&gt;, CC_bin &lt;chr&gt;,\n#   Doors &lt;dbl&gt;, Gears &lt;dbl&gt;, Cylinders &lt;dbl&gt;, Fuel_Type &lt;chr&gt;, Color &lt;chr&gt;,\n#   Met_Color &lt;dbl&gt;, Automatic &lt;dbl&gt;, Mfr_Guarantee &lt;dbl&gt;,\n#   BOVAG_Guarantee &lt;dbl&gt;, ABS &lt;dbl&gt;, Airbag_1 &lt;dbl&gt;, Airbag_2 &lt;dbl&gt;,\n#   Airco &lt;dbl&gt;, Automatic_airco &lt;dbl&gt;, Boardcomputer &lt;dbl&gt;, CD_Player &lt;dbl&gt;,\n#   Central_Lock &lt;dbl&gt;, Powered_Windows &lt;dbl&gt;, Power_Steering &lt;dbl&gt;, …\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe output object car_resale is a tibble data frame.\nTibble is a modern data frame that is similar to data frames in R Programming Language but with some enhancements to make them easier to use and more consistent. Tibble is a part of the tidyverse package in R. Using tibbles we can view and understand the data very easily especially when working with large datasets\n\n\n\n\n\nCode chunk below is used to calibrate a multiple linear regression model by using lm() of Base Stats of R.\n\nmodel &lt;- lm(Price~Age_08_04 + Mfg_Year + KM +\n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n🦄 Can see how the variables affecting price positively or negatively.\n\n\n\nCode below checks for Multicollinearity using check_collinearity() of performance package.\n\n\ncheck_collinearity() Usage\ncheck_collinearity(x, ...)\n\nmulticollinearity(x, ...)\n\n# Default S3 method\ncheck_collinearity(x, ci = 0.95, verbose = TRUE, ...)\n\n# S3 method for class 'glmmTMB'\ncheck_collinearity(\n  x,\n  component = c(\"all\", \"conditional\", \"count\", \"zi\", \"zero_inflated\"),\n  ci = 0.95,\n  verbose = TRUE,\n  ...\n)\n\ncheck_concurvity(x, ...)\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n               KM 1.46 [ 1.37,  1.57]         1.21      0.68     [0.64, 0.73]\n           Weight 1.41 [ 1.32,  1.51]         1.19      0.71     [0.66, 0.76]\n Guarantee_Period 1.04 [ 1.01,  1.17]         1.02      0.97     [0.86, 0.99]\n\nHigh Correlation\n\n      Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n  Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\n\nNext to plot the result:\n\n#install.packages(\"bayestestR\", repos = \"https://easystats.r-universe.dev\")\n#remotes::install_github(\"easystats/see\")\n#install.packages(\"performance\")\nlibrary(performance)\nlibrary(\"bayestestR\")\nlibrary(\"see\")\n\ncheck_c &lt;- check_collinearity(model)\nplot(check_c)\n\n\n\n\n\n\n\n\n\n\n\nChecking normality using check_normality() from the performance package.\n\n\ncheck_normality()usage\ncheck_normality(x, ...)\n\n# S3 method for class 'merMod'\ncheck_normality(x, effects = \n                  c(\"fixed\", \"random\"), ...)\n\n\nShow the code\nmodel1 &lt;- lm(Price ~ Age_08_04 + KM +\n               Weight + Guarantee_Period, \n             data = car_resale)\n\n#check normality\ncheck_n &lt;- check_normality(model1)\n\nplot(check_n)\n\n\n\n\n\n\n\n\n\n\n\n🐠 The Performance workflow\n\n\n\n\n\n\n\n\nCheck model for constant error variance using check_heteroscedasticity() from the performance package.\n\n\ncheck_heteroscedasticity() usage\ncheck_heteroscedasticity(x, ...)\n\ncheck_heteroskedasticity(x, ...)\n\ncheck_h &lt;- check_heteroscedasticity(model1)\n\nplot(check_h)\n\n\n\n\n\n\n\n\n\n\n\nUse check_model() to perform a complete model check.\nVisual check of various model assumptions (normality of residuals, normality of random effects, linear relationship, homogeneity of variance, multicollinearity).\nIf check_model() doesn’t work as expected, try setting verbose = TRUE to get hints about possible problems.\n\n\ncheck_model(x, ...)\n\n# Default S3 method\ncheck_model(\n  x,\n  panel = TRUE,\n  check = \"all\",\n  detrend = TRUE,\n  bandwidth = \"nrd\",\n  type = \"density\",\n  residual_type = NULL,\n  show_dots = NULL,\n  size_dot = 2,\n  size_line = 0.8,\n  size_title = 12,\n  size_axis_title = base_size,\n  base_size = 10,\n  alpha = 0.2,\n  alpha_dot = 0.8,\n  colors = c(\"#3aaf85\", \"#1b6ca8\", \"#cd201f\"),\n  theme = \"see::theme_lucid\",\n  verbose = FALSE,\n  ...\n)\n\n\nShow the code\ncheck_model(model1)\n\n\n\n\n\n\n\n\n\n\n\n\nUse plot() from the see package and parameters() from the parameters package to visualise the parameters of a regression model.\n\nplot(parameters(model1))\n\n\n\n\n\n\n\n\n\n\n\nUse ggcoefstats() from ggstatsplot package to visualise the parameters of a regression model.\n\n\nShow the code\nggcoefstats(model1,\n            output = \"plot\")",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 4-2"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_4.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_4.html",
    "title": "Hands-on_Ex04-4",
    "section": "",
    "text": "Funnel plot is a specially designed data visualisation for unbiased comparison between outlets, stores or business entities. We will learn the following in this chapter:\n\nPlot funnel plots using funnelPlotR package\nPlot static funnel plot with ggplot2 package\nplot interactive funnel plot by using both plotly R and ggplot2 packages\n\n\n\n\nFour R packages will be used in this exercise:\n\nreadr: import csv to R\nFunnerPlotR: create funnel plot\nggplot2: create funner plot manually\nknitr: build static html table\nplotly: create interactive funner plot\n\n\npacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)\n\n\n\n\nWe use a new set of data for this exercise - COVID-19_DKI_Jakarta as of 31st July 2021 from Open Data Covid-19 Provinsi DKI Jakarta portal. In this exercise, we will compare the cumulative COVID-19 cases and death by sub-district (i.e. kelurahan).\nFirst, we import the data into R and save it into a tibble data frame object called covid19.\n\ncovid19 &lt;- read_csv(\"data/COVID-19_DKI_Jakarta.csv\") %&gt;%\n  mutate_if(is.character, as.factor)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSub-district ID\nCity\nDistrict\nSub-district\nPositive\nRecovered\nDeath\n\n\n3172051003\nJAKARTA UTARA\nPADEMANGAN\nANCOL\n1776\n1691\n26\n\n\n3173041007\nJAKARTA BARAT\nTAMBORA\nANGKE\n1783\n1720\n29\n\n\n3175041005\nJAKARTA TIMUR\nKRAMAT JATI\nBALE KAMBANG\n2049\n1964\n31\n\n\n3175031003\nJAKARTA TIMUR\nJATINEGARA\nBALI MESTER\n827\n797\n13\n\n\n3175101006\nJAKARTA TIMUR\nCIPAYUNG\nBAMBU APUS\n2866\n2792\n27\n\n\n3174031002\nJAKARTA SELATAN\nMAMPANG PRAPATAN\nBANGKA\n1828\n1757\n26\n\n\n\n\n\n\nFunnelPlotR package uses ggplot to generate funner plots. It requires numerator (events of interest), denominator (population considered) and group. The key arguments selected for customisation are:\n\n\nFunnelPlotR Installation\ninstall.packages(\"FunnelPlotR\")\n\nlimit: plot limits (95 or 99)\nlabel_outliers: to label outliers (true or false)\nPoisson_limits: to add Poisson limits to the plot\nOD_adjust: to add overdispersed limits to the plot\nxrange and yrange: to specify the range to display for axes, acts like a zoom function\nOther aesthetic components, such as graph title, axis labels etc.\n\n\n\nThe code below plots a funnel plot.\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 1 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n\n\n\n\nThings to learn\n\n\n\n\ngroup in this function is different from the scatterplot. Here is defines the level of the points to be plotted, ie., Sub-district, District or City. If City is chosen, there are only six data points.\nBy default, data_type argument is “SR”.\nlimit: Plot limits, accepted values are 95 or 99, corresponding to 95% or 99.8% quantiles of the distribution.\n\n\n\n\n\n\nAdjust code to make over the previous plot.\n\n\nShow the code\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",\n  xrange = c(0, 6500),\n  yrange = c(0, 0.05)\n)\n\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n\n\n\n\nThings to learn from the code\n\n\n\n\n+data_type argument is used to change from default “SR” to “PR” (i.e., proportions).\n+xrange and yrange are used to set the range of x-axis and y-axis.\n\n\n\n\n\n\nMakeover 2 is to add titles for x axis and y axis.\n\n\nShow the code\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",\n  xrange = c(0, 6500),\n  yrange = c(0, 0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by \\nCumulative Total Number of Postive Cases\",\n  x_label = \"Cumulative COVID-19 Positive Cases\",\n  y_label = \"Cumulative Fatality Rate\",\n  \n)\n\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n\n\n\n\nThings to learn from code\n\n\n\n\nlabel = NA argument is to remove the default label outliers feature.\ntitle argument is used to add plot title.\nx_label and y_label arguments are used to add/edit x-axis and y-axis titles.\n\n\n\n\n\n\n\nIn this exercise, we will build funnel plots step-by-step with ggplot2. This will enhance the skills using ggplot2 to customise specialised data visualisation like Funnel Plot.\n\n\nTo plot the funnel plot from scratch:\n\ndrive cumulative death rate\nstandard error of cumulative death rate\n\n\ndf &lt;- covid19 %&gt;%\n  mutate(rate = Death/Positive) %&gt;%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %&gt;%\n  filter(rate &gt; 0)\n\n\nfit.mean is computed by using the code below:\n\n\nfit.mean &lt;- weighted.mean(df$rate, 1/df$rate.se^2)\n\n\n\n\nNext, we will compute the lower and upper limits for 95% Confidence Interval.\n\n\nShow the code\nnumber.seq &lt;- seq(1, max(df$Positive), 1)\nnumber.ll95 &lt;- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq))\nnumber.ul95 &lt;- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq))\nnumber.ll999 &lt;- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq))\nnumber.ul999 &lt;- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq))\ndfCI &lt;- data.frame(number.ll95, number.ul95, \n                   number.ll999, number.ul999,\n                   number.seq, fit.mean)\n\n\n\n\n\n\n\n\nNote\n\n\n\n95% of the data falls within 1.96 standard deviations of the mean.\n99.9% of the data falls within 3.29 standard deviations of the mean.\n\n\n\n\n\nUse the following code to plot a static funnel plot with ggplot2.\n\n\nShow the code\np &lt;- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label = `Sub-district`),\n             alpha = 0.4) +\n  geom_line(data = dfCI,\n            aes(x = number.seq,\n                y = number.ll95),\n            size = 0.4,\n            colour = \"skyblue\",\n            linetype = \"dashed\") +\n  geom_line(data = dfCI,\n            aes(x = number.seq,\n                y = number.ul95),\n            size = 0.4,\n            colour = \"skyblue\",\n            linetype = \"dashed\") +\n  geom_line(data = dfCI,\n            aes(x = number.seq,\n                y = number.ll999),\n            size = 0.4,\n            colour = \"skyblue\") +\n  geom_line(data = dfCI,\n            aes(x = number.seq,\n                y = number.ul999),\n            size = 0.4,\n            colour = 'skyblue') +\n  geom_hline(data = dfCI,\n             aes(yintercept = fit.mean),\n             size = 0.4,\n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0, 0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") +\n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") +\n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") +\n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size = 12),\n        legend.position = c(0.91, 0.85),\n        legend.title = element_text(size = 7),\n        legend.text = element_text(size = 7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\np\n\n\n\n\n\n\n\n\n\n\n\n\nto make the funnel plot interactive, we can use ggplot2 together with ggplotly() from plotly R package.\n\n\nShow the code\nfp_ggplotly &lt;- ggplotly(p,\n                        tooltip = c(\"label\",\n                                    \"x\",\n                                    \"y\"))\nfp_ggplotly\n\n\n\n\n\n\n\n\n\n\n\nfunnelPlotR package.\nFunnel Plots for Indirectly-standardised ratios.\nChanging funnel plot options\nggplot2 package.",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 4-4"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_4.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_4.html#overview",
    "title": "Hands-on_Ex04-4",
    "section": "",
    "text": "Funnel plot is a specially designed data visualisation for unbiased comparison between outlets, stores or business entities. We will learn the following in this chapter:\n\nPlot funnel plots using funnelPlotR package\nPlot static funnel plot with ggplot2 package\nplot interactive funnel plot by using both plotly R and ggplot2 packages",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 4-4"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_4.html#install-and-launch-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_4.html#install-and-launch-r-packages",
    "title": "Hands-on_Ex04-4",
    "section": "",
    "text": "Four R packages will be used in this exercise:\n\nreadr: import csv to R\nFunnerPlotR: create funnel plot\nggplot2: create funner plot manually\nknitr: build static html table\nplotly: create interactive funner plot\n\n\npacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 4-4"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_4.html#import-data",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_4.html#import-data",
    "title": "Hands-on_Ex04-4",
    "section": "",
    "text": "We use a new set of data for this exercise - COVID-19_DKI_Jakarta as of 31st July 2021 from Open Data Covid-19 Provinsi DKI Jakarta portal. In this exercise, we will compare the cumulative COVID-19 cases and death by sub-district (i.e. kelurahan).\nFirst, we import the data into R and save it into a tibble data frame object called covid19.\n\ncovid19 &lt;- read_csv(\"data/COVID-19_DKI_Jakarta.csv\") %&gt;%\n  mutate_if(is.character, as.factor)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSub-district ID\nCity\nDistrict\nSub-district\nPositive\nRecovered\nDeath\n\n\n3172051003\nJAKARTA UTARA\nPADEMANGAN\nANCOL\n1776\n1691\n26\n\n\n3173041007\nJAKARTA BARAT\nTAMBORA\nANGKE\n1783\n1720\n29\n\n\n3175041005\nJAKARTA TIMUR\nKRAMAT JATI\nBALE KAMBANG\n2049\n1964\n31\n\n\n3175031003\nJAKARTA TIMUR\nJATINEGARA\nBALI MESTER\n827\n797\n13\n\n\n3175101006\nJAKARTA TIMUR\nCIPAYUNG\nBAMBU APUS\n2866\n2792\n27\n\n\n3174031002\nJAKARTA SELATAN\nMAMPANG PRAPATAN\nBANGKA\n1828\n1757\n26",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 4-4"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_4.html#funnelplotr-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_4.html#funnelplotr-methods",
    "title": "Hands-on_Ex04-4",
    "section": "",
    "text": "FunnelPlotR package uses ggplot to generate funner plots. It requires numerator (events of interest), denominator (population considered) and group. The key arguments selected for customisation are:\n\n\nFunnelPlotR Installation\ninstall.packages(\"FunnelPlotR\")\n\nlimit: plot limits (95 or 99)\nlabel_outliers: to label outliers (true or false)\nPoisson_limits: to add Poisson limits to the plot\nOD_adjust: to add overdispersed limits to the plot\nxrange and yrange: to specify the range to display for axes, acts like a zoom function\nOther aesthetic components, such as graph title, axis labels etc.\n\n\n\nThe code below plots a funnel plot.\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 1 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n\n\n\n\nThings to learn\n\n\n\n\ngroup in this function is different from the scatterplot. Here is defines the level of the points to be plotted, ie., Sub-district, District or City. If City is chosen, there are only six data points.\nBy default, data_type argument is “SR”.\nlimit: Plot limits, accepted values are 95 or 99, corresponding to 95% or 99.8% quantiles of the distribution.\n\n\n\n\n\n\nAdjust code to make over the previous plot.\n\n\nShow the code\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",\n  xrange = c(0, 6500),\n  yrange = c(0, 0.05)\n)\n\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n\n\n\n\nThings to learn from the code\n\n\n\n\n+data_type argument is used to change from default “SR” to “PR” (i.e., proportions).\n+xrange and yrange are used to set the range of x-axis and y-axis.\n\n\n\n\n\n\nMakeover 2 is to add titles for x axis and y axis.\n\n\nShow the code\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",\n  xrange = c(0, 6500),\n  yrange = c(0, 0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by \\nCumulative Total Number of Postive Cases\",\n  x_label = \"Cumulative COVID-19 Positive Cases\",\n  y_label = \"Cumulative Fatality Rate\",\n  \n)\n\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n\n\n\n\nThings to learn from code\n\n\n\n\nlabel = NA argument is to remove the default label outliers feature.\ntitle argument is used to add plot title.\nx_label and y_label arguments are used to add/edit x-axis and y-axis titles.",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 4-4"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_4.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_4.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "title": "Hands-on_Ex04-4",
    "section": "",
    "text": "In this exercise, we will build funnel plots step-by-step with ggplot2. This will enhance the skills using ggplot2 to customise specialised data visualisation like Funnel Plot.\n\n\nTo plot the funnel plot from scratch:\n\ndrive cumulative death rate\nstandard error of cumulative death rate\n\n\ndf &lt;- covid19 %&gt;%\n  mutate(rate = Death/Positive) %&gt;%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %&gt;%\n  filter(rate &gt; 0)\n\n\nfit.mean is computed by using the code below:\n\n\nfit.mean &lt;- weighted.mean(df$rate, 1/df$rate.se^2)\n\n\n\n\nNext, we will compute the lower and upper limits for 95% Confidence Interval.\n\n\nShow the code\nnumber.seq &lt;- seq(1, max(df$Positive), 1)\nnumber.ll95 &lt;- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq))\nnumber.ul95 &lt;- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq))\nnumber.ll999 &lt;- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq))\nnumber.ul999 &lt;- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq))\ndfCI &lt;- data.frame(number.ll95, number.ul95, \n                   number.ll999, number.ul999,\n                   number.seq, fit.mean)\n\n\n\n\n\n\n\n\nNote\n\n\n\n95% of the data falls within 1.96 standard deviations of the mean.\n99.9% of the data falls within 3.29 standard deviations of the mean.\n\n\n\n\n\nUse the following code to plot a static funnel plot with ggplot2.\n\n\nShow the code\np &lt;- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label = `Sub-district`),\n             alpha = 0.4) +\n  geom_line(data = dfCI,\n            aes(x = number.seq,\n                y = number.ll95),\n            size = 0.4,\n            colour = \"skyblue\",\n            linetype = \"dashed\") +\n  geom_line(data = dfCI,\n            aes(x = number.seq,\n                y = number.ul95),\n            size = 0.4,\n            colour = \"skyblue\",\n            linetype = \"dashed\") +\n  geom_line(data = dfCI,\n            aes(x = number.seq,\n                y = number.ll999),\n            size = 0.4,\n            colour = \"skyblue\") +\n  geom_line(data = dfCI,\n            aes(x = number.seq,\n                y = number.ul999),\n            size = 0.4,\n            colour = 'skyblue') +\n  geom_hline(data = dfCI,\n             aes(yintercept = fit.mean),\n             size = 0.4,\n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0, 0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") +\n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") +\n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") +\n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size = 12),\n        legend.position = c(0.91, 0.85),\n        legend.title = element_text(size = 7),\n        legend.text = element_text(size = 7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\np\n\n\n\n\n\n\n\n\n\n\n\n\nto make the funnel plot interactive, we can use ggplot2 together with ggplotly() from plotly R package.\n\n\nShow the code\nfp_ggplotly &lt;- ggplotly(p,\n                        tooltip = c(\"label\",\n                                    \"x\",\n                                    \"y\"))\nfp_ggplotly",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 4-4"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_4.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_4.html#references",
    "title": "Hands-on_Ex04-4",
    "section": "",
    "text": "funnelPlotR package.\nFunnel Plots for Indirectly-standardised ratios.\nChanging funnel plot options\nggplot2 package.",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 4-4"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html",
    "title": "Hands-on Ex04-3",
    "section": "",
    "text": "In this chapter, we will do hands-on in creating statistical graphics for visualising uncertainty.\n\nto plot statistics error bars by using ggplot2\nto plot interactive error bars by combining ggplot2, plotly and DT\nto create advanced using ggdist\nto create hypothetical outcome plots (HOPs) with ungeviz package\n\n\n\n\n\n\nThe following R packages will be used for this exercise:\n\ntidyverse: a family of R packages for data science process\nplotly: can create interactive plot\ngganimate: can create animation plot\nDT: can display interactive HTML table\ncrosstalk: to implement cross-widget interactions (currently linked brushing and filtering)\nggdist: to visualise distribution and uncertainty\n\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\n\npacman::p_load(ungeviz, plotly, corsstalk,\n               DT, ggdist, ggridges,\n               colorspace, gganimate, tidyverse)\n\n\n\n\nThe Exam_data.csv dataset will be used for this exercise.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\n\n\nA point estimate is a single number, such as a mean score. Uncertainty, is expressed as standard error, confidence interval, or credible interval. Don’t confuse the uncertainty of a point estimate with the variation in the sample.\nNow, we will plot error bars of MATHS scores by RACE using the data provided in exam tibble data frame.\nCode below will be used to derive the necessary summary statistics:\n\nCodeMathematics\n\n\n\nmy_sum &lt;- exam %&gt;%\n  #group the observation by RACE; group_by() from dplyr package\n  group_by(RACE) %&gt;% \n  \n  #compute the count of observations, mean, standard deviation\n  summarise( \n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n  ) %&gt;%\n  \n  #derive standard error of Maths by RACE\n  mutate(se=sd/sqrt(n-1)) \n\nThe output is saved as a tibble data table called my_sum.\n\n\n\n\n\n\nSummary of code above\n\n\n\n\ngroup_by() from dplyr package is used to group the observation by RACE\nsummarise() is used to compute count of observations, mean, standard deviation\nmutate() is used to derive standard error of MATHS by RACE\n\n\n\n\n\n\n\n\n\n🔑🔑🔑 Next code is used to display my_sum tibble data frame in an HTML table format.\n\nCodeTable\n\n\nknitr:::kable(head(my_sum),\n              format = 'html')\n\n\n\n\n\n\n\nRACE\nn\nmean\nsd\nse\n\n\n\n\nChinese\n193\n76.50777\n15.69040\n1.132357\n\n\nIndian\n12\n60.66667\n23.35237\n7.041005\n\n\nMalay\n108\n57.44444\n21.13478\n2.043177\n\n\nOthers\n9\n69.66667\n10.72381\n3.791438\n\n\n\n\n\n\n\n\n\n\n\n\nNow, plotting the standard error bars for the mean score of MATHS by RACE.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSummary of code above\n\n\n\n\nThe error bars are computed by using the formula mean +/- se\nFor geom_point(), it is important to indicate stat=\"identity\"\n\n\n\n\n\nggplot(my_sum) + \n  geom_errorbar(\n    aes(x = RACE,\n        ymin=mean-se,\n        ymax=mean+se),\n    width = 0.2,\n    colour = \"blue\",\n    alpha = 0.9,\n    size = 0.5\n  ) +\n  geom_point(\n    aes(x = RACE,\n        y = mean),\n    stat = \"identity\",\n    color = \"red\",\n    size = 2.5,\n    alpha = 1\n  ) +\n  ggtitle(\"Standard Error of Mean MATHS Score by RACE\")\n\n\n\n\n\n\nInstead of plotting error bars of point estimates, we can also plot Confidence Intervals of the mean scores of MATHS by RACE.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x = reorder(RACE, -mean),\n        ymin=mean-1.96*se,\n        ymax=mean+1.96*se),\n    width=0.2,\n    colour=\"darkgreen\",\n    alpha=0.9,\n    size=1\n  ) + \n  geom_point(aes(\n    x = RACE,\n    y = mean),\n    stat=\"identity\",\n    color=\"red\",\n    alpha=1,\n    size=5\n    ) +\n  labs(x = \"MATHS score\",\n       title = \"95% Confidence Interval of Mean MATHS Score by RACE\")\n\n\n\n\n\n\nSummary of code\n\n\n\n\nThe Confidence Intervals are computed by using the formula mean +/- 1.96*se\nThe error bars are sorted using the average maths scores\nlabs() argument of ggplot2 is used to change the x-axis label\n\n\n\n\n\n\n\n\n\nTo plot interactive error bars for the 99% Confidence Interval of the mean score for MATHS by RACE.\n\n\nThe primary use for SharedData is to be passed to Crosstalk-compatible widgets in place of a data frame. Each SharedData$new(...) call makes a new “group” of widgets that link to each other, but not to widgets in other groups. You can also use a SharedData object from Shiny code in order to react to filtering and brushing from non-widget visualizations (like ggplot2 plots).\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#install.packages(\"leaflet\")\nlibrary(shiny)\nlibrary(crosstalk)\nlibrary(leaflet)\nlibrary(DT)\n\nshared_df = SharedData$new(my_sum)\n\nbscols(widths = c(4.5,8),\n       ggplotly((ggplot(shared_df) +\n                   geom_errorbar(\n                     aes(x = reorder(RACE, -mean),\n                         ymin = mean-2.58*se,\n                         ymax = mean+2.58*se),\n                     width = 0.2,\n                     colour = \"blue\",\n                     alpha = 0.8,\n                     size = 0.6\n                   ) +\n                   geom_point(\n                     aes(x = RACE,\n                         y = mean,\n                         text = paste(\"Race: \", `RACE`,\n                                      \"&lt;br&gt;N: \", `n`,\n                                      \"&lt;br&gt;Avg. Scores: \", round(mean, digits = 2),\n                                      \"&lt;br&gt;95% CI:[\",\n                                      round((mean-2.58*se), digits = 2), \",\",\n                                      round((mean+2.58*se), digits = 2), \"]\")),\n                        stat = \"identity\",\n                        color = \"pink\",\n                        size = 2.5,\n                        alpha = 1) +\n                   xlab(\"Race\") +\n                   ylab(\"Average Scores\") +\n                   theme_minimal() +\n                   theme(axis.text.x = element_text(\n                     angle = 45, vjust = 0.8, hjust = 1),\n                     plot.title = element_text(size = 8, face = \"bold\")) +\n                   ggtitle(\"99% Confidence Interval of &lt;br&gt;Average MATHS Score by RACE\")),\n                tooltip = \"text\"),\n       DT::datatable(shared_df,\n                     rownames = FALSE,\n                     class = \"compact\",\n                     width = \"150%\",\n                     options = list(pageLength = 10,\n                                    scrollX=T),\n                     colnames = c(\"No. of pupils\",\n                                  \"Avg. scores\",\n                                  \"Std Dev\",\n                                  \"Std Error\")) %&gt;%\n         formatRound(columns = c('mean', 'sd', 'se'),\n                     digits = 2))\n\n\n\n\n\n\n\nggdist for distribution and uncertainty visualisation:\nIt is an R package that provides flexible set of ggplot2 geoms and stats designed for visualising distributions and uncertainty.\nIt can visualise both frequentist and Bayesian uncertainty. Uncertainty visualization can be unified through the perspective of distribution visualization.\n\nFrequentist model: one visualises confidence distribution or bootstrap distributions (see vignette (“freq-uncertainty-vis”) ::: column-margin ## Setup for Frequentist uncertainty visualization\n\n\n\nFrequentist uncertainty visualization Setup\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggdist)\nlibrary(ggplot2)\nlibrary(broom)\nlibrary(distributional)\n\ntheme_set(theme_ggdist())\n\nBayesian model: one visualises probability distributions (see tidyverse package that builds on top of ggdist)\n\n\nVisualisationCheatsheet\n\n\n\n\n\n\n\n\n\n\n\nstat_pointinterval() of ggdist is used in the code below to build a visualisation to display distribution of MATHS scores by RACE.\n\nPlotCode🦖 + arguments\n\n\n\n\n\n\n\n\n\n\n\n\n\nexam %&gt;%\n  ggplot(aes(x= RACE,\n             y = MATHS)) +\n  stat_pointinterval(\n    color = \"skyblue\"\n  ) +\n  labs(\n    title = \"Visualising Confidence Intervals of Mean Scores for MATHS\",\n    subtitle = \"Mean point + multiple-interval plot\"\n  )\n\n\n\n\n\n\nNote\n\n\n\nThis function comes with many arguments. See next tab for example.\n\n\n\n\nAdded the following arguments\n\n.width = 0.95\n.point = median\n.interval = qi\ncolor = red\n\n\n\nShow the code\ntheme_set(theme_bw())\n\nexam %&gt;%\n  ggplot(aes(\n    x = RACE, y = MATHS)) +\n  stat_pointinterval(\n    .width = 0.95,\n    .point = median,\n    .interval = qi,\n    color = \"red\") +\n  labs(title = \"Visualising Confidence Intervals of Median Scores for MATHS by RACE\",\n       subtitle = \"Median point + multiple-interval plot\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nDIY to show 95% and 99% confidence intervals.\n\n\n\n\nShow the code\nexam %&gt;%\nggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(\n    show.legend = FALSE,\n    .width = c(0.95, 0.99),\n    aes(interval_color = stat(level)),\n    point_fill = \"grey\",\n    point_colour = \"grey\",\n    point_size = 5\n  ) +\n  #Define colors of the intervals\n  scale_color_manual(\n    values = c(\"steelblue\", \"pink\"),\n    aesthetics = \"interval_color\"\n  ) +\n  labs(\n    title = \"Visualising Confidence Intervals of Mean Scores for MATHS by RACE\",\n    subtitle = \"Mean point + multiple-interval plot\"\n  ) +\n  theme(\n    panel.background = element_rect(fill = \"transparent\", color = NA),\n    plot.background = element_rect(fill = \"transparent\", color = NA),\n    legend.background = element_rect(fill = \"transparent\", color = NA)\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nstat_gradientinterval() of ggdist is used in the code below to build a visualisation for displaying distribution of MATHS scores by RACE.\n\n\nShow the code\nexam %&gt;%\n  ggplot(\n    aes(x = RACE,\n        y = MATHS)) +\n  stat_gradientinterval(\n    fill = \"skyblue\",\n    show.legend = TRUE\n  ) +\n  labs(\n    title = \"Visualising Confidence Intervals of Mean Score for MATHS by RACE\",\n    subtitle = \"Gradient + interval plot\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n1️⃣ Step 1: Install ungeviz package\ndevtools::install_github(\"wilkelab/ungeviz\")\n2️⃣ Step 2: Launch the application in R\n\nlibrary(ungeviz)\n\n\nMATHS by RACEENGLISH by RACESCIENCE by RACE\n\n\n\n\nShow the code\nggplot(data = exam,\n       aes(x = factor(RACE), y = MATHS)) +\n  geom_point(position = position_jitter(\n    height = 0.3, width = 0.05),\n    size = 0.6, color = \"darkolivegreen\", alpha = 0.6) +\n  geom_hpline(data = sampler(25, group = RACE),\n              height = 0.6, color = \"pink\") +\n  theme_bw() +\n  transition_states(.draw, 1, 3)\n\n\n\n\n\n\n\n\n\nShow the code\n#.draw is a generated column indicating the sample draw.\n\n\n\n\n\n\nShow the code\nggplot(data = exam,\n       aes(x = factor(RACE), y = ENGLISH)) +\n  geom_point(position = position_jitter(\n    height = 0.3, width = 0.05),\n    size = 0.5, color = \"skyblue\", alpha = 0.6) +\n  geom_hpline(data = sampler(25, group = RACE),\n              height = 0.6, color = \"azure4\") +\n  theme_bw() +\n  transition_states(.draw, 1, 3)\n\n\n\n\n\n\n\n\n\nShow the code\n#.draw is a generated column indicating the sample draw.\n\n\n\n\n\n\nShow the code\nggplot(data = exam,\n       aes(x = factor(RACE), y = SCIENCE)) +\n  geom_point(position = position_jitter(\n    height = 0.3, width = 0.05),\n    size = 0.4, color = \"tan1\", alpha = 0.6) +\n  geom_hpline(data = sampler(25, group = RACE),\n              height = 0.6, color = \"pink1\") +\n  theme_bw() +\n  transition_states(.draw, 1, 3)\n\n\n\n\n\n\n\n\n\nShow the code\n#.draw is a generated column indicating the sample draw.\n\n\n\n\n\n\n\n\n\n🔖 Reading resource for HOPs:\nhttps://medium.com/hci-design-at-uw/hypothetical-outcomes-plots-experiencing-the-uncertain-b9ea60d7c740",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 4-3"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html#learning-outcome",
    "title": "Hands-on Ex04-3",
    "section": "",
    "text": "In this chapter, we will do hands-on in creating statistical graphics for visualising uncertainty.\n\nto plot statistics error bars by using ggplot2\nto plot interactive error bars by combining ggplot2, plotly and DT\nto create advanced using ggdist\nto create hypothetical outcome plots (HOPs) with ungeviz package",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 4-3"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html#getting-started",
    "title": "Hands-on Ex04-3",
    "section": "",
    "text": "The following R packages will be used for this exercise:\n\ntidyverse: a family of R packages for data science process\nplotly: can create interactive plot\ngganimate: can create animation plot\nDT: can display interactive HTML table\ncrosstalk: to implement cross-widget interactions (currently linked brushing and filtering)\nggdist: to visualise distribution and uncertainty\n\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\n\npacman::p_load(ungeviz, plotly, corsstalk,\n               DT, ggdist, ggridges,\n               colorspace, gganimate, tidyverse)\n\n\n\n\nThe Exam_data.csv dataset will be used for this exercise.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 4-3"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html#visualising-the-uncertainty-of-point-estimates-ggplot2-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html#visualising-the-uncertainty-of-point-estimates-ggplot2-methods",
    "title": "Hands-on Ex04-3",
    "section": "",
    "text": "A point estimate is a single number, such as a mean score. Uncertainty, is expressed as standard error, confidence interval, or credible interval. Don’t confuse the uncertainty of a point estimate with the variation in the sample.\nNow, we will plot error bars of MATHS scores by RACE using the data provided in exam tibble data frame.\nCode below will be used to derive the necessary summary statistics:\n\nCodeMathematics\n\n\n\nmy_sum &lt;- exam %&gt;%\n  #group the observation by RACE; group_by() from dplyr package\n  group_by(RACE) %&gt;% \n  \n  #compute the count of observations, mean, standard deviation\n  summarise( \n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n  ) %&gt;%\n  \n  #derive standard error of Maths by RACE\n  mutate(se=sd/sqrt(n-1)) \n\nThe output is saved as a tibble data table called my_sum.\n\n\n\n\n\n\nSummary of code above\n\n\n\n\ngroup_by() from dplyr package is used to group the observation by RACE\nsummarise() is used to compute count of observations, mean, standard deviation\nmutate() is used to derive standard error of MATHS by RACE\n\n\n\n\n\n\n\n\n\n🔑🔑🔑 Next code is used to display my_sum tibble data frame in an HTML table format.\n\nCodeTable\n\n\nknitr:::kable(head(my_sum),\n              format = 'html')\n\n\n\n\n\n\n\nRACE\nn\nmean\nsd\nse\n\n\n\n\nChinese\n193\n76.50777\n15.69040\n1.132357\n\n\nIndian\n12\n60.66667\n23.35237\n7.041005\n\n\nMalay\n108\n57.44444\n21.13478\n2.043177\n\n\nOthers\n9\n69.66667\n10.72381\n3.791438\n\n\n\n\n\n\n\n\n\n\n\n\nNow, plotting the standard error bars for the mean score of MATHS by RACE.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSummary of code above\n\n\n\n\nThe error bars are computed by using the formula mean +/- se\nFor geom_point(), it is important to indicate stat=\"identity\"\n\n\n\n\n\nggplot(my_sum) + \n  geom_errorbar(\n    aes(x = RACE,\n        ymin=mean-se,\n        ymax=mean+se),\n    width = 0.2,\n    colour = \"blue\",\n    alpha = 0.9,\n    size = 0.5\n  ) +\n  geom_point(\n    aes(x = RACE,\n        y = mean),\n    stat = \"identity\",\n    color = \"red\",\n    size = 2.5,\n    alpha = 1\n  ) +\n  ggtitle(\"Standard Error of Mean MATHS Score by RACE\")\n\n\n\n\n\n\nInstead of plotting error bars of point estimates, we can also plot Confidence Intervals of the mean scores of MATHS by RACE.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x = reorder(RACE, -mean),\n        ymin=mean-1.96*se,\n        ymax=mean+1.96*se),\n    width=0.2,\n    colour=\"darkgreen\",\n    alpha=0.9,\n    size=1\n  ) + \n  geom_point(aes(\n    x = RACE,\n    y = mean),\n    stat=\"identity\",\n    color=\"red\",\n    alpha=1,\n    size=5\n    ) +\n  labs(x = \"MATHS score\",\n       title = \"95% Confidence Interval of Mean MATHS Score by RACE\")\n\n\n\n\n\n\nSummary of code\n\n\n\n\nThe Confidence Intervals are computed by using the formula mean +/- 1.96*se\nThe error bars are sorted using the average maths scores\nlabs() argument of ggplot2 is used to change the x-axis label\n\n\n\n\n\n\n\n\n\nTo plot interactive error bars for the 99% Confidence Interval of the mean score for MATHS by RACE.\n\n\nThe primary use for SharedData is to be passed to Crosstalk-compatible widgets in place of a data frame. Each SharedData$new(...) call makes a new “group” of widgets that link to each other, but not to widgets in other groups. You can also use a SharedData object from Shiny code in order to react to filtering and brushing from non-widget visualizations (like ggplot2 plots).\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#install.packages(\"leaflet\")\nlibrary(shiny)\nlibrary(crosstalk)\nlibrary(leaflet)\nlibrary(DT)\n\nshared_df = SharedData$new(my_sum)\n\nbscols(widths = c(4.5,8),\n       ggplotly((ggplot(shared_df) +\n                   geom_errorbar(\n                     aes(x = reorder(RACE, -mean),\n                         ymin = mean-2.58*se,\n                         ymax = mean+2.58*se),\n                     width = 0.2,\n                     colour = \"blue\",\n                     alpha = 0.8,\n                     size = 0.6\n                   ) +\n                   geom_point(\n                     aes(x = RACE,\n                         y = mean,\n                         text = paste(\"Race: \", `RACE`,\n                                      \"&lt;br&gt;N: \", `n`,\n                                      \"&lt;br&gt;Avg. Scores: \", round(mean, digits = 2),\n                                      \"&lt;br&gt;95% CI:[\",\n                                      round((mean-2.58*se), digits = 2), \",\",\n                                      round((mean+2.58*se), digits = 2), \"]\")),\n                        stat = \"identity\",\n                        color = \"pink\",\n                        size = 2.5,\n                        alpha = 1) +\n                   xlab(\"Race\") +\n                   ylab(\"Average Scores\") +\n                   theme_minimal() +\n                   theme(axis.text.x = element_text(\n                     angle = 45, vjust = 0.8, hjust = 1),\n                     plot.title = element_text(size = 8, face = \"bold\")) +\n                   ggtitle(\"99% Confidence Interval of &lt;br&gt;Average MATHS Score by RACE\")),\n                tooltip = \"text\"),\n       DT::datatable(shared_df,\n                     rownames = FALSE,\n                     class = \"compact\",\n                     width = \"150%\",\n                     options = list(pageLength = 10,\n                                    scrollX=T),\n                     colnames = c(\"No. of pupils\",\n                                  \"Avg. scores\",\n                                  \"Std Dev\",\n                                  \"Std Error\")) %&gt;%\n         formatRound(columns = c('mean', 'sd', 'se'),\n                     digits = 2))",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 4-3"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html#visualsing-uncertainty-ggdist-package",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html#visualsing-uncertainty-ggdist-package",
    "title": "Hands-on Ex04-3",
    "section": "",
    "text": "ggdist for distribution and uncertainty visualisation:\nIt is an R package that provides flexible set of ggplot2 geoms and stats designed for visualising distributions and uncertainty.\nIt can visualise both frequentist and Bayesian uncertainty. Uncertainty visualization can be unified through the perspective of distribution visualization.\n\nFrequentist model: one visualises confidence distribution or bootstrap distributions (see vignette (“freq-uncertainty-vis”) ::: column-margin ## Setup for Frequentist uncertainty visualization\n\n\n\nFrequentist uncertainty visualization Setup\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggdist)\nlibrary(ggplot2)\nlibrary(broom)\nlibrary(distributional)\n\ntheme_set(theme_ggdist())\n\nBayesian model: one visualises probability distributions (see tidyverse package that builds on top of ggdist)\n\n\nVisualisationCheatsheet\n\n\n\n\n\n\n\n\n\n\n\nstat_pointinterval() of ggdist is used in the code below to build a visualisation to display distribution of MATHS scores by RACE.\n\nPlotCode🦖 + arguments\n\n\n\n\n\n\n\n\n\n\n\n\n\nexam %&gt;%\n  ggplot(aes(x= RACE,\n             y = MATHS)) +\n  stat_pointinterval(\n    color = \"skyblue\"\n  ) +\n  labs(\n    title = \"Visualising Confidence Intervals of Mean Scores for MATHS\",\n    subtitle = \"Mean point + multiple-interval plot\"\n  )\n\n\n\n\n\n\nNote\n\n\n\nThis function comes with many arguments. See next tab for example.\n\n\n\n\nAdded the following arguments\n\n.width = 0.95\n.point = median\n.interval = qi\ncolor = red\n\n\n\nShow the code\ntheme_set(theme_bw())\n\nexam %&gt;%\n  ggplot(aes(\n    x = RACE, y = MATHS)) +\n  stat_pointinterval(\n    .width = 0.95,\n    .point = median,\n    .interval = qi,\n    color = \"red\") +\n  labs(title = \"Visualising Confidence Intervals of Median Scores for MATHS by RACE\",\n       subtitle = \"Median point + multiple-interval plot\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nDIY to show 95% and 99% confidence intervals.\n\n\n\n\nShow the code\nexam %&gt;%\nggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(\n    show.legend = FALSE,\n    .width = c(0.95, 0.99),\n    aes(interval_color = stat(level)),\n    point_fill = \"grey\",\n    point_colour = \"grey\",\n    point_size = 5\n  ) +\n  #Define colors of the intervals\n  scale_color_manual(\n    values = c(\"steelblue\", \"pink\"),\n    aesthetics = \"interval_color\"\n  ) +\n  labs(\n    title = \"Visualising Confidence Intervals of Mean Scores for MATHS by RACE\",\n    subtitle = \"Mean point + multiple-interval plot\"\n  ) +\n  theme(\n    panel.background = element_rect(fill = \"transparent\", color = NA),\n    plot.background = element_rect(fill = \"transparent\", color = NA),\n    legend.background = element_rect(fill = \"transparent\", color = NA)\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nstat_gradientinterval() of ggdist is used in the code below to build a visualisation for displaying distribution of MATHS scores by RACE.\n\n\nShow the code\nexam %&gt;%\n  ggplot(\n    aes(x = RACE,\n        y = MATHS)) +\n  stat_gradientinterval(\n    fill = \"skyblue\",\n    show.legend = TRUE\n  ) +\n  labs(\n    title = \"Visualising Confidence Intervals of Mean Score for MATHS by RACE\",\n    subtitle = \"Gradient + interval plot\"\n  )",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 4-3"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops",
    "title": "Hands-on Ex04-3",
    "section": "",
    "text": "1️⃣ Step 1: Install ungeviz package\ndevtools::install_github(\"wilkelab/ungeviz\")\n2️⃣ Step 2: Launch the application in R\n\nlibrary(ungeviz)\n\n\nMATHS by RACEENGLISH by RACESCIENCE by RACE\n\n\n\n\nShow the code\nggplot(data = exam,\n       aes(x = factor(RACE), y = MATHS)) +\n  geom_point(position = position_jitter(\n    height = 0.3, width = 0.05),\n    size = 0.6, color = \"darkolivegreen\", alpha = 0.6) +\n  geom_hpline(data = sampler(25, group = RACE),\n              height = 0.6, color = \"pink\") +\n  theme_bw() +\n  transition_states(.draw, 1, 3)\n\n\n\n\n\n\n\n\n\nShow the code\n#.draw is a generated column indicating the sample draw.\n\n\n\n\n\n\nShow the code\nggplot(data = exam,\n       aes(x = factor(RACE), y = ENGLISH)) +\n  geom_point(position = position_jitter(\n    height = 0.3, width = 0.05),\n    size = 0.5, color = \"skyblue\", alpha = 0.6) +\n  geom_hpline(data = sampler(25, group = RACE),\n              height = 0.6, color = \"azure4\") +\n  theme_bw() +\n  transition_states(.draw, 1, 3)\n\n\n\n\n\n\n\n\n\nShow the code\n#.draw is a generated column indicating the sample draw.\n\n\n\n\n\n\nShow the code\nggplot(data = exam,\n       aes(x = factor(RACE), y = SCIENCE)) +\n  geom_point(position = position_jitter(\n    height = 0.3, width = 0.05),\n    size = 0.4, color = \"tan1\", alpha = 0.6) +\n  geom_hpline(data = sampler(25, group = RACE),\n              height = 0.6, color = \"pink1\") +\n  theme_bw() +\n  transition_states(.draw, 1, 3)\n\n\n\n\n\n\n\n\n\nShow the code\n#.draw is a generated column indicating the sample draw.\n\n\n\n\n\n\n\n\n\n🔖 Reading resource for HOPs:\nhttps://medium.com/hci-design-at-uw/hypothetical-outcomes-plots-experiencing-the-uncertain-b9ea60d7c740",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 4-3"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html",
    "title": "Hands-on Ex04-1",
    "section": "",
    "text": "Visualising distribution is not new in statistical analysis. In Session 1, there are some of the popular statustistical graphics methods for visualising distribution, such as histogram, probability density curve (pdf), boxplot, notch plot and violin plot, and how they can be created using ggplot2.\nIn this session, we will learn two relatively new statistical graphic methods for visualisaing distribution, namely ridgeline plot and raincloud plot using ggplot2 and its extensions.\n\n\n\n\n\nThe following R packages will be used for this exercise.\n\nggridges: a ggplot2 extension specially designed for plotting ridgeline plots\nggdist: a ggplot2 extension specially designed for visualising distribution and uncertainty.\ntidyverse: a family of R packages to meet the modern data science and visual communication needs\nggthemes: a ggplot extension that provides the user additional themes, scales, and geoms for the ggplots package.\ncolorspace: a R pckage provides a broad toolbox for selecting individual colours or colour palettes, manipulating these colours, and employing them in various kinds of visualisations.\n\nThe code chunk below will be used loading these R pakcages into RStudio environment.\n\npacman::p_load(ggdist, ggridges, ggthemes, colorspace, tidyverse)\n\n\n\n\nFor the purpose of this exercise, Exam_data.csv will be used.\nIn the code chunk below, read_csv() of readr package is used to import Exam_data.csv into R and saved it into a tibble data.frame.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\n\n\nRidgeline plot (sometimes called Joyplot) is a data visualisation technique for revealing the distribution of a numeric value for several groups. Distribution can be represented using histograms or density plots, all aligned to the same horizontal scale and presented with a slight overlap.\n\n\n🦄 WHAT FOR\n\nRidgeline plots make sense when the number of group to represent is medium to high, and thus a classic window separation would take to much space. Indeed, the fact that groups overlap each other allows to use space more efficiently. If you have less than ~6 groups, dealing with other distribution plots is probably better.\nIt works well when there is a clear pattern in the result, like if there is an obvious ranking in groups. Otherwise group will tend to overlap each other, leading to a messy plot not providing any insight.\n\nFigure below is a ridgelines plot showing the distribution of English scores by class.\n\n\nShow the code\nggplot(exam,\n       aes(x = ENGLISH,\n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 2.5,\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0,0),\n  ) +\n  scale_y_discrete(name = \"Class\", expand = expansion(add=c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\nThere are several ways to plot ridgeline plot with R. In this section, we will learn how to plot ridgeline plot by using ggridges package.\nggridges package provides two main geom to plot ridgeline plots. They are:\ngrom_ridgeline() and geom_density_ridges(). The former takes height values directly to draw the ridgelines, and the latter first estimates data densities and then draws those using ridgelines.\nThe ridgeline plot below is plotted by using geom_density_ridges().\n\n🦖 PracticeExample plot\n\n\n🦖 Changed colour fill, opacity, no grid lines and scale.\n\n\nShow the code\nggplot(exam,\n       aes(x = ENGLISH,\n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 5,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    fill = lighten(\"pink\", 0.5),\n    color = \"#7097BB\"\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0,0),\n  ) +\n  scale_y_discrete(name = \"Class\", expand = expansion(add=c(0.2, 2.6))) +\n  theme_ridges(grid = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(exam,\n       aes(x = ENGLISH,\n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    fill = lighten(\"#7097BB\", .3),\n    color = \"white\"\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0,0),\n  ) +\n  scale_y_discrete(name = NULL, expand = expansion(add=c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSometimes we would like to have the area under a ridgeline not filled with a single solid colour but rather with colours that vary in some form along the x axis. This effect can be achieved by using either geom_ridgeline_gradient() or geom_density_ridges_gradient().\nBoth geoms work just like geom_ridgeline() and geom_density_ridges()\n\n🦖 PracticeExample plot\n\n\n🦖 Applied a different filling colour scheme.\n\n\nShow the code\nggplot(exam,\n       aes(x = ENGLISH,\n           y = CLASS,\n           fill = stat(x))) +\n  geom_density_ridges_gradient(\n    scale = 3,\n    rel_min_height = 0.01) +\n  scale_fill_viridis_c(name = \"Temp. [F]\",\n                       option = \"G\") +\n  scale_x_continuous(name = \"English grades\",\n                     expand = c(0,0)\n  ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n    theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(exam,\n       aes(x = ENGLISH,\n           y = CLASS,\n           fill = stat(x))) +\n  geom_density_ridges_gradient(\n    scale = 3,\n    rel_min_height = 0.01) +\n  scale_fill_viridis_c(name = \"Temp. [F]\",\n                       option = \"C\") +\n  scale_x_continuous(name = \"English grades\",\n                     expand = c(0,0)\n  ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n    theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBesides providing additional geom objects to support the need to plot ridgeline plot, ggridges package also provides a stat function called stat_density_ridges() that replaces stat_density() of ggplot2.\nFigure below is plotted by mapping the probabilities calculated by using stat(ecdf) which represent the empirical cumulative density function for the distribution of English score.\n\nPracticeExample plot\n\n\nUsed scale_fill_viridis_b to replace scale_fill_viridis_c, and changed theme colour.\n❓ Need discrete data to use scale_fill_viridis_d ? &gt; see next example!\n\n\nShow the code\nggplot(exam,\n       aes(x = ENGLISH, y = CLASS,\n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom=\"density_ridges_gradient\",\n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_b(name = \"Tail probability\",\n                       option = \"B\",\n                       direction = -1) +\n  theme_ridges() \n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(exam,\n       aes(x = ENGLISH, y = CLASS,\n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom=\"density_ridges_gradient\",\n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1) +\n  theme_ridges() \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIt is important to include the argument calc_ecdf = TRUE in stat_density_ridges().\n\n\n\n\n\nBy using geom_density_ridges_gradient(), we can colour the ridgeline plot by quantile, via the calculated stat(quantile) aesthetic as shown in the figure below.\n\n🦖 PracticeExample Plot\n\n\n🦖 Changed theme colours\n\n\nShow the code\nggplot(exam,\n       aes(x = ENGLISH,\n           y = CLASS,\n           fill = factor(stat(quantile)))) +\n  stat_density_ridges(\n    geom = \"Density_ridges_gradient\",\n    calc_ecdf = TRUE,\n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quantiles\",\n                       option = \"B\") +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(exam,\n       aes(x = ENGLISH,\n           y = CLASS,\n           fill = factor(stat(quantile)))) +\n  stat_density_ridges(\n    geom = \"Density_ridges_gradient\",\n    calc_ecdf = TRUE,\n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quantiles\") +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\n\nInstead of using number to define the quantiles, we can also specify quantiles by cutting points such as 2.5% and 97.5% tails to colour the ridgeline plot, shown in figure below.\n\n📝 alpha in scale_fill_manual()\n\n🦖 PracticeExample Plot\n\n\n🦖。Changed colours fill.\n\n\nShow the code\nggplot(exam,\n       aes(x = ENGLISH,\n           y = CLASS,\n           fill = factor(stat(quantile)))) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE,\n    quantiles = c(0.025, 0.975)\n  ) +\n  scale_fill_manual(\n    name = \"Probability\",\n    values = alpha(c(\"#E76F51\", \"#FCEDA0\", \"#6AA68B\"), 0.5),\n    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\")\n  ) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(exam,\n       aes(x = ENGLISH,\n           y = CLASS,\n           fill = factor(stat(quantile)))) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE,\n    quantiles = c(0.025, 0.975)\n  ) +\n  scale_fill_manual(\n    name = \"Probability\",\n    values = c(\"#FF0000A0\", \"#A0A0A0A0\", \"#0000FFA0\"),\n    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\")\n  ) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRaincloud Plot is a data visualisation techniques that produces a half-density to a distribution plot. It gets the name because the density plot is in the shape of a “raincloud”. The raincloud (half-density) plot enhances the traditional boxplot by highlighting multiple modalities (an indicator that groups may exist). The boxplot does not show where densities are clustered, but the raincloud plot does!\nIn this section, we will learn how to create a raincloud plot to visualise the distribution of English score by race. It will be created by using functions provided by ggdist and ggplot2 packages.\n\n\nFirst, we will plot a Half-Eye graph by using stat_halfeye() of ggdist package.\nThis produces a Half Eye visualisation, which contains a half-density and a slab-interval.\n\n🦖 PracticeExample Plot\n\n\n🦖 With slab interval; changed color for the slab & interval, points.\n\n\nShow the code\nggplot(exam,\n       aes(x = RACE,\n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               slab_color = \"black\",\n               slab_fill = \"pink\",\n               slab_linetype = \"dashed\",\n               slab_linewidth = 0.3,\n               slab_alpha = 0.6,\n               interval_colour = \"skyblue\",\n               point_fill = \"yellow\",\n               point_colour = \"red\",\n               point_size = 2\n) \n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(exam,\n       aes(x = RACE,\n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from code above\n\n\n\nWe remove the slab interval by setting .width = 0 and point_colour = NA.\n\n\n\n\n\n\n\n\nNext, we will add the second geometry layer using geom_boxplot() of ggplot2. This produces a narrow boxplot. We reduce the width and adjust the opacity.\n\n🦖 PracticeExample Plot\n\n\n🦖 Changed slab colour, fill, linetype to dotline, slab alpha, and added color to the boxplot. Outliers are shown as well.\n\n\nShow the code\nggplot(exam,\n       aes(x = RACE,\n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               slab_color = \"black\",\n               slab_fill = \"pink\",\n               slab_linetype = \"dashed\",\n               slab_linewidth = 0.3,\n               slab_alpha = 0.4,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = 0.2,\n               col = \"steelblue\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(exam,\n       aes(x = RACE,\n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = 0.2,\n               outlier.shape = NA)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNext, we will add the third geometry layer using stat_dots() of ggdist package. This produces a half-dotplot, which is similar to a histogram that indicates the number of samples (number of dots) in each bin. We select side = \"left\" to indicate we want it on the left-hand side.\n\nPracticeExample Plot\n\n\n🦖 Changed stat_dots color by CLASS\n\n\nShow the code\nggplot(exam,\n       aes(x = RACE,\n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               slab_color = \"black\",\n               slab_fill = \"grey\",\n               slab_linetype = \"dashed\",\n               slab_linewidth = 0.3,\n               slab_alpha = 0.4,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = 0.2,\n               col = \"grey\",\n               outlier.shape = NA) +\n  stat_dots(side = \"left\",\n            justification = 1.2,\n            binwidth = .5,\n            dotsize = 2,\n            aes(color = CLASS))\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(exam,\n       aes(x = RACE,\n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = 0.2,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\",\n            justification = 1.2,\n            binwidth = .5,\n            dotsize = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLastly, coord_flit() of ggplot2 package will be used to flip the raincloud chart horizontally to give it the raincloud appearance. At the same time, theme_economist() of ggthemes package is used to give the raincloud chart a professional publishing standard look.\n\nPracticeExample Plot\n\n\nUsed a different theme theme_stata() and changed colours for the slab and dots.\n\n\nShow the code\nggplot(exam,\n       aes(x = RACE,\n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               slab_color = \"grey\",\n               slab_fill = \"#D6DED5\",\n               slab_linetype = \"solid\",\n               slab_linewidth = 0.4,\n               slab_alpha = 0.5,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = 0.2,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\",\n            justification = 1.2,\n            binwidth = .5,\n            dotsize = 1.2,\n            aes(color = CLASS)) +\n              \n  coord_flip() +\n  theme_stata()\n\n\n\n\n\n\n\n\n\n🕵️ Notice the there are fewer dots when using colours to display CLASS.\n\n\nShow the code\nggplot(exam,\n       aes(x = RACE,\n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = 0.2,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\",\n            justification = 1.2,\n            binwidth = .5,\n            dotsize = 1.2) +\n  coord_flip() +\n  theme_stata()\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(exam,\n       aes(x = RACE,\n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = 0.2,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\",\n            justification = 1.2,\n            binwidth = .5,\n            dotsize = 1.5) +\n  coord_flip() +\n  theme_economist()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroducing Ridgeline Plots (formerly Joyplots)\n🎯 Claus O. Wilke Fundamentals of Data Visualization especially Chapter 6, 7, 8, 9 and 10.\nAllen M, Poggiali D, Whitaker K et al. “Raincloud plots: a multi-platform tool for robust data. visualization” [version 2; peer review: 2 approved]. Welcome Open Res 2021, pp. 4:63.\nDots + interval stats and geoms\nAdditional reference: Cedric Scherer Data Visualization & Info Disign [slides]",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 4-1"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#learning-outcome",
    "title": "Hands-on Ex04-1",
    "section": "",
    "text": "Visualising distribution is not new in statistical analysis. In Session 1, there are some of the popular statustistical graphics methods for visualising distribution, such as histogram, probability density curve (pdf), boxplot, notch plot and violin plot, and how they can be created using ggplot2.\nIn this session, we will learn two relatively new statistical graphic methods for visualisaing distribution, namely ridgeline plot and raincloud plot using ggplot2 and its extensions.",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 4-1"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#getting-started",
    "title": "Hands-on Ex04-1",
    "section": "",
    "text": "The following R packages will be used for this exercise.\n\nggridges: a ggplot2 extension specially designed for plotting ridgeline plots\nggdist: a ggplot2 extension specially designed for visualising distribution and uncertainty.\ntidyverse: a family of R packages to meet the modern data science and visual communication needs\nggthemes: a ggplot extension that provides the user additional themes, scales, and geoms for the ggplots package.\ncolorspace: a R pckage provides a broad toolbox for selecting individual colours or colour palettes, manipulating these colours, and employing them in various kinds of visualisations.\n\nThe code chunk below will be used loading these R pakcages into RStudio environment.\n\npacman::p_load(ggdist, ggridges, ggthemes, colorspace, tidyverse)\n\n\n\n\nFor the purpose of this exercise, Exam_data.csv will be used.\nIn the code chunk below, read_csv() of readr package is used to import Exam_data.csv into R and saved it into a tibble data.frame.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 4-1"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#visualising-distribution-with-ridgeline-plot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#visualising-distribution-with-ridgeline-plot",
    "title": "Hands-on Ex04-1",
    "section": "",
    "text": "Ridgeline plot (sometimes called Joyplot) is a data visualisation technique for revealing the distribution of a numeric value for several groups. Distribution can be represented using histograms or density plots, all aligned to the same horizontal scale and presented with a slight overlap.\n\n\n🦄 WHAT FOR\n\nRidgeline plots make sense when the number of group to represent is medium to high, and thus a classic window separation would take to much space. Indeed, the fact that groups overlap each other allows to use space more efficiently. If you have less than ~6 groups, dealing with other distribution plots is probably better.\nIt works well when there is a clear pattern in the result, like if there is an obvious ranking in groups. Otherwise group will tend to overlap each other, leading to a messy plot not providing any insight.\n\nFigure below is a ridgelines plot showing the distribution of English scores by class.\n\n\nShow the code\nggplot(exam,\n       aes(x = ENGLISH,\n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 2.5,\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0,0),\n  ) +\n  scale_y_discrete(name = \"Class\", expand = expansion(add=c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\nThere are several ways to plot ridgeline plot with R. In this section, we will learn how to plot ridgeline plot by using ggridges package.\nggridges package provides two main geom to plot ridgeline plots. They are:\ngrom_ridgeline() and geom_density_ridges(). The former takes height values directly to draw the ridgelines, and the latter first estimates data densities and then draws those using ridgelines.\nThe ridgeline plot below is plotted by using geom_density_ridges().\n\n🦖 PracticeExample plot\n\n\n🦖 Changed colour fill, opacity, no grid lines and scale.\n\n\nShow the code\nggplot(exam,\n       aes(x = ENGLISH,\n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 5,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    fill = lighten(\"pink\", 0.5),\n    color = \"#7097BB\"\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0,0),\n  ) +\n  scale_y_discrete(name = \"Class\", expand = expansion(add=c(0.2, 2.6))) +\n  theme_ridges(grid = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(exam,\n       aes(x = ENGLISH,\n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    fill = lighten(\"#7097BB\", .3),\n    color = \"white\"\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0,0),\n  ) +\n  scale_y_discrete(name = NULL, expand = expansion(add=c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSometimes we would like to have the area under a ridgeline not filled with a single solid colour but rather with colours that vary in some form along the x axis. This effect can be achieved by using either geom_ridgeline_gradient() or geom_density_ridges_gradient().\nBoth geoms work just like geom_ridgeline() and geom_density_ridges()\n\n🦖 PracticeExample plot\n\n\n🦖 Applied a different filling colour scheme.\n\n\nShow the code\nggplot(exam,\n       aes(x = ENGLISH,\n           y = CLASS,\n           fill = stat(x))) +\n  geom_density_ridges_gradient(\n    scale = 3,\n    rel_min_height = 0.01) +\n  scale_fill_viridis_c(name = \"Temp. [F]\",\n                       option = \"G\") +\n  scale_x_continuous(name = \"English grades\",\n                     expand = c(0,0)\n  ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n    theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(exam,\n       aes(x = ENGLISH,\n           y = CLASS,\n           fill = stat(x))) +\n  geom_density_ridges_gradient(\n    scale = 3,\n    rel_min_height = 0.01) +\n  scale_fill_viridis_c(name = \"Temp. [F]\",\n                       option = \"C\") +\n  scale_x_continuous(name = \"English grades\",\n                     expand = c(0,0)\n  ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n    theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBesides providing additional geom objects to support the need to plot ridgeline plot, ggridges package also provides a stat function called stat_density_ridges() that replaces stat_density() of ggplot2.\nFigure below is plotted by mapping the probabilities calculated by using stat(ecdf) which represent the empirical cumulative density function for the distribution of English score.\n\nPracticeExample plot\n\n\nUsed scale_fill_viridis_b to replace scale_fill_viridis_c, and changed theme colour.\n❓ Need discrete data to use scale_fill_viridis_d ? &gt; see next example!\n\n\nShow the code\nggplot(exam,\n       aes(x = ENGLISH, y = CLASS,\n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom=\"density_ridges_gradient\",\n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_b(name = \"Tail probability\",\n                       option = \"B\",\n                       direction = -1) +\n  theme_ridges() \n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(exam,\n       aes(x = ENGLISH, y = CLASS,\n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom=\"density_ridges_gradient\",\n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1) +\n  theme_ridges() \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIt is important to include the argument calc_ecdf = TRUE in stat_density_ridges().\n\n\n\n\n\nBy using geom_density_ridges_gradient(), we can colour the ridgeline plot by quantile, via the calculated stat(quantile) aesthetic as shown in the figure below.\n\n🦖 PracticeExample Plot\n\n\n🦖 Changed theme colours\n\n\nShow the code\nggplot(exam,\n       aes(x = ENGLISH,\n           y = CLASS,\n           fill = factor(stat(quantile)))) +\n  stat_density_ridges(\n    geom = \"Density_ridges_gradient\",\n    calc_ecdf = TRUE,\n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quantiles\",\n                       option = \"B\") +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(exam,\n       aes(x = ENGLISH,\n           y = CLASS,\n           fill = factor(stat(quantile)))) +\n  stat_density_ridges(\n    geom = \"Density_ridges_gradient\",\n    calc_ecdf = TRUE,\n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quantiles\") +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\n\nInstead of using number to define the quantiles, we can also specify quantiles by cutting points such as 2.5% and 97.5% tails to colour the ridgeline plot, shown in figure below.\n\n📝 alpha in scale_fill_manual()\n\n🦖 PracticeExample Plot\n\n\n🦖。Changed colours fill.\n\n\nShow the code\nggplot(exam,\n       aes(x = ENGLISH,\n           y = CLASS,\n           fill = factor(stat(quantile)))) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE,\n    quantiles = c(0.025, 0.975)\n  ) +\n  scale_fill_manual(\n    name = \"Probability\",\n    values = alpha(c(\"#E76F51\", \"#FCEDA0\", \"#6AA68B\"), 0.5),\n    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\")\n  ) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(exam,\n       aes(x = ENGLISH,\n           y = CLASS,\n           fill = factor(stat(quantile)))) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE,\n    quantiles = c(0.025, 0.975)\n  ) +\n  scale_fill_manual(\n    name = \"Probability\",\n    values = c(\"#FF0000A0\", \"#A0A0A0A0\", \"#0000FFA0\"),\n    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\")\n  ) +\n  theme_ridges()",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 4-1"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#visualsing-distribution-with-raincloud-plot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#visualsing-distribution-with-raincloud-plot",
    "title": "Hands-on Ex04-1",
    "section": "",
    "text": "Raincloud Plot is a data visualisation techniques that produces a half-density to a distribution plot. It gets the name because the density plot is in the shape of a “raincloud”. The raincloud (half-density) plot enhances the traditional boxplot by highlighting multiple modalities (an indicator that groups may exist). The boxplot does not show where densities are clustered, but the raincloud plot does!\nIn this section, we will learn how to create a raincloud plot to visualise the distribution of English score by race. It will be created by using functions provided by ggdist and ggplot2 packages.\n\n\nFirst, we will plot a Half-Eye graph by using stat_halfeye() of ggdist package.\nThis produces a Half Eye visualisation, which contains a half-density and a slab-interval.\n\n🦖 PracticeExample Plot\n\n\n🦖 With slab interval; changed color for the slab & interval, points.\n\n\nShow the code\nggplot(exam,\n       aes(x = RACE,\n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               slab_color = \"black\",\n               slab_fill = \"pink\",\n               slab_linetype = \"dashed\",\n               slab_linewidth = 0.3,\n               slab_alpha = 0.6,\n               interval_colour = \"skyblue\",\n               point_fill = \"yellow\",\n               point_colour = \"red\",\n               point_size = 2\n) \n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(exam,\n       aes(x = RACE,\n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from code above\n\n\n\nWe remove the slab interval by setting .width = 0 and point_colour = NA.\n\n\n\n\n\n\n\n\nNext, we will add the second geometry layer using geom_boxplot() of ggplot2. This produces a narrow boxplot. We reduce the width and adjust the opacity.\n\n🦖 PracticeExample Plot\n\n\n🦖 Changed slab colour, fill, linetype to dotline, slab alpha, and added color to the boxplot. Outliers are shown as well.\n\n\nShow the code\nggplot(exam,\n       aes(x = RACE,\n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               slab_color = \"black\",\n               slab_fill = \"pink\",\n               slab_linetype = \"dashed\",\n               slab_linewidth = 0.3,\n               slab_alpha = 0.4,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = 0.2,\n               col = \"steelblue\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(exam,\n       aes(x = RACE,\n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = 0.2,\n               outlier.shape = NA)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNext, we will add the third geometry layer using stat_dots() of ggdist package. This produces a half-dotplot, which is similar to a histogram that indicates the number of samples (number of dots) in each bin. We select side = \"left\" to indicate we want it on the left-hand side.\n\nPracticeExample Plot\n\n\n🦖 Changed stat_dots color by CLASS\n\n\nShow the code\nggplot(exam,\n       aes(x = RACE,\n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               slab_color = \"black\",\n               slab_fill = \"grey\",\n               slab_linetype = \"dashed\",\n               slab_linewidth = 0.3,\n               slab_alpha = 0.4,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = 0.2,\n               col = \"grey\",\n               outlier.shape = NA) +\n  stat_dots(side = \"left\",\n            justification = 1.2,\n            binwidth = .5,\n            dotsize = 2,\n            aes(color = CLASS))\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(exam,\n       aes(x = RACE,\n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = 0.2,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\",\n            justification = 1.2,\n            binwidth = .5,\n            dotsize = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLastly, coord_flit() of ggplot2 package will be used to flip the raincloud chart horizontally to give it the raincloud appearance. At the same time, theme_economist() of ggthemes package is used to give the raincloud chart a professional publishing standard look.\n\nPracticeExample Plot\n\n\nUsed a different theme theme_stata() and changed colours for the slab and dots.\n\n\nShow the code\nggplot(exam,\n       aes(x = RACE,\n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               slab_color = \"grey\",\n               slab_fill = \"#D6DED5\",\n               slab_linetype = \"solid\",\n               slab_linewidth = 0.4,\n               slab_alpha = 0.5,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = 0.2,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\",\n            justification = 1.2,\n            binwidth = .5,\n            dotsize = 1.2,\n            aes(color = CLASS)) +\n              \n  coord_flip() +\n  theme_stata()\n\n\n\n\n\n\n\n\n\n🕵️ Notice the there are fewer dots when using colours to display CLASS.\n\n\nShow the code\nggplot(exam,\n       aes(x = RACE,\n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = 0.2,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\",\n            justification = 1.2,\n            binwidth = .5,\n            dotsize = 1.2) +\n  coord_flip() +\n  theme_stata()\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(exam,\n       aes(x = RACE,\n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = 0.2,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\",\n            justification = 1.2,\n            binwidth = .5,\n            dotsize = 1.5) +\n  coord_flip() +\n  theme_economist()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroducing Ridgeline Plots (formerly Joyplots)\n🎯 Claus O. Wilke Fundamentals of Data Visualization especially Chapter 6, 7, 8, 9 and 10.\nAllen M, Poggiali D, Whitaker K et al. “Raincloud plots: a multi-platform tool for robust data. visualization” [version 2; peer review: 2 approved]. Welcome Open Res 2021, pp. 4:63.\nDots + interval stats and geoms\nAdditional reference: Cedric Scherer Data Visualization & Info Disign [slides]",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 4-1"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html",
    "title": "Hands-on_Ex03_2",
    "section": "",
    "text": "When telling a visually-driven data story, animated graphics tends to attract the interest of the audience and make deeper impression than static graphics. In this hands-on exercise, I will create animated data visualisation with gganimate and plotly r packages. At the same time, I will learn how to 1/ reshape data by using tidyr package, and 2/ process, wrangle and transform datawith dplyr package.\n\n\nWhen creating animations, the plot does not actually move. Instead, many individual plots are built and then stitched together as movie frames - like an old-school flip book or cartoon. Each frame is a different plot when conveying motion, which is built using some relevant subset of the aggregated data.The subset drives the flow of the animation when stitched back together.\n\n\n\n\n\n\n\n\nBefore diving into the steps for creating an animated statistical graph, it’s important to understand some of the key concepts and terminology related to this type of visualisation.\n\nFrame: In an animated line graph, each frame represents a different point in time or a different category. When the frame changes, the data points on the graph are updated to reflect the new data.\nAnimation attributes: The animation attributes are the settings that control how the animation behaves. For example, you can specify the duration of each frame, the easing function used to transition between frames, and whether to start the animation from the current frame or from the beginning.\n\n\n\n\n\n\n\nTip\n\n\n\nBefore starting making animated graphs, think of the question first:\nDoes it make sense to go through the effort?\nIf you are conducting an exploratory data analysis, an animated graphic may not be worth the time investment. However, if you are giving a presentation, a few well-placed animated graphics can help an audience connect with your topic remarkably better than static counterparts.\n\n\n\n\n\n\n\n\nFirst, write a code chunk to check, install and load the following R packages:\n\nplotly: R library for plotting interactive statistical graphs.\ngganimate: a ggplot extension for creating animated statistical graphs.\ngifski: converts video frames to GIF animations using pngquant’s fancy features for efficient cross-frame palettes and temporal dithering. It produces animated GIFs that use thousands of colors per frame.\ngapminer: an excerpt of the data available at Gapminder.org. We just want to use its country_colors scheme.\ntidyverse: a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\n\n\npacman::p_load(readxl, gifski, gapminder,\n               plotly, gganimate, tidyverse)\n\n\n\n\nIn this hands-on exercise, the Data worksheet from GlobalPopulation Excel workbook will be used.\nWrite a code chunk to import Data worksheet from GlobalPopulation Excel workbook by using appropriate R package from tidyverse family.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      shee=\"Data\") %&gt;%\n  mutate_each_(funs(factor(.)), col) %&gt;%\n  mutate(Year = as.integer(Year))\n\n\n\n\n\n\n\nNote\n\n\n\n\nread_xls of readxl package is used to import the Excel worksheet.\nmutate_each_() of dplyr package is used to convert all character data type into factor.\nmutate of dplyr package is used to convert data values of Year field into integer.\n\n\n\nUnfortunately, mutate_each_() was deprecated in dplyr 0.7.0 and funs() was deprecated in dplyr 0.8.0. In view of this, we will re-write the code by using mutate_at() show in the code chunk below.\n\n\n❓ mutate_at() links back to the same page in textbook?\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet = \"Data\") %&gt;%\n  mutate_at(col, as.factor) %&gt;%\n  mutate(Year = as.integer(Year))\nInstead of using mutate_at(), across() can be used to derive the same outputs.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet = \"Data\") %&gt;%\n  mutate(across(col, as.factor)) %&gt;%\n  mutate(Year = as.integer(Year))\n\n\n\n\n\ngganimate extends the grammar of graphics as implemented by ggplot2 to include the description of animation. It does this by providing a range of new grammar classes that can be added to the plot object in order to customise how it should change with time.\n\ntransition_*() defines how the data should be spread out and how it relates to itself across time.\nview_*() defines how to positional scales should change along the animation.\nshadow_*() defines how data from other points in time should be presented in the given point in time.\nenter_*()/exit_*() defines how new data should appear and how old data should disappear during the course of animation.\nease_aes() defines how different aesthetics should be eased during transitions.\n\n\n\nIn the code chunk below, the basic ggplot2 functions are used to create a static bubble plot.\n\nggplot(globalPop, aes(x = Old, y = Young,\n                      size = Population,\n                      colour = Country)) +\n  geom_point(alpha = 0.7,\n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2,12)) +\n  labs(title = 'Year: {frame_time}',\n       x = '% Aged',\n       y = '% Young') \n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, - transition_time() of gganimate is used to create transition through distinct states in time (i.e. Year) - ease_aes() is used to control easing of aesthetics. The default is linear. Other methods are: quadratic, cubic, quartic, quintic, sine, circular, exponential, elastic, back, and bounce.\n\n🦖 PracticeOriginal\n\n\n🦖 Different theme and title, ease_aes\n\nggplot(globalPop, aes(x = Old, y = Young,\n                      size = Population,\n                      colour = Country)) +\n  geom_point(alpha = 0.7,\n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'The animated bubble chart | Year: {frame_time}',\n       x = '% Aged',\n       y = '% Young') +\n  transition_time(Year) +\n  ease_aes('cubic-in-out') +\n  theme_dark()\n\n\n\n\n\n\n\n\n\n\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') +\n  transition_time(Year) +       \n  ease_aes('linear')          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn Plotly R package, both ggplotly() and plot_ly support key frame animations through the frame argument/aesthetic. They also support an ids argument/aesthetic to ensure smooth transitions between objects with the same ID (which helps facilitate object constancy).\n\n\nIn this sub-section, we will learn how to create an animated bubble plot by using ggplotly() method.\n\n🦖 PracticePlotCode\n\n\n🦖 Used theme_bw()\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young') +\n  theme_bw()\n\nggplotly(gg)\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe animated bubble plot above includes a play/pause button and a slider component for controlling the animation.\n\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young')\n\nggplotly(gg)\n\n\n\nNotice that although show.legend=FALSE argument was used, the legend still appears on the plot.\nTo overcome this problem, `theme(legend.position=‘none’) should be used.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young') + \n  theme(legend.position='none')\n\nggplotly(gg)\n\n\n\n\n\n\nIn this sub-section, we will learn how to create an animated bubble plot with plot_ly() method.\n\n🦖 PracticePlotCode\n\n\n🦖 Adjusted bubble sizes\n\nbp2 &lt;- globalPop %&gt;%\n  plot_ly(x = ~Old,\n          y = ~ Young,\n          size = ~Population,\n          color = ~Continent,\n          sizes = c(2,500),\n          frame = ~Year,\n          text = ~Country,\n          hoverinfo = \"text\",\n          type = 'scatter',\n          mode = 'markers'\n          ) %&gt;%\n  layout(showlegend = FALSE)\n\nbp2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbp &lt;- globalPop %&gt;%\n  plot_ly(x = ~Old,\n          y = ~ Young,\n          size = ~Population,\n          color = ~Continent,\n          sizes = c(2,100),\n          frame = ~Year,\n          text = ~Country,\n          hoverinfo = \"text\",\n          type = 'scatter',\n          mode = 'markers'\n          ) %&gt;%\n  layout(showlegend = FALSE)\nbp\n\n\n\n\n\n\n\n\nGetting Started\nVisit this link for a very interesting implementation of gganimate by a senior\n\nBuilding an animation step-by-step with gganimate\n\nCreating a composite gif with multiple gganimate panels\n\n\n\n\n📝 Used Tableau to design a prototype, then implemented with gganimate.\n\n🎯 Try to use the methods to implement an animation.",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 3-2"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#overview",
    "title": "Hands-on_Ex03_2",
    "section": "",
    "text": "When telling a visually-driven data story, animated graphics tends to attract the interest of the audience and make deeper impression than static graphics. In this hands-on exercise, I will create animated data visualisation with gganimate and plotly r packages. At the same time, I will learn how to 1/ reshape data by using tidyr package, and 2/ process, wrangle and transform datawith dplyr package.\n\n\nWhen creating animations, the plot does not actually move. Instead, many individual plots are built and then stitched together as movie frames - like an old-school flip book or cartoon. Each frame is a different plot when conveying motion, which is built using some relevant subset of the aggregated data.The subset drives the flow of the animation when stitched back together.\n\n\n\n\n\n\n\n\nBefore diving into the steps for creating an animated statistical graph, it’s important to understand some of the key concepts and terminology related to this type of visualisation.\n\nFrame: In an animated line graph, each frame represents a different point in time or a different category. When the frame changes, the data points on the graph are updated to reflect the new data.\nAnimation attributes: The animation attributes are the settings that control how the animation behaves. For example, you can specify the duration of each frame, the easing function used to transition between frames, and whether to start the animation from the current frame or from the beginning.\n\n\n\n\n\n\n\nTip\n\n\n\nBefore starting making animated graphs, think of the question first:\nDoes it make sense to go through the effort?\nIf you are conducting an exploratory data analysis, an animated graphic may not be worth the time investment. However, if you are giving a presentation, a few well-placed animated graphics can help an audience connect with your topic remarkably better than static counterparts.",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 3-2"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#getting-started",
    "title": "Hands-on_Ex03_2",
    "section": "",
    "text": "First, write a code chunk to check, install and load the following R packages:\n\nplotly: R library for plotting interactive statistical graphs.\ngganimate: a ggplot extension for creating animated statistical graphs.\ngifski: converts video frames to GIF animations using pngquant’s fancy features for efficient cross-frame palettes and temporal dithering. It produces animated GIFs that use thousands of colors per frame.\ngapminer: an excerpt of the data available at Gapminder.org. We just want to use its country_colors scheme.\ntidyverse: a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\n\n\npacman::p_load(readxl, gifski, gapminder,\n               plotly, gganimate, tidyverse)\n\n\n\n\nIn this hands-on exercise, the Data worksheet from GlobalPopulation Excel workbook will be used.\nWrite a code chunk to import Data worksheet from GlobalPopulation Excel workbook by using appropriate R package from tidyverse family.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      shee=\"Data\") %&gt;%\n  mutate_each_(funs(factor(.)), col) %&gt;%\n  mutate(Year = as.integer(Year))\n\n\n\n\n\n\n\nNote\n\n\n\n\nread_xls of readxl package is used to import the Excel worksheet.\nmutate_each_() of dplyr package is used to convert all character data type into factor.\nmutate of dplyr package is used to convert data values of Year field into integer.\n\n\n\nUnfortunately, mutate_each_() was deprecated in dplyr 0.7.0 and funs() was deprecated in dplyr 0.8.0. In view of this, we will re-write the code by using mutate_at() show in the code chunk below.\n\n\n❓ mutate_at() links back to the same page in textbook?\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet = \"Data\") %&gt;%\n  mutate_at(col, as.factor) %&gt;%\n  mutate(Year = as.integer(Year))\nInstead of using mutate_at(), across() can be used to derive the same outputs.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet = \"Data\") %&gt;%\n  mutate(across(col, as.factor)) %&gt;%\n  mutate(Year = as.integer(Year))",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 3-2"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#animated-data-visualisation-gganimate-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#animated-data-visualisation-gganimate-methods",
    "title": "Hands-on_Ex03_2",
    "section": "",
    "text": "gganimate extends the grammar of graphics as implemented by ggplot2 to include the description of animation. It does this by providing a range of new grammar classes that can be added to the plot object in order to customise how it should change with time.\n\ntransition_*() defines how the data should be spread out and how it relates to itself across time.\nview_*() defines how to positional scales should change along the animation.\nshadow_*() defines how data from other points in time should be presented in the given point in time.\nenter_*()/exit_*() defines how new data should appear and how old data should disappear during the course of animation.\nease_aes() defines how different aesthetics should be eased during transitions.\n\n\n\nIn the code chunk below, the basic ggplot2 functions are used to create a static bubble plot.\n\nggplot(globalPop, aes(x = Old, y = Young,\n                      size = Population,\n                      colour = Country)) +\n  geom_point(alpha = 0.7,\n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2,12)) +\n  labs(title = 'Year: {frame_time}',\n       x = '% Aged',\n       y = '% Young') \n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, - transition_time() of gganimate is used to create transition through distinct states in time (i.e. Year) - ease_aes() is used to control easing of aesthetics. The default is linear. Other methods are: quadratic, cubic, quartic, quintic, sine, circular, exponential, elastic, back, and bounce.\n\n🦖 PracticeOriginal\n\n\n🦖 Different theme and title, ease_aes\n\nggplot(globalPop, aes(x = Old, y = Young,\n                      size = Population,\n                      colour = Country)) +\n  geom_point(alpha = 0.7,\n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'The animated bubble chart | Year: {frame_time}',\n       x = '% Aged',\n       y = '% Young') +\n  transition_time(Year) +\n  ease_aes('cubic-in-out') +\n  theme_dark()\n\n\n\n\n\n\n\n\n\n\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') +\n  transition_time(Year) +       \n  ease_aes('linear')",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 3-2"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#animated-data-visualisation-plotly",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#animated-data-visualisation-plotly",
    "title": "Hands-on_Ex03_2",
    "section": "",
    "text": "In Plotly R package, both ggplotly() and plot_ly support key frame animations through the frame argument/aesthetic. They also support an ids argument/aesthetic to ensure smooth transitions between objects with the same ID (which helps facilitate object constancy).\n\n\nIn this sub-section, we will learn how to create an animated bubble plot by using ggplotly() method.\n\n🦖 PracticePlotCode\n\n\n🦖 Used theme_bw()\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young') +\n  theme_bw()\n\nggplotly(gg)\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe animated bubble plot above includes a play/pause button and a slider component for controlling the animation.\n\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young')\n\nggplotly(gg)\n\n\n\nNotice that although show.legend=FALSE argument was used, the legend still appears on the plot.\nTo overcome this problem, `theme(legend.position=‘none’) should be used.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young') + \n  theme(legend.position='none')\n\nggplotly(gg)\n\n\n\n\n\n\nIn this sub-section, we will learn how to create an animated bubble plot with plot_ly() method.\n\n🦖 PracticePlotCode\n\n\n🦖 Adjusted bubble sizes\n\nbp2 &lt;- globalPop %&gt;%\n  plot_ly(x = ~Old,\n          y = ~ Young,\n          size = ~Population,\n          color = ~Continent,\n          sizes = c(2,500),\n          frame = ~Year,\n          text = ~Country,\n          hoverinfo = \"text\",\n          type = 'scatter',\n          mode = 'markers'\n          ) %&gt;%\n  layout(showlegend = FALSE)\n\nbp2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbp &lt;- globalPop %&gt;%\n  plot_ly(x = ~Old,\n          y = ~ Young,\n          size = ~Population,\n          color = ~Continent,\n          sizes = c(2,100),\n          frame = ~Year,\n          text = ~Country,\n          hoverinfo = \"text\",\n          type = 'scatter',\n          mode = 'markers'\n          ) %&gt;%\n  layout(showlegend = FALSE)\nbp",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 3-2"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#reference",
    "title": "Hands-on_Ex03_2",
    "section": "",
    "text": "Getting Started\nVisit this link for a very interesting implementation of gganimate by a senior\n\nBuilding an animation step-by-step with gganimate\n\nCreating a composite gif with multiple gganimate panels\n\n\n\n\n📝 Used Tableau to design a prototype, then implemented with gganimate.\n\n🎯 Try to use the methods to implement an animation.",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 3-2"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_5.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_5.html",
    "title": "Hands-on_Ex05-5",
    "section": "",
    "text": "A Treemap displays hierarchical data as a set of nested rectangles. Each group is represented by a rectangle, which area is proportional to its value. Using color schemes and or interactivity, it is possible to represent several dimensions: groups, subgroups etc.\nWe will learn using selected functions provided in dplyr package, how to plot static treemap by using treemap package and design interactive treemap by using d3treeR package.\n\n\n\nCheck if treemap and tidyverse pacakges have been installed in R.\n\npacman::p_load(treemap, treemapify, tidyverse) \n\n\n\n\n\nImport datasetData wrangling\n\n\nread_csv() of readr is used to import realis2018.csv into R and parsed it into tibble R data.frame format. The output tibble data.frame is called realis2018.\n\nrealis2018 &lt;- read_csv(\"data/realis2018.csv\")\n\n\n\nThe data.frame realis2018 is in trasaction record form, which is highly disaggregated and not appropriate to be used to plot a treemap. We will do the following the prepare a data frame for treemap visualisation.\n\ngroup transaction records by Project Name, Planning Region, Planning Area, Property Type and Type of Sale, and\ncompute Total Unit Sold, Total Area, Median Unit Price and Median Transacted Price by applying appropriate summary statistics on No. of Units, Area (sqm), Unit Price ($ psm) and Transacted Price ($) respectively.\n\ngroup_by() and summarize() will be used to perform these steps.\nGrouped summaries without the Pipe\n\nrealis2018_grouped &lt;- group_by(realis2018, `Project Name`,\n                               `Planning Region`, `Planning Area`, \n                               `Property Type`, `Type of Sale`)\nrealis2018_summarised &lt;- summarise(realis2018_grouped, \n                          `Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE),\n                          `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n                          `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE), \n                          `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))\n\n\nAggregation functions such as sum() and median() obey the usual rule of missing values: if there’s any missing value in the input, the output will be a missing value. The argument na.rm = TRUE removes the missing values prior to computation.\nThe code chunk above is not very efficient because we have to give each intermediate data.frame a name, even though we don’t have to care about it.\n\nGrouped summaries with the pipe %&gt;%\nThe code chunk below shows a more efficient way to tackle the same processes by using the pipe, %&gt;%.\n\nrealis2018_summarised &lt;- realis2018 %&gt;% \n  group_by(`Project Name`,`Planning Region`, \n           `Planning Area`, `Property Type`, \n           `Type of Sale`) %&gt;%\n  summarise(`Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE), \n            `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n            `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE),\n            `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))\n\n\n\n\n\n\nGrouping affects the verbs as follows\n\n\n\ngrouped select() is the same as ungrouped select(), except that grouping variables are always retained.\ngrouped arrange() is the same as ungrouped; unless you set .by_group = TRUE, in which case it orders first by the grouping variables.\nmutate() and filter() are most useful in conjunction with window functions (like rank(), or min(x) == x). They are described in detail in vignette(“window-functions”).\nsample_n() and sample_frac() sample the specified number/fraction of rows in each group.\nsummarise() computes the summary for each group.\n\nResource: - dplyr - Pipes %&gt;%\n\n\n\n\n\ntreemap() offers at least 43 arguments. In this section, we will only explore the major arguments for designing elegent and yet truthful treemaps.\n\n\ntreemap() of Treemap package is used to plot a treemap showing the distribution of median unit prices and total unit sold of resale condominium by geographic hierarchy in 2017.\nFirst, we will select records belongs to resale condominium property type from realis2018_selected data frame.\n\nrealis2018_selected &lt;- realis2018_summarised %&gt;%\n  filter(`Property Type` == \"Condominium\", `Type of Sale` == \"Resale\")\n\n\n\n\nUse three core arguments of treemap(), namely: index, vSize and vColor to design a basic treemap.\n\n\nShow the code\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\nLearning\n\n\n\nindex\n\nThe index vector must consist of at least two column names or else no hierarchy treemap will be plotted.\nIf multiple column names are provided, such as the code chunk above, the first name is the highest aggregation level, the second name the second highest aggregation level, and so on.\n\nvSize\nThe column must not contain negative values, because its values will be used to map the sizes of the rectangles of the treemaps.\n\nWarning\nThe treemap above was wrongly coloured. For a correctly designed treemap, the colours of the rectagles should be in different intensity showing, in our case, median unit prices.\nFor treemap(), vColor is used in combination with the argument type to determine the colours of the rectangles. Without defining type, like the code chunk above, treemap() assumes type = index, in our case, the hierarchy of planning areas.\n\n\n\n\n\nIn the code below, type argument is defined as “value”.\n\n\nShow the code\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type = \"value\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\nLearning from the code\n\n\n\nThe rectangles are coloured with different intensity of green, reflecting their respective median unit prices.\nThe legend reveals that the values are binned into ten bins, i.e. 0-5,000, 5,000-10,000, etc. with an equal interval of 5,000.\n\n\n\n\n\n\nThere are two arguments that determine the mapping to color palettes: mapping and palette.\nThe only difference between “value” and “manual” is the default value for mapping.\nThe “value” treemap considers palette to be a diverging color palette (say ColorBrewer’s “RdYlBu”), and maps it in such a way that: - 0 corresponds to the middle color (typically white or yellow) - -max(abs(values)) to the left-end color - max(abs(values)) to the right-end color.\nThe “manual” treemap simply maps - min(values) to the left-end color - max(values) to the right-end color - mean(range(values)) to the middle color.\n\n“value” type“manual” type\n\n\n\n\nShow the code\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\nLearning from the code\n\n\n\nAlthough the colour palette used is RdYlBu but there are no red rectangles in the treemap above. This is because all the median unit prices are positive.\nThe reason why we see only 5000 to 45000 in the legend is because the range argument is by default c(min(values, max(values)) with some pretty rounding.\n\n\n\n\n\nThe “manual” type does not interpret the values as the “value” type does. Instead, the value range is mapped linearly to the colour palette.\n\n\nShow the code\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\nLearning from the code\n\n\nThe colour scheme used is very copnfusing. This is because mapping = (min(values), mean(range(values)), max(values)).\nIt is not wise to use diverging colour palette such as RdYlBu if the values are all positive or negative ::: goals-container\nTo overcome this, a single color palette should be used, such as Blues.\n\n\n\n\nShow the code\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nreemap() supports two popular treemap layouts, namely: squarified and pivotSize. The default is pivotSize.\nThe squarified treemap algorithm (Bruls et al., 2000) produces good aspect ratios, but ignores the sorting order of the rectangles (sortID). The ordered treemap, pivot-by-size, algorithm (Bederson et al., 2002) takes the sorting order (sortID) into account while aspect ratios are still acceptable.\n\nalgorithm argumentsortID\n\n\nThe code below plots a squarified treemap by changing the algorithm argument.\n\n\nShow the code\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"squarified\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\nWhen “pivotSize” algorithm is used, sortID argument can be used to dertemine the order in which the rectangles are placed from top left to bottom right.\n\n\nShow the code\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"pivotSize\",\n        sortID = \"Median Transacted Price\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntreemapify is a R package specially developed to draw treemaps in ggplot2. We will learn how to design treemps closely resembling treemaps from previous section by using treemapify.\nResources: - Introduction to “treemapify” - user guide.\n\n\n\n\nShow the code\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`),\n       layout = \"scol\",\n       start = \"bottomleft\") + \n  geom_treemap() +\n  scale_fill_gradient(low = \"light blue\", high = \"blue\") +\n  theme(\n      plot.title = element_text(hjust=0, family = \"Bold\"),\n      plot.background = element_rect(fill = \"#f1f4f5\", color = \"#f1f4f5\"),\n      legend.background = element_rect(fill=\"#f1f4f5\"),\n      panel.background = element_rect(fill=\"#f1f4f5\"))   \n\n\n\n\n\n\n\n\n\n\n\n\n\nGrouped by Planning Region.Grouped by Planning AreaAdd boundary line\n\n\n\n\nShow the code\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`),\n       start = \"topleft\") + \n  geom_treemap() +\n  theme(\n      plot.title = element_text(hjust=0, family = \"Bold\"),\n      plot.background = element_rect(fill = \"#f1f4f5\", color = \"#f1f4f5\"),\n      legend.background = element_rect(fill=\"#f1f4f5\"),\n      panel.background = element_rect(fill=\"#f1f4f5\")) \n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) +  #added as subgroup2\n  geom_treemap()\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap() +\n  geom_treemap_subgroup2_border(colour = \"pink\", #add lines\n                                size = 2) +\n  geom_treemap_subgroup_border(colour = \"#BB993E\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStep 1. Install devtool package\ninstall.packages(\"devtools\")\nStep 2. Load devtool library and install the package found in GitHub.\n\nlibrary(devtools)\ninstall_github(\"timelyportfolio/d3treeR\")\nforce = TRUE\n\nStep 3. Launch d3treeR package\n\nlibrary(d3treeR)\n\n\n\n\n\n\nStep 1. treemap() is used to build a treemap by using selected variables in condominium data.frame. The treemap created is save as object called tm.\n\n\nShow the code\ntm &lt;- treemap(realis2018_summarised,\n        index=c(\"Planning Region\", \"Planning Area\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        title=\"Private Residential Property Sold, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\n\n\nd3tree(tm,rootname = \"Singapore\")\n\n\n\n\n\n\n\n\n\n\n\nR for Visual Analytics",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 5-5"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_5.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_5.html#overview",
    "title": "Hands-on_Ex05-5",
    "section": "",
    "text": "A Treemap displays hierarchical data as a set of nested rectangles. Each group is represented by a rectangle, which area is proportional to its value. Using color schemes and or interactivity, it is possible to represent several dimensions: groups, subgroups etc.\nWe will learn using selected functions provided in dplyr package, how to plot static treemap by using treemap package and design interactive treemap by using d3treeR package.",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 5-5"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_5.html#install-and-launch-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_5.html#install-and-launch-r-packages",
    "title": "Hands-on_Ex05-5",
    "section": "",
    "text": "Check if treemap and tidyverse pacakges have been installed in R.\n\npacman::p_load(treemap, treemapify, tidyverse)",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 5-5"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_5.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_5.html#data-preparation",
    "title": "Hands-on_Ex05-5",
    "section": "",
    "text": "Import datasetData wrangling\n\n\nread_csv() of readr is used to import realis2018.csv into R and parsed it into tibble R data.frame format. The output tibble data.frame is called realis2018.\n\nrealis2018 &lt;- read_csv(\"data/realis2018.csv\")\n\n\n\nThe data.frame realis2018 is in trasaction record form, which is highly disaggregated and not appropriate to be used to plot a treemap. We will do the following the prepare a data frame for treemap visualisation.\n\ngroup transaction records by Project Name, Planning Region, Planning Area, Property Type and Type of Sale, and\ncompute Total Unit Sold, Total Area, Median Unit Price and Median Transacted Price by applying appropriate summary statistics on No. of Units, Area (sqm), Unit Price ($ psm) and Transacted Price ($) respectively.\n\ngroup_by() and summarize() will be used to perform these steps.\nGrouped summaries without the Pipe\n\nrealis2018_grouped &lt;- group_by(realis2018, `Project Name`,\n                               `Planning Region`, `Planning Area`, \n                               `Property Type`, `Type of Sale`)\nrealis2018_summarised &lt;- summarise(realis2018_grouped, \n                          `Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE),\n                          `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n                          `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE), \n                          `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))\n\n\nAggregation functions such as sum() and median() obey the usual rule of missing values: if there’s any missing value in the input, the output will be a missing value. The argument na.rm = TRUE removes the missing values prior to computation.\nThe code chunk above is not very efficient because we have to give each intermediate data.frame a name, even though we don’t have to care about it.\n\nGrouped summaries with the pipe %&gt;%\nThe code chunk below shows a more efficient way to tackle the same processes by using the pipe, %&gt;%.\n\nrealis2018_summarised &lt;- realis2018 %&gt;% \n  group_by(`Project Name`,`Planning Region`, \n           `Planning Area`, `Property Type`, \n           `Type of Sale`) %&gt;%\n  summarise(`Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE), \n            `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n            `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE),\n            `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))\n\n\n\n\n\n\nGrouping affects the verbs as follows\n\n\n\ngrouped select() is the same as ungrouped select(), except that grouping variables are always retained.\ngrouped arrange() is the same as ungrouped; unless you set .by_group = TRUE, in which case it orders first by the grouping variables.\nmutate() and filter() are most useful in conjunction with window functions (like rank(), or min(x) == x). They are described in detail in vignette(“window-functions”).\nsample_n() and sample_frac() sample the specified number/fraction of rows in each group.\nsummarise() computes the summary for each group.\n\nResource: - dplyr - Pipes %&gt;%",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 5-5"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_5.html#design-treemap-with-treemap-package",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_5.html#design-treemap-with-treemap-package",
    "title": "Hands-on_Ex05-5",
    "section": "",
    "text": "treemap() offers at least 43 arguments. In this section, we will only explore the major arguments for designing elegent and yet truthful treemaps.\n\n\ntreemap() of Treemap package is used to plot a treemap showing the distribution of median unit prices and total unit sold of resale condominium by geographic hierarchy in 2017.\nFirst, we will select records belongs to resale condominium property type from realis2018_selected data frame.\n\nrealis2018_selected &lt;- realis2018_summarised %&gt;%\n  filter(`Property Type` == \"Condominium\", `Type of Sale` == \"Resale\")\n\n\n\n\nUse three core arguments of treemap(), namely: index, vSize and vColor to design a basic treemap.\n\n\nShow the code\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\nLearning\n\n\n\nindex\n\nThe index vector must consist of at least two column names or else no hierarchy treemap will be plotted.\nIf multiple column names are provided, such as the code chunk above, the first name is the highest aggregation level, the second name the second highest aggregation level, and so on.\n\nvSize\nThe column must not contain negative values, because its values will be used to map the sizes of the rectangles of the treemaps.\n\nWarning\nThe treemap above was wrongly coloured. For a correctly designed treemap, the colours of the rectagles should be in different intensity showing, in our case, median unit prices.\nFor treemap(), vColor is used in combination with the argument type to determine the colours of the rectangles. Without defining type, like the code chunk above, treemap() assumes type = index, in our case, the hierarchy of planning areas.\n\n\n\n\n\nIn the code below, type argument is defined as “value”.\n\n\nShow the code\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type = \"value\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\nLearning from the code\n\n\n\nThe rectangles are coloured with different intensity of green, reflecting their respective median unit prices.\nThe legend reveals that the values are binned into ten bins, i.e. 0-5,000, 5,000-10,000, etc. with an equal interval of 5,000.\n\n\n\n\n\n\nThere are two arguments that determine the mapping to color palettes: mapping and palette.\nThe only difference between “value” and “manual” is the default value for mapping.\nThe “value” treemap considers palette to be a diverging color palette (say ColorBrewer’s “RdYlBu”), and maps it in such a way that: - 0 corresponds to the middle color (typically white or yellow) - -max(abs(values)) to the left-end color - max(abs(values)) to the right-end color.\nThe “manual” treemap simply maps - min(values) to the left-end color - max(values) to the right-end color - mean(range(values)) to the middle color.\n\n“value” type“manual” type\n\n\n\n\nShow the code\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\nLearning from the code\n\n\n\nAlthough the colour palette used is RdYlBu but there are no red rectangles in the treemap above. This is because all the median unit prices are positive.\nThe reason why we see only 5000 to 45000 in the legend is because the range argument is by default c(min(values, max(values)) with some pretty rounding.\n\n\n\n\n\nThe “manual” type does not interpret the values as the “value” type does. Instead, the value range is mapped linearly to the colour palette.\n\n\nShow the code\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\nLearning from the code\n\n\nThe colour scheme used is very copnfusing. This is because mapping = (min(values), mean(range(values)), max(values)).\nIt is not wise to use diverging colour palette such as RdYlBu if the values are all positive or negative ::: goals-container\nTo overcome this, a single color palette should be used, such as Blues.\n\n\n\n\nShow the code\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 5-5"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_5.html#treemap-layout",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_5.html#treemap-layout",
    "title": "Hands-on_Ex05-5",
    "section": "",
    "text": "reemap() supports two popular treemap layouts, namely: squarified and pivotSize. The default is pivotSize.\nThe squarified treemap algorithm (Bruls et al., 2000) produces good aspect ratios, but ignores the sorting order of the rectangles (sortID). The ordered treemap, pivot-by-size, algorithm (Bederson et al., 2002) takes the sorting order (sortID) into account while aspect ratios are still acceptable.\n\nalgorithm argumentsortID\n\n\nThe code below plots a squarified treemap by changing the algorithm argument.\n\n\nShow the code\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"squarified\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\nWhen “pivotSize” algorithm is used, sortID argument can be used to dertemine the order in which the rectangles are placed from top left to bottom right.\n\n\nShow the code\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"pivotSize\",\n        sortID = \"Median Transacted Price\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 5-5"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_5.html#design-treemap-using-treemapify-package",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_5.html#design-treemap-using-treemapify-package",
    "title": "Hands-on_Ex05-5",
    "section": "",
    "text": "treemapify is a R package specially developed to draw treemaps in ggplot2. We will learn how to design treemps closely resembling treemaps from previous section by using treemapify.\nResources: - Introduction to “treemapify” - user guide.\n\n\n\n\nShow the code\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`),\n       layout = \"scol\",\n       start = \"bottomleft\") + \n  geom_treemap() +\n  scale_fill_gradient(low = \"light blue\", high = \"blue\") +\n  theme(\n      plot.title = element_text(hjust=0, family = \"Bold\"),\n      plot.background = element_rect(fill = \"#f1f4f5\", color = \"#f1f4f5\"),\n      legend.background = element_rect(fill=\"#f1f4f5\"),\n      panel.background = element_rect(fill=\"#f1f4f5\"))   \n\n\n\n\n\n\n\n\n\n\n\n\n\nGrouped by Planning Region.Grouped by Planning AreaAdd boundary line\n\n\n\n\nShow the code\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`),\n       start = \"topleft\") + \n  geom_treemap() +\n  theme(\n      plot.title = element_text(hjust=0, family = \"Bold\"),\n      plot.background = element_rect(fill = \"#f1f4f5\", color = \"#f1f4f5\"),\n      legend.background = element_rect(fill=\"#f1f4f5\"),\n      panel.background = element_rect(fill=\"#f1f4f5\")) \n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) +  #added as subgroup2\n  geom_treemap()\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap() +\n  geom_treemap_subgroup2_border(colour = \"pink\", #add lines\n                                size = 2) +\n  geom_treemap_subgroup_border(colour = \"#BB993E\")",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 5-5"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_5.html#design-interactive-treemap-using-d3treer",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_5.html#design-interactive-treemap-using-d3treer",
    "title": "Hands-on_Ex05-5",
    "section": "",
    "text": "Step 1. Install devtool package\ninstall.packages(\"devtools\")\nStep 2. Load devtool library and install the package found in GitHub.\n\nlibrary(devtools)\ninstall_github(\"timelyportfolio/d3treeR\")\nforce = TRUE\n\nStep 3. Launch d3treeR package\n\nlibrary(d3treeR)\n\n\n\n\n\n\nStep 1. treemap() is used to build a treemap by using selected variables in condominium data.frame. The treemap created is save as object called tm.\n\n\nShow the code\ntm &lt;- treemap(realis2018_summarised,\n        index=c(\"Planning Region\", \"Planning Area\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        title=\"Private Residential Property Sold, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\n\n\nd3tree(tm,rootname = \"Singapore\")",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 5-5"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_5.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_5.html#reference",
    "title": "Hands-on_Ex05-5",
    "section": "",
    "text": "R for Visual Analytics",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 5-5"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_1.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_1.html",
    "title": "Hands-on_Ex05-1",
    "section": "",
    "text": "Ternary plots are a way of displaying the distribution and variability of three-part compositional data. (For example, the proportion of aged, economy active and young population or sand, silt, and clay in soil.)\nThe display is a triangle with sides scaled from 0 to 1. Each side represents one of the three components. A point is plotted so that a line drawn perpendicular from the point to each leg of the triangle intersect at the component values of the point.\nIn this hands-on, I will build ternary plot programmatically using R for visualising and analysing population structure of Singapore. Here are the 4 steps:\n\nInstall and launch tidyverse and ggtern packages.\nDerive three new measures using mutate() function of dplyr package.\nBuild a static ternary plot using ggtern() function of ggtern package.\nBuild an interactive ternary plot using plot-ly() function of Plotly R package.\n\n\n\n\n2 main R packages will be used.\n\n\n\nR Package\nOverview\n\n\n\n\nggtern\na ggplot extension that plots ternary diagrams. The package will be used to plot static ternary plots.\n\n\nPlotply R\nan R package for creating interactive web-based graphs via plotly’s JavaScript graphing library, plotly.js.\nThe plotly R library contains the ggplotly function, which will convert ggplot2 figures into a Plotly object.\n\n\ntidyverse\nselected tidyverse family packages: readr, dplyr and tidyr are installed and loaded.\n\n\n\nVersion 3.2.1 of ggplot2 will be installed instead of the latest version of ggplot2, because the current version of ggtern package is not compatible to the latest version of ggplot2.\n\npacman::p_load(plotly, ggtern, tidyverse)\n\n\n\n\n\n\nThe Singapore Residents by Planning AreaSubzone, Age Group, Sex and Type of Dwelling, June 2000-2018 data will be used.\nFile name: respopagsex2000to2018_tidy.csv\n\nImport dataPrepare data\n\n\n\npop_data &lt;- read_csv(\"data/respopagsex2000to2018_tidy.csv\")\nhead(pop_data)\n\n# A tibble: 6 × 5\n  PA         SZ                     AG      Year Population\n  &lt;chr&gt;      &lt;chr&gt;                  &lt;chr&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n1 Ang Mo Kio Ang Mo Kio Town Centre AGE0-4  2011        290\n2 Ang Mo Kio Ang Mo Kio Town Centre AGE0-4  2012        270\n3 Ang Mo Kio Ang Mo Kio Town Centre AGE0-4  2013        260\n4 Ang Mo Kio Ang Mo Kio Town Centre AGE0-4  2014        250\n5 Ang Mo Kio Ang Mo Kio Town Centre AGE0-4  2015        260\n6 Ang Mo Kio Ang Mo Kio Town Centre AGE0-4  2016        250\n\n\n\n\nUse mutate() function of dplyr package to derive 3 new measures, namely: young, active and old.\n\n#Deriving the young, economy active and old measures\nagpop_mutated &lt;- pop_data %&gt;%\n  mutate(`Year` = as.character(Year)) %&gt;%\n  spread(AG, Population) %&gt;% #turn the values in Population col into AG cols.\n  mutate(YOUNG = rowSums(.[4:8])) %&gt;% #Age 0-24\n  mutate(ACTIVE = rowSums(.[9:16])) %&gt;% #Age 25-64\n  mutate(OLD = rowSums(.[17:21])) %&gt;% #Age &gt;65\n  mutate(TOTAL = rowSums(.[22:24])) %&gt;% #Age \n  filter(Year == 2018) %&gt;%\n  filter(TOTAL &gt;0)\n\n\n\n\n\n\n\n\n\n+, -, log(), etc., for their usual mathematical meanings\nlead(), lag()\ndense_rank(), min_rank(), percent_rank(), row_number(), cume_dist(), ntile()\ncumsum(), cummean(), cummin(), cummax(), cumany(), cumall()\nna_if(), coalesce()\nif_else(), recode(), case_when()\n\n\n\n\nBecause mutating expressions are computed within groups, they may yield different results on grouped tibbles. This will be the case as soon as an aggregating, lagging, or ranking function is involved. Compare this ungrouped mutate:\nstarwars %&gt;%\n  select(name, mass, species) %&gt;%\n  mutate(mass_norm = mass / mean(mass, na.rm = TRUE))\n\n\n\nstarwars %&gt;%\n  select(name, mass, species) %&gt;%\n  group_by(species) %&gt;%\n  mutate(mass_norm = mass / mean(mass, na.rm = TRUE))\nThe former normalises mass by the global average whereas the latter normalises by the averages within species levels.\n\n\n\n\n\n\n\nUse ggtern() function of ggtern package to create a simple ternary plot:\n\nClassictheme_rgbw()Interactive\n\n\n\n\nShow the code\n#Building the static ternary plot\nggtern(data=agpop_mutated, \n       aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggtern(data = agpop_mutated, \n       aes(\n         x = YOUNG, y = ACTIVE, z = OLD\n)) +\n  geom_point() +\n  labs(title = \"Popultation structure, 2015\") +\n  theme_rgbw()\n\n\n\n\n\n\n\n\n\n\n\nUse plot_ly() to create an interactive plot.:\n\n\nShow the code\n# Function for creating annotation object too\nlabel &lt;- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1, #Position of the annotation in the plot\n    ax = 0, ay = 0, #annotation has no arrow\n    xref = \"paper\", yref = \"paper\",  #Positioning is relative to the entire figure, not data points\n    align = \"center\",\n    font = list(family = \"Calibri\", size = 15, color = \"white\"),\n    bgcolor = \"#000000\", # Background color of the annotation box (light gray)\n    bordercolor = \"black\", \n    borderwidth = 2\n  )\n}\n\n# Function for creating axis formatting too\naxis &lt;- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes &lt;- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\n# Initiate a plotly visualization\nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"black\"), \n  type = \"scatterternary\"\n) %&gt;%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 5-1"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_1.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_1.html#overview",
    "title": "Hands-on_Ex05-1",
    "section": "",
    "text": "Ternary plots are a way of displaying the distribution and variability of three-part compositional data. (For example, the proportion of aged, economy active and young population or sand, silt, and clay in soil.)\nThe display is a triangle with sides scaled from 0 to 1. Each side represents one of the three components. A point is plotted so that a line drawn perpendicular from the point to each leg of the triangle intersect at the component values of the point.\nIn this hands-on, I will build ternary plot programmatically using R for visualising and analysing population structure of Singapore. Here are the 4 steps:\n\nInstall and launch tidyverse and ggtern packages.\nDerive three new measures using mutate() function of dplyr package.\nBuild a static ternary plot using ggtern() function of ggtern package.\nBuild an interactive ternary plot using plot-ly() function of Plotly R package.",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 5-1"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_1.html#install-and-launch-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_1.html#install-and-launch-r-packages",
    "title": "Hands-on_Ex05-1",
    "section": "",
    "text": "2 main R packages will be used.\n\n\n\nR Package\nOverview\n\n\n\n\nggtern\na ggplot extension that plots ternary diagrams. The package will be used to plot static ternary plots.\n\n\nPlotply R\nan R package for creating interactive web-based graphs via plotly’s JavaScript graphing library, plotly.js.\nThe plotly R library contains the ggplotly function, which will convert ggplot2 figures into a Plotly object.\n\n\ntidyverse\nselected tidyverse family packages: readr, dplyr and tidyr are installed and loaded.\n\n\n\nVersion 3.2.1 of ggplot2 will be installed instead of the latest version of ggplot2, because the current version of ggtern package is not compatible to the latest version of ggplot2.\n\npacman::p_load(plotly, ggtern, tidyverse)",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 5-1"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_1.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_1.html#data-preparation",
    "title": "Hands-on_Ex05-1",
    "section": "",
    "text": "The Singapore Residents by Planning AreaSubzone, Age Group, Sex and Type of Dwelling, June 2000-2018 data will be used.\nFile name: respopagsex2000to2018_tidy.csv\n\nImport dataPrepare data\n\n\n\npop_data &lt;- read_csv(\"data/respopagsex2000to2018_tidy.csv\")\nhead(pop_data)\n\n# A tibble: 6 × 5\n  PA         SZ                     AG      Year Population\n  &lt;chr&gt;      &lt;chr&gt;                  &lt;chr&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n1 Ang Mo Kio Ang Mo Kio Town Centre AGE0-4  2011        290\n2 Ang Mo Kio Ang Mo Kio Town Centre AGE0-4  2012        270\n3 Ang Mo Kio Ang Mo Kio Town Centre AGE0-4  2013        260\n4 Ang Mo Kio Ang Mo Kio Town Centre AGE0-4  2014        250\n5 Ang Mo Kio Ang Mo Kio Town Centre AGE0-4  2015        260\n6 Ang Mo Kio Ang Mo Kio Town Centre AGE0-4  2016        250\n\n\n\n\nUse mutate() function of dplyr package to derive 3 new measures, namely: young, active and old.\n\n#Deriving the young, economy active and old measures\nagpop_mutated &lt;- pop_data %&gt;%\n  mutate(`Year` = as.character(Year)) %&gt;%\n  spread(AG, Population) %&gt;% #turn the values in Population col into AG cols.\n  mutate(YOUNG = rowSums(.[4:8])) %&gt;% #Age 0-24\n  mutate(ACTIVE = rowSums(.[9:16])) %&gt;% #Age 25-64\n  mutate(OLD = rowSums(.[17:21])) %&gt;% #Age &gt;65\n  mutate(TOTAL = rowSums(.[22:24])) %&gt;% #Age \n  filter(Year == 2018) %&gt;%\n  filter(TOTAL &gt;0)\n\n\n\n\n\n\n\n\n\n+, -, log(), etc., for their usual mathematical meanings\nlead(), lag()\ndense_rank(), min_rank(), percent_rank(), row_number(), cume_dist(), ntile()\ncumsum(), cummean(), cummin(), cummax(), cumany(), cumall()\nna_if(), coalesce()\nif_else(), recode(), case_when()\n\n\n\n\nBecause mutating expressions are computed within groups, they may yield different results on grouped tibbles. This will be the case as soon as an aggregating, lagging, or ranking function is involved. Compare this ungrouped mutate:\nstarwars %&gt;%\n  select(name, mass, species) %&gt;%\n  mutate(mass_norm = mass / mean(mass, na.rm = TRUE))\n\n\n\nstarwars %&gt;%\n  select(name, mass, species) %&gt;%\n  group_by(species) %&gt;%\n  mutate(mass_norm = mass / mean(mass, na.rm = TRUE))\nThe former normalises mass by the global average whereas the latter normalises by the averages within species levels.",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 5-1"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_1.html#plot-ternary-diagram-with-r",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_1.html#plot-ternary-diagram-with-r",
    "title": "Hands-on_Ex05-1",
    "section": "",
    "text": "Use ggtern() function of ggtern package to create a simple ternary plot:\n\nClassictheme_rgbw()Interactive\n\n\n\n\nShow the code\n#Building the static ternary plot\nggtern(data=agpop_mutated, \n       aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggtern(data = agpop_mutated, \n       aes(\n         x = YOUNG, y = ACTIVE, z = OLD\n)) +\n  geom_point() +\n  labs(title = \"Popultation structure, 2015\") +\n  theme_rgbw()\n\n\n\n\n\n\n\n\n\n\n\nUse plot_ly() to create an interactive plot.:\n\n\nShow the code\n# Function for creating annotation object too\nlabel &lt;- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1, #Position of the annotation in the plot\n    ax = 0, ay = 0, #annotation has no arrow\n    xref = \"paper\", yref = \"paper\",  #Positioning is relative to the entire figure, not data points\n    align = \"center\",\n    font = list(family = \"Calibri\", size = 15, color = \"white\"),\n    bgcolor = \"#000000\", # Background color of the annotation box (light gray)\n    bordercolor = \"black\", \n    borderwidth = 2\n  )\n}\n\n# Function for creating axis formatting too\naxis &lt;- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes &lt;- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\n# Initiate a plotly visualization\nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"black\"), \n  type = \"scatterternary\"\n) %&gt;%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 5-1"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_2.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_2.html",
    "title": "Hands-on_Ex05-2",
    "section": "",
    "text": "Correlation coefficient is a popular statistic that use to measure the type and strength of the relationship between two variables. A correlation coefficient of 1 shows a perfect linear relationship between the two variables, while a -1.0 shows a perfect inverse relationship between the two variables. A correlation coefficient of 0.0 shows no linear relationship between the two variables.\nWhen multivariate data are used, the correlation coefficeints of the pair comparisons are displayed in a table form known as correlation matrix or scatterplot matrix.\nWhen the data is large, both in terms of the number of observations and the number of variables, Corrgram tend to be used to visually explore and analyse the structure and the patterns of relations among variables.\nWe will learn:\n\nHow to create correlation matrix using pairs() of R Graphics.\nHow to plot corrgram using corrplot package of R.\nHow to create an interactive correlation matrix using plotly R.\n\n\n\n\n\nInstall & launch R packagesImport data\n\n\nUse the code below to install and launch corrplot, ggpubr, plotly and tidyverse in R studio.\n\npacman::p_load(corrplot, ggstatsplot, tidyverse)\n\n\n\nIn this hands-on exercise, the Wine Quality Data Set of UCI Machine Learning Repository will be used. The data set consists of 13 variables and 6497 observations. For the purpose of this exercise, we have combined the red wine and white wine data into one data file. It is called wine_quality and is in csv file format.\n\nwine &lt;- read_csv(\"data/wine_quality.csv\")\n\nBeside quality and type, the test of the variables are numerical and continuous data type.\nUse glimpse() to have a look at the columns run down the page, and data runs across.\n\nglimpse(wine)\n\nRows: 6,497\nColumns: 13\n$ `fixed acidity`        &lt;dbl&gt; 7.4, 7.8, 7.8, 11.2, 7.4, 7.4, 7.9, 7.3, 7.8, 7…\n$ `volatile acidity`     &lt;dbl&gt; 0.700, 0.880, 0.760, 0.280, 0.700, 0.660, 0.600…\n$ `citric acid`          &lt;dbl&gt; 0.00, 0.00, 0.04, 0.56, 0.00, 0.00, 0.06, 0.00,…\n$ `residual sugar`       &lt;dbl&gt; 1.9, 2.6, 2.3, 1.9, 1.9, 1.8, 1.6, 1.2, 2.0, 6.…\n$ chlorides              &lt;dbl&gt; 0.076, 0.098, 0.092, 0.075, 0.076, 0.075, 0.069…\n$ `free sulfur dioxide`  &lt;dbl&gt; 11, 25, 15, 17, 11, 13, 15, 15, 9, 17, 15, 17, …\n$ `total sulfur dioxide` &lt;dbl&gt; 34, 67, 54, 60, 34, 40, 59, 21, 18, 102, 65, 10…\n$ density                &lt;dbl&gt; 0.9978, 0.9968, 0.9970, 0.9980, 0.9978, 0.9978,…\n$ pH                     &lt;dbl&gt; 3.51, 3.20, 3.26, 3.16, 3.51, 3.51, 3.30, 3.39,…\n$ sulphates              &lt;dbl&gt; 0.56, 0.68, 0.65, 0.58, 0.56, 0.56, 0.46, 0.47,…\n$ alcohol                &lt;dbl&gt; 9.4, 9.8, 9.8, 9.8, 9.4, 9.4, 9.4, 10.0, 9.5, 1…\n$ quality                &lt;dbl&gt; 5, 5, 5, 6, 5, 5, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5,…\n$ type                   &lt;chr&gt; \"red\", \"red\", \"red\", \"red\", \"red\", \"red\", \"red\"…\n\n\n\n\n\n\n\n\nWe will use pairs function of R Graphics to create a scatterplot matrix. There are many other ways to do so, too. See pairs function.\n\n\n\npairs(x, ...)\n\n## S3 method for class 'formula'\npairs(formula, data = NULL, ..., subset,\n      na.action = stats::na.pass)\n\n## Default S3 method:\npairs(x, labels, panel = points, ...,\n      horInd = 1:nc, \n      verInd = 1:nc,\n      lower.panel = panel, \n      upper.panel = panel,\n      diag.panel = NULL, \n      text.panel = textPanel,\n      label.pos = 0.5 + has.diag/3, \n      line.main = 3,\n      cex.labels = NULL, font.labels = 1,\n      row1attop = TRUE, gap = 1, \n      log = \"\",\n      horOdd = !row1attop, \n      verOdd = !row1attop)\n\n\nFigure below shows the scatterplot matrix of Wine Quality Data: 11x11 matrix.\n\n\nShow the code\npar(bg = \"#f1f4f5\")\n\npairs(wine[,1:11],\n      main = \"Correlation Matrix\")\n\n\n\n\n\n\n\n\n\nFigure below shows scatterplot matrix with different variables columns 2 to 12 of wine dataframe: fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates and alcohol.\n\n\nShow the code\npar(bg = \"#f1f4f5\")\n\npairs(wine[,2:12],\n      main = \"Correlation Matrix with 2:12 vars\")\n\n\n\n\n\n\n\n\n\nFigure below shows scatterplot matrix with chosen variables: total sulfur dioxide, density, pH, sulphates and alcohol.\n\n\nShow the code\npar(bg = \"#f1f4f5\")\n\npairs(wine[, c(\"total sulfur dioxide\", \"density\", \"pH\", \"sulphates\", \"alcohol\")],\n      main = \"Correlation Matrix with 2:12 vars\")\n\n\n\n\n\n\n\n\n\n\n\n\nTo show the lower half of the correlation matrix, the upper.panelargument will be used as shown in the code chunk below.\n\n\nShow the code\npar(bg = \"#f1f4f5\")\npairs(wine[,2:12], upper.panel = NULL)\n\n\n\n\n\n\n\n\n\nWe can also display the upper half.\n\n\nShow the code\npar(bg = \"#f1f4f5\")\npairs(wine[,2:12], lower.panel = NULL)\n\n\n\n\n\n\n\n\n\n\n\n\nTo show the correlation coefficient of each pair of variables instead of a scatter plot, panel.cor function will be used. This will also show higher correlations in a larger font.\n\n\nShow the code\npar(bg = \"#f1f4f5\")\n\npanel.cor &lt;- function(x, y, digits = 2, prefix = \"\", cex.cor, ...) {\n  usr &lt;- par(\"usr\")\n  on.exit(par(usr))\n  par(usr = c(0, 1, 0 , 1))\n  r &lt;- abs(cor(x, y, use = \"complete.obs\"))\n  txt &lt;- format(c(r, 0.123456789), digits = digits)[1]\n  text &lt;- paste(prefix, txt, sep = \"\")\n  if(missing(cex.cor)) cex.cor &lt;- 0.8/strwidth(txt)\n  text(0.5, 0.5, txt, cex = cex.cor * (1 + r) / 2)\n}\n\npairs(wine[, 2:12],\n      upper.panel = panel.cor)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCorrelation matrix with scatterplot can look cluttered when observations are more than 500. Corrgram data visualisation technique suggested by D. J. Murdoch and E. D. Chow (1996) and Friendly, M (2002) and will be used. 3 R packages will be used to plot corrgram: corrgram, ellipse and corrplot.\nHere we will visualise correlation matrix with ggcorrmat() of ggstatsplot package.\n\n\nAdvantage of using ggcormat() over many other methods to visualise correlation matrix is its ability to provide a comprehensive and statistical report.\nggcorrmat() uses the following default arguments:\n\nmatrix.type = “upper”\nsig.level = 0.05\nconf.level = 0.95\n\n\n\nShow the code\nggstatsplot::ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  ggcorrplot.args = list(\n    lab_size = 2.8,\n    tl.cex = 8,\n    pch.cex = 8\n  )\n)\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggstatsplot::ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  colors = c(\"#ed939d\", \"#fcfaf8\", \"#82afd9\"),\n  ggcorrplot.args = list(outline.color = \"black\",\n                         hc.order = TRUE,\n                         lab_size = 2.8,\n                         tl.cex = 8,\n                         pch.cex = 8),\n  title = \"Corrlogram for wine dataset\",\n  subtitle = \"Four pairs are no significant at p&lt; 0.05\"\n)\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\ncor.vars argument is used to compute the correlation matrix needed to build the corrgram.\nggcorrplot.args argument provide additional (mostly aesthetic) arguments that will be passed to ggcorrplot::ggcorrplot function. The list should avoid any of the following arguments since they are already internally being used: corr, method, p.mat, sig.level, ggtheme, colors, lab, pch, legend.title, digits.\nThe sample sub-code chunk can be used to control specific component of the plot such as the font size of the x-axis, y-axis, and the statistical report.\n\n\n\nggplot.component = list(\n  theme(text = element_text(size = 5),\n        axis.text.x = element_text(size = 8),\n        axis.text.y = element_text(size = 8))\n)\n\n\n\n\nggstasplot is an extension of ggplot2, so also supports faceting. However the feature is in the grouped_ggcorrmat() of ggstatsplot.\n\n#| code-fold: true\n#| code-summary: \"Show the code\"\n\ngrouped_ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  grouping.var = type,\n  type = \"robust\",\n  colors = c(\"#ed939d\", \"#fcfaf8\", \"#82afd9\"),\n  p.adjust.method = \"holm\",\n  plotgrid.args = list(ncol = 2),\n  ggcorrplot.args = list(outline.color = \"black\",\n                         hc.order = TRUE,\n                         lab_size = 4,\n                         tl.cex = 12,\n                         pch.cex = 9\n                         ),\n  annotation.args = list(\n    tag_levels = \"a\",\n    title = \"Correlogram for wine dataset\",\n    subtitle = \"The measures are: alcohol, sulphates, fixed acidity, citric acid, chlorides, residual sugar, density, free sulfur dioxide and volatile acidity\",\n    caption = \"Dataset: UCI Machine Learning Repository\"\n  )\n) \n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nUse fig-width and fig-height to adjust the spaces.\nTo build a facet plot, the only argument needed is grouping.var.\nBehind group_ggcorrmat(), patchwork package is used to create the multiplot. plotgrid.args argument provides a list of additional arguments passed to patchwork::wrap_plots, except for guides argument which is already separately specified earlier.\nLikewise, annotation.args argument is calling plot annotation arguments of patchwork package.\n\n\n\n\n\n\n🔆 Resource: An Introduction to corrplot Package\n\n\n\nCompute the correlation matrix of wine data frame\n\n\nwine.cor &lt;- cor(wine[,1:11])\n\n\nUse corrplot() to plot the corrgram by using all the default settings.\n\n\npar(bg = \"#f1f4f5\")\n\ncorrplot(wine.cor)\n\n\n\n\n\n\n\n\n\n\nThe default settings\n\n\n\nvisual object used to plot the coorgram: circle\nlayout of the corrgram: symmetric matrix\ncolor scheme: diverging blue-red\nThe intensity of the colour or also know as saturation is used to represent the strength of the correlation coefficient.\nDarker colours indicate relatively stronger linear relationship between the paired variables\n\n\n\n\n\nMore settings\n\n\n\nmatrix.type: Character, \"full\" (default), \"upper\" or \"lower\", display full matrix, lower triangular or upper triangular matrix.\nmethod: Character argument that decides the visualization method of correlation matrix to be used. Allowed values are square (default), circle\ncorr.method: A character string indicating which correlation coefficient is to be computed (pearson (default) or kendall or spearman). robust can also be entered but only if output argument is set to either correlations or p-values. The robust correlation used is percentage bend correlation (see ?WRS2::pball). Abbreviations will also work: \"p\" (for parametric/Pearson’s r), \"np\" (nonparametric/Spearman’s rho), r (robust).\ndigits: Decides the number of decimal digits to be displayed (Default: 2)\nsig.level: Significance level (Default: 0.05). If the p-value in p-value matrix is bigger than sig.level, then the corresponding correlation coefficient is regarded as insignificant and flagged as such in the plot. This argument is relevant only when output = \"plot\".\nggtheme:\nA function, ggplot2 theme name. Default value is ggplot2::theme_bw(). Any of the ggplot2 themes, or themes from extension packages are allowed (e.g., ggthemes::theme_fivethirtyeight(), hrbrthemes::theme_ipsum_ps(), etc.).\nsubtitle: The text for the plot subtitle.\nlab.col: Color to be used for the correlation coefficient labels (applicable only when lab = TRUE).\nlab.size: Size to be used for the correlation coefficient labels (applicable only when lab = TRUE).\nmessages: Decides whether messages references, notes, and warnings are to be displayed (Default: TRUE).\noutline = to draw the black outline of the correlation objects such as circles or squares.\naddgrid.col = to determine the color of the grids. Would dissapear if NA.\norder = the order of the columns. If not specified it is plotted as in the original matrix, but sometimes it is not so informative. Possible methods are: “AOE” (angular order of the eigenvectors), “FPC” (first principal component), “hclust”, “alphabet”. There is also hclust.method to determine the agglomeration method if the order is “hclust”.\naddrect = when the order is “hclust”, determines the number of rectangles according to the hierarchical cluster. rect.something arguments are about the rectangles added according to this argument.\ncl.something = these are the arguments about the color legend.\ntl.something = these are the arguments about the text labels.\n\n\n\n\n\n\nIn corrplot package, there are seven visual geometrics (parameter method) can be used to encode the attribute values. They are: circle, square, ellipse, number, shade, color and pie. The default is circle, like the figure in 6.1.\nThe default setting can be changed by using the method argument. See the code below:\n\nellipsesquarenumbershadecolorpieaddrect\n\n\n\n\nShow the code\npar(bg = \"#f1f4f5\")\ncorrplot(wine.cor,\n         method = \"ellipse\",\n         tl.srt = 45,\n         bg = \"#f1f4f5\",\n         title = \"Correlation Plot with Ellipse\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\npar(bg = \"#f1f4f5\")\ncorrplot(wine.cor,\n         method = \"square\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\npar(bg = \"#f1f4f5\")\ncorrplot(wine.cor,\n         method = \"number\",\n         number.cex = 0.65,\n         tl.srt = 45,\n         bg = \"#f1f4f5\",\n         title = \"Correlation Plot with Number\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\npar(bg = \"#f1f4f5\")\ncorrplot(wine.cor,\n         method = \"shade\",\n         tl.srt = 45,\n         bg = \"#f1f4f5\",\n         title = \"Correlation Plot with Shade\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\npar(bg = \"#f1f4f5\")\ncorrplot(wine.cor,\n         method = \"color\",\n         tl.srt = 45,\n         bg = \"#f1f4f5\",\n         title = \"Correlation Plot with Color\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\npar(bg = \"#f1f4f5\")\ncorrplot(wine.cor,\n         method = \"pie\",\n         tl.srt = 45,\n         bg = \"#f1f4f5\",\n         title = \"Correlation Plot with Pie\")\n\n\n\n\n\n\n\n\n\n\n\naddrect argument sets the value in numbers representing the number of clusters.\n\n\nShow the code\npar(bg = \"#f1f4f5\")\n\ncorrplot(wine.cor,\n         method = \"ellipse\",\n         outline = T,\n         addgrid.col = \"darkgray\",\n         order=\"hclust\",\n         addrect = 4,   \n         rect.col = \"black\",\n         rect.lwd = 5,\n         cl.pos = \"b\",\n         tl.col = \"indianred4\",\n         tl.cex = 0.6,\n         tl.srt = 45,\n         bg = \"#f1f4f5\",\n         #addCoef.col = \"white\",\n         #number.digits = 2,\n         #number.cex = 0.75,\n         title=\"Correlation Plot with Ellipses and Clusters\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncorrplor() supports three layout types, namely: full, upper or lower. The default is full which display full matrix. The default setting can be changed by using the type argument of corrplot().\n\n\nShow the code\npar(bg = \"#f1f4f5\")\ncorrplot(wine.cor,\n         method = \"ellipse\",\n         type = \"lower\",\n         tl.srt = 45,\n         title = \"Correlation Plot - Lower Type\")\n\n\n\n\n\n\n\n\n\n\nTo turn off the diagonal cells: diag\nTo change the axis text label colour: tl.col\n\n\n\nShow the code\npar(bg = \"#f1f4f5\")\ncorrplot(wine.cor,\n         method = \"ellipse\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.cex = 0.5,\n         tl.offset = 1.5,\n         tl.srt = 45,\n         cl.cex = 0.5,\n         cl.offset = 1,\n         title = \"Correlation Plot - Text Label in Black\")\n\n\n\n\n\n\n\n\n\n\n\n\nTo create a coorgram with mixed layout, the corrplot.mixed(), a wrapped function for mixed visualisation style will be used.\n\n\nShow the code\npar(bg = \"#f1f4f5\")\n\ncorrplot.mixed(wine.cor,\n               lower = \"ellipse\",\n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\",\n               tl.cex = 0.6,\n               tl.srt = 45,\n               number.cex = 0.5)\n\n\n\n\n\n\n\n\n\nNote that argument lower and upper are used to define the visualisation method used. In this case ellipse is used to map the lower half of the corrgram and numerical matrix (i.e. number) is used to map the upper half of the corrgram.\nThe argument tl.pos, on the other, is used to specify the placement of the axis label.\nLastly, the diag argument is used to specify the glyph on the principal diagonal of the corrgram.\n\n\n\nWe are also interested to know which pair of variables their correlation coefficient are statistically significant. Figure below shows a corrgram combined with the significant test. The corrgram reveals that not all correlation pairs are statistically significant.\nWith corrplot package, we can use the cor.mtest() to compute the p-values and confidence interval for each pair of variables.\n\nwine.sig = cor.mtest(wine.cor,\n                     conf.level = .95)\n\nWe can then use the p.mat argument of corrplot function as shown in the code chunk below.\n\n\nShow the code\npar(bg = \"#f1f4f5\")\n\ncorrplot(wine.cor,\n         method = \"number\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.srt = 45,\n         tl.cex = 0.6,\n         number.cex = 0.7,\n         p.mat = wine.sig$p,\n         sig.level = .05)\n\n\n\n\n\n\n\n\n\n\n\n\nMatrix reorder is very important for mining the hiden structure and pattern in a corrgram. By default, the order of attributes of a corrgram is sorted according to the correlation matrix (i.e. “original”). The default setting can be over-write by using the order argument of corrplot(). Currently, corrplot package support four sorting methods, they are:\n\n“AOE” is for the angular order of the eigenvectors. See Michael Friendly (2002) for details.\n“FPC” for the first principal component order.\n“hclust” for hierarchical clustering order, and “hclust.method” for the agglomeration method to be used. It should be one of “ward”, “single”, “complete”, “average”, “mcquitty”, “median” or “centroid”.\n“alphabet” for alphabetical order. “AOE”, “FPC”, “hclust”, “alphabet”. More algorithms can be found in seriation package.\n\n\n\nShow the code\npar(bg = \"#f1f4f5\")\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               tl.srt = 45,\n               tl.cex = 0.6,\n               diag = \"l\",\n               order=\"AOE\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\n\n\n\n\nggcormat() of ggstatsplot package\nggscatmat and ggpairs of GGally.\ncorrplot. A graphical display of a correlation matrix or general matrix. It also contains some algorithms to do matrix reordering. In addition, corrplot is good at details, including choosing color, text labels, color labels, layout, etc.\ncorrgram calculates correlation of variables and displays the results graphically. Included panel functions can display points, shading, ellipses, and correlation values with confidence intervals.\n\n\n\n\nIf using hclust, corrplot()can draw rectangles around the corrgram based on the results of hierarchical clustering. addrect indicates the number of clusters.\n\n\nShow the code\npar(bg = \"#f1f4f5\")\ncorrplot(wine.cor,\n         method = \"ellipse\",\n         tl.pos = \"lt\",\n         tl.col = \"black\",\n         tl.cex = 0.6,\n         tl.srt = 45,\n         order = \"hclust\",\n         hclust.method = \"ward.D\",\n         addrect = 3\n         )\n\n\n\n\n\n\n\n\n\n\n\nShow the code\npar(bg = \"#f1f4f5\")\n\n## text labels rotated 45 degrees and  wider color legend with numbers right aligned\ncorrplot(wine.cor, \n         type = 'lower', \n         order = 'hclust', \n         tl.col = 'black',\n         tl.cex = 0.5,\n         cl.ratio = 0.2, \n         tl.srt = 45, \n         col = COL2('PuOr', 10))\n\n\n\n\n\n\n\n\n\n\n\nShow the code\npar(bg = \"#f1f4f5\")\n\n## text labels rotated 45 degrees and  wider color legend with numbers right aligned\ncorrplot(wine.cor, \n         type = \"upper\", \n         order = \"hclust\",\n         hclust.method = \"ward.D\",\n         tl.col = 'black',\n         tl.cex = 0.5, \n         tl.srt = 45, \n         col = c('white', 'black'),\n         bg = \"gold2\")\n\n\n\n\n\n\n\n\n\n\n\n\nMichael Friendly (2002). “Corrgrams: Exploratory displays for correlation matrices”. The American Statistician, 56, 316–324.\nD.J. Murdoch, E.D. Chow (1996). “A graphical display of large correlation matrices”. The American Statistician, 50, 178–180.",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 5-2"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_2.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_2.html#overview",
    "title": "Hands-on_Ex05-2",
    "section": "",
    "text": "Correlation coefficient is a popular statistic that use to measure the type and strength of the relationship between two variables. A correlation coefficient of 1 shows a perfect linear relationship between the two variables, while a -1.0 shows a perfect inverse relationship between the two variables. A correlation coefficient of 0.0 shows no linear relationship between the two variables.\nWhen multivariate data are used, the correlation coefficeints of the pair comparisons are displayed in a table form known as correlation matrix or scatterplot matrix.\nWhen the data is large, both in terms of the number of observations and the number of variables, Corrgram tend to be used to visually explore and analyse the structure and the patterns of relations among variables.\nWe will learn:\n\nHow to create correlation matrix using pairs() of R Graphics.\nHow to plot corrgram using corrplot package of R.\nHow to create an interactive correlation matrix using plotly R.",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 5-2"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_2.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_2.html#getting-started",
    "title": "Hands-on_Ex05-2",
    "section": "",
    "text": "Install & launch R packagesImport data\n\n\nUse the code below to install and launch corrplot, ggpubr, plotly and tidyverse in R studio.\n\npacman::p_load(corrplot, ggstatsplot, tidyverse)\n\n\n\nIn this hands-on exercise, the Wine Quality Data Set of UCI Machine Learning Repository will be used. The data set consists of 13 variables and 6497 observations. For the purpose of this exercise, we have combined the red wine and white wine data into one data file. It is called wine_quality and is in csv file format.\n\nwine &lt;- read_csv(\"data/wine_quality.csv\")\n\nBeside quality and type, the test of the variables are numerical and continuous data type.\nUse glimpse() to have a look at the columns run down the page, and data runs across.\n\nglimpse(wine)\n\nRows: 6,497\nColumns: 13\n$ `fixed acidity`        &lt;dbl&gt; 7.4, 7.8, 7.8, 11.2, 7.4, 7.4, 7.9, 7.3, 7.8, 7…\n$ `volatile acidity`     &lt;dbl&gt; 0.700, 0.880, 0.760, 0.280, 0.700, 0.660, 0.600…\n$ `citric acid`          &lt;dbl&gt; 0.00, 0.00, 0.04, 0.56, 0.00, 0.00, 0.06, 0.00,…\n$ `residual sugar`       &lt;dbl&gt; 1.9, 2.6, 2.3, 1.9, 1.9, 1.8, 1.6, 1.2, 2.0, 6.…\n$ chlorides              &lt;dbl&gt; 0.076, 0.098, 0.092, 0.075, 0.076, 0.075, 0.069…\n$ `free sulfur dioxide`  &lt;dbl&gt; 11, 25, 15, 17, 11, 13, 15, 15, 9, 17, 15, 17, …\n$ `total sulfur dioxide` &lt;dbl&gt; 34, 67, 54, 60, 34, 40, 59, 21, 18, 102, 65, 10…\n$ density                &lt;dbl&gt; 0.9978, 0.9968, 0.9970, 0.9980, 0.9978, 0.9978,…\n$ pH                     &lt;dbl&gt; 3.51, 3.20, 3.26, 3.16, 3.51, 3.51, 3.30, 3.39,…\n$ sulphates              &lt;dbl&gt; 0.56, 0.68, 0.65, 0.58, 0.56, 0.56, 0.46, 0.47,…\n$ alcohol                &lt;dbl&gt; 9.4, 9.8, 9.8, 9.8, 9.4, 9.4, 9.4, 10.0, 9.5, 1…\n$ quality                &lt;dbl&gt; 5, 5, 5, 6, 5, 5, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5,…\n$ type                   &lt;chr&gt; \"red\", \"red\", \"red\", \"red\", \"red\", \"red\", \"red\"…",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 5-2"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_2.html#build-correlation-matrix-pairs-method",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_2.html#build-correlation-matrix-pairs-method",
    "title": "Hands-on_Ex05-2",
    "section": "",
    "text": "We will use pairs function of R Graphics to create a scatterplot matrix. There are many other ways to do so, too. See pairs function.\n\n\n\npairs(x, ...)\n\n## S3 method for class 'formula'\npairs(formula, data = NULL, ..., subset,\n      na.action = stats::na.pass)\n\n## Default S3 method:\npairs(x, labels, panel = points, ...,\n      horInd = 1:nc, \n      verInd = 1:nc,\n      lower.panel = panel, \n      upper.panel = panel,\n      diag.panel = NULL, \n      text.panel = textPanel,\n      label.pos = 0.5 + has.diag/3, \n      line.main = 3,\n      cex.labels = NULL, font.labels = 1,\n      row1attop = TRUE, gap = 1, \n      log = \"\",\n      horOdd = !row1attop, \n      verOdd = !row1attop)\n\n\nFigure below shows the scatterplot matrix of Wine Quality Data: 11x11 matrix.\n\n\nShow the code\npar(bg = \"#f1f4f5\")\n\npairs(wine[,1:11],\n      main = \"Correlation Matrix\")\n\n\n\n\n\n\n\n\n\nFigure below shows scatterplot matrix with different variables columns 2 to 12 of wine dataframe: fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates and alcohol.\n\n\nShow the code\npar(bg = \"#f1f4f5\")\n\npairs(wine[,2:12],\n      main = \"Correlation Matrix with 2:12 vars\")\n\n\n\n\n\n\n\n\n\nFigure below shows scatterplot matrix with chosen variables: total sulfur dioxide, density, pH, sulphates and alcohol.\n\n\nShow the code\npar(bg = \"#f1f4f5\")\n\npairs(wine[, c(\"total sulfur dioxide\", \"density\", \"pH\", \"sulphates\", \"alcohol\")],\n      main = \"Correlation Matrix with 2:12 vars\")\n\n\n\n\n\n\n\n\n\n\n\n\nTo show the lower half of the correlation matrix, the upper.panelargument will be used as shown in the code chunk below.\n\n\nShow the code\npar(bg = \"#f1f4f5\")\npairs(wine[,2:12], upper.panel = NULL)\n\n\n\n\n\n\n\n\n\nWe can also display the upper half.\n\n\nShow the code\npar(bg = \"#f1f4f5\")\npairs(wine[,2:12], lower.panel = NULL)\n\n\n\n\n\n\n\n\n\n\n\n\nTo show the correlation coefficient of each pair of variables instead of a scatter plot, panel.cor function will be used. This will also show higher correlations in a larger font.\n\n\nShow the code\npar(bg = \"#f1f4f5\")\n\npanel.cor &lt;- function(x, y, digits = 2, prefix = \"\", cex.cor, ...) {\n  usr &lt;- par(\"usr\")\n  on.exit(par(usr))\n  par(usr = c(0, 1, 0 , 1))\n  r &lt;- abs(cor(x, y, use = \"complete.obs\"))\n  txt &lt;- format(c(r, 0.123456789), digits = digits)[1]\n  text &lt;- paste(prefix, txt, sep = \"\")\n  if(missing(cex.cor)) cex.cor &lt;- 0.8/strwidth(txt)\n  text(0.5, 0.5, txt, cex = cex.cor * (1 + r) / 2)\n}\n\npairs(wine[, 2:12],\n      upper.panel = panel.cor)",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 5-2"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_2.html#visualise-correlation-matrix-ggcormat",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_2.html#visualise-correlation-matrix-ggcormat",
    "title": "Hands-on_Ex05-2",
    "section": "",
    "text": "Correlation matrix with scatterplot can look cluttered when observations are more than 500. Corrgram data visualisation technique suggested by D. J. Murdoch and E. D. Chow (1996) and Friendly, M (2002) and will be used. 3 R packages will be used to plot corrgram: corrgram, ellipse and corrplot.\nHere we will visualise correlation matrix with ggcorrmat() of ggstatsplot package.\n\n\nAdvantage of using ggcormat() over many other methods to visualise correlation matrix is its ability to provide a comprehensive and statistical report.\nggcorrmat() uses the following default arguments:\n\nmatrix.type = “upper”\nsig.level = 0.05\nconf.level = 0.95\n\n\n\nShow the code\nggstatsplot::ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  ggcorrplot.args = list(\n    lab_size = 2.8,\n    tl.cex = 8,\n    pch.cex = 8\n  )\n)\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggstatsplot::ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  colors = c(\"#ed939d\", \"#fcfaf8\", \"#82afd9\"),\n  ggcorrplot.args = list(outline.color = \"black\",\n                         hc.order = TRUE,\n                         lab_size = 2.8,\n                         tl.cex = 8,\n                         pch.cex = 8),\n  title = \"Corrlogram for wine dataset\",\n  subtitle = \"Four pairs are no significant at p&lt; 0.05\"\n)\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\ncor.vars argument is used to compute the correlation matrix needed to build the corrgram.\nggcorrplot.args argument provide additional (mostly aesthetic) arguments that will be passed to ggcorrplot::ggcorrplot function. The list should avoid any of the following arguments since they are already internally being used: corr, method, p.mat, sig.level, ggtheme, colors, lab, pch, legend.title, digits.\nThe sample sub-code chunk can be used to control specific component of the plot such as the font size of the x-axis, y-axis, and the statistical report.\n\n\n\nggplot.component = list(\n  theme(text = element_text(size = 5),\n        axis.text.x = element_text(size = 8),\n        axis.text.y = element_text(size = 8))\n)",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 5-2"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_2.html#build-multiple-plots",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_2.html#build-multiple-plots",
    "title": "Hands-on_Ex05-2",
    "section": "",
    "text": "ggstasplot is an extension of ggplot2, so also supports faceting. However the feature is in the grouped_ggcorrmat() of ggstatsplot.\n\n#| code-fold: true\n#| code-summary: \"Show the code\"\n\ngrouped_ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  grouping.var = type,\n  type = \"robust\",\n  colors = c(\"#ed939d\", \"#fcfaf8\", \"#82afd9\"),\n  p.adjust.method = \"holm\",\n  plotgrid.args = list(ncol = 2),\n  ggcorrplot.args = list(outline.color = \"black\",\n                         hc.order = TRUE,\n                         lab_size = 4,\n                         tl.cex = 12,\n                         pch.cex = 9\n                         ),\n  annotation.args = list(\n    tag_levels = \"a\",\n    title = \"Correlogram for wine dataset\",\n    subtitle = \"The measures are: alcohol, sulphates, fixed acidity, citric acid, chlorides, residual sugar, density, free sulfur dioxide and volatile acidity\",\n    caption = \"Dataset: UCI Machine Learning Repository\"\n  )\n) \n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nUse fig-width and fig-height to adjust the spaces.\nTo build a facet plot, the only argument needed is grouping.var.\nBehind group_ggcorrmat(), patchwork package is used to create the multiplot. plotgrid.args argument provides a list of additional arguments passed to patchwork::wrap_plots, except for guides argument which is already separately specified earlier.\nLikewise, annotation.args argument is calling plot annotation arguments of patchwork package.",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 5-2"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_2.html#visualise-correlation-matrix-using-corrplot-pakcage",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_2.html#visualise-correlation-matrix-using-corrplot-pakcage",
    "title": "Hands-on_Ex05-2",
    "section": "",
    "text": "🔆 Resource: An Introduction to corrplot Package\n\n\n\nCompute the correlation matrix of wine data frame\n\n\nwine.cor &lt;- cor(wine[,1:11])\n\n\nUse corrplot() to plot the corrgram by using all the default settings.\n\n\npar(bg = \"#f1f4f5\")\n\ncorrplot(wine.cor)\n\n\n\n\n\n\n\n\n\n\nThe default settings\n\n\n\nvisual object used to plot the coorgram: circle\nlayout of the corrgram: symmetric matrix\ncolor scheme: diverging blue-red\nThe intensity of the colour or also know as saturation is used to represent the strength of the correlation coefficient.\nDarker colours indicate relatively stronger linear relationship between the paired variables\n\n\n\n\n\nMore settings\n\n\n\nmatrix.type: Character, \"full\" (default), \"upper\" or \"lower\", display full matrix, lower triangular or upper triangular matrix.\nmethod: Character argument that decides the visualization method of correlation matrix to be used. Allowed values are square (default), circle\ncorr.method: A character string indicating which correlation coefficient is to be computed (pearson (default) or kendall or spearman). robust can also be entered but only if output argument is set to either correlations or p-values. The robust correlation used is percentage bend correlation (see ?WRS2::pball). Abbreviations will also work: \"p\" (for parametric/Pearson’s r), \"np\" (nonparametric/Spearman’s rho), r (robust).\ndigits: Decides the number of decimal digits to be displayed (Default: 2)\nsig.level: Significance level (Default: 0.05). If the p-value in p-value matrix is bigger than sig.level, then the corresponding correlation coefficient is regarded as insignificant and flagged as such in the plot. This argument is relevant only when output = \"plot\".\nggtheme:\nA function, ggplot2 theme name. Default value is ggplot2::theme_bw(). Any of the ggplot2 themes, or themes from extension packages are allowed (e.g., ggthemes::theme_fivethirtyeight(), hrbrthemes::theme_ipsum_ps(), etc.).\nsubtitle: The text for the plot subtitle.\nlab.col: Color to be used for the correlation coefficient labels (applicable only when lab = TRUE).\nlab.size: Size to be used for the correlation coefficient labels (applicable only when lab = TRUE).\nmessages: Decides whether messages references, notes, and warnings are to be displayed (Default: TRUE).\noutline = to draw the black outline of the correlation objects such as circles or squares.\naddgrid.col = to determine the color of the grids. Would dissapear if NA.\norder = the order of the columns. If not specified it is plotted as in the original matrix, but sometimes it is not so informative. Possible methods are: “AOE” (angular order of the eigenvectors), “FPC” (first principal component), “hclust”, “alphabet”. There is also hclust.method to determine the agglomeration method if the order is “hclust”.\naddrect = when the order is “hclust”, determines the number of rectangles according to the hierarchical cluster. rect.something arguments are about the rectangles added according to this argument.\ncl.something = these are the arguments about the color legend.\ntl.something = these are the arguments about the text labels.\n\n\n\n\n\n\nIn corrplot package, there are seven visual geometrics (parameter method) can be used to encode the attribute values. They are: circle, square, ellipse, number, shade, color and pie. The default is circle, like the figure in 6.1.\nThe default setting can be changed by using the method argument. See the code below:\n\nellipsesquarenumbershadecolorpieaddrect\n\n\n\n\nShow the code\npar(bg = \"#f1f4f5\")\ncorrplot(wine.cor,\n         method = \"ellipse\",\n         tl.srt = 45,\n         bg = \"#f1f4f5\",\n         title = \"Correlation Plot with Ellipse\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\npar(bg = \"#f1f4f5\")\ncorrplot(wine.cor,\n         method = \"square\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\npar(bg = \"#f1f4f5\")\ncorrplot(wine.cor,\n         method = \"number\",\n         number.cex = 0.65,\n         tl.srt = 45,\n         bg = \"#f1f4f5\",\n         title = \"Correlation Plot with Number\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\npar(bg = \"#f1f4f5\")\ncorrplot(wine.cor,\n         method = \"shade\",\n         tl.srt = 45,\n         bg = \"#f1f4f5\",\n         title = \"Correlation Plot with Shade\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\npar(bg = \"#f1f4f5\")\ncorrplot(wine.cor,\n         method = \"color\",\n         tl.srt = 45,\n         bg = \"#f1f4f5\",\n         title = \"Correlation Plot with Color\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\npar(bg = \"#f1f4f5\")\ncorrplot(wine.cor,\n         method = \"pie\",\n         tl.srt = 45,\n         bg = \"#f1f4f5\",\n         title = \"Correlation Plot with Pie\")\n\n\n\n\n\n\n\n\n\n\n\naddrect argument sets the value in numbers representing the number of clusters.\n\n\nShow the code\npar(bg = \"#f1f4f5\")\n\ncorrplot(wine.cor,\n         method = \"ellipse\",\n         outline = T,\n         addgrid.col = \"darkgray\",\n         order=\"hclust\",\n         addrect = 4,   \n         rect.col = \"black\",\n         rect.lwd = 5,\n         cl.pos = \"b\",\n         tl.col = \"indianred4\",\n         tl.cex = 0.6,\n         tl.srt = 45,\n         bg = \"#f1f4f5\",\n         #addCoef.col = \"white\",\n         #number.digits = 2,\n         #number.cex = 0.75,\n         title=\"Correlation Plot with Ellipses and Clusters\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncorrplor() supports three layout types, namely: full, upper or lower. The default is full which display full matrix. The default setting can be changed by using the type argument of corrplot().\n\n\nShow the code\npar(bg = \"#f1f4f5\")\ncorrplot(wine.cor,\n         method = \"ellipse\",\n         type = \"lower\",\n         tl.srt = 45,\n         title = \"Correlation Plot - Lower Type\")\n\n\n\n\n\n\n\n\n\n\nTo turn off the diagonal cells: diag\nTo change the axis text label colour: tl.col\n\n\n\nShow the code\npar(bg = \"#f1f4f5\")\ncorrplot(wine.cor,\n         method = \"ellipse\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.cex = 0.5,\n         tl.offset = 1.5,\n         tl.srt = 45,\n         cl.cex = 0.5,\n         cl.offset = 1,\n         title = \"Correlation Plot - Text Label in Black\")\n\n\n\n\n\n\n\n\n\n\n\n\nTo create a coorgram with mixed layout, the corrplot.mixed(), a wrapped function for mixed visualisation style will be used.\n\n\nShow the code\npar(bg = \"#f1f4f5\")\n\ncorrplot.mixed(wine.cor,\n               lower = \"ellipse\",\n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\",\n               tl.cex = 0.6,\n               tl.srt = 45,\n               number.cex = 0.5)\n\n\n\n\n\n\n\n\n\nNote that argument lower and upper are used to define the visualisation method used. In this case ellipse is used to map the lower half of the corrgram and numerical matrix (i.e. number) is used to map the upper half of the corrgram.\nThe argument tl.pos, on the other, is used to specify the placement of the axis label.\nLastly, the diag argument is used to specify the glyph on the principal diagonal of the corrgram.\n\n\n\nWe are also interested to know which pair of variables their correlation coefficient are statistically significant. Figure below shows a corrgram combined with the significant test. The corrgram reveals that not all correlation pairs are statistically significant.\nWith corrplot package, we can use the cor.mtest() to compute the p-values and confidence interval for each pair of variables.\n\nwine.sig = cor.mtest(wine.cor,\n                     conf.level = .95)\n\nWe can then use the p.mat argument of corrplot function as shown in the code chunk below.\n\n\nShow the code\npar(bg = \"#f1f4f5\")\n\ncorrplot(wine.cor,\n         method = \"number\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.srt = 45,\n         tl.cex = 0.6,\n         number.cex = 0.7,\n         p.mat = wine.sig$p,\n         sig.level = .05)\n\n\n\n\n\n\n\n\n\n\n\n\nMatrix reorder is very important for mining the hiden structure and pattern in a corrgram. By default, the order of attributes of a corrgram is sorted according to the correlation matrix (i.e. “original”). The default setting can be over-write by using the order argument of corrplot(). Currently, corrplot package support four sorting methods, they are:\n\n“AOE” is for the angular order of the eigenvectors. See Michael Friendly (2002) for details.\n“FPC” for the first principal component order.\n“hclust” for hierarchical clustering order, and “hclust.method” for the agglomeration method to be used. It should be one of “ward”, “single”, “complete”, “average”, “mcquitty”, “median” or “centroid”.\n“alphabet” for alphabetical order. “AOE”, “FPC”, “hclust”, “alphabet”. More algorithms can be found in seriation package.\n\n\n\nShow the code\npar(bg = \"#f1f4f5\")\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               tl.srt = 45,\n               tl.cex = 0.6,\n               diag = \"l\",\n               order=\"AOE\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\n\n\n\n\nggcormat() of ggstatsplot package\nggscatmat and ggpairs of GGally.\ncorrplot. A graphical display of a correlation matrix or general matrix. It also contains some algorithms to do matrix reordering. In addition, corrplot is good at details, including choosing color, text labels, color labels, layout, etc.\ncorrgram calculates correlation of variables and displays the results graphically. Included panel functions can display points, shading, ellipses, and correlation values with confidence intervals.\n\n\n\n\nIf using hclust, corrplot()can draw rectangles around the corrgram based on the results of hierarchical clustering. addrect indicates the number of clusters.\n\n\nShow the code\npar(bg = \"#f1f4f5\")\ncorrplot(wine.cor,\n         method = \"ellipse\",\n         tl.pos = \"lt\",\n         tl.col = \"black\",\n         tl.cex = 0.6,\n         tl.srt = 45,\n         order = \"hclust\",\n         hclust.method = \"ward.D\",\n         addrect = 3\n         )\n\n\n\n\n\n\n\n\n\n\n\nShow the code\npar(bg = \"#f1f4f5\")\n\n## text labels rotated 45 degrees and  wider color legend with numbers right aligned\ncorrplot(wine.cor, \n         type = 'lower', \n         order = 'hclust', \n         tl.col = 'black',\n         tl.cex = 0.5,\n         cl.ratio = 0.2, \n         tl.srt = 45, \n         col = COL2('PuOr', 10))\n\n\n\n\n\n\n\n\n\n\n\nShow the code\npar(bg = \"#f1f4f5\")\n\n## text labels rotated 45 degrees and  wider color legend with numbers right aligned\ncorrplot(wine.cor, \n         type = \"upper\", \n         order = \"hclust\",\n         hclust.method = \"ward.D\",\n         tl.col = 'black',\n         tl.cex = 0.5, \n         tl.srt = 45, \n         col = c('white', 'black'),\n         bg = \"gold2\")\n\n\n\n\n\n\n\n\n\n\n\n\nMichael Friendly (2002). “Corrgrams: Exploratory displays for correlation matrices”. The American Statistician, 56, 316–324.\nD.J. Murdoch, E.D. Chow (1996). “A graphical display of large correlation matrices”. The American Statistician, 50, 178–180.",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 5-2"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07_a.html",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07_a.html",
    "title": "Hands-on_Ex07a",
    "section": "",
    "text": "A horizon graph is an analytical graphical method specially designed for visualising large numbers of time-series. It aims to overcome the issue of visualising highly overlapping time-series as shown in the figure below."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07_a.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07_a.html#overview",
    "title": "Hands-on_Ex07a",
    "section": "",
    "text": "A horizon graph is an analytical graphical method specially designed for visualising large numbers of time-series. It aims to overcome the issue of visualising highly overlapping time-series as shown in the figure below."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex_09.html",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex_09.html",
    "title": "Hands-on_Ex_09",
    "section": "",
    "text": "Learning objectives include the following:\n\ncreate graph object data frames, manipulate them using appropriate functions of dplyr, lubridate, and tidygraph.\nbuild network graph visualisation using appropriate function of ggraph\ncompute network geometrics using tidygraph\nbuild advanced gragh visualisation by incorporating the network geometrics\nbuild interactive network visualisation using visNetwork package\n\n\n\n\nFour network data modeling and visualisation packages will be installed and launched. They are igraph, tidygraph, ggraph and visNetwork. In addition, tidyverse and lubridate (specially designed to handle and wrangling time data) will be installed and launched, too.\n\n\n\nThe data sets used in this hands-on exercise is from an oil exploration and extraction company. There are two data sets. One contains the nodes data and the other contains the edges (also know as link) data.\n\n\nGAStech-email_edges.csv which consists of two weeks of 9063 emails correspondances between 55 employees.\n\n\n\nGAStech_email_nodes.csv which consist of the names, department and title of the 55 employees.\n\n\n\nimport GAStech_email_node.csv and GAStech_email_edges-v2.csv into RStudio environment by using read_csv() of readr package.\n\npacman::p_load(readr, dplyr, lubridate)\n\n\nGAStech_nodes &lt;- read_csv(\"data/GAStech_email_node.csv\")\nGAStech_edges &lt;- read_csv(\"data/GAStech_email_edge-v2.csv\")\n\n\n\n\nNext, we examine the structure of the data frame using glimpse() of dplyr.\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 8\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\n\n\nNote\n\n\nThe output report of GAStech_edges above reveals that the SentDate is treated as “Character” data type instead of date data type. It is important to change the data type of SentDate field back to “Date”” data type.\n\n\n\n\n\n\nGAStech_edges &lt;- GAStech_edges %&gt;%\n  mutate(SendDate = dmy(SentDate)) %&gt;%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\n\nLearn from the code\n\n\n\nboth dmy() and wday() are functions of lubridate package. lubridate is an R package that makes it easier to work with dates and times.\ndmy() transforms the SentDate to Date data type.\nwday() returns the day of the week as a decimal number or an ordered factor if label is TRUE. The argument abbr is FALSE keep the daya spells in full, i.e. Monday. The function will create a new column in the data.frame i.e. Weekday and the output of wday() will save in this newly created field.\nthe values in the Weekday field are in ordinal scale.\n\n\n\n\n\n\nTable below shows the data structure of the reformatted GAStech_edges data frame.\n\n\nRows: 9,063\nColumns: 10\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n$ SendDate    &lt;date&gt; 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-0…\n$ Weekday     &lt;ord&gt; Friday, Friday, Friday, Friday, Friday, Friday, Friday, Fr…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex_09.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex_09.html#overview",
    "title": "Hands-on_Ex_09",
    "section": "",
    "text": "Learning objectives include the following:\n\ncreate graph object data frames, manipulate them using appropriate functions of dplyr, lubridate, and tidygraph.\nbuild network graph visualisation using appropriate function of ggraph\ncompute network geometrics using tidygraph\nbuild advanced gragh visualisation by incorporating the network geometrics\nbuild interactive network visualisation using visNetwork package"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex_09.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex_09.html#getting-started",
    "title": "Hands-on_Ex_09",
    "section": "",
    "text": "Four network data modeling and visualisation packages will be installed and launched. They are igraph, tidygraph, ggraph and visNetwork. In addition, tidyverse and lubridate (specially designed to handle and wrangling time data) will be installed and launched, too."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex_09.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex_09.html#the-data",
    "title": "Hands-on_Ex_09",
    "section": "",
    "text": "The data sets used in this hands-on exercise is from an oil exploration and extraction company. There are two data sets. One contains the nodes data and the other contains the edges (also know as link) data.\n\n\nGAStech-email_edges.csv which consists of two weeks of 9063 emails correspondances between 55 employees.\n\n\n\nGAStech_email_nodes.csv which consist of the names, department and title of the 55 employees.\n\n\n\nimport GAStech_email_node.csv and GAStech_email_edges-v2.csv into RStudio environment by using read_csv() of readr package.\n\npacman::p_load(readr, dplyr, lubridate)\n\n\nGAStech_nodes &lt;- read_csv(\"data/GAStech_email_node.csv\")\nGAStech_edges &lt;- read_csv(\"data/GAStech_email_edge-v2.csv\")\n\n\n\n\nNext, we examine the structure of the data frame using glimpse() of dplyr.\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 8\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\n\n\nNote\n\n\nThe output report of GAStech_edges above reveals that the SentDate is treated as “Character” data type instead of date data type. It is important to change the data type of SentDate field back to “Date”” data type.\n\n\n\n\n\n\nGAStech_edges &lt;- GAStech_edges %&gt;%\n  mutate(SendDate = dmy(SentDate)) %&gt;%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\n\nLearn from the code\n\n\n\nboth dmy() and wday() are functions of lubridate package. lubridate is an R package that makes it easier to work with dates and times.\ndmy() transforms the SentDate to Date data type.\nwday() returns the day of the week as a decimal number or an ordered factor if label is TRUE. The argument abbr is FALSE keep the daya spells in full, i.e. Monday. The function will create a new column in the data.frame i.e. Weekday and the output of wday() will save in this newly created field.\nthe values in the Weekday field are in ordinal scale.\n\n\n\n\n\n\nTable below shows the data structure of the reformatted GAStech_edges data frame.\n\n\nRows: 9,063\nColumns: 10\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n$ SendDate    &lt;date&gt; 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-0…\n$ Weekday     &lt;ord&gt; Friday, Friday, Friday, Friday, Friday, Friday, Friday, Fr…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex_09.html#the-dplyr-verbs",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex_09.html#the-dplyr-verbs",
    "title": "Hands-on_Ex_09",
    "section": "The dplyr verbs",
    "text": "The dplyr verbs\n\niris_tree &lt;- iris_tree %&gt;% \n    activate(nodes) %&gt;% \n    mutate(Species = ifelse(leaf, as.character(iris$Species)[label], NA)) %&gt;% \n    activate(edges) %&gt;% \n    mutate(to_setose = .N()$Species[to] == 'setosa')\niris_tree\n\n# A tbl_graph: 299 nodes and 298 edges\n#\n# A rooted tree\n#\n# Edge Data: 298 × 3 (active)\n    from    to to_setose\n   &lt;int&gt; &lt;int&gt; &lt;lgl&gt;    \n 1     3     1 NA       \n 2     3     2 NA       \n 3     7     5 NA       \n 4     7     6 NA       \n 5     8     4 NA       \n 6     8     7 NA       \n 7     9     3 NA       \n 8     9     8 NA       \n 9    13    11 NA       \n10    13    12 NA       \n# ℹ 288 more rows\n#\n# Node Data: 299 × 5\n  height leaf  label members Species\n   &lt;dbl&gt; &lt;lgl&gt; &lt;chr&gt;   &lt;int&gt; &lt;chr&gt;  \n1  0     TRUE  \"108\"       1 &lt;NA&gt;   \n2  0     TRUE  \"131\"       1 &lt;NA&gt;   \n3  0.265 FALSE \"\"          2 &lt;NA&gt;   \n# ℹ 296 more rows\n\n\n.N() function is used to gain access to the node data while manipulating the edge data. Similarly .E() will give you the edge data and .G() will give you the tbl_graph object itself.\nWhile one might expect all of dplyrs verbs to be supported in that manner, there is a clear limitation in the relational data structure that requires rows to maintain their identity. Thus, summarise() and do() are not allowed as there is no clear interpretation of how alterations on the node and edge data with these verbs should be interpreted. If these operations are required I suggest applying them to a tibble representation and then joining the result back in.\nSpeaking of joining, all joins from dplyr are supported. Nodes and edges are added and removed as required by the join. New edge data to be joined in must have a to and from column referencing valid nodes in the existing graph.\n\nlibrary(dplyr)\niris_sum &lt;- iris %&gt;% \n    group_by(Species) %&gt;% \n    summarise_all(mean) %&gt;% \n    ungroup()\niris_tree &lt;- iris_tree %&gt;% \n    activate(nodes) %&gt;% \n    left_join(iris_sum)\niris_tree\n\n# A tbl_graph: 299 nodes and 298 edges\n#\n# A rooted tree\n#\n# Node Data: 299 × 9 (active)\n   height leaf  label members Species Sepal.Length Sepal.Width Petal.Length\n    &lt;dbl&gt; &lt;lgl&gt; &lt;chr&gt;   &lt;int&gt; &lt;chr&gt;          &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;\n 1  0     TRUE  \"108\"       1 &lt;NA&gt;              NA          NA           NA\n 2  0     TRUE  \"131\"       1 &lt;NA&gt;              NA          NA           NA\n 3  0.265 FALSE \"\"          2 &lt;NA&gt;              NA          NA           NA\n 4  0     TRUE  \"103\"       1 &lt;NA&gt;              NA          NA           NA\n 5  0     TRUE  \"126\"       1 &lt;NA&gt;              NA          NA           NA\n 6  0     TRUE  \"130\"       1 &lt;NA&gt;              NA          NA           NA\n 7  0.346 FALSE \"\"          2 &lt;NA&gt;              NA          NA           NA\n 8  0.520 FALSE \"\"          3 &lt;NA&gt;              NA          NA           NA\n 9  0.557 FALSE \"\"          5 &lt;NA&gt;              NA          NA           NA\n10  0     TRUE  \"119\"       1 &lt;NA&gt;              NA          NA           NA\n# ℹ 289 more rows\n# ℹ 1 more variable: Petal.Width &lt;dbl&gt;\n#\n# Edge Data: 298 × 3\n   from    to to_setose\n  &lt;int&gt; &lt;int&gt; &lt;lgl&gt;    \n1     3     1 NA       \n2     3     2 NA       \n3     7     5 NA       \n# ℹ 295 more rows\n\n\n\nlibrary(ggraph)\ngr1 &lt;- create_notable('bull') %&gt;% \n    mutate(name = letters[1:5])\ngr2 &lt;- create_ring(5) %&gt;% \n    mutate(name = letters[4:8])\n\n# Plot\ngr1 %&gt;% bind_graphs(gr2) %&gt;% \n    ggraph(layout = 'kk') + \n    geom_edge_link() + \n    geom_node_point(size = 8, colour = 'steelblue') +\n    geom_node_text(aes(label = name), colour = 'white', vjust = 0.4) + \n    ggtitle('Binding graphs') + \n    theme_graph()\n\n\n\n\n\n\n\n\n\ngr1 %&gt;% graph_join(gr2) %&gt;% \n    ggraph(layout = 'kk') + \n    geom_edge_link() + \n    geom_node_point(size = 8, colour = 'steelblue') +\n    geom_node_text(aes(label = name), colour = 'white', vjust = 0.4) + \n    ggtitle('Joining graphs') + \n    theme_graph()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_3.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_3.html",
    "title": "Hands-on_Ex08_3",
    "section": "",
    "text": "Importing geospatial data in rds format into R environment.\nCreating cartographic quality choropleth maps by using appropriate tmap functions.\nCreating rate map\nCreating percentile map\nCreating boxmap\n\n\n\n\n\n\n\n\npacman::p_load(sf, tmap, tidyverse)\n\n\n\n\nFor the purpose of this hands-on exercise, a prepared data set called NGA_wp.rds will be used. The data set is a polygon feature data.frame providing information on water point of Nigeria at the LGA level.\n\nNGA_wp &lt;- read_rds(\"data/rds/NGA_wp.rds\")\n\n\n\n\n\n\n\nTo plot a choropleth map showing the distribution of non-function water point by LGA\n\nlibrary(tmap)\nlibrary(RColorBrewer)\nlibrary(viridis)\np1 &lt;- tm_shape(NGA_wp) +\n  tm_fill(\"wp_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = viridis(10)) +\n  tm_borders(lwd = 0.1,\n             alpha = 0.5) +\n  tm_layout(main.title = \"Distribution of functional water point by LGAs\",\n            legend.outside = FALSE)\np2 &lt;- tm_shape(NGA_wp) +\n  tm_fill(\"total_wp\",\n          n = 10,\n          style = \"equal\",\n          palette = viridis(10)) +\n  tm_borders(lwd = 0.1,\n             alpha = 0.5) +\n  tm_layout(main.title = \"Distribution of total  water point by LGAs\",\n            legend.outside = FALSE)\ntmap_arrange(p2, p1, nrow = 1)\n\n\n\n\n\n\n\ntmap_mode(\"plot\") # Try explicitly setting the mode\n\n\n\n\n\nWater points are not equally distributed in space. That means that if we do not account for how many water points are somewhere, we end up mapping total water point size rather than our topic of interest.\n\n\nWe will tabulate the proportion of functional water points and the proportion of non-functional water points in each LGA. In the following code chunk, mutate() from dplyr package is used to derive two fields, namely pct_functional and pct_nonfunctional.\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  mutate(pct_functional = wp_functional/total_wp) %&gt;%\n  mutate(pct_nonfunctional = wp_nonfunctional/total_wp)\n\n\n\n\nPlot a choropleth map showing the distribution of percentage functional water point by LGA.\n\ntm_shape(NGA_wp) +\n  tm_fill(\"pct_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\",\n          legend.hist = TRUE) +\n  tm_borders(lwd = 0.1,\n             alpha = 0.3) +\n  tm_layout(main.title = \"Rate map of functional water point by LGAs\",\n            legend.outside = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\nExtreme value maps are variations of common choropleth maps where the classification is designed to highlight extreme values at the lower and upper end of the scale, with the goal of identifying outliers.\nThese maps were developed in the spirit of spatializing EDA, i.e., adding spatial features to commonly used approaches in non-spatial EDA (Anselin 1994).\n\n\nThe percentile map is a special type of quantile map with six specific categories: 0-1%, 1-10%, 10-50%, 50-90%, 90-99%, and 99-100%. The corresponding breakpoints can be derived by means of the base R quantile command, passing an explicit vector of cumulative probabilities as c(0,.01,.1,.5,.9,.99,1). Note that the begin and endpoint need to be included.\n\n\nStep 1: Exclude records with NA by using the code chunk below.\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  drop_na()\n\nStep 2: Creating customised classification and extracting values\n\npercent &lt;- c(0,.01,.1,.5,.9,.99,1)\nvar &lt;- NGA_wp[\"pct_functional\"] %&gt;%\n  st_set_geometry(NULL)\nquantile(var[,1], percent)\n\n       0%        1%       10%       50%       90%       99%      100% \n0.0000000 0.0000000 0.2169811 0.4791667 0.8611111 1.0000000 1.0000000 \n\n\n\n\nNote\n\n\nWhen variables are extracted from an sf data.frame, the geometry is extracted as well. For mapping and spatial manipulation, this is the expected behavior, but many base R functions cannot deal with the geometry. Specifically, the quantile() gives an error. As a result st_set_geomtry(NULL) is used to drop geomtry field.\n\n\n\n\n\nWriting a function has three big advantages over using copy-and-paste:\n\nYou can give a function an evocative name that makes your code easier to understand.\nAs requirements change, you only need to update code in one place, instead of many.\nYou eliminate the chance of making incidental mistakes when you copy and paste (i.e. updating a variable name in one place, but not in another).\n\nSource: Chapter 19: Functions of R for Data Science.\n\n\n\nFirstly, we will write an R function as shown below to extract a variable (i.e. wp_nonfunctional) as a vector out of an sf data.frame.\n\narguments:\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% \n    st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n\nNext, we will write a percentile mapping function by using the code chunk below.\n\n\nShow the code\npercentmap &lt;- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\n  percent &lt;- c(0,.01,.1,.5,.9,.99,1)\n  var &lt;- get.var(vnam, df)\n  bperc &lt;- quantile(var, percent)\n  tm_shape(df) +\n  tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Blues\",\n          labels=c(\"&lt; 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"&gt; 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            main.title.position = \"right\",\n            legend.width = 6,       \n            legend.height = 8,       \n            legend.text.size = 0.9,     \n            legend.title.size = 1.2,\n            legend.frame = FALSE,\n            frame.col = \"grey\",\n            legend.outside = FALSE,\n            frame = FALSE) \n\n}\n\n\n\n\n\nRun function:\n\npercentmap(\"total_wp\", NGA_wp)\n\n\n\n\n\n\n\n\n\n\n\n\nIn essence, a box map is an augmented quartile map, with an additional lower and upper category. When there are lower outliers, then the starting point for the breaks is the minimum value, and the second break is the lower fence. In contrast, when there are no lower outliers, then the starting point for the breaks will be the lower fence, and the second break is the minimum value (there will be no observations that fall in the interval between the lower fence and the minimum value).\n\nggplot(data = NGA_wp,\n       aes(x = \"\",\n           y = wp_nonfunctional)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nDisplaying summary statistics on a choropleth map by using the basic principles of boxplot.\nTo create a box map, a custom breaks specification will be used. However, there is a complication. The break points for the box map vary depending on whether lower or upper outliers are present.\n\n\n\n\n\nThe code chunk below is an R function that creating break points for a box map.\n\narguments:\n\nv: vector with observations\nmult: multiplier for IQR (default 1.5)\n\nreturns:\n\nbb: vector with 7 break points compute quartile and fences\n\n\n\n\nShow the code\nboxbreaks &lt;- function(v,mult=1.5) {\n  qv &lt;- unname(quantile(v))\n  iqr &lt;- qv[4] - qv[2]\n  upfence &lt;- qv[4] + mult * iqr\n  lofence &lt;- qv[2] - mult * iqr\n  # initialize break points vector\n  bb &lt;- vector(mode=\"numeric\",length=7)\n  # logic for lower and upper fences\n  if (lofence &lt; qv[1]) {  # no lower outliers\n    bb[1] &lt;- lofence\n    bb[2] &lt;- floor(qv[1])\n  } else {\n    bb[2] &lt;- lofence\n    bb[1] &lt;- qv[1]\n  }\n  if (upfence &gt; qv[5]) { # no upper outliers\n    bb[7] &lt;- upfence\n    bb[6] &lt;- ceiling(qv[5])\n  } else {\n    bb[6] &lt;- upfence\n    bb[7] &lt;- qv[5]\n  }\n  bb[3:5] &lt;- qv[2:4]\n  return(bb)\n}\n\n\n\n\n\nThe code chunk below is an R function to extract a variable as a vector out of an sf data frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n\nLet’s test the newly created function.\n\nvar &lt;- get.var(\"wp_nonfunctional\", NGA_wp) \nboxbreaks(var)\n\n[1] -56.5   0.0  14.0  34.0  61.0 131.5 278.0\n\n\n\n\n\nThe code chunk below is an R function to create a box map.\n\narguments:\n\nvnam: variable name (as character, in quotes)\ndf: simple features polygon layer\nlegtitle: legend title\nmtitle: map title\nmult: multiplier for IQR -\n\nreturns:\n\na tmap-element (plots a map)\n\n\n\nShow the code\nboxmap &lt;- function(vnam, df, \n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5){\n  var &lt;- get.var(vnam,df)\n  bb &lt;- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,title=legtitle,\n             breaks=bb,\n             palette=\"Blues\",\n          labels = c(\"lower outlier\", \n                     \"&lt; 25%\", \n                     \"25% - 50%\", \n                     \"50% - 75%\",\n                     \"&gt; 75%\", \n                     \"upper outlier\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            main.title.position = c(\"left\"),\n            legend.outside = FALSE,\n            frame = FALSE,\n            legend.frame = FALSE)\n}\n\n\n\n\ntmap_mode(\"plot\")\nboxmap(\"wp_nonfunctional\", NGA_wp)\n\n\n\n\n\n\n\n\n\n\n\n\n\nKam, T. S. (2023, December 4). R for Visual Analytics. https://r4va.netlify.app/",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 8-3"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_3.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_3.html#overview",
    "title": "Hands-on_Ex08_3",
    "section": "",
    "text": "Importing geospatial data in rds format into R environment.\nCreating cartographic quality choropleth maps by using appropriate tmap functions.\nCreating rate map\nCreating percentile map\nCreating boxmap",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 8-3"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_3.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_3.html#getting-started",
    "title": "Hands-on_Ex08_3",
    "section": "",
    "text": "pacman::p_load(sf, tmap, tidyverse)\n\n\n\n\nFor the purpose of this hands-on exercise, a prepared data set called NGA_wp.rds will be used. The data set is a polygon feature data.frame providing information on water point of Nigeria at the LGA level.\n\nNGA_wp &lt;- read_rds(\"data/rds/NGA_wp.rds\")",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 8-3"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_3.html#basic-choropleth-mapping",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_3.html#basic-choropleth-mapping",
    "title": "Hands-on_Ex08_3",
    "section": "",
    "text": "To plot a choropleth map showing the distribution of non-function water point by LGA\n\nlibrary(tmap)\nlibrary(RColorBrewer)\nlibrary(viridis)\np1 &lt;- tm_shape(NGA_wp) +\n  tm_fill(\"wp_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = viridis(10)) +\n  tm_borders(lwd = 0.1,\n             alpha = 0.5) +\n  tm_layout(main.title = \"Distribution of functional water point by LGAs\",\n            legend.outside = FALSE)\np2 &lt;- tm_shape(NGA_wp) +\n  tm_fill(\"total_wp\",\n          n = 10,\n          style = \"equal\",\n          palette = viridis(10)) +\n  tm_borders(lwd = 0.1,\n             alpha = 0.5) +\n  tm_layout(main.title = \"Distribution of total  water point by LGAs\",\n            legend.outside = FALSE)\ntmap_arrange(p2, p1, nrow = 1)\n\n\n\n\n\n\n\ntmap_mode(\"plot\") # Try explicitly setting the mode",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 8-3"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_3.html#choropleth-map-for-rates",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_3.html#choropleth-map-for-rates",
    "title": "Hands-on_Ex08_3",
    "section": "",
    "text": "Water points are not equally distributed in space. That means that if we do not account for how many water points are somewhere, we end up mapping total water point size rather than our topic of interest.\n\n\nWe will tabulate the proportion of functional water points and the proportion of non-functional water points in each LGA. In the following code chunk, mutate() from dplyr package is used to derive two fields, namely pct_functional and pct_nonfunctional.\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  mutate(pct_functional = wp_functional/total_wp) %&gt;%\n  mutate(pct_nonfunctional = wp_nonfunctional/total_wp)\n\n\n\n\nPlot a choropleth map showing the distribution of percentage functional water point by LGA.\n\ntm_shape(NGA_wp) +\n  tm_fill(\"pct_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\",\n          legend.hist = TRUE) +\n  tm_borders(lwd = 0.1,\n             alpha = 0.3) +\n  tm_layout(main.title = \"Rate map of functional water point by LGAs\",\n            legend.outside = TRUE)",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 8-3"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_3.html#extreme-value-maps",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_3.html#extreme-value-maps",
    "title": "Hands-on_Ex08_3",
    "section": "",
    "text": "Extreme value maps are variations of common choropleth maps where the classification is designed to highlight extreme values at the lower and upper end of the scale, with the goal of identifying outliers.\nThese maps were developed in the spirit of spatializing EDA, i.e., adding spatial features to commonly used approaches in non-spatial EDA (Anselin 1994).\n\n\nThe percentile map is a special type of quantile map with six specific categories: 0-1%, 1-10%, 10-50%, 50-90%, 90-99%, and 99-100%. The corresponding breakpoints can be derived by means of the base R quantile command, passing an explicit vector of cumulative probabilities as c(0,.01,.1,.5,.9,.99,1). Note that the begin and endpoint need to be included.\n\n\nStep 1: Exclude records with NA by using the code chunk below.\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  drop_na()\n\nStep 2: Creating customised classification and extracting values\n\npercent &lt;- c(0,.01,.1,.5,.9,.99,1)\nvar &lt;- NGA_wp[\"pct_functional\"] %&gt;%\n  st_set_geometry(NULL)\nquantile(var[,1], percent)\n\n       0%        1%       10%       50%       90%       99%      100% \n0.0000000 0.0000000 0.2169811 0.4791667 0.8611111 1.0000000 1.0000000 \n\n\n\n\nNote\n\n\nWhen variables are extracted from an sf data.frame, the geometry is extracted as well. For mapping and spatial manipulation, this is the expected behavior, but many base R functions cannot deal with the geometry. Specifically, the quantile() gives an error. As a result st_set_geomtry(NULL) is used to drop geomtry field.\n\n\n\n\n\nWriting a function has three big advantages over using copy-and-paste:\n\nYou can give a function an evocative name that makes your code easier to understand.\nAs requirements change, you only need to update code in one place, instead of many.\nYou eliminate the chance of making incidental mistakes when you copy and paste (i.e. updating a variable name in one place, but not in another).\n\nSource: Chapter 19: Functions of R for Data Science.\n\n\n\nFirstly, we will write an R function as shown below to extract a variable (i.e. wp_nonfunctional) as a vector out of an sf data.frame.\n\narguments:\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% \n    st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n\nNext, we will write a percentile mapping function by using the code chunk below.\n\n\nShow the code\npercentmap &lt;- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\n  percent &lt;- c(0,.01,.1,.5,.9,.99,1)\n  var &lt;- get.var(vnam, df)\n  bperc &lt;- quantile(var, percent)\n  tm_shape(df) +\n  tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Blues\",\n          labels=c(\"&lt; 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"&gt; 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            main.title.position = \"right\",\n            legend.width = 6,       \n            legend.height = 8,       \n            legend.text.size = 0.9,     \n            legend.title.size = 1.2,\n            legend.frame = FALSE,\n            frame.col = \"grey\",\n            legend.outside = FALSE,\n            frame = FALSE) \n\n}\n\n\n\n\n\nRun function:\n\npercentmap(\"total_wp\", NGA_wp)\n\n\n\n\n\n\n\n\n\n\n\n\nIn essence, a box map is an augmented quartile map, with an additional lower and upper category. When there are lower outliers, then the starting point for the breaks is the minimum value, and the second break is the lower fence. In contrast, when there are no lower outliers, then the starting point for the breaks will be the lower fence, and the second break is the minimum value (there will be no observations that fall in the interval between the lower fence and the minimum value).\n\nggplot(data = NGA_wp,\n       aes(x = \"\",\n           y = wp_nonfunctional)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nDisplaying summary statistics on a choropleth map by using the basic principles of boxplot.\nTo create a box map, a custom breaks specification will be used. However, there is a complication. The break points for the box map vary depending on whether lower or upper outliers are present.\n\n\n\n\n\nThe code chunk below is an R function that creating break points for a box map.\n\narguments:\n\nv: vector with observations\nmult: multiplier for IQR (default 1.5)\n\nreturns:\n\nbb: vector with 7 break points compute quartile and fences\n\n\n\n\nShow the code\nboxbreaks &lt;- function(v,mult=1.5) {\n  qv &lt;- unname(quantile(v))\n  iqr &lt;- qv[4] - qv[2]\n  upfence &lt;- qv[4] + mult * iqr\n  lofence &lt;- qv[2] - mult * iqr\n  # initialize break points vector\n  bb &lt;- vector(mode=\"numeric\",length=7)\n  # logic for lower and upper fences\n  if (lofence &lt; qv[1]) {  # no lower outliers\n    bb[1] &lt;- lofence\n    bb[2] &lt;- floor(qv[1])\n  } else {\n    bb[2] &lt;- lofence\n    bb[1] &lt;- qv[1]\n  }\n  if (upfence &gt; qv[5]) { # no upper outliers\n    bb[7] &lt;- upfence\n    bb[6] &lt;- ceiling(qv[5])\n  } else {\n    bb[6] &lt;- upfence\n    bb[7] &lt;- qv[5]\n  }\n  bb[3:5] &lt;- qv[2:4]\n  return(bb)\n}\n\n\n\n\n\nThe code chunk below is an R function to extract a variable as a vector out of an sf data frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n\nLet’s test the newly created function.\n\nvar &lt;- get.var(\"wp_nonfunctional\", NGA_wp) \nboxbreaks(var)\n\n[1] -56.5   0.0  14.0  34.0  61.0 131.5 278.0\n\n\n\n\n\nThe code chunk below is an R function to create a box map.\n\narguments:\n\nvnam: variable name (as character, in quotes)\ndf: simple features polygon layer\nlegtitle: legend title\nmtitle: map title\nmult: multiplier for IQR -\n\nreturns:\n\na tmap-element (plots a map)\n\n\n\nShow the code\nboxmap &lt;- function(vnam, df, \n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5){\n  var &lt;- get.var(vnam,df)\n  bb &lt;- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,title=legtitle,\n             breaks=bb,\n             palette=\"Blues\",\n          labels = c(\"lower outlier\", \n                     \"&lt; 25%\", \n                     \"25% - 50%\", \n                     \"50% - 75%\",\n                     \"&gt; 75%\", \n                     \"upper outlier\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            main.title.position = c(\"left\"),\n            legend.outside = FALSE,\n            frame = FALSE,\n            legend.frame = FALSE)\n}\n\n\n\n\ntmap_mode(\"plot\")\nboxmap(\"wp_nonfunctional\", NGA_wp)",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 8-3"
    ]
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_3.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_3.html#reference",
    "title": "Hands-on_Ex08_3",
    "section": "",
    "text": "Kam, T. S. (2023, December 4). R for Visual Analytics. https://r4va.netlify.app/",
    "crumbs": [
      "![](/images/house.svg)",
      "Hands-on Exercise",
      "Hands-on Exercise 8-3"
    ]
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01.html#overview",
    "href": "Take-home_Ex/Take-home_Ex01.html#overview",
    "title": "Take-home Exercise 1",
    "section": "1 Overview",
    "text": "1 Overview\n\n1.1 Abstract\nThis study presents an in-depth analysis of ship performance and profitability, focusing on various operational metrics, ship types, and environmental factors. Using a dataset spanning one year, the study identifies seasonal trends in voyage frequencies, revealing fluctuations in ship activity during specific months, particularly among bulk carriers. Visualisation plots was used to explore profitability across ship types, with key performance drivers such as engine type, maintenance status, route type, and operational efficiency playing significant roles in financial outcomes. Findings suggest that while rough weather conditions and longer turnaround times tend to reduce profitability, specific ship-engine combinations exhibit resilience under varying conditions. Time-based profit trends indicate an overall upward trajectory, with several months showing notable profitability increases.\n\n\n1.2 Task\nAn international media company that publishes weekly content on digital platforms is planning to release articles on “Ship Performance in the Gulf of Guinea”. As a graphical editor of the media company, I am going to prepare data visualisation for the article focusing on ship performance assessment.\nThis report will use Exploratory Data Analysis (EDA) methods and ggplot2 functions to visualise insights on 1. Ships’ profitability 2. Operational factors affecting voyage performance.",
    "crumbs": [
      "![](/images/house.svg)",
      "Take-home Exercise",
      "Take-home_Ex01"
    ]
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01.html#install-and-load-packages",
    "href": "Take-home_Ex/Take-home_Ex01.html#install-and-load-packages",
    "title": "Take-home Exercise 1",
    "section": "2 Install and Load Packages",
    "text": "2 Install and Load Packages\n\npacman::p_load(tidyverse, ggplot2, haven, knitr, patchwork, ggthemes, \n               ggridges, gganimate,ggdist, ggtext, colorspace, magrittr, \n               patchwork, RColorBrewer, ggstatsplot, egg, geomtextpath, \n               readxl, performance, parameters, see, ggiraph, plotlyr,\n               treemap, treemapify)",
    "crumbs": [
      "![](/images/house.svg)",
      "Take-home Exercise",
      "Take-home_Ex01"
    ]
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01.html#data-preparation",
    "href": "Take-home_Ex/Take-home_Ex01.html#data-preparation",
    "title": "Take-home Exercise 1",
    "section": "3 Data Preparation",
    "text": "3 Data Preparation\nThe dataset Ship Performance Clustering Dataset is downloaded from Kagglel.com. This file contains a detailed dataset focusing on the operational performance of various ship types across different routes. Each row represents the performance metrics and attributes for a specific voyage or ship over a given timeframe.\n\n3.1 Import file and check\nImport the csv file using read_csv().\n\ndata_ship &lt;- read_csv(\"data/Ship_Pfm_Dataset.csv\")\n\nNext I would like to observe the variables and their data type and understand the dataset.\nThe dataset consists of 18 columns and 2,736 rows (observations). Each observation contains an entry recording a voyage for which the ship’s profile and operational information. As the result of code shows, there are 5 categorical variables, 1 date variable and 12 numerical variables.\n\nglimpse(data_ship)\n\nRows: 2,736\nColumns: 18\n$ Date                    &lt;date&gt; 2023-06-04, 2023-06-11, 2023-06-18, 2023-06-2…\n$ Ship_Type               &lt;chr&gt; \"Container Ship\", \"Fish Carrier\", \"Container S…\n$ Route_Type              &lt;chr&gt; \"None\", \"Short-haul\", \"Long-haul\", \"Transocean…\n$ Engine_Type             &lt;chr&gt; \"Heavy Fuel Oil (HFO)\", \"Steam Turbine\", \"Dies…\n$ Maintenance_Status      &lt;chr&gt; \"Critical\", \"Good\", \"Fair\", \"Fair\", \"Fair\", \"F…\n$ Speed_Over_Ground_knots &lt;dbl&gt; 12.59756, 10.38758, 20.74975, 21.05510, 13.742…\n$ Engine_Power_kW         &lt;dbl&gt; 2062.9840, 1796.0574, 1648.5567, 915.2618, 108…\n$ Distance_Traveled_nm    &lt;dbl&gt; 1030.9436, 1060.4864, 658.8741, 1126.8225, 144…\n$ Draft_meters            &lt;dbl&gt; 14.132284, 14.653083, 7.199261, 11.789063, 9.7…\n$ Weather_Condition       &lt;chr&gt; \"Moderate\", \"Rough\", \"Moderate\", \"Moderate\", \"…\n$ Cargo_Weight_tons       &lt;dbl&gt; 1959.0179, 162.3947, 178.0409, 1737.3853, 260.…\n$ Operational_Cost_USD    &lt;dbl&gt; 483832.35, 483388.00, 448543.40, 261349.61, 28…\n$ Revenue_per_Voyage_USD  &lt;dbl&gt; 292183.27, 883765.79, 394018.75, 87551.38, 676…\n$ Turnaround_Time_hours   &lt;dbl&gt; 25.86708, 63.24820, 49.41815, 22.40911, 64.158…\n$ Efficiency_nm_per_kWh   &lt;dbl&gt; 1.4551789, 0.2903614, 0.4995945, 0.7029057, 1.…\n$ Seasonal_Impact_Score   &lt;dbl&gt; 1.4156533, 0.8856478, 1.4058132, 1.3707043, 0.…\n$ Weekly_Voyage_Count     &lt;dbl&gt; 1, 6, 9, 1, 8, 7, 3, 6, 8, 2, 9, 4, 3, 7, 7, 3…\n$ Average_Load_Percentage &lt;dbl&gt; 93.76925, 93.89537, 96.21824, 66.19370, 80.008…\n\n\n\n\n3.2 Data Wrangling\nThe diagram below shows the variables selected for this study:\n\n\n\n\n\n\n3.2.1 Add a variable\nTo assess the ships’ finance performance, I will add a variable Profit, deriving from Revenue_per_Voyage_USD subtracting Operational_Cost_USD.\nProfit = (Revenue_per_Voyage_USD - Operational_Cost_USD)\n\nlibrary(dplyr)\ndata_ship &lt;- data_ship %&gt;%\n  mutate(Profit = Revenue_per_Voyage_USD - Operational_Cost_USD)\n\nNow, I will use str() to have a look and confirm Profit is added to the data frame and the data type is numeric.\n\nstr(data_ship)\n\ntibble [2,736 × 19] (S3: tbl_df/tbl/data.frame)\n $ Date                   : Date[1:2736], format: \"2023-06-04\" \"2023-06-11\" ...\n $ Ship_Type              : chr [1:2736] \"Container Ship\" \"Fish Carrier\" \"Container Ship\" \"Bulk Carrier\" ...\n $ Route_Type             : chr [1:2736] \"None\" \"Short-haul\" \"Long-haul\" \"Transoceanic\" ...\n $ Engine_Type            : chr [1:2736] \"Heavy Fuel Oil (HFO)\" \"Steam Turbine\" \"Diesel\" \"Steam Turbine\" ...\n $ Maintenance_Status     : chr [1:2736] \"Critical\" \"Good\" \"Fair\" \"Fair\" ...\n $ Speed_Over_Ground_knots: num [1:2736] 12.6 10.4 20.7 21.1 13.7 ...\n $ Engine_Power_kW        : num [1:2736] 2063 1796 1649 915 1090 ...\n $ Distance_Traveled_nm   : num [1:2736] 1031 1060 659 1127 1445 ...\n $ Draft_meters           : num [1:2736] 14.13 14.65 7.2 11.79 9.73 ...\n $ Weather_Condition      : chr [1:2736] \"Moderate\" \"Rough\" \"Moderate\" \"Moderate\" ...\n $ Cargo_Weight_tons      : num [1:2736] 1959 162 178 1737 261 ...\n $ Operational_Cost_USD   : num [1:2736] 483832 483388 448543 261350 287718 ...\n $ Revenue_per_Voyage_USD : num [1:2736] 292183 883766 394019 87551 676121 ...\n $ Turnaround_Time_hours  : num [1:2736] 25.9 63.2 49.4 22.4 64.2 ...\n $ Efficiency_nm_per_kWh  : num [1:2736] 1.455 0.29 0.5 0.703 1.331 ...\n $ Seasonal_Impact_Score  : num [1:2736] 1.416 0.886 1.406 1.371 0.583 ...\n $ Weekly_Voyage_Count    : num [1:2736] 1 6 9 1 8 7 3 6 8 2 ...\n $ Average_Load_Percentage: num [1:2736] 93.8 93.9 96.2 66.2 80 ...\n $ Profit                 : num [1:2736] -191649 400378 -54525 -173798 388403 ...\n\n\nNext, let’s use summary() to run a summary of the dataset to understand the overall statistics of the data.\n\nsummary(data_ship)\n\n      Date             Ship_Type          Route_Type        Engine_Type       \n Min.   :2023-06-04   Length:2736        Length:2736        Length:2736       \n 1st Qu.:2023-09-10   Class :character   Class :character   Class :character  \n Median :2023-12-17   Mode  :character   Mode  :character   Mode  :character  \n Mean   :2023-12-17                                                           \n 3rd Qu.:2024-03-24                                                           \n Max.   :2024-06-30                                                           \n Maintenance_Status Speed_Over_Ground_knots Engine_Power_kW\n Length:2736        Min.   :10.01           Min.   : 501   \n Class :character   1st Qu.:13.93           1st Qu.:1148   \n Mode  :character   Median :17.71           Median :1757   \n                    Mean   :17.60           Mean   :1758   \n                    3rd Qu.:21.28           3rd Qu.:2383   \n                    Max.   :25.00           Max.   :2999   \n Distance_Traveled_nm  Draft_meters    Weather_Condition  Cargo_Weight_tons\n Min.   :  50.43      Min.   : 5.002   Length:2736        Min.   :  50.23  \n 1st Qu.: 548.51      1st Qu.: 7.437   Class :character   1st Qu.: 553.98  \n Median :1037.82      Median : 9.919   Mode  :character   Median :1043.21  \n Mean   :1036.41      Mean   : 9.929                      Mean   :1032.57  \n 3rd Qu.:1540.93      3rd Qu.:12.413                      3rd Qu.:1527.72  \n Max.   :1998.34      Max.   :14.993                      Max.   :1999.13  \n Operational_Cost_USD Revenue_per_Voyage_USD Turnaround_Time_hours\n Min.   : 10092       Min.   : 50352         Min.   :12.02        \n 1st Qu.:131293       1st Qu.:290346         1st Qu.:26.17        \n Median :257158       Median :520177         Median :41.59        \n Mean   :255143       Mean   :521362         Mean   :41.75        \n 3rd Qu.:381797       3rd Qu.:750073         3rd Qu.:57.36        \n Max.   :499735       Max.   :999917         Max.   :71.97        \n Efficiency_nm_per_kWh Seasonal_Impact_Score Weekly_Voyage_Count\n Min.   :0.1002        Min.   :0.500         Min.   :1.000      \n 1st Qu.:0.4636        1st Qu.:0.758         1st Qu.:3.000      \n Median :0.7899        Median :1.009         Median :5.000      \n Mean   :0.7987        Mean   :1.004         Mean   :4.915      \n 3rd Qu.:1.1474        3rd Qu.:1.253         3rd Qu.:7.000      \n Max.   :1.4993        Max.   :1.499         Max.   :9.000      \n Average_Load_Percentage     Profit       \n Min.   : 50.01          Min.   :-444584  \n 1st Qu.: 62.70          1st Qu.:  40885  \n Median : 75.50          Median : 262716  \n Mean   : 75.22          Mean   : 266219  \n 3rd Qu.: 87.72          3rd Qu.: 492216  \n Max.   :100.00          Max.   : 977168  \n\n\n\n\n3.2.2 Variable selection\nTo perform an analysis to achieve the objectives aforementioned, the following variables will be selected.\n\nVariable Selection\n:\n\n\n\n\n\n\n\n\n\nCategory\nVariable\nDescription\nType\nValue\n\n\n\n\nOperation\nDate\nDate\ndate\nYYYY-MM-DD\n\n\nShip\nShip_Type\nType of ship\nchar\nTanker, Container Ship, Fish Carrier, Bulk Carrier\n\n\nOperations\nRoute_Type\nShipping route type\nchar\nShort-haul, Long-haul, Transoceanic\n\n\nShip\nEngine_Type\nType of engine\nchar\nDiesel, Heavy Fuel Oil\n\n\nShip\nMaintenance_Status\nMaintenance condition of the ship\nchar\nFair, Critical, Good\n\n\nShip\nSpeed_Over_Ground_knots\nAverage speed of the ship over water (in knots).\nnum\n\n\n\nShip\nEngine_Power_kW\nEngine power output (in kilowatts).\nnum\n\n\n\nShip\nDistance_Traveled_nm\nTotal distance traveled by the ship (in nautical miles).\nnum\n\n\n\nOperations\nWeather_Condition\nPrevailing weather conditions during voyages\nchar\nCalm, Moderate, Rough\n\n\nOperations\nCargo_Weight_tons\nbbb\nnum\n\n\n\nBusiness\nOperational_Cost_USD\nTotal operational cost per voyage (in thousand USD).\nnum\n\n\n\nBusiness\nRevenue_per_Voyage_USD\nRevenue generated per voyage (in thousand USD).\nnum\n\n\n\nShip\nTurnaround_Time_hours\nTurnaround time of the voyage\nnum\n\n\n\nShip\nEfficiency_nm_per_kWh\nEnergy efficiency calculated in nautical miles per kilowatt-hour.\nnum\n\n\n\nOperations\nAverage_Load_Percentage\nAverage of the load capacity (%)\nnum\n\n\n\nBusiness\nProfit\nEarning from a voyage (in thousand USD)\nnum\n\n\n\n\nThe code below is used to select and reorder columns of wanted variables using select()\n\nship &lt;- data_ship %&gt;%\n  \n  select(Date, Ship_Type, Route_Type, Engine_Type, Maintenance_Status, Speed_Over_Ground_knots,\n        Engine_Power_kW, Distance_Traveled_nm, Efficiency_nm_per_kWh,\n        Weather_Condition, Profit, Operational_Cost_USD, Revenue_per_Voyage_USD,  \n        Average_Load_Percentage, Cargo_Weight_tons, Turnaround_Time_hours) \n\nUse glimese() to check and confirm the new data frame ship is created, and now has 16 columns.\n\nglimpse(ship)\n\nRows: 2,736\nColumns: 16\n$ Date                    &lt;date&gt; 2023-06-04, 2023-06-11, 2023-06-18, 2023-06-2…\n$ Ship_Type               &lt;chr&gt; \"Container Ship\", \"Fish Carrier\", \"Container S…\n$ Route_Type              &lt;chr&gt; \"None\", \"Short-haul\", \"Long-haul\", \"Transocean…\n$ Engine_Type             &lt;chr&gt; \"Heavy Fuel Oil (HFO)\", \"Steam Turbine\", \"Dies…\n$ Maintenance_Status      &lt;chr&gt; \"Critical\", \"Good\", \"Fair\", \"Fair\", \"Fair\", \"F…\n$ Speed_Over_Ground_knots &lt;dbl&gt; 12.59756, 10.38758, 20.74975, 21.05510, 13.742…\n$ Engine_Power_kW         &lt;dbl&gt; 2062.9840, 1796.0574, 1648.5567, 915.2618, 108…\n$ Distance_Traveled_nm    &lt;dbl&gt; 1030.9436, 1060.4864, 658.8741, 1126.8225, 144…\n$ Efficiency_nm_per_kWh   &lt;dbl&gt; 1.4551789, 0.2903614, 0.4995945, 0.7029057, 1.…\n$ Weather_Condition       &lt;chr&gt; \"Moderate\", \"Rough\", \"Moderate\", \"Moderate\", \"…\n$ Profit                  &lt;dbl&gt; -191649.081, 400377.787, -54524.657, -173798.2…\n$ Operational_Cost_USD    &lt;dbl&gt; 483832.35, 483388.00, 448543.40, 261349.61, 28…\n$ Revenue_per_Voyage_USD  &lt;dbl&gt; 292183.27, 883765.79, 394018.75, 87551.38, 676…\n$ Average_Load_Percentage &lt;dbl&gt; 93.76925, 93.89537, 96.21824, 66.19370, 80.008…\n$ Cargo_Weight_tons       &lt;dbl&gt; 1959.0179, 162.3947, 178.0409, 1737.3853, 260.…\n$ Turnaround_Time_hours   &lt;dbl&gt; 25.86708, 63.24820, 49.41815, 22.40911, 64.158…\n\n\n\n\n3.2.3 Missing values\nBefore I use the selected data to perform analysis, I want to check if there are missing values to remove. If an entry has a missing value, it may affect the analysis result.\nis.na() can be used to check this. Before I dive into each variable, I would like to have an overall check if there indeed are missing values. After this check, there is no missing value found.\n\nwhich(is.na(ship))\n\ninteger(0)\n\nsum(is.na(ship))\n\n[1] 0\n\n\nWe see no missing values in numeric data. However, we observed some “None” values in the character data types: Ship_Type, Route_Type, Engine_Type, and Weather_Condition. Therefore, I will remove entries containing “None” using the code below. As a result, a tibble frame of 2,127 entries is derived.\n\nlibrary(dplyr)\n\n#check row numbers before filter\nnrow(ship)\n\n[1] 2736\n\nship_filter &lt;- ship %&gt;%\n  filter(!if_any(c(Ship_Type, Route_Type, Engine_Type, Weather_Condition, Maintenance_Status), ~ .x == \"None\"))\n\n#check row numbers after filter\nnrow(ship_filter) \n\n[1] 2127\n\n\n\n\n3.2.4 Convert data type\nFrom 3.2.2, I observed that Maintenance_Status, Weather_Condition, Ship_Type, Route_Type, Engine_Type are all character data type. In fact, Maintenance_Status, Weather_Condition can be converted to ordinal data type, and Ship_Type, Route_Type, Engine_Type to factor data type to derive better result.\nUse the code below to perform data type conversion:\n\ncol_f &lt;- c(\"Ship_Type\", \"Route_Type\", \"Engine_Type\", \"Weather_Condition\")\n#Column names should be in quotation marks (\" \")\n\nship_filter &lt;- ship_filter %&gt;%\n  mutate(across(col_f, as.factor)) %&gt;%\n  mutate(Maintenance_Status = factor(Maintenance_Status,\n                                     levels = c(\"Good\", \"Fair\", \"Critical\"),\n                                     ordered = TRUE)) \n\nI also want to convert the unit for the monetary values into thousand dollars as the unit for Operational_Cost_USD, Revenue_per_Voyage_USD and Profit.\n\nship_filter &lt;- ship_filter %&gt;%\n  mutate(Operational_Cost_USD = round(Operational_Cost_USD / 1000, 0), #convert to thousand dollars, leaving on decimal places.\n         Revenue_per_Voyage_USD = round(Revenue_per_Voyage_USD / 1000, 0),\n         Profit = round(Profit / 1000, 0))\n\nI use kable() to check the conversion result, and confirm the desired variables have been converted accordingly.\n\nkable(head(ship_filter, n=3), caption = \"Ship Performance Dataset\")\n\n\nShip Performance Dataset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDate\nShip_Type\nRoute_Type\nEngine_Type\nMaintenance_Status\nSpeed_Over_Ground_knots\nEngine_Power_kW\nDistance_Traveled_nm\nEfficiency_nm_per_kWh\nWeather_Condition\nProfit\nOperational_Cost_USD\nRevenue_per_Voyage_USD\nAverage_Load_Percentage\nCargo_Weight_tons\nTurnaround_Time_hours\n\n\n\n\n2023-06-11\nFish Carrier\nShort-haul\nSteam Turbine\nGood\n10.38758\n1796.0574\n1060.4864\n0.2903614\nRough\n400\n483\n884\n93.89537\n162.3947\n63.24820\n\n\n2023-06-18\nContainer Ship\nLong-haul\nDiesel\nFair\n20.74975\n1648.5567\n658.8741\n0.4995945\nModerate\n-55\n449\n394\n96.21824\n178.0409\n49.41815\n\n\n2023-06-25\nBulk Carrier\nTransoceanic\nSteam Turbine\nFair\n21.05510\n915.2618\n1126.8225\n0.7029057\nModerate\n-174\n261\n88\n66.19370\n1737.3853\n22.40911",
    "crumbs": [
      "![](/images/house.svg)",
      "Take-home Exercise",
      "Take-home_Ex01"
    ]
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01.html#voyage-profile",
    "href": "Take-home_Ex/Take-home_Ex01.html#voyage-profile",
    "title": "Take-home Exercise 1",
    "section": "4 Voyage Profile",
    "text": "4 Voyage Profile\nTo perform profit performance analysis in the next section, we shall understand the profile of the data and variables to determine the direction for the performance analysis. Below I will utilise variables to visualise ship conditions, weather conditions and operational factors by the different ship types to obtain preliminary understanding of patterns or trends.\n\n4.1 Ship conditions & routes\n\n\nShow the code\n# Code bar chart for Ship type\np_st &lt;- ggplot(data = ship_filter,\n               aes(x = Ship_Type)) +\n  geom_bar(fill = \"grey20\") +\n  ylim(0, 1000) +\n  geom_text(stat=\"count\",\n            aes(label = paste0(after_stat(count),\", \",\n                               round(after_stat(count)/sum(after_stat(count))*100, 0), \"%\")),\n            vjust = -0.5,\n            size = 3) +\n  labs(x = \"\",\n       y = \"\",\n       title = \"Ship types\") +\n  theme_classic() +\n  theme(plot.background = element_rect(fill = \"#f1f4f5\"),\n        panel.background = element_rect(fill = \"#f1f4f5\"),\n        panel.border = element_blank(),\n        plot.title = element_text(size = 10, face = \"bold\"),\n        text = element_text(size = 10))\n\n# Code bar chart for Engine type\n\np_et &lt;- ggplot(data = ship_filter,\n               aes(x = Engine_Type)) +\n  geom_bar(fill = \"grey20\") +\n  ylim(0, 1000) +\n  geom_text(stat=\"count\",\n            aes(label = paste0(after_stat(count),\", \",\n                               round(after_stat(count)/sum(after_stat(count))*100, 0), \"%\")),\n            vjust = -0.5,\n            size = 3) +\n  labs(x = \"\",\n       y = \"\",\n       title = \"Engine types\") +\n  theme_classic() +\n  theme(plot.background = element_rect(fill = \"#f1f4f5\"),\n        panel.background = element_rect(fill = \"#f1f4f5\"),\n        panel.border = element_blank(),\n        plot.title = element_text(size = 10, face = \"bold\"),\n        text = element_text(size = 10))\n\n\n# Code bar chart for Route type\n\np_rt &lt;- ggplot(data = ship_filter,\n               aes(x = Route_Type)) +\n  geom_bar(fill = \"grey20\") +\n  ylim(0, 1000) +\n  geom_text(stat=\"count\",\n            aes(label = paste0(after_stat(count),\", \",\n                               round(after_stat(count)/sum(after_stat(count))*100, 0), \"%\")),\n            vjust = -0.5,\n            size = 3) +\n  labs(x = \"\",\n       y = \"\",\n       title = \"Route types\") +\n  theme_classic() +\n  theme(plot.background = element_rect(fill = \"#f1f4f5\"),\n        panel.background = element_rect(fill = \"#f1f4f5\"),\n        panel.border = element_blank(),\n        plot.title = element_text(size = 10, face = \"bold\"),\n        text = element_text(size = 10))\n\n#Code bar chart for Maintenance status\n\np_ms &lt;- ggplot(data = ship_filter,\n               aes(x = Maintenance_Status)) +\n  geom_bar(fill = \"grey20\") +\n  ylim(0, 1000) +\n  geom_text(stat=\"count\",\n            aes(label = paste0(after_stat(count),\", \",\n                               round(after_stat(count)/sum(after_stat(count))*100, 0), \"%\")),\n            vjust = -0.5,\n            size = 3) +\n  labs(x = \"\",\n       y = \"\",\n       title = \"Maintenance status\") +\n  theme_classic() +\n  theme(plot.background = element_rect(fill = \"#f1f4f5\"),\n        panel.background = element_rect(fill = \"#f1f4f5\"),\n        panel.border = element_blank(),\n        plot.title = element_text(size = 10, face = \"bold\"),\n        text = element_text(size = 10))\n\n#Combine all charts\n\npatchwork &lt;- (p_st | p_et) / (p_rt | p_ms)\npatchwork\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\nThe dataset is fairly evenly distributed across different ship types, engine types, route types, and maintenance statuses, with each category varying by 0 ~ 3%.\nThe largest different is between Long-haul trips and Short haul, Transoceanic, which is 3%.\n\n\n\n\n\n\n4.2 Weather conditions\nI aimed to analyse the overall voyage distribution of weather conditions as well as their trends over time with geom_bar(). Bar charts is used to represent the distribution, while a stacked bar chart visualises the percentage occurrence of the three different weather conditions within each month.\n\n\nShow the code\n#Plot1\np_wthr_1 &lt;- ggplot(data = ship_filter,\n               aes(x = Weather_Condition, fill = Weather_Condition)) +\n  geom_bar() +\n  ylim(0, 1000) +\n  geom_text(stat=\"count\",\n            aes(label = paste0(after_stat(count),\", \",\n                               round(after_stat(count)/sum(after_stat(count))*100, 0), \"%\")),\n            vjust = -0.5,\n            size = 3) +\n  scale_fill_manual(values = c(\"Calm\" = \"#bcd6be\",\n                               \"Moderate\" = \"#f5e8ce\",\n                               \"Rough\" = \"#e0bcc0\")) +\n  labs(x = \"\",\n       y = \"\",\n       title = \"Weather Condition \\n Overview\") +\n  theme_light() +\n  theme(plot.background = element_rect(fill = \"#f1f4f5\"),\n        panel.background = element_rect(fill = \"#f1f4f5\"),\n        panel.border = element_blank(),\n        plot.title = element_text(size = 12, face = \"bold\"),\n        text = element_text(size = 8),\n        legend.text = element_text(size = 8),  \n        legend.title = element_text(size = 8, face = \"bold\"),  \n#        legend.key.size = unit(0.5, \"cm\"),  \n#        legend.spacing.y = unit(0.3, \"cm\"),\n        legend.position = \"none\")  \n\n# Plot2\n# Extract month and year from the Date\nship_filter_month &lt;- ship_filter %&gt;%\n  mutate(Month = floor_date(Date, \"month\"))\n\n# Group by Month and Weather type, then count occurrences\nweather_by_month_bar &lt;- ship_filter_month %&gt;%\n  group_by(Month, Weather_Condition) %&gt;%\n  summarise(Count = n(), .groups = \"drop\")\n\n# Calculate total occurrences per month\ntotal_per_month_bar &lt;- weather_by_month_bar %&gt;%\n  group_by(Month) %&gt;%\n  summarise(Total = sum(Count))\n\n# Join total occurrences per month and compute percentage\nweather_percentage_bar &lt;- weather_by_month_bar %&gt;%\n  left_join(total_per_month_bar, by = \"Month\") %&gt;%\n  mutate(Percentage = (Count / Total) * 100) \n\n# Plot stacked bar chart with percentage\np_wthr_2 &lt;- ggplot(weather_percentage_bar, \n       aes(x = Month, y = Percentage, fill = factor(Weather_Condition, levels = c(\"Calm\", \"Moderate\", \"Rough\")))) +\n  geom_bar(stat = \"identity\", position = \"stack\") +  # Use identity because we computed percentages\n  geom_text(aes(label = paste0(round(Percentage, 0), \"%\")), \n            position = position_stack(vjust = 0.5),  \n            size = 3, color = \"black\") +  \n  scale_fill_manual(values = c(\"Calm\" = \"#bcd6be\",\n                               \"Moderate\" = \"#f5e8ce\",\n                               \"Rough\" = \"#e0bcc0\")) + \n  labs(title = \"Weather Distribution by Month (%)\",\n       x = \"Month\",\n       y = \"Percentage (%)\",\n       fill = \"Weather\") +\n  theme_article() +\n  scale_x_date(labels = scales::date_format(\"%m/%y\"), breaks = \"1 month\") + \n  theme(plot.title = element_text(size = 12, face = \"bold\"),\n        plot.background = element_rect(fill = \"#f1f4f5\"),\n        panel.background = element_rect(fill = \"#f1f4f5\"),\n        panel.border = element_blank(),\n        text = element_text(size = 8),\n        legend.text = element_text(size = 8),  \n        legend.title = element_text(size = 8, face = \"bold\"), \n        legend.key.size = unit(0.5, \"cm\"),  \n        legend.spacing.y = unit(0.3, \"cm\"),\n        legend.position = \"top\")  \n\n#Combine plots\np_wthr_2 + p_wthr_1 + plot_layout(widths = c(2.5,1))\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\nThe Weather Condition Overview chart on the right shows that voyages in rough weather occur less frequently than those in other weather conditions, yet they still make up over 30% of the year. While ships primarily operate in fine weather, nearly one-third of the journeys experience rough conditions for both the ships and personnel.\nJanuary recorded the fewest rough journeys compared to other months, while April had the highest count of rough journeys.\nShips are capable of operating under any weather condition throughout the year. There is no specific month when the journeys were consistently exceptional or consistently poor.\n\n\n\n\n\n4.3 Operational effects by ship type and route type\nThis section delves into the operational performance of various ships, examining key factors such as average load, engine power, cargo weight, turnaround time, distance traveled, and energy efficiency. To visualize the distribution of these factors across different ship and route types, stat_halfeye() is used to generate half-eye plots. This method offers a clear view of the distributions, revealing trends and the spread of each operational effect. By comparing these distributions, I aim to identify how different ship types and routes may influence these operational effects.\n\nAverage loadEngine powerCargo weightTurnaround timeDistance travelledEnergy efficiency\n\n\n\n\nShow the code\n#Plot1\np_heye_al &lt;- ggplot(ship_filter,\n       aes(x = Ship_Type,\n           y = Average_Load_Percentage,\n           fill = Route_Type)) +\n  ggdist::stat_halfeye(.width=c(0,1), adjust = .5,\n                       shape = 21,\n                       point_size = 1,\n                       interval_color = \"grey70\") +\n  scale_fill_manual(values = c(\"Coastal\" = adjustcolor(\"#FF9EAA\", alpha.f = 0.5),\n                               \"Long-haul\" = adjustcolor(\"#3AA6B9\", alpha.f = 0.5), \n                               \"Short-haul\" = adjustcolor(\"#e0c080\", alpha.f = 0.5),\n                               \"Transoceanic\" = adjustcolor(\"grey70\", alpha.f = 0.5)),\n                               name = NULL) +\n  labs(title = \"Halfeye Plots by Route Type\") +\n  theme(plot.background = element_rect(fill = \"#f1f4f5\", color = NA),\n        panel.background = element_rect(fill = \"#f1f4f5\", color = NA),\n        legend.background = element_rect(fill = \"#f1f4f5\", color = NA),  \n        legend.key = element_rect(fill = \"#f1f4f5\", color = NA)\n        )\n\n\n#Plot2\n\nmedian_load = median(ship_filter$Average_Load_Percentage)\n\np_heye_al_st &lt;- ggplot(ship_filter,\n       aes(x = Ship_Type,\n           y = Average_Load_Percentage)) +\n  ggdist::stat_interval(.width = 1:4*.25) +\n  ggdist::stat_halfeye(.width = 0, fill = \"grey80\", color = \"white\", position = position_nudge(x = .024)) +\n  scale_color_viridis_d(option = \"mako\", direction = -1, end = .9) +\n  geom_hline(yintercept = median_load, linetype = \"dashed\", color = \"#3AA6B9\") +  # Add median line\n  annotate(\"text\", x = 1.2, y = median_load, label = paste(\"Median:\", round(median_load, 2)),\n            color = \"#3AA6B9\", vjust = -1, hjust = 0, size = 3) +  # Add text label\n  labs(title = \"Halfeye Plots with Median Line\") +\n  theme(plot.background = element_rect(fill = \"#f1f4f5\", color = NA),\n        panel.background = element_rect(fill = \"#f1f4f5\", color = NA),\n        legend.background = element_rect(fill = \"#f1f4f5\", color = NA),  \n        legend.key = element_rect(fill = \"#f1f4f5\", color = NA)\n        )\n\n#Combine plots\np_heye_al_st / p_heye_al + plot_layout(height = c(1, 1.5))\n\n\n\n\n\n\n\n\n\n\n\nObervations\n\n\nAcross various operational effects, none of the distributions follow a normal distribution. Instead, multimodal distributions are observed across the four route types for each ship type. Although the median scores vary among different ship types and route types for these operational effects, they all converge towards similar median values in the end, regardless of the ship type.\nAverage load Fish carriers and tankers generally have lower median of Average load percentages for long-haul trips, but higher median values for coastal trips. Bulk carrier has the lowest median of the average load percentage in transoceanic journey and highest for short-haul journey. Container ship have closer median scores among coastal, long-haul and short-haul. It has higher median score for average load in transoceanic trips.\n\n\n\n\n\n\nShow the code\n#Plot1\np_heye_ep &lt;- ggplot(ship_filter,\n       aes(x = Ship_Type,\n           y = Engine_Power_kW,\n           fill = Route_Type)) +\n  ggdist::stat_halfeye(.width=c(0,1), adjust = .5,\n                       shape = 21,\n                       point_size = 2) +\n  scale_fill_manual(values = c(\"Coastal\" = adjustcolor(\"#FF9EAA\", alpha.f = 0.5),\n                               \"Long-haul\" = adjustcolor(\"#3AA6B9\", alpha.f = 0.5), \n                               \"Short-haul\" = adjustcolor(\"#e0c080\", alpha.f = 0.5),\n                               \"Transoceanic\" = adjustcolor(\"grey70\", alpha.f = 0.5)), \n                                 name = NULL) +\n  labs(title = \"Halfeye Plots of Engine Power by Route Type\") +\n  theme(plot.background = element_rect(fill = \"#f1f4f5\", color = NA),\n        panel.background = element_rect(fill = \"#f1f4f5\", color = NA),\n        legend.background = element_rect(fill = \"#f1f4f5\", color = NA),  \n        legend.key = element_rect(fill = \"#f1f4f5\", color = NA)\n        )\n\n\n#Plot2\n\nmedian_load = median(ship_filter$Engine_Power_kW)\n\np_heye_ep_st &lt;- ggplot(ship_filter,\n       aes(x = Ship_Type,\n           y = Engine_Power_kW)) +\n  ggdist::stat_interval(.width = 1:4*.25) +\n  ggdist::stat_halfeye(.width = 0, fill = \"grey80\", \n                       color = \"white\", position = position_nudge(x = .024)) +\n  scale_color_viridis_d(option = \"cividis\", direction = -1, end = .9) +\n  geom_hline(yintercept = median_load, linetype = \"dashed\", color = \"blue\") +  # Add median line\n  annotate(\"text\", x = 1.2, y = median_load, label = paste(\"Median:\", round(median_load, 2)),\n            color = \"blue\", vjust = -1, hjust = 0, size = 3) +  # Add text label\n  labs(title = \"Halfeye Plots of Engine Power with Median Line\") +\n  theme(plot.background = element_rect(fill = \"#f1f4f5\", color = NA),\n        panel.background = element_rect(fill = \"#f1f4f5\", color = NA),\n        legend.background = element_rect(fill = \"#f1f4f5\", color = NA),  \n        legend.key = element_rect(fill = \"#f1f4f5\", color = NA)\n        )\n\n#Combine plots\np_heye_ep_st / p_heye_ep + plot_layout(height = c(1, 1.5))\n\n\n\n\n\n\n\n\n\n\n\nEngine power\n\n\n\nAmong the four ship types, the Fish Carrier shows the widest range of median engine power across the different route types. It has the lowest median engine power for long-haul trips and the highest for transoceanic trips.\nOverall, the Tanker has a higher median engine power compared to the Container ship.\n\n\n\n\n\n\n\nShow the code\n#Plot1\np_heye_cw &lt;- ggplot(ship_filter,\n       aes(x = Ship_Type,\n           y = Cargo_Weight_tons,\n           fill = Route_Type)) +\n  ggdist::stat_halfeye(.width=c(0,1), adjust = .5,\n                       shape = 21,\n                       point_size = 2) +\n  scale_fill_manual(values = c(\"Coastal\" = adjustcolor(\"#FF9EAA\", alpha.f = 0.5),\n                               \"Long-haul\" = adjustcolor(\"#3AA6B9\", alpha.f = 0.5), \n                               \"Short-haul\" = adjustcolor(\"#e0c080\", alpha.f = 0.5),\n                               \"Transoceanic\" = adjustcolor(\"grey70\", alpha.f = 0.5)), \n                               name = NULL) +\n  labs(title = \"Halfeye Plots of Cargo Weight by Route Type\") +\n  theme(plot.background = element_rect(fill = \"#f1f4f5\", color = NA),\n        panel.background = element_rect(fill = \"#f1f4f5\", color = NA),\n        legend.background = element_rect(fill = \"#f1f4f5\", color = NA),  \n        legend.key = element_rect(fill = \"#f1f4f5\", color = NA)\n        )\n\n\n#Plot2\n\nmedian_load = median(ship_filter$Cargo_Weight_tons)\n\np_heye_cw_st &lt;- ggplot(ship_filter,\n       aes(x = Ship_Type,\n           y = Cargo_Weight_tons)) +\n  ggdist::stat_interval(.width = 1:4*.25) +\n  ggdist::stat_halfeye(.width = 0, fill = \"grey80\", color = \"white\", position = position_nudge(x = .024)) +\n  scale_color_viridis_d(option = \"plasma\", direction = -1, end = .9) +\n  geom_hline(yintercept = median_load, linetype = \"dashed\", color = \"red\") +  # Add median line\n  annotate(\"text\", x = 1.2, y = median_load, label = paste(\"Median:\", round(median_load, 2)),\n            color = \"red\", vjust = -1, hjust = 0, size = 3) +  # Add text label\n  labs(title = \"Halfeye Plots of Cargo Weight with Median Line\") +\n  theme(plot.background = element_rect(fill = \"#f1f4f5\", color = NA),\n        panel.background = element_rect(fill = \"#f1f4f5\", color = NA),\n        legend.background = element_rect(fill = \"#f1f4f5\", color = NA),  \n        legend.key = element_rect(fill = \"#f1f4f5\", color = NA)\n        )\n\n#Combine plots\np_heye_cw_st / p_heye_cw + plot_layout(height = c(1, 1.5))\n\n\n\n\n\n\n\n\n\n\n\nCargo weight\n\n\n\nBulk carriers tend to have a higher concentration of lower cargo weights on Transoceanic trips. The density ridge line shows an obvious hump on the lower end of weight.\nFish carriers and Tankers show a greater concentration of higher cargo weights on Long-haul trips, while the concentration is lower on Short-haul trips.\nContainer ships show a higher concentration of cargo weights on Coastal and Transoceanic trips, with less concentration on Long-haul trips.\n\n\n\n\n\n\n\nShow the code\n#Plot1\np_heye_tt &lt;- ggplot(ship_filter,\n       aes(x = Ship_Type,\n           y = Turnaround_Time_hours,\n           fill = Route_Type)) +\n  ggdist::stat_halfeye(.width=c(0,1), adjust = .5,\n                       shape = 21,\n                       point_size = 2) +\n  scale_fill_manual(values = c(\"Coastal\" = adjustcolor(\"#FF9EAA\", alpha.f = 0.5),\n                               \"Long-haul\" = adjustcolor(\"#3AA6B9\", alpha.f = 0.5), \n                               \"Short-haul\" = adjustcolor(\"#e0c080\", alpha.f = 0.5),\n                               \"Transoceanic\" = adjustcolor(\"grey70\", alpha.f = 0.5)), \n                               name = NULL) +\n  labs(title = \"Halfeye Plots of Turnaround Time by Route Type\") +\n  theme(plot.background = element_rect(fill = \"#f1f4f5\", color = NA),\n        panel.background = element_rect(fill = \"#f1f4f5\", color = NA),\n        legend.background = element_rect(fill = \"#f1f4f5\", color = NA),  \n        legend.key = element_rect(fill = \"#f1f4f5\", color = NA)\n        )\n\n\n#Plot2\n\nmedian_load = median(ship_filter$Turnaround_Time_hours)\n\np_heye_tt_st &lt;- ggplot(ship_filter,\n       aes(x = Ship_Type,\n           y = Turnaround_Time_hours)) +\n  ggdist::stat_interval(.width = 1:4*.25) +\n  ggdist::stat_halfeye(.width = 0, fill = \"grey80\", color = \"white\", position = position_nudge(x = .024)) +\n  scale_color_viridis_d(option = \"rocket\", direction = -1, end = .9) +\n  geom_hline(yintercept = median_load, linetype = \"dashed\", color = \"green\") +  # Add median line\n  annotate(\"text\", x = 1.2, y = median_load, label = paste(\"Median:\", round(median_load, 2)),\n            color = \"green\", vjust = -1, hjust = 0, size = 3) +  # Add text label\n  labs(title = \"Halfeye Plots of Turnaround Time with Median Line\") +\n  theme(plot.background = element_rect(fill = \"#f1f4f5\", color = NA),\n        panel.background = element_rect(fill = \"#f1f4f5\", color = NA),\n        legend.background = element_rect(fill = \"#f1f4f5\", color = NA),  \n        legend.key = element_rect(fill = \"#f1f4f5\", color = NA)\n        )\n\n#Combine plots\np_heye_tt_st / p_heye_tt + plot_layout(height = c(1, 1.5))\n\n\n\n\n\n\n\n\n\n\n\nTurnaround time\n\n\n\nBulk carriers exhibit longer turnaround times on coastal, long-haul, and transoceanic routes, which aligns with the extended distances they cover. In contrast, Fish carriers show an inverse trend—short-haul routes have higher turnaround times, while long-haul routes see quicker turnarounds.\nThis suggests that Fish carriers on short-haul routes may frequently stop at sea to receive fish from fishing vessels before returning, whereas long-haul voyages likely involve fewer interruptions. Further data could clarify this operational pattern.\n\n\n\n\n\n\n\nShow the code\n#Plot1\np_heye_dt &lt;- ggplot(ship_filter,\n       aes(x = Ship_Type,\n           y = Distance_Traveled_nm,\n           fill = Route_Type)) +\n  ggdist::stat_halfeye(.width=c(0,1), adjust = .5,\n                       shape = 21,\n                       point_size = 2) +\n  scale_fill_manual(values = c(\"Coastal\" = adjustcolor(\"#FF9EAA\", alpha.f = 0.5),\n                               \"Long-haul\" = adjustcolor(\"#3AA6B9\", alpha.f = 0.5), \n                               \"Short-haul\" = adjustcolor(\"#e0c080\", alpha.f = 0.5),\n                               \"Transoceanic\" = adjustcolor(\"grey70\", alpha.f = 0.5)), \n                               name = NULL) +\n  labs(title = \"Halfeye Plots of Distance by Route Type\") +\n  theme(plot.background = element_rect(fill = \"#f1f4f5\", color = NA),\n        panel.background = element_rect(fill = \"#f1f4f5\", color = NA),\n        legend.background = element_rect(fill = \"#f1f4f5\", color = NA),  \n        legend.key = element_rect(fill = \"#f1f4f5\", color = NA)\n        )\n\n#Plot2\n\nmedian_load = median(ship_filter$Distance_Traveled_nm)\n\np_heye_dt_st &lt;- ggplot(ship_filter,\n       aes(x = Ship_Type,\n           y = Distance_Traveled_nm)) +\n  ggdist::stat_interval(.width = 1:4*.25) +\n  ggdist::stat_halfeye(.width = 0, fill = \"grey80\", color = \"white\", position = position_nudge(x = .024)) +\n  scale_color_viridis_d(option = \"inferno\", direction = -1, end = .9) +\n  geom_hline(yintercept = median_load, linetype = \"dashed\", color = \"grey20\") +  # Add median line\n  annotate(\"text\", x = 1.2, y = median_load, label = paste(\"Median:\", round(median_load, 2)),\n            color = \"grey20\", vjust = -1, hjust = 0, size = 3) +  # Add text label\n  labs(title = \"Halfeye Plots of Distance with Median Line\") +\n  theme(plot.background = element_rect(fill = \"#f1f4f5\", color = NA),\n        panel.background = element_rect(fill = \"#f1f4f5\", color = NA),\n        legend.background = element_rect(fill = \"#f1f4f5\", color = NA),  \n        legend.key = element_rect(fill = \"#f1f4f5\", color = NA)\n        )\n\n#Combine plots\np_heye_dt_st / p_heye_dt + plot_layout(height = c(1, 1.5))\n\n\n\n\n\n\n\n\n\n\n\nDistance travelled*\n\n\n\nBoth Bulk carriers and Fish carriers exhibit strong bimodal distributions in the distances traveled on long-haul routes. However, they differ significantly in their average travel distances compared to other routes. Bulk carriers show the shortest average distance for long-haul trips, while Fish carriers record the longest. This disparity suggests that despite similar route classifications, the operational characteristics or requirements for these ship types influence their journey lengths.\n\n\n\n\n\n\n\nShow the code\n# Plot1\np_heye_ee_et &lt;- ggplot(ship_filter,\n       aes(x = Ship_Type,\n           y = Efficiency_nm_per_kWh,\n           fill = Engine_Type)) +\n  ggdist::stat_halfeye(.width=c(0,1), adjust = .5,\n                       shape = 21,\n                       point_size = 2) +\n  scale_fill_manual(values = c(\"Heavy Fuel Oil (HFO)\" = adjustcolor(\"#F9DBBA\", alpha.f = 0.6),\n                               \"Steam Turbine\" = adjustcolor(\"#DA498D\", alpha.f = 0.6), \n                               \"Diesel\" = adjustcolor(\"#96CEB4\", alpha.f = 0.6),\n                               name = NULL)) +\n  labs(title = \"Halfeye Plots of Energy Efficiency by Engine Type\") +\n  theme(plot.background = element_rect(fill = \"#f1f4f5\", color = NA),\n        panel.background = element_rect(fill = \"#f1f4f5\", color = NA),\n        legend.background = element_rect(fill = \"#f1f4f5\", color = NA),  \n        legend.key = element_rect(fill = \"#f1f4f5\", color = NA)\n        )\n\n\n# Plot2\n\nmedian_load = median(ship_filter$Efficiency_nm_per_kWh)\n\np_heye_ee &lt;- ggplot(ship_filter,\n       aes(x = Ship_Type,\n           y = Efficiency_nm_per_kWh)) +\n  ggdist::stat_interval(.width = 1:4*.25) +\n  ggdist::stat_halfeye(.width = 0, fill = \"grey80\", color = \"white\", position = position_nudge(x = .024)) +\n  scale_color_viridis_d(option = \"magma\", direction = -1, end = .9) +\n  geom_hline(yintercept = median_load, linetype = \"dashed\", color = \"brown\") +  # Add median line\n  annotate(\"text\", x = 1.2, y = median_load, label = paste(\"Median:\", round(median_load, 2)),\n            color = \"brown\", vjust = -1, hjust = 0, size = 3) +  # Add text label\n  labs(title = \"Halfeye Plots of Energy Efficiency with Median Line\") \n\n\n# Plot3\np_heye_ee_wc &lt;- ggplot(ship_filter,\n       aes(x = Ship_Type,\n           y = Efficiency_nm_per_kWh,\n           fill = Weather_Condition)) +\n  ggdist::stat_halfeye(.width=c(0,1), adjust = .5,\n                       shape = 21,\n                       point_size = 3) +\n  scale_fill_manual(values = c(\"Moderate\" = adjustcolor(\"#F9DBBA\", alpha.f = 0.6),\n                               \"Rough\" = adjustcolor(\"#DA498D\", alpha.f = 0.6), \n                               \"Calm\" = adjustcolor(\"#5B99C2\", alpha.f = 0.6),\n                               name = NULL)) +\n  labs(title = \"Halfeye Plots of Energy Efficiency by Weather\") +\n  theme(plot.background = element_rect(fill = \"#f1f4f5\", color = NA),\n        panel.background = element_rect(fill = \"#f1f4f5\", color = NA),\n        legend.background = element_rect(fill = \"#f1f4f5\", color = NA),  \n        legend.key = element_rect(fill = \"#f1f4f5\", color = NA)\n        )\n\n# Plot4\np_heye_ee_ms &lt;- ggplot(ship_filter,\n       aes(x = Ship_Type,\n           y = Efficiency_nm_per_kWh,\n           fill = Maintenance_Status)) +\n  ggdist::stat_halfeye(.width=c(0,1), adjust = .5,\n                       shape = 21,\n                       point_size = 2) +\n  scale_fill_manual(values = c(\"Fair\" = adjustcolor(\"#F9DBBA\", alpha.f = 0.6),\n                               \"Critical\" = adjustcolor(\"#8B5DFF\", alpha.f = 0.6), \n                               \"Good\" = adjustcolor(\"#41B3A2\", alpha.f = 0.6),\n                               name = NULL)) +\n  labs(title = \"Halfeye Plots of Energy Efficiency by Maintenance\") \n\n\n# Combine plots\n(p_heye_ee | p_heye_ee_et) / (p_heye_ee_wc | p_heye_ee_ms)\n\n\n\n\n\n\n\n\n\n\n\nEnergy efficiency\n\n\nThe energy efficiency distribution appears relatively uniform across all ship types, suggesting that there is no significant disparity in energy performance across different vessels.\nAn interesting observation is that Container ships demonstrate a remarkbly higher average energy efficiency during calm weather conditions. In contrast, Fish carriers show a slight negative skew in energy efficiency during calm weather, indicating that Fish containers may face unique operational constaints in such conditions.\nWhile most ship types exhibit a positive correlation between energy efficiency and maintenance status, Fish carriers deviate from this trend. They show a lower average energy efficiency when in good maintenance status. This anomaly could potentially be attributed to the specific logistics requirements of Fish carriers, which might necessitate operational adjustments that affect their energy performance. Further investigation is needed to understand the factors influencing this discrepancy.\n\n\n\n\n\n\n\n4.4 Voyage frequency\n\n4.4.1 Overall voyage frequency over time\nTo analyse voyage frequency trends over time, a bar chart was plotted to illustrate the monthly distribution of voyages in the dataset.\n\n\nShow the code\nvoyage_count &lt;- ship_filter %&gt;%\n  mutate(Month = format(as.Date(Date), \"%Y-%m\")) %&gt;% #to extract Year-Month\n  group_by(Month) %&gt;%\n  summarise(Count = n()) #count rows\nvoyage_count_scaled &lt;- voyage_count %&gt;%\n  mutate(Count_scaled = Count / 10)\n\n#calculate average\nmean_voyage &lt;- mean(voyage_count$Count)\n\nggplot(voyage_count_scaled,\n       aes(x = Month,\n           y = Count_scaled)) +\n  geom_bar(stat = \"identity\", \n           fill = \"grey30\") +\n  labs(x = \"Date\", y = \"Voyage Count (scaled by 10) \",\n       title = \"Voyage Frequency Over Time\") +\n  theme_light() +\n  geom_hline(yintercept = mean_voyage/10, color = \"#3AA6B9\", linetype = \"dashed\", size = 1) + \n  annotate(\"text\", x = 3.2, y = mean_voyage/10 + 1, \n           label = paste(\"Mean: \", round(mean_voyage/10, 2)), color = \"#3AA6B9\")+\n  theme(plot.background = element_rect(fill = \"#f1f4f5\", color = NA),\n        panel.background = element_rect(fill = \"#f1f4f5\", color = NA),\n        legend.background = element_rect(fill = \"#f1f4f5\", color = NA),  \n        legend.key = element_rect(fill = \"#f1f4f5\", color = NA)\n        )\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\nVoyage frequencies exhibit seasonal fluctuations, with notable peaks in July, October, and December 2023, as well as March and June 2024.\nMarch 2024 recorded the highest voyage count, nearing 200 voyages.\nMost other months maintained a steady frequency around 150 voyages, with September recording the lowest.\n\n\n\n\n\n4.4.2 Voyage frequency by ship type\nTo gain deeper insights into voyage frequencies by ship type and their distribution over time, the combined bar charts plot below presents voyage frequencies by ship type on the right and their monthly percentages over time.\n\n\nShow the code\n# Extract month and year from the Date\nship_filter_month &lt;- ship_filter %&gt;%\n  mutate(Month = floor_date(Date, \"month\"))\n\n# Group by Month and Ship type, then count occurrences\ntrip_by_month_bar &lt;- ship_filter_month %&gt;%\n  group_by(Month, Ship_Type) %&gt;%\n  summarise(Count = n(), .groups = \"drop\")\n\n# Calculate total occurrences per month\ntotal_trip_per_month_bar &lt;- trip_by_month_bar %&gt;%\n  group_by(Month) %&gt;%\n  summarise(Total = sum(Count))\n\n# Join total occurrences per month and compute percentage\ntrip_percentage_bar &lt;- trip_by_month_bar %&gt;%\n  left_join(total_trip_per_month_bar, by = \"Month\") %&gt;%\n  mutate(Percentage = (Count / Total) * 100)  # Convert to percentage\n\n# Plot stacked bar chart with percentage\np_trip_ct_1 &lt;- ggplot(trip_percentage_bar, \n       aes(x = Month, y = Percentage, fill = factor(Ship_Type, levels = c(\"Bulk Carrier\", \"Container Ship\", \"Fish Carrier\", \"Tanker\")))) +\n  geom_bar(stat = \"identity\", position = \"stack\") +  # Use identity because we computed percentages\n  geom_text(aes(label = paste0(round(Percentage, 0), \"%\")), \n            position = position_stack(vjust = 0.5),  # Center the text in each segment\n            size = 2.5, color = \"black\") +  # Adjust text size and color\n  scale_fill_manual(values = c(\"Bulk Carrier\" = \"#bcd6be\",\n                               \"Container Ship\" = \"#f5e8ce\",\n                               \"Fish Carrier\" = \"#e0bcc0\",\n                               \"Tanker\" = \"#9bc5cc\")) + \n  labs(title = \"Number of Trips Over Time (%)\",\n       x = \"Month\",\n       y = \"Percentage (%)\",\n       fill = \"Ship_Type\") +\n  theme_light() +\n  scale_x_date(labels = scales::date_format(\"%m/%y\"), breaks = \"1 month\") + \n  theme(plot.title = element_text(size = 8, face = \"bold\"),\n        plot.background = element_rect(fill = \"#f1f4f5\"),\n        panel.background = element_rect(fill = \"#f1f4f5\"),\n        panel.border = element_blank(),\n        text = element_text(size = 8),\n        legend.text = element_text(size = 6),  # Change legend text size\n        legend.title = element_text(size = 6, face = \"bold\"),  # Change legend title size\n        legend.key.size = unit(0.5, \"cm\"),  # Adjust legend key size (box size)\n        legend.spacing.y = unit(0.3, \"cm\"),\n        legend.position = \"top\") \n\n###------------ Plot2 ------------\n#Count the number of trips by ship\ntrip_count &lt;- ship_filter %&gt;%\n  group_by(Ship_Type) %&gt;%\n  summarise(Trip_Count = n(), .group = \"drop\")\n\n#calculation\ntotal_trips &lt;- sum(trip_count$Trip_Count)\ntrip_count &lt;- trip_count %&gt;%\n  mutate(Percentage = (Trip_Count / total_trips) * 100)\n\n#plot the bar chart\np_trip_ct_2 &lt;- ggplot(trip_count,\n       aes(x = Ship_Type,\n           y = Trip_Count,\n           fill = Ship_Type)) +\n  geom_bar(stat = \"identity\", show.legend = FALSE) + #stat = \"identity\": use the values in 'Trip_Count'\n  labs(title = \"Trip Count by Ship Type\",\n       x = \"Ship Type\",\n       y = \"Number of Trips\") +\n  geom_text(aes(label = paste0(Trip_Count,\" (\", round(Percentage, 1), \"%)\")),\n            vjust = -0.8, size = 2, angle = 45) +\n  theme_light() +\n  theme(plot.title = element_text(size = 8, face = \"bold\"),\n        plot.background = element_rect(fill = \"#f1f4f5\"),\n        panel.background = element_rect(fill = \"#f1f4f5\"),\n        panel.border = element_blank(),\n        text = element_text(size = 8),\n        legend.text = element_text(size = 6), \n        legend.title = element_text(size = 6, face = \"bold\"), \n        legend.key.size = unit(0.5, \"cm\"),\n        legend.spacing.y = unit(0.3, \"cm\"),\n        legend.position = \"none\",\n        axis.text.x = element_text(angle = 45, hjust = 1)) +\n  scale_fill_manual(values = c(\"Bulk Carrier\" = \"#bcd6be\",\n                               \"Container Ship\" = \"#f5e8ce\",\n                               \"Fish Carrier\" = \"#e0bcc0\",\n                               \"Tanker\" = \"#9bc5cc\")) \n#Combine plots\np_trip_ct_1 + p_trip_ct_2 + plot_layout(widths = c(2.5,1))\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\nBalanced Distribution with Leading Segments Voyage frequencies are fairly evenly distributed across ship types. Bulk carriers recorded the highest share at nearly 26%, followed by tankers, container ships, and fish carriers, each contributing approximately 25%.\n\nBulk Carrier Trends Bulk carriers’ voyage frequencies range from 20% to 34%, with peak activity in August, November 2023 and April 2024, where they accounted for close to or more than 1/3 of total monthly voyages.\nContainer Ship Patterns Container ships showed fluctuations between 19% and 29%. Peak months included December 2023 and March, June 2024, when they made up nearly 30% of total voyages.\nFish Carrier Variability Fish carriers exhibited the widest range, from 16% to 33%, with the lowest frequency in November 2023 and the highest in January 2024.\nTanker Stability Tankers maintained steadier voyage frequencies, ranging from 21% to 29%, suggesting that seasonal variations had less impact on their operations compared to other ship types.",
    "crumbs": [
      "![](/images/house.svg)",
      "Take-home Exercise",
      "Take-home_Ex01"
    ]
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01.html#profit-performance",
    "href": "Take-home_Ex/Take-home_Ex01.html#profit-performance",
    "title": "Take-home Exercise 1",
    "section": "5 Profit Performance",
    "text": "5 Profit Performance\n\n5.1 Finance performance overview\nTo assess the financial performance across all ship types, a boxplot analysis was conducted, examining key metrics such as operational cost, revenue per trip, and profit (all in thousand dollars). This provides an overarching view of profitability and cost efficiency across voyages.\n\n\nShow the code\n#Plot operational cost distribution\np1 &lt;- ggplot(ship_filter,\n       aes(y = Operational_Cost_USD, x = \"All ship types\")) +\n  geom_violin(outlier.colour = \"purple\",\n              color = \"#A3B23B\",\n              fill = \"#F4F8D3\",\n              alpha = 0.4) + \n  geom_boxplot(width = .2,\n               color = \"grey60\") +\n  geom_point(position = \"jitter\",\n             size = 0.2,\n             color = \"#F4F8D3\",\n             alpha = 0.3) +\n  coord_cartesian(ylim = c(-500, 1000)) +\n  theme_light() +\n  theme(plot.background = element_rect(fill = \"#f1f4f5\", color = NA),\n        panel.background = element_rect(fill = \"#f1f4f5\", color = NA),\n        panel.border = element_blank())\n\n#Plot revenue distribution\np2&lt;- ggplot(ship_filter,\n       aes(y = Revenue_per_Voyage_USD, x = \"All ship types\")) +\n  geom_violin(outlier.colour = \"blue\",\n               color = \"#5FB0B0\",\n               fill = \"#73C7C7\",\n               alpha = 0.4) +\n  geom_boxplot(width = .2,\n               color = \"grey60\") +\n  geom_point(position = \"jitter\",\n             size = 0.2,\n             color = \"#73C7C7\",\n             alpha = 0.3) +\n  coord_cartesian(ylim = c(-500, 1000)) +\n  theme_light() +\n  theme(plot.background = element_rect(fill = \"#f1f4f5\", color = NA),\n        panel.background = element_rect(fill = \"#f1f4f5\", color = NA),\n        panel.border = element_blank())\n\n#Plot profit distribution\np3 &lt;- ggplot(ship_filter,\n       aes(y = Profit, x = \"All ship types\")) +\n  geom_violin(outlier.colour = \"green\",\n               color = \"#E6A5B1\",\n               fill = \"#F7CFD8\",\n               alpha = 0.4) +\n  geom_boxplot(width = .2,\n               color = \"grey60\") +\n  geom_point(position = \"jitter\",\n             size = 0.2,\n             color = \"#F7CFD8\",\n             alpha = 0.3) +\n  coord_cartesian(ylim = c(-500, 1000)) +\n  theme_light() +\n  theme(plot.background = element_rect(fill = \"#f1f4f5\", color = NA),\n        panel.background = element_rect(fill = \"#f1f4f5\", color = NA),\n        panel.border = element_blank())\n\npatchwork &lt;- p1 + p2 + p3\npatchwork + plot_annotation(\n  title = \"Finance Distribution Overview\") &\n  theme(plot.title = element_text(size = 12, face = \"bold\"),\n        plot.background = element_rect(fill = \"#f1f4f5\", color = NA)\n)\n\n\n\n\n\n\n\n\n\nFor a deeper analysis of profit variations between ship types, a ggbetweenstats plot was employed. This visualisation not only compares profit distributions but also evaluates the statistical significance of differences, offering insights into which vessel types demonstrate superior financial performance.\n\n\nShow the code\n# Plot statboxplot by ship types\nggbetweenstats(\n  data = ship_filter,\n  x = Ship_Type,\n  y = Profit,\n  type = \"p\",\n  mean.ci = TRUE,\n  pariwise.comparisons = TRUE,\n  pairwise.display = \"s\",\n  p.adjust.methods = \"fdr\",\n  message = FALSE\n) +\n  labs(title = \"Welch’s one-way ANOVA\") +\n  theme(panel.background = element_rect(fill = \"#f1f4f5\", color = NA),\n        plot.background = element_rect(fill = \"#f1f4f5\", color = NA),\n        plot.title = element_text(size = 16, face = \"bold\") \n        )\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\nThe distribution of operational costs and revenue appears relatively uniform, with operational costs ranging from $0 to $500K and revenue $0 to $1M. In addition, no significant outliers were detected, suggesting consistent financial performance.\nWith voyage counts closely clustered between 521 and 550 trips, profit exhibits a normal distribution, suggesting a balanced spread of earnings per trip.\nStatistical analysis using Welch’s one-way ANOVA produced a p-value of 0.84, far exceeding the 0.05 threshold. This indicates no statistically significant difference in profit performance across ship types. This suggested that factors other than vessel classification may be influencing profitability.\n\n\n\n\n\n5.2 Profit performance by ship, engine type in different aspects\nIn this section, we dive deeper into the performance of ships by examining categorical variables through density ridge plots. By analysing ship types and their respective engine types, we assess their performance across various factors such as routes, weather conditions, and maintenance status. Each row of the plot represents a different engine type, while the columns correspond to individual ship types, providing a comprehensive view of how these elements interact.\n\n5.2.1 Operational conditions\n\nRoute TypeWeather ConditionMaintenance status\n\n\n\n\nShow the code\n###------------1 Plot Bulk Carrier -----------###\n\n# Filter data for only \"Bulk Carrier\" ships\nbulkc_data &lt;- ship_filter %&gt;%\n  filter(Ship_Type == \"Bulk Carrier\")\n\n# Calculate mean profit for each Engine Type and Route Type\nmean_profit_bulkc &lt;- bulkc_data %&gt;%\n  group_by(Engine_Type, Route_Type) %&gt;%\n  summarise(mean_profit_bulkc = mean(Profit, na.rm = TRUE), .groups = \"drop\")\n\n# Create Plot_bulkc\np_ridg_bulkc &lt;- ggplot(bulkc_data, aes(x = Profit, \n                        y = Engine_Type, \n                        fill = Route_Type, \n                        color = Route_Type)) +\n  geom_density_ridges(\n    alpha = 0.2,           \n    scale = 6,            \n    rel_min_height = 0.01,\n    position = \"identity\"   # Ensures full overlap\n  ) +\n  geom_point(data = mean_profit_bulkc, \n             aes(x = mean_profit_bulkc, y = Engine_Type, fill = Route_Type), \n             shape = 23, size = 3, stroke = 0.5, color = \"grey90\") +\n  facet_wrap(~ Engine_Type, ncol = 1) +\n  labs(x = \"Bulk Carrier\", y = NULL) +  \n  scale_fill_manual(values = c(\"Coastal\" = \"#FF9EAA\",\n                               \"Long-haul\" = \"#3AA6B9\",\n                               \"Short-haul\" = \"#e0c080\",\n                               \"Transoceanic\" = \"grey70\")) +  \n  scale_color_manual(values = c(\"Coastal\" = \"#FF9EAA\",\n                               \"Long-haul\" = \"#3AA6B9\",\n                               \"Short-haul\" = \"#e0c080\",\n                               \"Transoceanic\" = \"grey70\")) + \n  theme_classic() +\n  theme(axis.text.y = element_blank(),  \n        axis.ticks.y = element_blank(),\n        axis.line.y = element_blank(),\n        panel.grid.major = element_blank(),  \n        panel.grid.minor = element_blank(),\n        strip.text.y = element_blank(),\n        strip.background = element_blank(), \n        legend.position = \"none\",\n        plot.title = element_text(size = 12, face = \"bold\",\n                                  hjust = 0.5, vjust = -120),\n        panel.spacing = unit(1, \"lines\"),\n        plot.margin = margin(t = 10, r = 10, b = 30, l = 20)\n        ) \n\n\n###------------2 Plot Container Ship -----------###\n# Filter data for only \"Container Ship\" ships\ncship_data &lt;- ship_filter %&gt;%\n  filter(Ship_Type == \"Container Ship\")\n\n# Calculate mean profit for each Engine Type and Route Type\nmean_profit_cship &lt;- cship_data %&gt;%\n  group_by(Engine_Type, Route_Type) %&gt;%\n  summarise(mean_profit_cship = mean(Profit, na.rm = TRUE), .groups = \"drop\")\n\n# Create Plot_cship\np_ridg_cship &lt;- ggplot(cship_data, aes(x = Profit, \n                        y = Engine_Type, \n                        fill = Route_Type, \n                        color = Route_Type)) +\n  geom_density_ridges(\n    alpha = 0.2,           \n    scale = 6,            \n    rel_min_height = 0.01,\n    position = \"identity\"   # Ensures full overlap\n  ) +\n  geom_point(data = mean_profit_cship, \n             aes(x = mean_profit_cship, y = Engine_Type, fill = Route_Type), \n             shape = 23, size = 3, stroke = 0.5, color = \"grey90\") +\n  facet_wrap(~ Engine_Type, ncol = 1, strip.position = \"left\") + \n  labs(x = \"Container Ship\", y = NULL) +  \n  scale_fill_manual(values = c(\"Coastal\" = \"#FF9EAA\",\n                               \"Long-haul\" = \"#3AA6B9\",\n                               \"Short-haul\" = \"#e0c080\",\n                               \"Transoceanic\" = \"grey70\")) +  \n  scale_color_manual(values = c(\"Coastal\" = \"#FF9EAA\",\n                               \"Long-haul\" = \"#3AA6B9\",\n                               \"Short-haul\" = \"#e0c080\",\n                               \"Transoceanic\" = \"grey70\")) + \n  theme_classic() +\n  theme(axis.text.y = element_blank(),  \n        axis.ticks.y = element_blank(),\n        axis.line.y = element_blank(),\n        panel.grid.major = element_blank(),  \n        panel.grid.minor = element_blank(),\n        strip.text.y = element_blank(),\n        strip.background = element_blank(), \n        legend.position = \"top\",\n        plot.title = element_text(size = 12, face = \"bold\",\n                                  hjust = 0.5, vjust = -120),\n        panel.spacing = unit(1, \"lines\")\n        )\n\n\n###-----------3 Plot Fish Carrier -----------###\n# Filter data for only \"Fish Carrier\" ships\nfishc_data &lt;- ship_filter %&gt;%\n  filter(Ship_Type == \"Fish Carrier\")\n\n# Calculate mean profit for each Engine Type and Route Type\nmean_profit_fishc &lt;- fishc_data %&gt;%\n  group_by(Engine_Type, Route_Type) %&gt;%\n  summarise(mean_profit_fishc = mean(Profit, na.rm = TRUE), .groups = \"drop\")\n\n# Create Plot_fishc\np_ridg_fishc &lt;- ggplot(fishc_data, aes(x = Profit, \n                        y = Engine_Type, \n                        fill = Route_Type, \n                        color = Route_Type)) +\n  geom_density_ridges(\n    alpha = 0.2,           \n    scale = 6,            \n    rel_min_height = 0.01,\n    position = \"identity\"   # Ensures full overlap\n  ) +\n  geom_point(data = mean_profit_fishc, \n             aes(x = mean_profit_fishc, y = Engine_Type, fill = Route_Type), \n             shape = 23, size = 3, stroke = 0.5, color = \"grey90\") +\n  facet_wrap(~ Engine_Type, ncol = 1, strip.position = \"left\") +  # Separate plots for each Route_Type\n  labs(x = \"Fish Carrier\", y = NULL) +  \n  scale_fill_manual(values = c(\"Coastal\" = \"#FF9EAA\",\n                               \"Long-haul\" = \"#3AA6B9\",\n                               \"Short-haul\" = \"#e0c080\",\n                               \"Transoceanic\" = \"grey70\")) +  \n  scale_color_manual(values = c(\"Coastal\" = \"#FF9EAA\",\n                               \"Long-haul\" = \"#3AA6B9\",\n                               \"Short-haul\" = \"#e0c080\",\n                               \"Transoceanic\" = \"grey70\")) + \n  theme_classic() +\n  theme(axis.text.y = element_blank(),  \n        axis.ticks.y = element_blank(),\n        axis.line.y = element_blank(),\n        panel.grid.major = element_blank(),  \n        panel.grid.minor = element_blank(),\n        strip.text.y = element_blank(),\n        strip.background = element_blank(), \n        legend.position = \"none\",\n        plot.title = element_text(size = 12, face = \"bold\",\n                                  hjust = 0.5, vjust = -120),\n        panel.spacing = unit(1, \"lines\")\n        )\n\n###-----------4 Plot Tanker-----------###\n# Filter data for only \"Tanker\" ships\ntanker_data &lt;- ship_filter %&gt;%\n  filter(Ship_Type == \"Tanker\")\n\n# Calculate mean profit for each Engine Type and Route Type\nmean_profit_tanker &lt;- tanker_data %&gt;%\n  group_by(Engine_Type, Route_Type) %&gt;%\n  summarise(mean_profit_tanker = mean(Profit, na.rm = TRUE), .groups = \"drop\")\n\n# Create Plot_tanker\np_ridg_tanker &lt;- ggplot(tanker_data, aes(x = Profit, \n                        y = Engine_Type, \n                        fill = Route_Type, \n                        color = Route_Type)) +\n  geom_density_ridges(\n    alpha = 0.2,           \n    scale = 6,            \n    rel_min_height = 0.01,\n    position = \"identity\"   # Ensures full overlap\n  ) +\n  geom_point(data = mean_profit_tanker, \n             aes(x = mean_profit_tanker, y = Engine_Type, fill = Route_Type), \n             shape = 23, size = 3, stroke = 0.5, color = \"grey90\") +\n  facet_wrap(~ Engine_Type, ncol = 1, strip.position = \"left\") +  # Separate plots for each Route_Type\n  labs(x = \"Tanker\", y = NULL) +  \n  scale_fill_manual(values = c(\"Coastal\" = \"#FF9EAA\",\n                               \"Long-haul\" = \"#3AA6B9\",\n                               \"Short-haul\" = \"#e0c080\",\n                               \"Transoceanic\" = \"grey70\")) +  \n  scale_color_manual(values = c(\"Coastal\" = \"#FF9EAA\",\n                               \"Long-haul\" = \"#3AA6B9\",\n                               \"Short-haul\" = \"#e0c080\",\n                               \"Transoceanic\" = \"grey70\")) + \n  theme_classic() +\n  theme(axis.text.y = element_blank(),  \n        axis.ticks.y = element_blank(),\n        axis.line.y = element_blank(),\n        panel.grid.major = element_blank(),  \n        panel.grid.minor = element_blank(),\n        strip.text.y = element_blank(),\n        strip.background = element_blank(), \n        legend.position = \"none\",\n        plot.title = element_text(size = 12, face = \"bold\",\n                                  hjust = 0.5, vjust = -120)\n        )\n\npatchwork &lt;- (p_ridg_bulkc | p_ridg_cship | p_ridg_fishc | p_ridg_tanker)\npatchwork \n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\nWhen comparing route performance across ship types, the findings reveal some interesting trends. Bulk carriers, which are powered by diesel engines, maintain a consistent performance across various routes. However, other ship types show noticeable variations.\nAmong the different ship types, Container ships with HFO engines demonstrate a lower average profit on long-haul trips compared to coastal and transoceanic routes. In contrast, Tankers equipped with HFO engines exhibit a right-skewed profit distribution on coastal routes, leading to a lower average profit compared to other route types.\nFish carriers  Displays varied profit patterns, regardless of the engine type. When operating on HFO engines, Fish carriers tend to exhibit a left-skewed profit distribution on long-haul routes, indicating that profits are more concentrated at the higher end. While the average profit doesn’t show a clear advantage, this skew suggests that certain engine and route combinations could potentially enhance profitability for Fish carriers under specific conditions. In transoceanic routes, Fish carriers show similar concentrated density regardless of the engine types.\n\n\n\n\n\n\n\nShow the code\n###------------1 Plot Bulk Carrier -----------###\n\n# Filter data for only \"Bulk Carrier\" ships\nbulkc_data &lt;- ship_filter %&gt;%\n  filter(Ship_Type == \"Bulk Carrier\")\n\n# Calculate mean profit for each Engine Type and Route Type\nmean_profit_bulkc &lt;- bulkc_data %&gt;%\n  group_by(Engine_Type, Weather_Condition) %&gt;%\n  summarise(mean_profit_bulkc = mean(Profit, na.rm = TRUE), .groups = \"drop\")\n\n# Create Plot_bulkc\np_ridg_bulkc_wc &lt;- ggplot(bulkc_data, aes(x = Profit, \n                        y = Engine_Type, \n                        fill = Weather_Condition, \n                        color = Weather_Condition)) +\n  geom_density_ridges(\n    alpha = 0.2,           \n    scale = 6,            \n    rel_min_height = 0.01,\n    position = \"identity\"   # Ensures full overlap\n  ) +\n  geom_point(data = mean_profit_bulkc, \n             aes(x = mean_profit_bulkc, y = Engine_Type, fill = Weather_Condition), \n             shape = 23, size = 3, stroke = 0.5, color = \"grey90\") +\n  facet_wrap(~ Engine_Type, ncol = 1) +\n  labs(x = \"Bulk Carrier\", y = NULL) +  \n  scale_fill_manual(values = c(\"Rough\" = \"#FF9EAA\",\n                               \"Calm\" = \"#3AA6B9\",\n                               \"Moderate\" = \"grey70\")) +  \n  scale_color_manual(values = c(\"Rough\" = \"#FF9EAA\",\n                               \"Calm\" = \"#3AA6B9\",\n                               \"Moderate\" = \"grey70\")) + \n  theme_classic() +\n  theme(axis.text.y = element_blank(),  \n        axis.ticks.y = element_blank(),\n        axis.line.y = element_blank(),\n        panel.grid.major = element_blank(),  \n        panel.grid.minor = element_blank(),\n        strip.text.y = element_blank(),\n        strip.background = element_blank(), \n        legend.position = \"none\",\n        plot.title = element_text(size = 12, face = \"bold\",\n                                  hjust = 0.5, vjust = -120),\n        panel.spacing = unit(1, \"lines\"),\n        plot.margin = margin(t = 10, r = 10, b = 30, l = 20)\n        ) \n\n\n###------------2 Plot Container Ship -----------###\n# Filter data for only \"Container Ship\" ships\ncship_data &lt;- ship_filter %&gt;%\n  filter(Ship_Type == \"Container Ship\")\n\n# Calculate mean profit for each Engine Type and Route Type\nmean_profit_cship &lt;- cship_data %&gt;%\n  group_by(Engine_Type, Weather_Condition) %&gt;%\n  summarise(mean_profit_cship = mean(Profit, na.rm = TRUE), .groups = \"drop\")\n\n# Create Plot_cship\np_ridg_cship_wc &lt;- ggplot(cship_data, aes(x = Profit, \n                        y = Engine_Type, \n                        fill = Weather_Condition, \n                        color = Weather_Condition)) +\n  geom_density_ridges(\n    alpha = 0.2,           \n    scale = 6,            \n    rel_min_height = 0.01,\n    position = \"identity\"   # Ensures full overlap\n  ) +\n  geom_point(data = mean_profit_cship, \n             aes(x = mean_profit_cship, y = Engine_Type, fill = Weather_Condition), \n             shape = 23, size = 3, stroke = 0.5, color = \"grey90\") +\n  facet_wrap(~ Engine_Type, ncol = 1, strip.position = \"left\") + \n  labs(x = \"Container Ship\", y = NULL) +  \n  scale_fill_manual(values = c(\"Rough\" = \"#FF9EAA\",\n                               \"Calm\" = \"#3AA6B9\",\n                               \"Moderate\" = \"grey70\")) +  \n  scale_color_manual(values = c(\"Rough\" = \"#FF9EAA\",\n                               \"Calm\" = \"#3AA6B9\",\n                               \"Moderate\" = \"grey70\")) + \n  theme_classic() +\n  theme(axis.text.y = element_blank(),  \n        axis.ticks.y = element_blank(),\n        axis.line.y = element_blank(),\n        panel.grid.major = element_blank(),  \n        panel.grid.minor = element_blank(),\n        strip.text.y = element_blank(),\n        strip.background = element_blank(), \n        legend.position = \"top\",\n        plot.title = element_text(size = 12, face = \"bold\",\n                                  hjust = 0.5, vjust = -120),\n        panel.spacing = unit(1, \"lines\")\n        )\n\n\n###-----------3 Plot Fish Carrier -----------###\n# Filter data for only \"Fish Carrier\" ships\nfishc_data &lt;- ship_filter %&gt;%\n  filter(Ship_Type == \"Fish Carrier\")\n\n# Calculate mean profit for each Engine Type and Route Type\nmean_profit_fishc &lt;- fishc_data %&gt;%\n  group_by(Engine_Type, Weather_Condition) %&gt;%\n  summarise(mean_profit_fishc = mean(Profit, na.rm = TRUE), .groups = \"drop\")\n\n# Create Plot_fishc\np_ridg_fishc_wc &lt;- ggplot(fishc_data, aes(x = Profit, \n                        y = Engine_Type, \n                        fill = Weather_Condition, \n                        color = Weather_Condition)) +\n  geom_density_ridges(\n    alpha = 0.2,           \n    scale = 6,            \n    rel_min_height = 0.01,\n    position = \"identity\"   # Ensures full overlap\n  ) +\n  geom_point(data = mean_profit_fishc, \n             aes(x = mean_profit_fishc, y = Engine_Type, fill = Weather_Condition), \n             shape = 23, size = 3, stroke = 0.5, color = \"grey90\") +\n  facet_wrap(~ Engine_Type, ncol = 1, strip.position = \"left\") +  # Separate plots for each Route_Type\n  labs(x = \"Fish Carrier\", y = NULL) +  \n  scale_fill_manual(values = c(\"Rough\" = \"#FF9EAA\",\n                               \"Calm\" = \"#3AA6B9\",\n                               \"Moderate\" = \"grey70\")) +  \n  scale_color_manual(values = c(\"Rough\" = \"#FF9EAA\",\n                               \"Calm\" = \"#3AA6B9\",\n                               \"Moderate\" = \"grey70\")) + \n  theme_classic() +\n  theme(axis.text.y = element_blank(),  \n        axis.ticks.y = element_blank(),\n        axis.line.y = element_blank(),\n        panel.grid.major = element_blank(),  \n        panel.grid.minor = element_blank(),\n        strip.text.y = element_blank(),\n        strip.background = element_blank(), \n        legend.position = \"none\",\n        plot.title = element_text(size = 12, face = \"bold\",\n                                  hjust = 0.5, vjust = -120),\n        panel.spacing = unit(1, \"lines\")\n        )\n\n###-----------4 Plot Tanker-----------###\n# Filter data for only \"Tanker\" ships\ntanker_data &lt;- ship_filter %&gt;%\n  filter(Ship_Type == \"Tanker\")\n\n# Calculate mean profit for each Engine Type and Route Type\nmean_profit_tanker &lt;- tanker_data %&gt;%\n  group_by(Engine_Type, Weather_Condition) %&gt;%\n  summarise(mean_profit_tanker = mean(Profit, na.rm = TRUE), .groups = \"drop\")\n\n# Create Plot_tanker\np_ridg_tanker_wc &lt;- ggplot(tanker_data, aes(x = Profit, \n                        y = Engine_Type, \n                        fill = Weather_Condition, \n                        color = Weather_Condition)) +\n  geom_density_ridges(\n    alpha = 0.2,           \n    scale = 6,            \n    rel_min_height = 0.01,\n    position = \"identity\"   # Ensures full overlap\n  ) +\n  geom_point(data = mean_profit_tanker, \n             aes(x = mean_profit_tanker, y = Engine_Type, fill = Weather_Condition), \n             shape = 23, size = 3, stroke = 0.5, color = \"grey90\") +\n  facet_wrap(~ Engine_Type, ncol = 1, strip.position = \"left\") +  # Separate plots for each Route_Type\n  labs(x = \"Tanker\", y = NULL) +  \n  scale_fill_manual(values = c(\"Rough\" = \"#FF9EAA\",\n                               \"Calm\" = \"#3AA6B9\",\n                               \"Moderate\" = \"grey70\")) +  \n  scale_color_manual(values = c(\"Rough\" = \"#FF9EAA\",\n                               \"Calm\" = \"#3AA6B9\",\n                               \"Moderate\" = \"grey70\")) + \n  theme_classic() +\n  theme(axis.text.y = element_blank(),  \n        axis.ticks.y = element_blank(),\n        axis.line.y = element_blank(),\n        panel.grid.major = element_blank(),  \n        panel.grid.minor = element_blank(),\n        strip.text.y = element_blank(),\n        strip.background = element_blank(), \n        legend.position = \"none\",\n        plot.title = element_text(size = 12, face = \"bold\",\n                                  hjust = 0.5, vjust = -120)\n        )\n\npatchwork &lt;- (p_ridg_bulkc_wc | p_ridg_cship_wc | p_ridg_fishc_wc | p_ridg_tanker_wc)\npatchwork \n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\nVoyages in rough weather often display skewed profit performance. Bulk carriers with diesel engines show opposite skewness between rough and moderate weather, a trend also observed in Tankers with steam turbine and HFO engines.\nEvery weather condition shows a few bimodal distribution for certain types of ship and engine combination. For example, Container ships running on HFO engine shows a bimodal distribution during rough weather, and so is Fish carrier with diesel & steam turbine engine during calm weather.\nCertain ship and engine combinations exhibit bimodal distributions under specific weather conditions: - Container ships with HFO engines show bimodal distribution in rough weather. - Fish carriers with diesel or steam turbine engines show bimodal distribution in calm weather.\n\n\n\n\n\n\n\nShow the code\n###------------1 Plot Bulk Carrier -----------###\n\n# Filter data for only \"Bulk Carrier\" ships\nbulkc_data &lt;- ship_filter %&gt;%\n  filter(Ship_Type == \"Bulk Carrier\")\n\n# Calculate mean profit for each Engine Type and Route Type\nmean_profit_bulkc &lt;- bulkc_data %&gt;%\n  group_by(Engine_Type, Maintenance_Status) %&gt;%\n  summarise(mean_profit_bulkc = mean(Profit, na.rm = TRUE), .groups = \"drop\")\n\n# Create Plot_bulkc\np_ridg_bulkc_ms &lt;- ggplot(bulkc_data, aes(x = Profit, \n                        y = Engine_Type, \n                        fill = Maintenance_Status, \n                        color = Maintenance_Status)) +\n  geom_density_ridges(\n    alpha = 0.2,           \n    scale = 6,            \n    rel_min_height = 0.01,\n    position = \"identity\"   # Ensures full overlap\n  ) +\n  geom_point(data = mean_profit_bulkc, \n             aes(x = mean_profit_bulkc, y = Engine_Type, fill = Maintenance_Status), \n             shape = 23, size = 3, stroke = 0.5, color = \"grey90\") +\n  facet_wrap(~ Engine_Type, ncol = 1) +\n  labs(x = \"Bulk Carrier\", y = NULL) +  \n  scale_fill_manual(values = c(\"Critical\" = \"#FF9EAA\",\n                               \"Good\" = \"#3AA6B9\",\n                               \"Fair\" = \"grey70\")) +  \n  scale_color_manual(values = c(\"Critical\" = \"#FF9EAA\",\n                               \"Good\" = \"#3AA6B9\",\n                               \"Fair\" = \"grey70\")) + \n  theme_classic() +\n  theme(axis.text.y = element_blank(),  \n        axis.ticks.y = element_blank(),\n        axis.line.y = element_blank(),\n        panel.grid.major = element_blank(),  \n        panel.grid.minor = element_blank(),\n        strip.text.y = element_blank(),\n        strip.background = element_blank(), \n        legend.position = \"none\",\n        plot.title = element_text(size = 12, face = \"bold\",\n                                  hjust = 0.5, vjust = -120),\n        panel.spacing = unit(1, \"lines\"),\n        plot.margin = margin(t = 10, r = 10, b = 30, l = 20)\n        ) \n\n\n###------------2 Plot Container Ship -----------###\n# Filter data for only \"Container Ship\" ships\ncship_data &lt;- ship_filter %&gt;%\n  filter(Ship_Type == \"Container Ship\")\n\n# Calculate mean profit for each Engine Type and Route Type\nmean_profit_cship &lt;- cship_data %&gt;%\n  group_by(Engine_Type, Maintenance_Status) %&gt;%\n  summarise(mean_profit_cship = mean(Profit, na.rm = TRUE), .groups = \"drop\")\n\n# Create Plot_cship\np_ridg_cship_ms &lt;- ggplot(cship_data, aes(x = Profit, \n                        y = Engine_Type, \n                        fill = Maintenance_Status, \n                        color = Maintenance_Status)) +\n  geom_density_ridges(\n    alpha = 0.2,           \n    scale = 6,            \n    rel_min_height = 0.01,\n    position = \"identity\"   # Ensures full overlap\n  ) +\n  geom_point(data = mean_profit_cship, \n             aes(x = mean_profit_cship, y = Engine_Type, fill = Maintenance_Status), \n             shape = 23, size = 3, stroke = 0.5, color = \"grey90\") +\n  facet_wrap(~ Engine_Type, ncol = 1, strip.position = \"left\") + \n  labs(x = \"Container Ship\", y = NULL) +  \n  scale_fill_manual(values = c(\"Critical\" = \"#FF9EAA\",\n                               \"Good\" = \"#3AA6B9\",\n                               \"Fair\" = \"grey70\")) +  \n  scale_color_manual(values = c(\"Critical\" = \"#FF9EAA\",\n                               \"Good\" = \"#3AA6B9\",\n                               \"Fair\" = \"grey70\")) + \n  theme_classic() +\n  theme(axis.text.y = element_blank(),  \n        axis.ticks.y = element_blank(),\n        axis.line.y = element_blank(),\n        panel.grid.major = element_blank(),  \n        panel.grid.minor = element_blank(),\n        strip.text.y = element_blank(),\n        strip.background = element_blank(), \n        legend.position = \"top\",\n        plot.title = element_text(size = 12, face = \"bold\",\n                                  hjust = 0.5, vjust = -120),\n        panel.spacing = unit(1, \"lines\")\n        )\n\n\n###-----------3 Plot Fish Carrier -----------###\n# Filter data for only \"Fish Carrier\" ships\nfishc_data &lt;- ship_filter %&gt;%\n  filter(Ship_Type == \"Fish Carrier\")\n\n# Calculate mean profit for each Engine Type and Route Type\nmean_profit_fishc &lt;- fishc_data %&gt;%\n  group_by(Engine_Type, Maintenance_Status) %&gt;%\n  summarise(mean_profit_fishc = mean(Profit, na.rm = TRUE), .groups = \"drop\")\n\n# Create Plot_fishc\np_ridg_fishc_ms &lt;- ggplot(fishc_data, aes(x = Profit, \n                        y = Engine_Type, \n                        fill = Maintenance_Status, \n                        color = Maintenance_Status)) +\n  geom_density_ridges(\n    alpha = 0.2,           \n    scale = 6,            \n    rel_min_height = 0.01,\n    position = \"identity\"   # Ensures full overlap\n  ) +\n  geom_point(data = mean_profit_fishc, \n             aes(x = mean_profit_fishc, y = Engine_Type, fill = Maintenance_Status), \n             shape = 23, size = 3, stroke = 0.5, color = \"grey90\") +\n  facet_wrap(~ Engine_Type, ncol = 1, strip.position = \"left\") +  # Separate plots for each Route_Type\n  labs(x = \"Fish Carrier\", y = NULL) +  \n  scale_fill_manual(values = c(\"Critical\" = \"#FF9EAA\",\n                               \"Good\" = \"#3AA6B9\",\n                               \"Fair\" = \"grey70\")) +  \n  scale_color_manual(values = c(\"Critical\" = \"#FF9EAA\",\n                               \"Good\" = \"#3AA6B9\",\n                               \"Fair\" = \"grey70\")) + \n  theme_classic() +\n  theme(axis.text.y = element_blank(),  \n        axis.ticks.y = element_blank(),\n        axis.line.y = element_blank(),\n        panel.grid.major = element_blank(),  \n        panel.grid.minor = element_blank(),\n        strip.text.y = element_blank(),\n        strip.background = element_blank(), \n        legend.position = \"none\",\n        plot.title = element_text(size = 12, face = \"bold\",\n                                  hjust = 0.5, vjust = -120),\n        panel.spacing = unit(1, \"lines\")\n        )\n\n###-----------4 Plot Tanker-----------###\n# Filter data for only \"Tanker\" ships\ntanker_data &lt;- ship_filter %&gt;%\n  filter(Ship_Type == \"Tanker\")\n\n# Calculate mean profit for each Engine Type and Route Type\nmean_profit_tanker &lt;- tanker_data %&gt;%\n  group_by(Engine_Type, Maintenance_Status) %&gt;%\n  summarise(mean_profit_tanker = mean(Profit, na.rm = TRUE), .groups = \"drop\")\n\n# Create Plot_tanker\np_ridg_tanker_ms &lt;- ggplot(tanker_data, aes(x = Profit, \n                        y = Engine_Type, \n                        fill = Maintenance_Status, \n                        color = Maintenance_Status)) +\n  geom_density_ridges(\n    alpha = 0.2,           \n    scale = 6,            \n    rel_min_height = 0.01,\n    position = \"identity\"   # Ensures full overlap\n  ) +\n  geom_point(data = mean_profit_tanker, \n             aes(x = mean_profit_tanker, y = Engine_Type, fill = Maintenance_Status), \n             shape = 23, size = 3, stroke = 0.5, color = \"grey90\") +\n  facet_wrap(~ Engine_Type, ncol = 1, strip.position = \"left\") +  # Separate plots for each Route_Type\n  labs(x = \"Tanker\", y = NULL) +  \n  scale_fill_manual(values = c(\"Critical\" = \"#FF9EAA\",\n                               \"Good\" = \"#3AA6B9\",\n                               \"Fair\" = \"grey70\")) +  \n  scale_color_manual(values = c(\"Critical\" = \"#FF9EAA\",\n                               \"Good\" = \"#3AA6B9\",\n                               \"Fair\" = \"grey70\")) + \n  theme_classic() +\n  theme(axis.text.y = element_blank(),  \n        axis.ticks.y = element_blank(),\n        axis.line.y = element_blank(),\n        panel.grid.major = element_blank(),  \n        panel.grid.minor = element_blank(),\n        strip.text.y = element_blank(),\n        strip.background = element_blank(), \n        legend.position = \"none\",\n        plot.title = element_text(size = 12, face = \"bold\",\n                                  hjust = 0.5, vjust = -120)\n        )\n\npatchwork &lt;- (p_ridg_bulkc_ms | p_ridg_cship_ms | p_ridg_fishc_ms | p_ridg_tanker_ms)\npatchwork \n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\nThe density plots reveal varying profit patterns across different maintenance statuses, particularly for Fish carriers and Tankers, indicating that maintenance status may have a differentiated impact on profitability depending on the ship type.\nInterestingly, ships with diesel and steam turbine engines in a Critical maintenance state tend to show consistently higher average profit across various ship types. In contrast, ships using HFO engines lag behind in terms of profitability. This pattern warrants further investigation to determine whether ships in critical maintenance states experience frequent voyages that limit maintenance time, potentially affecting performance. Additional data could help assess the relationship between ship maintenance status and profitability, especially for vessels using HFO engines.\n\n\n\n\n\n\n\n\n5.2.2 Performance Metrics\nTo analyse the performance metrics of ship types, I created scatter plots using geom_point() and geom_smooth() to visualize the data points and trend lines. In the combined plot below, the left panel shows the overall trend line, with points representing individual ship types, each color-coded accordingly. Hovering over a point reveals a tooltip with detailed information about that specific data point. On the right panel, separate trend lines for each ship type are plotted to highlight the differences in performance across ship types.\n\nEnergy EfficiencyEngine PowerAverage loadTurnaround timeCargo Weight\n\n\n\n\nShow the code\nlibrary(plotly)\np_pt_ee &lt;- ggplot(data=ship_filter,\n             aes(x = Efficiency_nm_per_kWh,\n                 y = Profit)) +\n  geom_point(size = 0.4,\n             aes(color = Ship_Type),\n             show.legend = FALSE) +\n  geom_smooth(method = lm,\n              size = 0.5) +\n  coord_cartesian(xlim=c(.1,1.5),\n                 ylim=c(-500,1000)) +\n  labs(title = \"Energy Efficiency with Overall Trend Line\",\n       x = \"Efficiency_nm_per_kWh\",\n       y = \"Profit (1KUSD)\") +\n  theme_classic() +\n  theme(plot.title = element_text(size = 10, face = \"bold\"),\n        plot.background = element_rect(fill = \"#f1f4f5\", color = NA),\n        panel.background = element_rect(fill = \"#f1f4f5\", color = NA,),\n        axis.title.x = element_text(size = 12),\n        axis.title.y = element_text(size = 12))  +\n  scale_color_manual(values = c(\"Bulk Carrier\" = \"#FF9EAA\", \n                                \"Container Ship\" = \"#3AA6B9\",\n                                \"Fish Carrier\" = \"#e0c080\",\n                                \"Tanker\" = \"#a5c7a7\")) \n\n\np_pt_ee_st &lt;- ggplot(data=ship_filter,\n             aes(x = Efficiency_nm_per_kWh,\n                 y = Profit,\n                 color = Ship_Type)) +\n  geom_point(colour = \"grey80\",\n             size = 0.4) +\n  geom_smooth(method = lm,\n              size = 0.5,\n              se = FALSE,\n              aes(color = Ship_Type)) +\n  scale_color_brewer(palette = \"Set2\") +\n  coord_cartesian(xlim=c(.1,1.5),\n                 ylim=c(-500,1000)) +\n  labs(title = \"Energy Efficiency with Trend Lines for All Ship Types\",\n       color = \"Ship Type\") +\n  theme_classic() +\n  theme(plot.title = element_text(size = 10, face = \"bold\"),\n        legend.text = element_text(size=10),\n        legend.position = \"right\",\n        plot.background = element_rect(fill = \"#f1f4f5\", color = NA),\n        legend.background = element_rect(fill = \"#f1f4f5\", color = \"#f1f4f5\"),\n        panel.background = element_rect(fill = \"#f1f4f5\", color = NA)\n        ) +\n  scale_color_manual(values = c(\"Bulk Carrier\" = \"#FF9EAA\", \n                                \"Container Ship\" = \"#3AA6B9\",\n                                \"Fish Carrier\" = \"#e0c080\",\n                                \"Tanker\" = \"#a5c7a7\")) \n\np1_plotly &lt;- ggplotly(p_pt_ee)\np2_plotly &lt;- ggplotly(p_pt_ee_st)\n\ncombined_plot &lt;- subplot(p1_plotly,  p2_plotly, nrows = 1)\n\np_plotly_ee &lt;- combined_plot %&gt;%\n  layout(\n    title = \"Energy Efficiency with Overall Trend Line\",\n    xaxis = list(title = \"Efficiency_nm_per_kWh\",\n                 titlefont = list(size = 12), tickfont = list(size = 12)),\n    yaxis = list(title = \"Profit (1KUSD)\",\n                 titlefont = list(size = 12), tickfont = list(size = 12))\n  )\np_plotly_ee\n\n\n\n\n\n\n\n\n\n\nShow the code\np_pt_ep &lt;- ggplot(data=ship_filter,\n             aes(x = Engine_Power_kW,\n                 y = Profit)) +\n  geom_point(size = 0.6,\n             aes(color = Ship_Type),\n             show.legend = FALSE) +\n  geom_smooth(method = lm,\n              size = 0.5) +\n  coord_cartesian(xlim=c(500,3000),\n                 ylim=c(-500,1000)) +\n  labs(title = \"Turnaround Time with Overall Trend Line\",\n       x = \"Engine_Power_kW\",\n       y = \"Profit (1KUSD)\") +\n  theme_classic() +\n  theme(plot.title = element_text(size = 10, face = \"bold\"),\n        plot.background = element_rect(fill = \"#f1f4f5\", color = NA),\n        panel.background = element_rect(fill = \"#f1f4f5\", color = NA)\n        ) +\n  scale_color_manual(values = c(\"Bulk Carrier\" = \"#FF9EAA\", \n                                \"Container Ship\" = \"#3AA6B9\",\n                                \"Fish Carrier\" = \"#e0c080\",\n                                \"Tanker\" = \"#a5c7a7\")) \n\n\np_pt_ep_st &lt;- ggplot(data=ship_filter,\n             aes(x = Engine_Power_kW,\n                 y = Profit,\n                 color = Ship_Type)) +\n  geom_point(size = 0.6,\n             colour = \"grey80\") +\n  geom_smooth(method = lm,\n              size = 0.5,\n              se = FALSE,\n              aes(color = Ship_Type)) +\n  scale_color_brewer(palette = \"Set2\") +\n  coord_cartesian(xlim=c(500,3000),\n                 ylim=c(-500,1000)) +\n  labs(title = \"Turnaround Time with Trend Lines for All Ship Types\",\n       color = \"Ship Type\") +\n  theme_classic() +\n  theme(plot.title = element_text(size = 10, face = \"bold\"),\n        legend.text = element_text(size=10),\n        legend.position = \"right\",\n        plot.background = element_rect(fill = \"#f1f4f5\", color = NA),\n        legend.background = element_rect(fill = \"#f1f4f5\", color = \"#f1f4f5\"),\n        panel.background = element_rect(fill = \"#f1f4f5\", color = NA)\n        ) +\n  scale_color_manual(values = c(\"Bulk Carrier\" = \"#FF9EAA\", \n                                \"Container Ship\" = \"#3AA6B9\",\n                                \"Fish Carrier\" = \"#e0c080\",\n                                \"Tanker\" = \"#a5c7a7\")) \n\n\np3_plotly &lt;- ggplotly(p_pt_ep)\np4_plotly &lt;- ggplotly(p_pt_ep_st)\n\n\ncombined_plot &lt;- subplot(p3_plotly,  p4_plotly, nrows = 1)\n\np_plotly_ep &lt;- combined_plot %&gt;%\n  layout(\n    title = \"Engine Power with Overall Trend Line\",\n    xaxis = list(title = \"Engine_Power_kW\",\n                 titlefont = list(size = 12), tickfont = list(size = 12)),\n    yaxis = list(title = \"Profit (1KUSD)\",\n                 titlefont = list(size = 12), tickfont = list(size = 12))\n  )\np_plotly_ep\n\n\n\n\n\n\n\n\n\n\nShow the code\np_pt_al &lt;- ggplot(data=ship_filter,\n             aes(x = Average_Load_Percentage,\n                 y = Profit)) +\n  geom_point(size = 0.6,\n             aes(color = Ship_Type),\n             show.legend = FALSE) +\n  geom_smooth(method = lm,\n              size = 0.5) +\n  coord_cartesian(xlim=c(40,100),\n                 ylim=c(-500,1000)) +\n  labs(title = \"Average Load vs Profit\",\n       x = \"Average_Load_Percentage\",\n       y = \"Profit (1KUSD)\") +\n  theme_classic() +\n  theme(plot.title = element_text(size = 10, face = \"bold\"),\n        plot.background = element_rect(fill = \"#f1f4f5\", color = NA),\n        legend.background = element_rect(fill = \"#f1f4f5\", color = \"#f1f4f5\"),\n        panel.background = element_rect(fill = \"#f1f4f5\", color = NA)) +\n  scale_color_manual(values = c(\"Bulk Carrier\" = \"#FF9EAA\", \n                                \"Container Ship\" = \"#3AA6B9\",\n                                \"Fish Carrier\" = \"#e0c080\",\n                                \"Tanker\" = \"#a5c7a7\")) \n\n\np_pt_al_st &lt;- ggplot(data=ship_filter,\n             aes(x = Average_Load_Percentage,\n                 y = Profit,\n                 color = Ship_Type)) +\n  geom_point(colour = \"grey\",\n             size = 0.6) +\n  geom_smooth(method = lm,\n              size = 0.5,\n              se = FALSE,\n              aes(color = Ship_Type)) +\n  scale_color_brewer(palette = \"Set2\") +\n  coord_cartesian(xlim=c(40,100),\n                 ylim=c(-500,1000)) +\n  labs(title = \"Average Load vs Profit by All Ship Types\",\n       color = \"Ship Type\") +\n  theme_classic() +\n  theme(plot.title = element_text(size = 10, face = \"bold\"),\n        legend.text = element_text(size=10),\n        legend.position = \"right\",\n        plot.background = element_rect(fill = \"#f1f4f5\", color = NA),\n        legend.background = element_rect(fill = \"#f1f4f5\", color = \"#f1f4f5\"),\n        panel.background = element_rect(fill = \"#f1f4f5\", color = NA)\n        ) +\n  scale_color_manual(values = c(\"Bulk Carrier\" = \"#FF9EAA\", \n                                \"Container Ship\" = \"#3AA6B9\",\n                                \"Fish Carrier\" = \"#e0c080\",\n                                \"Tanker\" = \"#a5c7a7\")) \n\n\np5_plotly &lt;- ggplotly(p_pt_al)\np6_plotly &lt;- ggplotly(p_pt_al_st)\n\ncombined_plot &lt;- subplot(p5_plotly,  p6_plotly, nrows = 1)\n\np_plotly_al &lt;- combined_plot %&gt;%\n  layout(\n    title = \"Average Load with Overall Trend Line\",\n    xaxis = list(title = \"Average_Load_Percentage\",\n                 titlefont = list(size = 12), tickfont = list(size = 12)),\n    yaxis = list(title = \"Profit (1KUSD)\",\n                 titlefont = list(size = 12), tickfont = list(size = 12))\n  )\np_plotly_al\n\n\n\n\n\n\n\n\n\n\nShow the code\np_pt_turntime &lt;- ggplot(data=ship_filter,\n             aes(x = Turnaround_Time_hours,\n                 y = Profit)) +\n  geom_point(size = 0.6,\n             aes(color = Ship_Type),\n             show.legend = FALSE) +\n  geom_smooth(method = lm,\n              size = 0.5) +\n  coord_cartesian(xlim=c(0,80),\n                 ylim=c(-500,1000)) +\n  labs(title = \"Turnaround Time with Overall Trend Line\",\n       x = \"Turnaround_Time_hours\",\n       y = \"Profit (1KUSD)\") +\n  theme_classic() +\n  theme(plot.title = element_text(size = 10, face = \"bold\"),\n        plot.background = element_rect(fill = \"#f1f4f5\", color = NA),\n        panel.background = element_rect(fill = \"#f1f4f5\", color = NA)) +\n  scale_color_manual(values = c(\"Bulk Carrier\" = \"#FF9EAA\", \n                                \"Container Ship\" = \"#3AA6B9\",\n                                \"Fish Carrier\" = \"#e0c080\",\n                                \"Tanker\" = \"#a5c7a7\")) \n\n\np_pt_turntime_st &lt;- ggplot(data=ship_filter,\n             aes(x = Turnaround_Time_hours,\n                 y = Profit,\n                 color = Ship_Type)) +\n  geom_point(colour = \"grey80\",\n             size = 0.6) +\n  geom_smooth(method = lm,\n              size = 0.5,\n              se = FALSE,\n              aes(color = Ship_Type)) +\n  scale_color_brewer(palette = \"Set2\") +\n  coord_cartesian(xlim=c(0, 80),\n                 ylim=c(-500,1000)) +\n  labs(title = \"Turnaround Time with Trend Lines for All Ship Types\",\n       color = \"Ship Type\") +\n  theme_classic() +\n  theme(plot.title = element_text(size = 10, face = \"bold\"),\n        legend.text = element_text(size=10),\n        legend.position = \"right\",\n        plot.background = element_rect(fill = \"#f1f4f5\", color = NA),\n        legend.background = element_rect(fill = \"#f1f4f5\", color = \"#f1f4f5\"),\n        panel.background = element_rect(fill = \"#f1f4f5\", color = NA)) +\n  scale_color_manual(values = c(\"Bulk Carrier\" = \"#FF9EAA\", \n                                \"Container Ship\" = \"#3AA6B9\",\n                                \"Fish Carrier\" = \"#e0c080\",\n                                \"Tanker\" = \"#a5c7a7\")) \n\np7_plotly &lt;- ggplotly(p_pt_turntime)\np8_plotly &lt;- ggplotly(p_pt_turntime_st)\n\ncombined_plot &lt;- subplot(p7_plotly,  p8_plotly, nrows = 1)\n\np_plotly_tt &lt;- combined_plot %&gt;%\n  layout(\n    title = \"Turnaround Time with Overall Trend Line\",\n    xaxis = list(title = \"Turnaround_Time_hours\",\n                 titlefont = list(size = 12), tickfont = list(size = 12)),\n    yaxis = list(title = \"Profit (1KUSD)\",\n                 titlefont = list(size = 12), tickfont = list(size = 12))\n  )\np_plotly_tt\n\n\n\n\n\n\n\n\n\n\nShow the code\np_pt_cargowt &lt;- ggplot(data=ship_filter,\n             aes(x = Cargo_Weight_tons,\n                 y = Profit)) +\n  geom_point(size = 0.6,\n             aes(color = Ship_Type),\n             show.legend = FALSE) +\n  geom_smooth(method = lm,\n              size = 0.5) +\n  coord_cartesian(xlim=c(50,2000),\n                 ylim=c(-500,1000)) +\n  labs(title = \"Cargo Weight with Overall Trend Line\",\n       x = \"Cargo_Weight_tons\",\n       y = \"Profit (1KUSD)\") +\n  theme_classic() +\n  theme(plot.title = element_text(size = 10, face = \"bold\"),\n        plot.background = element_rect(fill = \"#f1f4f5\", color = NA),\n        panel.background = element_rect(fill = \"#f1f4f5\", color = NA)) +\n  scale_color_manual(values = c(\"Bulk Carrier\" = \"#FF9EAA\", \n                                \"Container Ship\" = \"#3AA6B9\",\n                                \"Fish Carrier\" = \"#e0c080\",\n                                \"Tanker\" = \"#a5c7a7\")) \n\n\np_pt_cargowt_st &lt;- ggplot(data=ship_filter,\n             aes(x = Cargo_Weight_tons,\n                 y = Profit,\n                 color = Ship_Type)) +\n  geom_point(colour = \"grey80\",\n             size = 0.6) +\n  geom_smooth(method = lm,\n              size = 0.5,\n              se = FALSE,\n              aes(color = Ship_Type)) +\n  scale_color_brewer(palette = \"Set2\") +\n  coord_cartesian(xlim=c(50, 2000),\n                 ylim=c(-500,1000)) +\n  labs(title = \"Turnaround Time with Trend Lines for All Ship Types\",\n       color = \"Ship Type\") +\n  theme_classic() +\n  theme(plot.title = element_text(size = 10, face = \"bold\"),\n        legend.text = element_text(size=10),\n        legend.position = \"right\",\n        plot.background = element_rect(fill = \"#f1f4f5\", color = NA),\n        legend.background = element_rect(fill = \"#f1f4f5\", color = \"#f1f4f5\"),\n        panel.background = element_rect(fill = \"#f1f4f5\", color = NA)\n        ) +\n  scale_color_manual(values = c(\"Bulk Carrier\" = \"#FF9EAA\", \n                                \"Container Ship\" = \"#3AA6B9\",\n                                \"Fish Carrier\" = \"#e0c080\",\n                                \"Tanker\" = \"#a5c7a7\")) \n\n\np9_plotly &lt;- ggplotly(p_pt_cargowt)\np10_plotly &lt;- ggplotly(p_pt_cargowt_st)\n\ncombined_plot &lt;- subplot(p9_plotly,  p10_plotly, nrows = 1)\n\np_plotly_cw &lt;- combined_plot %&gt;%\n  layout(\n    title = \"Turnaround Time with Overall Trend Line\",\n    xaxis = list(title = \"Cargo_Weight_tons\",\n                 titlefont = list(size = 12), tickfont = list(size = 12)),\n    yaxis = list(title = \"Profit (1KUSD)\",\n                 titlefont = list(size = 12), tickfont = list(size = 12))\n  )\np_plotly_cw\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\nOverall trends in performance metrics Across the various performance metrics, both Average Load Percentage and Cargo Weight exhibit a slight upward trend, suggesting that higher load and cargo may be linked to improved profit performance. In contrast, Turnaround Time shows a mild downward slope, indicating that quicker turnarounds could positively impact profitability, aligning with industry expectations.\nEnergy efficiency and profitability for Tanker For Tanker, there is a clear positive correlation between energy efficiency and profit, suggesting that better fuel or energy management directly contributes to enhanced financial performance.\nAverage load percentage trends across ship types All ship types exhibit an overall upward trend in Average Load Percentage, but Container Ships demonstrate the most pronounced increase. This suggests that maximising load capacity might be a key driver for profit improvement, particularly for container vessels.\nTurnaround time impact on profitability Container Ships and Tankers show the most noticeable negative correlation between Turnaround Time and Profit, implying that longer wait times between voyages detract from profitability. Reducing turnaround time for these ship types could lead to more efficient operations and better financial outcomes.\nCargo weight and profit correlation Across all ship types, there is a slight but consistent positive correlation between Cargo Weight and Profit. While the relationship isn’t as strong, it suggests that heavier loads generally contribute to higher profits, emphasising the importance of maximising cargo capacity.\n\n\n\n\n\n5.2.3 Comparing Profit and Voyage frequency by ship type\ntreemap() is used to visually compare multiple categorical and numerical aspects of voyage performance. In this plot, total profit is represented by colour intensity, while voyage frequency determines the size of each rectangle. Larger rectangles indicate a higher number of trips, while darker colours represent greater profitability. The hierarchical structure follows a descending order, first grouping by ship type, then engine type, and finally route type. This organisation allows for a layered comparison, making it easier to observe patterns and relationships across these categories.\n\n\nShow the code\nlibrary(dplyr)\nship_treemap &lt;- ship_filter %&gt;%\n  group_by(Ship_Type, Engine_Type, Maintenance_Status, Weather_Condition, Route_Type) %&gt;%  \n  summarise(\n    Total_Profit = sum(Profit, na.rm = TRUE),  \n    Total_Revenue = sum(Revenue_per_Voyage_USD, na.rm = TRUE),\n    Total_Cargo = sum(Cargo_Weight_tons, na.rm = TRUE),\n    Voyage_Count = n()\n  ) %&gt;%\n  ungroup()  \n\ntreemap(ship_treemap,\n        index=c(\"Ship_Type\", \"Engine_Type\", \"Route_Type\"),\n        vSize=\"Voyage_Count\",\n        vColor=\"Total_Profit\",\n        type = \"value\",\n        palette=\"RdYlBu\",\n        algorithm = \"pivotSize\", \n        sortID = \"Total_Profit\",\n        title=\"Profit by Cargo Weight\",\n        title.legend = \"Profit ($1K USD)\",\n        border.col = c(\"black\", \"red\", \"white\"),\n        border.lwds = c(5, 2, 0.8)\n        )\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\nContainer ships powered by steam turbine engines on long-haul routes lead the industry in profitability, outperforming all other combinations of ship type, engine type, and route. Following closely behind are bulk carriers with diesel engines, also operating on long-haul routes.\nIn general, coastal and short-haul routes yield lower profits across all ship types. However, there are two notable exceptions—tankers with steam turbine engines and container ships with diesel engines, both of which achieve relatively strong profitability on coastal routes.\nWhile not universal, a clear trend emerges: most short-haul routes tend to generate lower profits, reinforcing the idea that longer voyages often offer greater financial returns.\n\n\n\n\n\n\n5.3 Performance over time\n\n5.3.1 Financial performance overview\nTo provide an overview of financial performance over time, a line chart visualises the trends in profit, revenue, and cost. The top five months with the highest profit are highlighted with red points, along with their respective profit amounts.\n\n\nShow the code\n# Extract month and year from the Date\nship_filter_month &lt;- ship_filter %&gt;%\n  mutate(Month = floor_date(Date, \"month\"))\n\n# Group by month and calculate total profit, cost, and revenue\nmonthly_totals &lt;- ship_filter_month %&gt;%\n  group_by(Month) %&gt;%\n  summarise(\n    Profit = sum(Profit, na.rm = TRUE),\n    Op_Cost = sum(Operational_Cost_USD, na.rm = TRUE),\n    Revenue = sum(Revenue_per_Voyage_USD, na.rm = TRUE)\n  )\n\n# Sort the data by Total_Profit in descending order and select the top 5 months\ntop_5_months &lt;- monthly_totals %&gt;%\n  arrange(desc(Profit)) %&gt;%\n  slice_head(n = 5) %&gt;%\n  mutate(\n    #Month_label = format(Month, \"%m/%y\"),  # Format date as mm/yy\n         Profit_label = paste0(\"$\", round(Profit, 2)))  # Create the label\n\n# Reshape the data from wide to long format\nmonthly_long &lt;- monthly_totals %&gt;%\n  pivot_longer(cols = c(Profit, Op_Cost, Revenue),\n               names_to = \"Type\",\n               values_to = \"Value\")\n\n# Plot total profit, total cost, and total revenue over time\nggplot(monthly_long, aes(x = Month, y = Value, color = Type, group = Type)) +\n  \n  geom_line(size = 0.6) +  # Line plot for each variable\n  geom_point(data = top_5_months, \n             aes(x = Month, y = Profit), \n             color = \"red\", size = 3.5, shape = 21, fill = \"red\",\n             inherit.aes = FALSE) + # Prevent from inheriting \"Type\"\n  geom_text(data = top_5_months, \n            aes(x = Month, y = Profit, label = Profit_label),\n            color = \"black\", size = 3.5, vjust = -2, hjust = 0.5,\n            inherit.aes = FALSE) +\n  labs(title = \"Profit, Cost, and Revenue Over Time\",\n       x = \"Month\",\n       y = \"Amount (1K USD)\",\n       color = \"Type\") +\n    \n  theme_light() +\n  scale_color_manual(values = c(\"Profit\" = \"#f2cbd0\", \"Op_Cost\" = \"grey70\", \n                                \"Revenue\" = \"#86b3ba\"),\n                     guide = \"none\") +\n  scale_x_date(labels = scales::date_format(\"%m/%y\"), breaks = \"1 month\") +\n  theme(plot.title = element_text(size = 14, face = \"bold\"),\n        legend.position = \"top\",\n        plot.background = element_rect(fill = \"#f1f4f5\"),\n        panel.background = element_rect(fill = \"#f1f4f5\"),\n        panel.border = element_blank()) +\n  geomtextpath::geom_textline(\n    aes(label = Type),\n    linewidth = 1,\n    fontface = \"bold\",\n    size = 3,\n    vjust = -.4,\n    hjust = .5) \n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\nThe top five months for profit are June, July, and October 2023, as well as March and June 2024.\nTotal profit fluctuates over time, but June 2024 outperformed June 2023 by 16.23%. This indicates an upward trend.\nProfit, revenue, and cost follow similar patterns, with profit and revenue showing the closest resemblance.\n\n\n\n\n\n5.3.2 Comparing Profit, Revenue, and Cost Across Ship Types\nTo compare financial performance across different ship types, I further break down the analysis by plotting profit, cost, and revenue trends for each ship type. This allows for a closer look at whether different ship types follow similar patterns over time. The top three highest amounts for each ship type are highlighted with circular points.\n\n\nShow the code\n###--------------- Plot profit\n# Aggregate total monthly profit for each ship type\nmonthly_profit &lt;- ship_filter %&gt;%\n  mutate(Month = floor_date(Date, \"month\")) %&gt;%\n  group_by(Month, Ship_Type) %&gt;%\n  summarise(Total_profit = sum(Profit, na.rm = TRUE), \n            .groups = \"drop\")\n\n# Identify top 3 months for each type\ntop_3_months &lt;- monthly_profit %&gt;%\n  group_by(Ship_Type) %&gt;%\n  slice_max(order_by = Total_profit, n = 3)\n\n# Define colors\nship_type_colors &lt;- c(\"#f2cbd0\", \"grey80\", \"grey40\", \"#9bc5cc\")\n\n# Plot profit over time for each ship type\np_line_pf &lt;- ggplot(monthly_profit, \n      aes(x = Month, \n          y = Total_profit, \n          color = Ship_Type, \n          group = Ship_Type)) +\n  geom_line(size = .8) + \n  geom_point(data = top_3_months, \n             aes(x = Month,\n                 y = Total_profit,\n                 inherit.aes = FALSE),\n             size = 3, shape = 21,\n             color = ship_type_colors[as.factor(top_3_months$Ship_Type)], \n             stroke = 1.5) +\n  labs(title = \"Monthly Profit Trends by Ship Type\",\n       x = \"Month\",\n       y = \"Total Profit (1KUSD)\",\n       color = \"Ship Type\") +\n  scale_color_manual(values = ship_type_colors) +  \n  scale_x_date(labels = scales::date_format(\"%m/%y\"), breaks = \"1 month\") +\n  theme_light() +\n  theme(plot.title = element_text(size = 14, face = \"bold\"),\n        legend.position = \"top\",\n        legend.background = element_rect(fill = \"#f1f4f5\", color = \"#f1f4f5\"),\n        legend.title = element_blank(),\n        plot.background = element_rect(fill = \"#f1f4f5\"),\n        panel.background = element_rect(fill = \"#f1f4f5\"),\n        panel.border = element_blank()) +\n  guides(fill = \"none\")\n\n###--------------- Plot cost \n# Aggregate total monthly cost for each ship type\nmonthly_cost &lt;- ship_filter %&gt;%\n  mutate(Month = floor_date(Date, \"month\")) %&gt;%\n  group_by(Month, Ship_Type) %&gt;%\n  summarise(Total_cost = sum(Operational_Cost_USD, na.rm = TRUE), \n            .groups = \"drop\")\n\n# Identify top 3 months for each type\ntop_3_months_cost &lt;- monthly_cost %&gt;%\n  group_by(Ship_Type) %&gt;%\n  slice_max(order_by = Total_cost, n = 3)\n\n# Define colors\nship_type_colors &lt;- c(\"#f2cbd0\", \"grey80\", \"grey40\", \"#9bc5cc\")\n\n# Plot cost over time for each ship type\np_line_cost &lt;- ggplot(monthly_cost, \n      aes(x = Month, \n          y = Total_cost, \n          color = Ship_Type, \n          group = Ship_Type)) +\n  geom_line(size = .8, linetype = \"twodash\") + \n  geom_point(data = top_3_months_cost, \n             aes(x = Month,\n                 y = Total_cost,\n                 inherit.aes = FALSE),\n             size = 3, shape = 21,\n             color = ship_type_colors[as.factor(top_3_months_cost$Ship_Type)], \n             stroke = 1.5) +\n  labs(title = \"Monthly Cost Trends by Ship Type\",\n       x = \"Month\",\n       y = \"Total Cost (1KUSD)\",\n       color = \"Ship Type\") +\n  scale_color_manual(values = ship_type_colors) +  \n  scale_x_date(labels = scales::date_format(\"%m/%y\"), breaks = \"1 month\") +\n  theme_light() +\n  theme(plot.title = element_text(size = 14, face = \"bold\"),\n        legend.position = \"top\",\n#        legend.background = element_rect(fill = \"#fcf0cc\", color = \"#fcf0cc\"),\n        legend.title = element_blank(),\n#       plot.background = element_rect(fill = \"#fcf0cc\"),\n#        panel.background = element_rect(fill = \"#fcf0cc\"),\n        panel.border = element_blank()) +\n  guides(fill = \"none\")\n\n###--------------- Plot revenue \n# Aggregate total monthly revenue for each ship type\nmonthly_rvn &lt;- ship_filter %&gt;%\n  mutate(Month = floor_date(Date, \"month\")) %&gt;%\n  group_by(Month, Ship_Type) %&gt;%\n  summarise(Total_rvn = sum(Revenue_per_Voyage_USD, na.rm = TRUE), \n            .groups = \"drop\")\n\n# Identify top 3 months for each type\ntop_3_months_rvn &lt;- monthly_rvn %&gt;%\n  group_by(Ship_Type) %&gt;%\n  slice_max(order_by = Total_rvn, n = 3)\n\n# Define colors\nship_type_colors &lt;- c(\"#e0bcc0\", \"grey80\", \"grey40\", \"#86b3ba\")\n\n# Plot revenue over time for each ship type\np_line_rvn &lt;- ggplot(monthly_rvn, \n      aes(x = Month, \n          y = Total_rvn, \n          color = Ship_Type, \n          group = Ship_Type)) +\n  geom_line(size = .8, linetype = \"dotted\") + \n  geom_point(data = top_3_months_rvn, \n             aes(x = Month,\n                 y = Total_rvn,\n                 inherit.aes = FALSE),\n             size = 3, shape = 21,\n             color = ship_type_colors[as.factor(top_3_months_rvn$Ship_Type)], \n             stroke = 1.5) +\n  labs(title = \"Monthly Revenue Trends by Ship Type\",\n       x = \"Month\",\n       y = \"Total Revenue (1KUSD)\",\n       color = \"Ship Type\") +\n  scale_color_manual(values = ship_type_colors) +  \n  scale_x_date(labels = scales::date_format(\"%m/%y\"), breaks = \"1 month\") +\n  theme_light() +\n  theme(plot.title = element_text(size = 14, face = \"bold\"),\n        legend.position = \"top\",\n        legend.background = element_rect(fill = \"#f1f4f5\", color = \"#f1f4f5\"),\n        legend.title = element_blank(),\n        plot.background = element_rect(fill = \"#f1f4f5\"),\n        panel.background = element_rect(fill = \"#f1f4f5\"),\n        panel.border = element_blank()) +\n  guides(fill = \"none\") \n\np_line_pf / p_line_cost / p_line_rvn \n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\nThe four ship types exhibit distinct profit patterns over time. Bulk Carriers, Container Ships, and Tankers all recorded their highest profit in March 2024, while Fish Carriers peaked in June 2024.\nBulk Carriers and Fish Carriers had contrasting profit trends in August 2023 and January 2024. Each ship type hit its lowest profit in one of these months, while the other achieved one of its highest profits.\nFish Carriers experienced the most volatile costs over time, which may be linked to voyage frequency, as referenced in section 4.4.2.\n\n\n\n\n\n5.3.3 Monthly Profit, Revenue, and Cost Trends by Ship Type\nThe top 5 total profit by ship types are highlighted\n\n\nShow the code\nlibrary(dplyr)\n# Extract month and year from the Date\nship_filter_month &lt;- ship_filter %&gt;%\n  mutate(Month = floor_date(Date, \"month\"))\n\n# Group by month and calculate total profit, cost, and revenue\nmonthly_mean_wc &lt;- ship_filter_month %&gt;%\n  group_by(Month, Weather_Condition) %&gt;%\n  summarise(\n    Profit = mean(Profit, na.rm = TRUE),\n    Op_Cost = mean(Operational_Cost_USD, na.rm = TRUE),\n    Revenue = mean(Revenue_per_Voyage_USD, na.rm = TRUE),\n    .groups = \"drop\"\n  ) \n\n# Sort the data by Total_Profit in descending order and select the top 5 months\ntop_5_months_wc &lt;- monthly_mean_wc %&gt;%\n  arrange(desc(Profit)) %&gt;%\n  slice_head(n = 5) %&gt;%\n  mutate(\n    #Month_label = format(Month, \"%m/%y\"),  # Format date as mm/yy\n         Profit_label = paste0(\"$\", round(Profit, 2)))  # Create the label\n\n# Reshape the data from wide to long format\nmonthly_long_wc &lt;- monthly_mean_wc %&gt;%\n  pivot_longer(cols = c(Profit, Op_Cost, Revenue),\n               names_to = \"Type\",\n               values_to = \"Value\")\n\n# Plot total profit, total cost, and total revenue over time\nggplot(monthly_long_wc, aes(x = Month, y = Value, color = Type, group = interaction(Weather_Condition, Type))) +\n  geom_line(size = 0.3) +  # Line plot for each variable\n  geom_point(data = top_5_months_wc, \n             aes(x = Month, y = Profit), \n             color = \"purple\", size = 3, shape = 21, fill = \"purple\",\n             inherit.aes = FALSE) + # Prevent from inheriting \"Type\"\n  geom_text(data = top_5_months_wc, \n            aes(x = Month, y = Profit, label = Profit_label),\n            color = \"black\", size = 3.5, vjust = -2, hjust = 0.5,\n            inherit.aes = FALSE) +\n  labs(title = \"Profit, Cost, and Revenue Over Time by Weather\",\n       x = \"Month\",\n       y = \"Amount (1K USD)\",\n       color = \"Type\") +\n  coord_cartesian(ylim = c(100, 610)) +\n    \n  theme_light() +\n  scale_color_manual(values = c(\"Profit\" = \"#f2cbd0\", \"Op_Cost\" = \"grey70\", \n                                \"Revenue\" = \"#9bc5cc\"),\n                     guide = \"none\") +\n  scale_x_date(labels = scales::date_format(\"%m/%y\"), breaks = \"1 month\") +\n  theme(plot.title = element_text(size = 14, face = \"bold\"),\n        legend.position = \"top\"\n        ) +\n  theme(plot.background = element_rect(fill = \"#f1f4f5\"),\n        panel.background = element_rect(fill = \"#f1f4f5\"),\n        panel.border = element_blank(),\n        axis.text.x = element_text(angle = 45, hjust = 1)) +\n  geomtextpath::geom_textline(\n    aes(label = Type),\n    linewidth = 1,\n    fontface = \"bold\",\n    size = 2,\n    vjust = -.4,\n    hjust = .5) +\n  facet_wrap(~ Weather_Condition, scales = \"free_y\") #facet by ship type\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\nThe relationship between weather conditions and voyage profitability reveals intriguing patterns. In March 2024, voyages under calm weather saw a significant surge in profit, while moderate weather conditions in May also recorded strong performance. Interestingly, rough weather conditions experienced three distinct profit peaks throughout the year, suggesting that challenging conditions do not always equate to lower profitability.\nOn the cost side, monthly operational expenses remained relatively stable across all weather conditions. Notably, costs under moderate weather showed a gradual decline, possibly indicating improved efficiency or adjustments in operations.\nA strong correlation between revenue and profit is evident, with profit peaking at different times of the year regardless of weather conditions. However, one trend remains consistent—whenever revenue rises, profit follows suit, reinforcing the impact of demand and pricing on overall voyage performance.",
    "crumbs": [
      "![](/images/house.svg)",
      "Take-home Exercise",
      "Take-home_Ex01"
    ]
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01.html#summary",
    "href": "Take-home_Ex/Take-home_Ex01.html#summary",
    "title": "Take-home Exercise 1",
    "section": "6 Summary",
    "text": "6 Summary\nThis study was conducted to understand the financial performance among different ship types using a collection of internal and external variables, as well as to undertand the profit and ship performance may be affected by other factors, such as weather conditions, energy efficiency, engine type, route type, cargo weight, etc. A variety of plots were used to explore the patterns and trends in a close look to the details to derive insights. The key findings are as follows:\n\nProfitability consistency across ship types\nStatistical analysis (Welch’s ANOVA, p-value = 0.84) indicates no significant difference in profit performance across ship types, suggesting that profitability is influenced by factors beyond vessel classification.\nEngine type and maintenance status affect profitability\nShips with diesel and steam turbine engines in a critical maintenance state tend to show higher average profits, while those using HFO engines lag behind. This suggests that frequent voyages with limited maintenance time may boost short-term profitability. Fish carriers and tankers also show varying profit patterns based on maintenance status, indicating a differentiated impact.\nWeather conditions and profitability patterns\nRough weather conditions do not always result in lower profitability. Certain ship and engine combinations show bimodal profit distributions under specific weather conditions. For example, container ships with HFO engines show a bimodal pattern in rough weather, while fish carriers with diesel or steam turbines exhibit a similar trend in calm weather.\nRoute type and profitability variation\nLong-haul routes typically yield higher profits than coastal and short-haul routes. However, tankers with steam turbine engines and container ships with diesel engines perform relatively well on coastal routes. Conversely, container ships with HFO engines show lower average profits on long-haul trips, while tankers with HFO engines exhibit a right-skewed profit distribution on coastal routes.\nOperational metrics influence financial performance\n\nLoad Capacity: Higher load percentages and cargo weights correlate with improved profits across ship types, with container ships showing the sharpest increase in load percentage over time. Turnaround Time: Longer turnaround times negatively impact profitability, particularly for container ships and tankers.\nEnergy Efficiency: Tankers show a positive correlation between energy efficiency and profitability, emphasizing the importance of fuel management.\n\nShip type-specific performance trends\n\nBulk Carriers: Exhibit longer turnaround times across all routes and lower cargo weight concentration on transoceanic trips.\nFish Carriers: Show volatile cost patterns, frequent bimodal distance distributions on long-haul routes, and longer turnaround times on short-haul voyages.\nContainer Ships: Demonstrate the highest energy efficiency in calm weather and the high average cargo weight on coastal and transoceanic routes.\nTankers: Maintain steadier voyage frequencies and show positive profitability correlations with energy efficiency.\n\nTime-based PProfit trends and market growth\nThe top five months for profit were June, July, and October 2023, as well as March and June 2024. Profit, revenue, and costs followed similar patterns, with June 2024 outperforming June 2023 by 16.23%, indicating an overall upward trend in profitability.\nweather and cost stability\nOperational costs remained stable across weather conditions, with moderate weather costs gradually declining. This reflected operational efficiency improvements. Despite slight fewer voyages in rough weather (~30% of total), profit peaks were observed in three distinct periods.\nMultimodal distributions in operational factors\nVarious performance metrics exhibit multimodal distributions rather than following a normal pattern, particularly in distance traveled on long-haul routes and engine power across ship types. These variations indicate that operational strategies differ significantly depending on ship type and route.\n\nFuture work & suggestions\n\nWork with data of longer duration: The dataset provided data for a year’s time frame, which may not be enough to conclude seasonal trends. More data with a longer time series will help navigate this.\nMore variables for exploration: Existing variables helped abstract some insights. More data and information needed to understand the trending behaviours, such as manufacture date, series number of ship, stops, restrictions of ship load, capacity, goods, size, logistics, pricing etc.\nPerform other analysis analysis: Using statistical analysis, geospatial analysis, exploratory, predictive modeling methods to perform analytics to derive more insights.",
    "crumbs": [
      "![](/images/house.svg)",
      "Take-home Exercise",
      "Take-home_Ex01"
    ]
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01.html#references",
    "href": "Take-home_Ex/Take-home_Ex01.html#references",
    "title": "Take-home Exercise 1",
    "section": "7 References",
    "text": "7 References\nKam, T. S. (2025). R for visual analytics. Retrieved from https://r4va.netlify.app/\nScherer, C. (2025). Exciting data visualizations with ggplot2 extensions. Retrieved from https://z3tt.github.io/exciting-extensions/slides.html#/course-materials",
    "crumbs": [
      "![](/images/house.svg)",
      "Take-home Exercise",
      "Take-home_Ex01"
    ]
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02.html#overview",
    "href": "Take-home_Ex/Take-home_Ex02.html#overview",
    "title": "Take-home_Ex02",
    "section": "1 Overview",
    "text": "1 Overview\nAs a visual analytics novice, I will apply newly acquired techniques to explore and analyse the changing trends and patterns of Singapore’s international trade since 2015. Using the data set from the Department of Statistics Singapore (DOS), I will re-create visualizations, offering critiques of the visualizations shared on the DOS website. In addition, I will analyze key time-series events to uncover insights from the data.\n\nTasks\nThere are 2 tasks I will complete in this assignment.\n\n1. Critiques & re-creation of visualisations\nI will select 3 visualisations from the Department of Statistics Singapore website that display the Singapore trading data. I will critique each visualisation, discuss their pros and cons. I will then provide sketches of improved versions. Using R packages, I will re-create the visualisations with clearer messaging.\n\n\n2. Data analysis\nI will perform time-series analysis using data visualisation techniques and R packages to uncover insights from the dataset.",
    "crumbs": [
      "![](/images/house.svg)",
      "Take-home Exercise",
      "Take-home_Ex02"
    ]
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02.html#visualisation-make-over",
    "href": "Take-home_Ex/Take-home_Ex02.html#visualisation-make-over",
    "title": "Take-home_Ex02",
    "section": "2 Visualisation Make-Over",
    "text": "2 Visualisation Make-Over\nThe Department of Statistics Singapore provides a series of visualizations on its website to illustrate Singapore’s international trade data. This assignment will critique three of the nine visualizations provided, highlighting their strengths and weaknesses, and then propose redesigned charts or graphics to better convey insights from the dataset.\nThe three visualizations selected for analysis are:\n\nComparison Bar Chart: Displays exports and imports from 2020 to 2024 at current prices.\nBubble Plot: Illustrates Singapore’s trade performance with major trading partners.\nMirror Bar Chart: Aims to compare imports and exports among top trading partners for the years 2019 and 2023, segmented by the top-performing trade partners.\n\nEach chart will be reviewed for aesthetics, effectiveness, and potential improvements.\n\n\n#1 Bar Chart\n\n\n#2 Bubble Plot\n\n\n#3 Mirror Bar Chart\n\n\n\n\n2.1 Visualisation #1 Bar Chart\n\n\n\n\n\nPROSCONSSKETCH\n\n\nThe visualisation has several strengths as follows:\n\nClear labeling for the bars: Each bar explicitly shows its exact value ($674.5 Bil, etc.), eliminating any guesswork about the precise figures represented.\nBalanced visual weight: The imports and exports are given equal visual prominence, avoiding biasing the viewer toward one trade direction over the other.\nComprehensive data presentation: The chart manages to show five years of data with two metrics per year plus totals (15 data points) in a single, compact visualization.\n\n\n\n\nUGLY\n\n🧶 Colours - The chart has several visual design issues that hinder its effectiveness. Primarily the colour scheme creates significant problems: each year uses a different color palette (red, yellow, blue, purple, teal), generating visual noise rather than facilitating cross-year comparisons. The colour coding makes temporal comparison difficult, while the subtle opacity differences between imports and exports provides insufficient visual distinction.\n🧶 Styling - The shipping container is appropriate to represent Trade data, but it does not enhance understanding of the data and is not recognisable at first glance.\n🧶 Labeling - system is also problematic. The Y axis labels for Imports and Exports use blue and green colouring. This introduces another colour dimension to an already chromatically overwhelming chart rather than clarifying the data.\n\nBAD\n\nThe chart’s structure impedes data interpretation. First, comparing the same metric across years is unnecessarily difficult as readers must visually jump between non-adjecent bars to track imports or exports over time. Second, the chart lacks clear visual hierarchy. The similar spacing between years and between categories within years, confuses their relationship. Third, the chosen format obscures temporal trends that would be immediately visible in a line chart or properly sequenced bar chart. Finally, displaying values to a decimal place (like $674.5 billion) creates an illusion of precision that adds no meaningful information at this scale and only contributes to visual clutter.\n\nWRONG\n\nThe “total” values, while mathematically correct, are conceptually flawed. Adding exports and imports creates a non-standard economic metric lacking clear meaning. If intended to show trade volume as an activity indicator, it should be explicitly labeled “Total Trade Volume” with context. Without this clarity, viewers might misinterpret the total as net economic benefit, when trade balance would be more meaningful.\n\n\n\nDESIGN RATIONALE\n\nDumbbell plot\nThe dumbbell plot effectively illustrates the comparison between imports and exports, highlighting the gap between the two for each year. It allows for clear observation of trends in trade values over time.\nColor scheme\nTwo distinct colors represent imports and exports, rather than using a different color for each year. This simplifies the visual presentation, as the years are clearly marked on the Y-axis and eliminate the need for color differentiation by year.\nWhat were removed\nThe cargo image, while thematically relevant, does not enhance comprehension and has been removed. Labels for trade amounts have been removed from the axes and are now placed next to the data points for better clarity.\n\n\n\n\n\n\n\n2.1.1 Data\nThe data set needed is the Merchandise Trade data from DOS website. Within the excel file Merchandise Trade By Commodity Section, (At Current Prices), Monthly, there are monthly trade volumes from 1964 Jan until 2025 Jan. The value for the amount is in thousand dollars.\nThis means some data wrangling is needed to derive the yearly sum of the trade amount for every year from 2020 ~ 2024.\nStep 1. Load and launch packages\n\n\nShow the code\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(knitr)\n\n\nStep 2. Import the data\n\nIMPORT EXCELMAKE SUBSET\n\n\n\n\nShow the code\nv1_data &lt;- read_xlsx(\"data/Mtrade_commodity.xlsx\", \"T1\")\nv1_data_import &lt;- read_xlsx(\"data/Mtrade_commodity.xlsx\", \"T3\")\nv1_data_export &lt;- read_xlsx(\"data/Mtrade_commodity.xlsx\", \"T5\")\nhead(v1_data)\n\n\n# A tibble: 6 × 734\n  ...1   ...2  ...3  ...4  ...5  ...6  ...7  ...8  ...9  ...10 ...11 ...12 ...13\n  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n1 Theme… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n2 Subje… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n3 Topic… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n4 Table… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n5 &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n6 Data … Chec… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n# ℹ 721 more variables: ...14 &lt;chr&gt;, ...15 &lt;chr&gt;, ...16 &lt;chr&gt;, ...17 &lt;chr&gt;,\n#   ...18 &lt;chr&gt;, ...19 &lt;chr&gt;, ...20 &lt;chr&gt;, ...21 &lt;chr&gt;, ...22 &lt;chr&gt;,\n#   ...23 &lt;chr&gt;, ...24 &lt;chr&gt;, ...25 &lt;chr&gt;, ...26 &lt;chr&gt;, ...27 &lt;chr&gt;,\n#   ...28 &lt;chr&gt;, ...29 &lt;chr&gt;, ...30 &lt;chr&gt;, ...31 &lt;chr&gt;, ...32 &lt;chr&gt;,\n#   ...33 &lt;chr&gt;, ...34 &lt;chr&gt;, ...35 &lt;chr&gt;, ...36 &lt;chr&gt;, ...37 &lt;chr&gt;,\n#   ...38 &lt;chr&gt;, ...39 &lt;chr&gt;, ...40 &lt;chr&gt;, ...41 &lt;chr&gt;, ...42 &lt;chr&gt;,\n#   ...43 &lt;chr&gt;, ...44 &lt;chr&gt;, ...45 &lt;chr&gt;, ...46 &lt;chr&gt;, ...47 &lt;chr&gt;, …\n\n\n\n\nObservation\n\n\n\nThe reading result shows that the fields are all in character type, which needs further conversion for computation later.\n\n\n\n\n\n\n\nShow the code\n# Make a subset of the data needed (just the total amount) - merch trade\nv1_subset &lt;- v1_data[c(10, 11),]\nv1_trans_matrix &lt;- t(v1_subset) #after transpose, the data is a matrix.\nv1_trans &lt;- as.data.frame(v1_trans_matrix) #now convert the matrix to df.\n\n# Make a subset of the data needed (just the total amount) - Imports\nv1_subset_import &lt;- v1_data_import[c(10, 11),]\nv1_trans_matrix_import &lt;- t(v1_subset_import) #after transpose, the data is a matrix.\nv1_trans_import &lt;- as.data.frame(v1_trans_matrix_import) #now convert the matrix to df.\n\n# Make a subset of the data needed (just the total amount) - Exports\nv1_subset_export &lt;- v1_data_export[c(10, 11),]\nv1_trans_matrix_export &lt;- t(v1_subset_export) #after transpose, the data is a matrix.\nv1_trans_export &lt;- as.data.frame(v1_trans_matrix_export) #now convert the matrix to df.\n\nkable(head(v1_trans))\n\n\n\n\n\n\nV1\nV2\n\n\n\n\n…1\nData Series\nTotal Merchandise Trade, (At Current Prices)\n\n\n…2\n2025 Jan\n114153979.9\n\n\n…3\n2024 Dec\n116278793.1\n\n\n…4\n2024 Nov\n110132324.5\n\n\n…5\n2024 Oct\n107525959.8\n\n\n…6\n2024 Sep\n103512459.9\n\n\n\n\n\nShow the code\nkable(head(v1_trans_import))\n\n\n\n\n\n\nV1\nV2\n\n\n\n\n…1\nData Series\nTotal Merchandise Imports\n\n\n…2\n2025 Jan\n54746366\n\n\n…3\n2024 Dec\n56135912\n\n\n…4\n2024 Nov\n51802132\n\n\n…5\n2024 Oct\n51415560\n\n\n…6\n2024 Sep\n49068356\n\n\n\n\n\nShow the code\nkable(head(v1_trans_export))\n\n\n\n\n\n\nV1\nV2\n\n\n\n\n…1\nData Series\nTotal Merchandise Exports\n\n\n…2\n2025 Jan\n59407614\n\n\n…3\n2024 Dec\n60142882\n\n\n…4\n2024 Nov\n58330193\n\n\n…5\n2024 Oct\n56110400\n\n\n…6\n2024 Sep\n54444104\n\n\n\n\n\n\n\nObservation\n\n\n\nThe subset data has new column names, so we will need to shift the first row up to be the column names.\n\n\n\n\n\n\nStep 3. Data wrangling\nIn this step, I will first correct the column names. Then I will extract the years from the 1st column so I can group them to sum up the trade values. I will also need to convert the data types to numeric from character type.\n\nMERCHANDISE TRADEIMPORTSEXPORTSCOMBINED\n\n\nBelow code is used to derive the data set for merchandise trade (import & export) yearly totals from 2020-2024.\n\n\nShow the code\n# Correct the column name\nreal_column_names &lt;- as.character(v1_trans[1, ])\ncolnames(v1_trans) &lt;- real_column_names\n\n# remove the first row\nv1_trans &lt;- v1_trans[-1, ]\n\n# Extract year first\nv1_trans$Year &lt;- substr(v1_trans$`Data Series`, 1, 4)\nv1_trans$Year &lt;- as.numeric(v1_trans$Year)\n\n# Convert type\nv1_trans$`Total Merchandise Trade, (At Current Prices)` &lt;- \n  as.numeric(v1_trans$`Total Merchandise Trade, (At Current Prices)`)\n\n# This is the data frame for visual 1\nv1_year_sum &lt;- v1_trans %&gt;%\n  filter(Year &gt;= 2020 & Year &lt;= 2024) %&gt;%\n  group_by(Year) %&gt;%\n  summarise(\n    YearTotal = sum(`Total Merchandise Trade, (At Current Prices)`, na.rm = TRUE))\n\nhead(v1_year_sum)\n\n\n# A tibble: 5 × 2\n   Year   YearTotal\n  &lt;dbl&gt;       &lt;dbl&gt;\n1  2020  969111983.\n2  2021 1159963031.\n3  2022 1365402518.\n4  2023 1205722551 \n5  2024 1285864467.\n\n\n\n\nBelow code is used to derive the data set for imports yearly totals from 2020-2024.\n\n\nShow the code\n# Correct the column name\nreal_column_names_im &lt;- as.character(v1_trans_import[1, ])\ncolnames(v1_trans_import) &lt;- real_column_names_im\n\n# remove the first row\nv1_trans_import &lt;- v1_trans_import[-1, ]\n\n# Extract year first\nv1_trans_import$Year &lt;- substr(v1_trans_import$`Data Series`, 1, 4)\nv1_trans_import$Year &lt;- as.numeric(v1_trans_import$Year)\n\n# Convert type\nv1_trans_import$`Total Merchandise Imports` &lt;- \n  as.numeric(v1_trans_import$`Total Merchandise Imports`)\n\n# This is the data frame for visual 1\nv1_year_sum_im &lt;- v1_trans_import %&gt;%\n  filter(Year &gt;= 2020 & Year &lt;= 2024) %&gt;%\n  group_by(Year) %&gt;%\n  summarise(\n    YearTotal_im = sum(`Total Merchandise Imports`, na.rm = TRUE))\n\nhead(v1_year_sum_im)\n\n\n# A tibble: 5 × 2\n   Year YearTotal_im\n  &lt;dbl&gt;        &lt;dbl&gt;\n1  2020    453467443\n2  2021    545881937\n3  2022    655435885\n4  2023    567319062\n5  2024    611359441\n\n\n\n\nBelow code is used to derive the data set for exports yearly totals from 2020-2024.\n\n\nShow the code\n# Correct the column name\nreal_column_names_ex &lt;- as.character(v1_trans_export[1, ])\ncolnames(v1_trans_export) &lt;- real_column_names_ex\n\n# remove the first row\nv1_trans_export &lt;- v1_trans_export[-1, ]\n\n# Extract year first\nv1_trans_export$Year &lt;- substr(v1_trans_export$`Data Series`, 1, 4)\nv1_trans_export$Year &lt;- as.numeric(v1_trans_export$Year)\n\n# Convert type\nv1_trans_export$`Total Merchandise Exports` &lt;- \n  as.numeric(v1_trans_export$`Total Merchandise Exports`)\n\n# This is the data frame for visual 1\nv1_year_sum_ex &lt;- v1_trans_export %&gt;%\n  filter(Year &gt;= 2020 & Year &lt;= 2024) %&gt;%\n  group_by(Year) %&gt;%\n  summarise(\n    YearTotal_ex = sum(`Total Merchandise Exports`, na.rm = TRUE))\n\nhead(v1_year_sum_ex)\n\n\n# A tibble: 5 × 2\n   Year YearTotal_ex\n  &lt;dbl&gt;        &lt;dbl&gt;\n1  2020    515644539\n2  2021    614081092\n3  2022    709966634\n4  2023    638403489\n5  2024    674505027\n\n\n\n\nI will combine Import and Export into one data frame for visualisation.\n\n\nShow the code\nv1_year_sum_im &lt;- v1_year_sum_im %&gt;%\n  rename(YearTotal = YearTotal_im) %&gt;%\n  mutate(ImEx = \"Import\")\n\nv1_year_sum_ex &lt;- v1_year_sum_ex %&gt;%\n  rename(YearTotal = YearTotal_ex) %&gt;%\n  mutate(ImEx = \"Export\")\n\nv1_combined &lt;- bind_rows(v1_year_sum_im, v1_year_sum_ex)\n\nv1_combined &lt;- v1_combined %&gt;%\n  arrange(Year, YearTotal, ImEx)\n\nhead(v1_combined)\n\n\n# A tibble: 6 × 3\n   Year YearTotal ImEx  \n  &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt; \n1  2020 453467443 Import\n2  2020 515644539 Export\n3  2021 545881937 Import\n4  2021 614081092 Export\n5  2022 655435885 Import\n6  2022 709966634 Export\n\n\n\n\n\n\n\n\n\n2.1.2 Visualisation make-over\nStep 1. Launch packages\n\n\nShow the code\nlibrary(tidyverse)\nlibrary(ggtext)\nlibrary(extrafont)\n\n\nStep 2. Code the visualisation\n\n\nShow the code\nmean_export &lt;- mean(v1_year_sum_ex$YearTotal, na.rm = TRUE)\nmean_import &lt;- mean(v1_year_sum_im$YearTotal, na.rm = TRUE)\n\np &lt;- ggplot(v1_combined)+\n  \n geom_segment(data = v1_year_sum_ex,\n              aes(x = YearTotal, y = Year,\n                  yend = v1_year_sum_im$Year, xend = v1_year_sum_im$YearTotal), \n              color = \"#aeb6bf\",\n              size = 4.5, #Note that I sized the segment to fit the points\n              alpha = .5) +\n  \n      # Add mean lines\n  geom_segment(aes(x = mean_export, \n                   y = min(v1_combined$Year),\n                   xend = mean_export, \n                   yend = 2024.5),  \n               color = \"#6A80B9\",  \n               linetype = \"solid\", \n               size = 0.2) +\n  \n  geom_segment(aes(x = mean_import, \n                   y = min(v1_combined$Year),\n                   xend = mean_import, \n                   yend = 2024.5), \n               color = \"#F37199\",  \n               linetype = \"solid\", \n               size = 0.2) +\n   # Add labels for the mean lines (display in billions)\n  annotate(\"text\", \n           x = mean_export + (max(v1_combined$YearTotal) - min(v1_combined$YearTotal))*0.05, \n           y = max(v1_combined$Year) + 0.7,\n           label = paste0(\"MEAN: \", round(mean_export/1000000, 1)),\n           color = \"#6A80B9\",\n           size = 3) +\n  \n  annotate(\"text\", \n           x = mean_import + (max(v1_combined$YearTotal) - min(v1_combined$YearTotal))*0.05,\n           y = max(v1_combined$Year) + 0.7,\n           label = paste0(\"MEAN: \", round(mean_import/1000000, 1)),\n           color = \"#F37199\",\n           size = 3) +\n  \n  geom_point(aes(x = YearTotal, y = Year, color = ImEx), \n             size = 4, \n             show.legend = TRUE) +\n  # Add text labels next to points\n  geom_text(data = v1_combined,\n            aes(x = YearTotal, y = Year, \n                label = paste0(round(YearTotal/1000000, 1)),\n                color = ImEx),\n            hjust = -0.3, # Position to the right of points\n            vjust = -2,  # Slight vertical adjustment\n            size = 2.5,   # Text size\n            show.legend = FALSE\n) +\n  \n  scale_color_manual(values = c(\"Import\" = \"#F37199\", \"Export\" = \"#6A80B9\")) +\n  labs(\n    x = \"Singapore Trade Volume (Billion S$)\",\n    y = \"Year\",\n    title = \"Total Merchandise Trade at Current Prices\",\n    subtitle = \"2020 - 2024\",\n    color = \"Import/Export\"\n  ) +\n    # Convert x-axis from thousands to billions\n  scale_x_continuous(labels = function(x) paste0(round(x/1000000, 1))) +\n  theme(\n    axis.title.x = element_text(\n      family = \"\",\n      size = 12,\n      face = \"bold\",\n      color = \"black\",\n      hjust = 1,\n      vjust = -1),\n    axis.title.y = element_text(\n      family = \"\",\n      size = 12,\n      face = \"bold\",\n      color = \"black\",\n      hjust = 0.5,\n      vjust = 2),\n    title = element_text(size = 15, face = \"bold\"),\n    legend.title = element_text(size = 12, face = \"bold\"),\n    legend.text = element_text(size = 10),\n    legend.position = \"right\",# Options: \"right\", \"left\", \"top\", \"bottom\", or c(x, y) coordinates\n    legend.background = element_blank(),\n    plot.background = element_rect(fill = \"#f1f4f5\"),\n    panel.background = element_blank()\n    ) \n\ndiff &lt;- v1_combined %&gt;%\n  tidyr::pivot_wider(\n    id_cols = Year,\n    names_from = ImEx,\n    values_from = YearTotal\n  ) \n\ndiff$Difference &lt;- diff$Export - diff$Import\ndiff$x_pos &lt;- diff$Import + (diff$Difference/2)\n\n\np +\n  geom_text(data = diff,\n            aes(label = paste(\"D: \", round(Difference/1000000, 1)),\n                x = x_pos, y = Year),\n            fill = \"white\",\n            color = \"black\",\n            size = 2,\n            show.legend = FALSE) -&gt; p_labelled\n\np_labelled\n\n\n\n\n\n\n\n\n\n\n\nMake-over\n\n\n\nColor - Used a focused two-color scheme to clearly distinguish between export and import values, enhancing data interpretation.\nTrends presentation - Viwers can easily tell the trends of Export and Import along the years 2020-2024 with an emphasis on the year-over-year trade patterns across the 2020-2024 period.\nMean score - Integrated mean value reference lines for both exports and imports.\nTrade surplus - Instead of showing the total volume of trade, the dumbbell format to highlight the gap between export and import values is utilised to easilty understand Surplus/Deficit amount. Utilized the dumbbell format to highlight the gap between export and import values\nX and Y axis - They are clearly defined with appropriate positions and labels, making the time progression and value comparisons intuitive\nData figures - Export and Import amounts for each year are annotated near the points, so it’s easy to refer to the actual amounts.\n\nThese improvements overall makes the plot more prominent in showing the trends of trade and Singapore’s trade balance position in these recent years.\n\n\n\n\n\n2.2 Visualisation #2 Bubble Plot\n\n\n\n\n\nPROSCONSSKETCH\n\n\n\nDual-color background (blue and green) - shows which trading relationship favour imports and exports.\nBubble size - The bubble size visually represent total trade volume, which makes it easy to identify Singapore’s most significant partner at a glance.\nLabeling - The labeling for each country provides the name and its total trade volume so viewers can easily retrieve the information.\nFootnote - It has also included an explanatory note to clarify how to interpret the bubble positions relative to the diagnol dividing line.\n\n\n\nUGLY\n\nColor - Similar to Visualisation #1, the color scheme lacks cohesion. Each country has a different color without any apparent system or logic. Although at first glance it looks colorful, it has added noise rather than enhaning understanding.\nLabeling - Although the labels provide useful information, they altogether make the chart unnecessary clutter looking. The positioning and spacing relative to their bubbles are inconsistent and look random.\n\nBAD\n\nThe explanatory text at the bottom is lengthy and could be simplified or converted to visual elements for quicker comprehension.\nThe footnote states that viewer can use the centre point (white circle) of the bubble to determine whether Singapore has deficit or surplus with the trading partner, but lacking coloring opacity made it hard to achieve this.\n\n\n\nWRONG\n\nLabeling - On the website, the lables for X axis and Y axis are in confusing positions where viewer might misunderstand the x axis as Imports and y as Exports, as it is against the normal axis labeling convention. This issue does not appear in the PDF file for download.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.2.1 Data\nFor this visualisation, the dataset Merchandise Trade by Region/Market from the Department of Statistics Singapore (DOS) will be used.\nThe dataset consists of three tabs: Imports, Domestic Exports, and Re-Exports. I will combine data from all three tabs to calculate the total trade volume for each country, which will be plotted in a bubble plot. The dataset contains monthly trade volumes from January 2003 to January 2025, with trade values expressed in millions of dollars. Data wrangling is required to aggregate the trade amounts by year for 2024.\nStep 1. Load and launch packages\n\n\nShow the code\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(knitr)\n\n\nStep 2. Import the data and make subsets\n\nIMPORT EXCELIMPORTEXPORTRE-EXPORT\n\n\n\n\nShow the code\nv2_data_im &lt;- read_xlsx(\"data/Mtrade_region.xlsx\", \"T1\")\nv2_data_ex &lt;- read_xlsx(\"data/Mtrade_region.xlsx\", \"T2\")\nv2_data_reex &lt;- read_xlsx(\"data/Mtrade_region.xlsx\", \"T3\")\nhead(v2_data_im)\n\n\n# A tibble: 6 × 266\n  ...1   ...2  ...3  ...4  ...5  ...6  ...7  ...8  ...9  ...10 ...11 ...12 ...13\n  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n1 Theme… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n2 Subje… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n3 Topic… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n4 Table… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n5 &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n6 Data … Chec… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n# ℹ 253 more variables: ...14 &lt;chr&gt;, ...15 &lt;chr&gt;, ...16 &lt;chr&gt;, ...17 &lt;chr&gt;,\n#   ...18 &lt;chr&gt;, ...19 &lt;chr&gt;, ...20 &lt;chr&gt;, ...21 &lt;chr&gt;, ...22 &lt;chr&gt;,\n#   ...23 &lt;chr&gt;, ...24 &lt;chr&gt;, ...25 &lt;chr&gt;, ...26 &lt;chr&gt;, ...27 &lt;chr&gt;,\n#   ...28 &lt;chr&gt;, ...29 &lt;chr&gt;, ...30 &lt;chr&gt;, ...31 &lt;chr&gt;, ...32 &lt;chr&gt;,\n#   ...33 &lt;chr&gt;, ...34 &lt;chr&gt;, ...35 &lt;chr&gt;, ...36 &lt;chr&gt;, ...37 &lt;chr&gt;,\n#   ...38 &lt;chr&gt;, ...39 &lt;chr&gt;, ...40 &lt;chr&gt;, ...41 &lt;chr&gt;, ...42 &lt;chr&gt;,\n#   ...43 &lt;chr&gt;, ...44 &lt;chr&gt;, ...45 &lt;chr&gt;, ...46 &lt;chr&gt;, ...47 &lt;chr&gt;, …\n\n\n\n\nObservation\n\n\n\nSimilar to the other set of data used in the previous section, the reading result shows that the fields are all in character type. The dataset also needs further conversion for computation later.\n\n\n\n\n\n\n\nShow the code\n# Make a subset of the total IMPORT amount for each country\nv2_subset_im &lt;- v2_data_im[c(10:170),]\nv2_trans_matrix_im &lt;- t(v2_subset_im) #after transpose, the data is a matrix.\nv2_trans_im &lt;- as.data.frame(v2_trans_matrix_im) #now convert the matrix to df.\nkable(head(v2_trans_im))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nV1\nV2\nV3\nV4\nV5\nV6\nV7\nV8\nV9\nV10\nV11\nV12\nV13\nV14\nV15\nV16\nV17\nV18\nV19\nV20\nV21\nV22\nV23\nV24\nV25\nV26\nV27\nV28\nV29\nV30\nV31\nV32\nV33\nV34\nV35\nV36\nV37\nV38\nV39\nV40\nV41\nV42\nV43\nV44\nV45\nV46\nV47\nV48\nV49\nV50\nV51\nV52\nV53\nV54\nV55\nV56\nV57\nV58\nV59\nV60\nV61\nV62\nV63\nV64\nV65\nV66\nV67\nV68\nV69\nV70\nV71\nV72\nV73\nV74\nV75\nV76\nV77\nV78\nV79\nV80\nV81\nV82\nV83\nV84\nV85\nV86\nV87\nV88\nV89\nV90\nV91\nV92\nV93\nV94\nV95\nV96\nV97\nV98\nV99\nV100\nV101\nV102\nV103\nV104\nV105\nV106\nV107\nV108\nV109\nV110\nV111\nV112\nV113\nV114\nV115\nV116\nV117\nV118\nV119\nV120\nV121\nV122\nV123\nV124\nV125\nV126\nV127\nV128\nV129\nV130\nV131\nV132\nV133\nV134\nV135\nV136\nV137\nV138\nV139\nV140\nV141\nV142\nV143\nV144\nV145\nV146\nV147\nV148\nV149\nV150\nV151\nV152\nV153\nV154\nV155\nV156\nV157\nV158\nV159\nV160\nV161\n\n\n\n\n…1\nData Series\nTotal All Markets\nAmerica\nAntigua And Barbuda\nArgentina\nBahamas\nBermuda\nBrazil\nCanada\nChile\nColombia\nCosta Rica\nCuba\nDominican Rep\nEcuador\nEl Salvador\nGuatemala\nGuyana\nHonduras\nJamaica\nMexico\nNetherlands Antilles\nPanama\nParaguay\nPeru\nPuerto Rico\nSt. Vincent And The Grenadines\nTrinidad And Tobago\nUnited States\nUnited States Virgin Islands\nUruguay\nVenezuela\nOther Markets America\nAsia\nAfghanistan\nBahrain\nBangladesh\nBrunei\nCambodia\nChina\nChristmas Island\nHong Kong\nIndia\nIndonesia\nIran\nIraq\nIsrael\nJapan\nJordan\nKazakhstan\nKorea, Dem Peo Rep Of\nKorea, Rep Of\nKuwait\nLao\nLebanon\nMacao\nMalaysia\nMaldives\nMongolia\nMyanmar\nNepal\nOman\nPakistan\nPhilippines\nQatar\nSaudi Arabia\nSri Lanka\nSyria\nTaiwan\nThailand\nTurkiye\nUnited Arab Emirates\nViet Nam\nYemen\nOther Markets Asia\nEurope\nAustria\nBelarus\nBelgium\nBulgaria\nCroatia\nCyprus\nCzech Rep\nDenmark\nEstonia\nFinland\nFrance\nGermany\nGreece\nHungary\nIreland\nItaly\nLatvia\nLithuania\nLuxembourg\nMalta\nNetherlands\nNorway\nPoland\nPortugal\nRomania\nRussia\nSlovakia\nSlovenia\nSpain\nSvalbard And Jan Mayen Islands\nSweden\nSwitzerland\nUkraine\nUnited Kingdom\nOther Markets Europe\nOceania\nAntarctica\nAustralia\nFiji\nFrench Polynesia\nGuam\nMarshall Islands\nNew Caledonia\nNew Zealand\nNorthern Mariana Islands\nPapua New Guinea\nSamoa\nSolomon Islands\nVanuatu\nOther Markets Oceania\nAfrica\nAlgeria\nAngola\nBenin\nCameroon\nCape Verde\nComoros\nCongo, Dem Rep Of\nCote D’ivoire\nDjibouti\nEgypt\nEthiopia\nGabon\nGhana\nGuinea\nKenya\nLiberia\nLibya\nMadagascar\nMauritius\nMorocco\nMozambique\nNigeria\nReunion\nSeychelles\nSierra Leone\nSomalia\nSouth Africa\nSudan\nSwaziland\nTanzania\nTunisia\nZambia\nZimbabwe\nOther Markets Africa\n\n\n…2\n2025 Jan\n54746.4\n6923.3\n0\n4\n0\n0\n870.2\n267.5\n12.6\n17.6\n40\n0.6\n5.7\n15.2\n1.2\n0.2\n0.3\n0.9\n0.1\n267.6\n0\n0.3\n0.3\n9.4\n15.9\n0\n1.3\n5388.6\n0\n2.7\n0\n0.8\n39520.8\n0\n86\n16.3\n205.5\n87.8\n6801.2\n0\n696\n1098.7\n1765.7\n1.6\n201.9\n64\n2600.1\n2.9\n12.8\n0\n3775\n100.3\n7.9\n0.3\n0.3\n6445.1\n0.1\n0\n4.3\n0.3\n140.6\n58.6\n539.6\n507.1\n658.1\n10\n0\n10152.7\n1139.7\n96.2\n1340.2\n794\n0\n109.7\n6931.2\n91.3\n3.1\n191.5\n5.1\n1.9\n3.1\n126.9\n134.6\n29.6\n41\n1248.2\n902.9\n21.3\n45.4\n327\n636\n1.4\n7.8\n3.4\n10.9\n294.2\n78.1\n80\n32.3\n31.3\n494.8\n10.6\n8.5\n113.3\n0\n132.8\n725.1\n3.2\n1086.5\n8.1\n666.1\n0\n574.5\n0.6\n0\n0\n0\n0\n80.3\n0\n10.1\n0\n0\n0\n0.4\n705.1\n0\n68.5\n0\n36.6\n0.3\n0\n20.2\n5.5\n0.8\n82.8\n8.2\n0\n18.2\n0\n1.6\n0\n0\n2.8\n0.6\n18.5\n14.4\n118.9\n0\n0.1\n0\n0\n103.5\n0\n0.1\n1.8\n12\n18.8\n1.5\n169.1\n\n\n…3\n2024 Dec\n56135.9\n7873.7\n0\n12.5\n8.1\n0\n586.8\n212.7\n5.7\n19.4\n72.5\n0.8\n6.1\n8.8\n2.5\n0.3\n0\n0.5\n0.1\n263.7\n0\n0.3\n0.7\n8.1\n10.2\n0\n0.1\n6651.8\n0\n0.7\n0\n1.4\n39721.8\n0\n81.4\n18.1\n94.7\n50.1\n7168\n0\n769.2\n857\n2006.9\n4\n459.2\n76.6\n2790.1\n5.4\n7.6\n0\n3675.7\n152.5\n6\n0.2\n0.4\n6569.9\n3.9\n0\n5.5\n0.1\n41.4\n17.3\n654.4\n507.5\n838.9\n11.2\n0\n8847.7\n1421.6\n67\n1659.5\n781.2\n0.1\n71.5\n7373.9\n77.4\n0.3\n134.9\n8.3\n2.6\n2.4\n133.3\n77.4\n5.6\n49.1\n1355.9\n1108.3\n43.7\n56.7\n449.3\n633.1\n2\n9.3\n3\n71\n331.4\n53.7\n71.6\n41\n19.8\n367.1\n11.5\n7.2\n179.5\n0\n172.8\n702.6\n14.1\n1166.6\n11.6\n751.8\n0\n671.1\n0.4\n2.5\n0\n0\n0.4\n60\n0\n15.5\n0\n0.1\n0.1\n1.7\n414.7\n19.7\n0\n0\n15\n0\n0\n5.5\n9.3\n0\n3.5\n4.8\n0\n12.8\n0\n1.3\n0\n0\n2.2\n1\n23.9\n89\n72.3\n0\n0.1\n0\n0\n40.1\n0\n0.4\n22.8\n11.2\n0.2\n0.1\n79.4\n\n\n…4\n2024 Nov\n51802.1\n7879.6\n0\n116.2\n0\n0\n942.4\n221.6\n8\n9.2\n70.2\n1.3\n5.9\n7.7\n1.2\n0.3\n0.1\n0.3\n0\n426.6\n0\n0.1\n0.4\n18.3\n9.8\n0\n49.6\n5988.7\n0\n0.9\n0\n0.7\n35194.8\n0\n2.1\n16.6\n93.7\n120.3\n6841.2\n0\n442.4\n909.9\n1940.8\n2.3\n164.8\n69.5\n2879.8\n4.9\n26.9\n0\n2793.8\n223.6\n1.1\n0.6\n1\n5778.2\n3.6\n0\n8.7\n0.5\n39.1\n6.4\n496\n441.7\n973.2\n12.9\n0\n7360\n1228.3\n41\n1538.8\n717.1\n0.3\n13.6\n7666.3\n104.5\n3.3\n132.9\n10.2\n2.2\n5.4\n100.8\n105.5\n26.4\n29.9\n1549.4\n1070.4\n12\n59.9\n494\n671.4\n1.9\n11.7\n3.2\n13.4\n274.5\n66.6\n75.8\n34.5\n24.8\n432.5\n12.1\n9.3\n351.7\n0\n123.9\n684.6\n11.4\n1146.9\n9.2\n404.5\n0\n338.7\n0.2\n0\n0\n0\n0\n55.7\n0\n9\n0\n0\n0\n0.9\n656.9\n47.6\n152.9\n0\n7.2\n0\n0\n1.5\n12.4\n0.5\n37.5\n11.8\n0\n24.7\n0\n1.3\n0\n0\n2\n0.9\n15.9\n59.8\n17.2\n0\n0\n0.2\n0\n51.2\n0\n0\n4.1\n12\n23.6\n1.2\n171.4\n\n\n…5\n2024 Oct\n51415.6\n8077.6\n0\n4.1\n0\n0\n639.9\n323.8\n7.1\n2.4\n58\n0.8\n7.4\n9.7\n1.4\n1.3\n0.3\n1\n0.1\n897.9\n0\n0.3\n0.4\n14.6\n9.7\n0\n0\n6092.8\n0\n2\n0.1\n2.3\n34284.1\n0\n115.9\n15.4\n94.7\n15\n6070.1\n0\n386.8\n989.6\n1973.1\n1\n203.8\n83.2\n2943.2\n4\n0\n0\n3000.3\n55.7\n0.7\n0.3\n1.9\n5574\n0.5\n0.1\n7\n0.8\n66.4\n56.5\n462.4\n551.2\n881.1\n9.4\n0\n6976.4\n1517.2\n50.2\n1371.3\n803.6\n0\n1.3\n7204.6\n100.8\n1.2\n208\n4.6\n2.7\n1.6\n114.2\n51.1\n4.1\n35.9\n1393.9\n1103.5\n13.3\n48.3\n199.9\n644.9\n3.8\n10.8\n1.4\n14.4\n537.3\n54.4\n83.3\n33.3\n31\n535.5\n8.4\n6.6\n124.2\n0\n131.2\n743.8\n7\n940.7\n9.6\n1097.3\n0\n1002.6\n0.3\n0\n1\n0\n0.5\n64.9\n0\n27.7\n0\n0\n0\n0.3\n751.9\n117.5\n0.5\n0\n16.5\n0.2\n0.3\n2.9\n18.9\n0.5\n1.7\n29.7\n0\n14\n0\n0.8\n0\n0\n0.5\n0.7\n15.3\n130.6\n183.7\n0.2\n0.1\n0\n0\n88.1\n42.4\n0\n0.5\n12\n0\n1.4\n72.8\n\n\n…6\n2024 Sep\n49068.4\n9112\n0\n8.1\n0\n0\n786.6\n236.5\n2.3\n3.3\n50.1\n1\n7.4\n3.7\n1.5\n0.9\n0.1\n0.3\n0.1\n1486.9\n0\n43.7\n0.7\n1.8\n7.4\n0\n1.9\n6449.3\n0\n17.4\n0\n1\n31828.7\n0\n23\n27.3\n83.9\n26.6\n5716.2\n0.1\n476.6\n774.4\n1650.2\n0\n133.3\n90.1\n2381.9\n2.2\n0.7\n0\n3041.7\n2.4\n0.5\n0.3\n0.1\n5462\n0.1\n0.2\n10.3\n0.6\n37.1\n19\n458\n460.4\n507.6\n8.7\n0\n7195.8\n1250.2\n98.4\n1193.1\n694.4\n0.3\n1.2\n6825.8\n104.3\n6.2\n101\n4.4\n3.2\n1.5\n228.1\n66.1\n31.9\n46.7\n1325.7\n1081.3\n134.6\n59.6\n502.2\n603.3\n2.1\n10.1\n4.2\n28.8\n270.6\n42.7\n78.9\n32.5\n26.4\n186.2\n10.6\n7.3\n153.5\n0\n147.8\n571.3\n3.2\n942.5\n6.9\n566.9\n0\n449.6\n0.8\n0.2\n0.1\n0\n0.1\n97.6\n0\n17.8\n0.1\n0\n0\n0.6\n735\n0\n217.8\n0\n11.1\n0\n1.2\n0.1\n12.4\n0\n24.8\n6.3\n0\n6\n0\n0.6\n0\n0\n2.6\n0.4\n19.6\n141.7\n160\n3.5\n0\n0\n0\n44.7\n0\n0.1\n1.2\n7.1\n0.2\n1.9\n71.4\n\n\n\n\n\n\n\n\n\nShow the code\nv2_subset_ex &lt;- v2_data_ex[c(10:170),]\nv2_trans_matrix_ex &lt;- t(v2_subset_ex) #after transpose, the data is a matrix.\nv2_trans_ex &lt;- as.data.frame(v2_trans_matrix_ex) #now convert the matrix to df.\nkable(head(v2_trans_ex))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nV1\nV2\nV3\nV4\nV5\nV6\nV7\nV8\nV9\nV10\nV11\nV12\nV13\nV14\nV15\nV16\nV17\nV18\nV19\nV20\nV21\nV22\nV23\nV24\nV25\nV26\nV27\nV28\nV29\nV30\nV31\nV32\nV33\nV34\nV35\nV36\nV37\nV38\nV39\nV40\nV41\nV42\nV43\nV44\nV45\nV46\nV47\nV48\nV49\nV50\nV51\nV52\nV53\nV54\nV55\nV56\nV57\nV58\nV59\nV60\nV61\nV62\nV63\nV64\nV65\nV66\nV67\nV68\nV69\nV70\nV71\nV72\nV73\nV74\nV75\nV76\nV77\nV78\nV79\nV80\nV81\nV82\nV83\nV84\nV85\nV86\nV87\nV88\nV89\nV90\nV91\nV92\nV93\nV94\nV95\nV96\nV97\nV98\nV99\nV100\nV101\nV102\nV103\nV104\nV105\nV106\nV107\nV108\nV109\nV110\nV111\nV112\nV113\nV114\nV115\nV116\nV117\nV118\nV119\nV120\nV121\nV122\nV123\nV124\nV125\nV126\nV127\nV128\nV129\nV130\nV131\nV132\nV133\nV134\nV135\nV136\nV137\nV138\nV139\nV140\nV141\nV142\nV143\nV144\nV145\nV146\nV147\nV148\nV149\nV150\nV151\nV152\nV153\nV154\nV155\nV156\nV157\nV158\nV159\nV160\nV161\n\n\n\n\n…1\nData Series\nTotal All Markets\nAmerica\nAntigua And Barbuda\nArgentina\nBahamas\nBermuda\nBrazil\nCanada\nChile\nColombia\nCosta Rica\nCuba\nDominican Rep\nEcuador\nEl Salvador\nGuatemala\nGuyana\nHonduras\nJamaica\nMexico\nNetherlands Antilles\nPanama\nParaguay\nPeru\nPuerto Rico\nSt. Vincent And The Grenadines\nTrinidad And Tobago\nUnited States\nUnited States Virgin Islands\nUruguay\nVenezuela\nOther Markets America\nAsia\nAfghanistan\nBahrain\nBangladesh\nBrunei\nCambodia\nChina\nChristmas Island\nHong Kong\nIndia\nIndonesia\nIran\nIraq\nIsrael\nJapan\nJordan\nKazakhstan\nKorea, Dem Peo Rep Of\nKorea, Rep Of\nKuwait\nLao\nLebanon\nMacao\nMalaysia\nMaldives\nMongolia\nMyanmar\nNepal\nOman\nPakistan\nPhilippines\nQatar\nSaudi Arabia\nSri Lanka\nSyria\nTaiwan\nThailand\nTurkiye\nUnited Arab Emirates\nViet Nam\nYemen\nOther Markets Asia\nEurope\nAustria\nBelarus\nBelgium\nBulgaria\nCroatia\nCyprus\nCzech Rep\nDenmark\nEstonia\nFinland\nFrance\nGermany\nGreece\nHungary\nIreland\nItaly\nLatvia\nLithuania\nLuxembourg\nMalta\nNetherlands\nNorway\nPoland\nPortugal\nRomania\nRussia\nSlovakia\nSlovenia\nSpain\nSvalbard And Jan Mayen Islands\nSweden\nSwitzerland\nUkraine\nUnited Kingdom\nOther Markets Europe\nOceania\nAntarctica\nAustralia\nFiji\nFrench Polynesia\nGuam\nMarshall Islands\nNew Caledonia\nNew Zealand\nNorthern Mariana Islands\nPapua New Guinea\nSamoa\nSolomon Islands\nVanuatu\nOther Markets Oceania\nAfrica\nAlgeria\nAngola\nBenin\nCameroon\nCape Verde\nComoros\nCongo, Dem Rep Of\nCote D’ivoire\nDjibouti\nEgypt\nEthiopia\nGabon\nGhana\nGuinea\nKenya\nLiberia\nLibya\nMadagascar\nMauritius\nMorocco\nMozambique\nNigeria\nReunion\nSeychelles\nSierra Leone\nSomalia\nSouth Africa\nSudan\nSwaziland\nTanzania\nTunisia\nZambia\nZimbabwe\nOther Markets Africa\n\n\n…2\n2025 Jan\n24672\n4263.1\n8.8\n5.3\n51.4\n2.7\n40.2\n33.7\n5.1\n4.3\n4.8\n0\n1.1\n2.9\n0.6\n0.3\n7.2\n0.9\n0\n48.2\n0\n532.6\n0.2\n3.7\n238.5\n0.7\n0.3\n3254.7\n0\n0.6\n0\n14.3\n15623.3\n0\n2.3\n194.6\n17.8\n103.9\n2257.3\n0\n1866.1\n638.1\n2002.7\n1.1\n8.4\n27.4\n830\n0.8\n5.7\n0\n1110.4\n16.2\n3.6\n0.7\n4.4\n2468.6\n9.1\n2.9\n273.4\n5.7\n91.8\n180.4\n566.1\n87.7\n73.6\n77.9\n0.2\n1099.7\n616.5\n30.6\n178\n759.2\n1\n9.6\n2123.3\n5.4\n0\n128.9\n0.2\n2.1\n46.1\n3.8\n36.4\n12.2\n5.9\n114.2\n189\n65.2\n44.2\n92.4\n55\n0.6\n0.1\n1.4\n189.6\n622.8\n65.5\n33.1\n70.3\n3.9\n9.8\n0.5\n1.8\n9.2\n0\n2.1\n137.8\n0.4\n134.3\n39.1\n1821.9\n0\n908\n21.3\n4.1\n24.1\n425.5\n16.3\n303.9\n4.5\n82.4\n0\n16.7\n1.3\n13.7\n840.3\n2\n21.6\n0\n2.1\n0.1\n0.1\n1.9\n4.4\n0.1\n16.2\n2.2\n1\n4\n2.5\n2.7\n669.5\n4\n0.1\n8.1\n19.6\n0.6\n21.2\n23.4\n0.6\n2.5\n0\n12.9\n0\n1.5\n7\n0.6\n0.3\n0.9\n6.6\n\n\n…3\n2024 Dec\n23684.7\n3607.9\n7.1\n6\n48.1\n7.7\n32.3\n35.6\n4.7\n7.8\n4\n0.4\n3.3\n2.1\n0.1\n0.5\n6.9\n0.5\n0.1\n52\n0\n493\n0.2\n4.8\n89.1\n0.9\n0.8\n2781.3\n0\n1.2\n0\n17.5\n15306\n0\n5\n168.9\n15.5\n87\n2871.4\n0\n1583.9\n544.9\n2068\n0.1\n7.1\n23.2\n828.6\n8\n3\n0\n944\n14.5\n3.3\n0.3\n5.6\n2276.5\n9.4\n3.2\n208.8\n5.8\n13.3\n83.2\n347.7\n72.8\n117.2\n105.3\n0\n1255\n684.7\n39.3\n195.9\n694.8\n0.1\n10.9\n2053\n9.1\n0.2\n206.7\n0.3\n1.9\n36\n3.6\n37.5\n16.3\n8.4\n93.3\n265.8\n79.2\n4.6\n74.3\n50.2\n1.6\n0.2\n8.7\n167.9\n420.5\n59.5\n21.4\n52\n3.1\n9.5\n0.6\n2.9\n17.5\n0\n2.4\n76.8\n0\n288.3\n32.6\n1885.4\n0\n928\n66.6\n0.6\n24.6\n393.9\n20.2\n344.8\n11.7\n61.2\n13.6\n7.4\n1.5\n11.4\n832.4\n4.9\n13.5\n0.2\n3.6\n0\n3.7\n1\n0.5\n0.2\n15.7\n1.9\n1.9\n25.6\n3.7\n10.9\n624.4\n1.6\n0.1\n2.4\n17.5\n3\n7.8\n51.2\n0.7\n2.2\n0.2\n16.7\n0\n2.1\n4.3\n1\n0.5\n0.3\n9\n\n\n…4\n2024 Nov\n23438.7\n3128.7\n8.3\n3.9\n60.5\n0.5\n37.8\n78.9\n4.4\n4.2\n4.5\n0\n1.2\n3.2\n0.8\n0.6\n4.1\n0.1\n0\n69.4\n0\n520.7\n0\n5.7\n122.4\n0.1\n0.3\n2179.1\n0\n0.4\n0.1\n17.3\n14697.1\n0\n13.6\n280.4\n20\n139.6\n2633.5\n0\n1538.5\n709\n1839.6\n1.2\n4.9\n22.3\n771.5\n1.8\n2.5\n0\n881.7\n16.3\n3.1\n0.7\n6.6\n2189.8\n4.9\n4.9\n189.3\n2.4\n14.3\n128.8\n424.9\n58.8\n85.5\n84.8\n0.1\n1101.6\n760.2\n41.6\n187.9\n520.2\n0.7\n9.6\n2268.5\n8.5\n0.1\n136.4\n0.1\n1.3\n63.2\n6.2\n38.3\n3.8\n4.7\n141.2\n184.6\n84.6\n18.8\n126.9\n75.2\n0.2\n0.8\n2.1\n186.8\n372.6\n51.1\n24.5\n59.5\n6.3\n10.3\n0.6\n3.8\n11.2\n0\n2\n93.1\n0\n521\n28.4\n2475.6\n0\n1234.7\n38.3\n3.3\n22.4\n680.8\n68.5\n300.2\n11\n80.1\n4.7\n15.8\n4.8\n10.9\n868.8\n2.6\n40.5\n0.1\n3.5\n0\n1.5\n1.6\n1.1\n0.1\n19\n2.8\n3.2\n4.1\n2.5\n7.5\n645.7\n3\n0\n2.4\n34.7\n1.1\n9.7\n45.3\n0.4\n2.6\n0.2\n16.6\n0\n2\n4.6\n0.1\n0.3\n1.1\n8.7\n\n\n…5\n2024 Oct\n22147.8\n2935.5\n7.7\n6.4\n36.1\n5.4\n62.2\n38.6\n6.9\n5.3\n4.3\n0\n1.7\n3.3\n0.5\n0.4\n2.9\n0.6\n0.1\n60.4\n0\n492.9\n0.2\n5.9\n49.4\n1.6\n0.6\n2126.5\n0\n0.4\n0.1\n15.2\n14497.3\n0\n2.3\n202.4\n19.7\n208.6\n2845\n0\n1060.3\n516.3\n1633.6\n0\n5.9\n27.4\n793.6\n9.7\n2\n0\n886.3\n20.5\n2.6\n0.4\n3.1\n2406.4\n4.2\n2.7\n223.3\n2.8\n17.5\n112.3\n488.2\n62.2\n121\n173.7\n0.1\n1146.6\n591.1\n26.7\n153.5\n714.9\n0.1\n10.3\n2258.1\n18.4\n0.1\n165.9\n0.6\n17.9\n38.1\n3\n33.8\n3.2\n2.8\n114\n166.5\n54.2\n44.8\n95.1\n94.5\n1.7\n0.2\n5.5\n164.3\n385.5\n47.4\n24.8\n49.1\n3.3\n4.4\n1\n4.5\n10.5\n0\n4.6\n87.1\n1.4\n572.6\n37.4\n1723.8\n0\n803.5\n72.6\n7.3\n8.1\n445.3\n17.9\n224.2\n2.2\n91.2\n12\n14.3\n2.7\n22.6\n733.2\n1.2\n7.4\n0\n4\n0.1\n1\n1.7\n1\n0.4\n14.9\n2\n10.6\n6.1\n1.2\n4.9\n548.1\n3.9\n0.2\n11.1\n38.3\n0.8\n5.1\n28.3\n0.8\n2.3\n0.1\n18.3\n0\n2.9\n3.6\n0.7\n0.1\n0.4\n11.9\n\n\n…6\n2024 Sep\n21966.7\n3294.2\n8.2\n3\n59.3\n0.7\n30\n33.5\n6.8\n7.4\n4.9\n1.6\n0.9\n3.7\n0.4\n0.8\n6.2\n0.8\n0\n214\n0\n533.5\n0\n3.9\n125.9\n1.9\n0.4\n2226.5\n0\n0.7\n0.1\n19.1\n13316.2\n0\n3.5\n217.8\n14.3\n127.5\n2789.3\n0\n1135.8\n566.7\n1527.4\n0.7\n4.2\n24.4\n712.8\n2.2\n1.8\n0\n865.7\n16.5\n2.7\n0.5\n6.1\n2160.4\n6\n2.6\n175.4\n2.2\n9.8\n77.5\n377.4\n42.4\n118.7\n102.5\n0\n1019.5\n567.1\n26.8\n166.4\n433.6\n0.8\n7\n2782.3\n24.2\n0.1\n779.3\n0.3\n0.2\n50.6\n3.9\n36.4\n0.1\n3.4\n138.2\n208.4\n89.5\n37\n93.9\n59.5\n0.5\n0.1\n9.3\n164.6\n397.5\n66\n23.6\n54.4\n3.8\n9.2\n1.1\n3.7\n58.6\n0\n3.8\n83.9\n1.1\n355.2\n20.7\n1689.4\n0\n837\n35.3\n4.9\n41.4\n424.1\n17.7\n186.9\n20.2\n85.5\n5.9\n10.7\n0.5\n19.2\n884.6\n2.6\n7.8\n0.1\n0.8\n0\n0\n1.5\n3.8\n1.3\n18.9\n1.4\n2.9\n4.8\n1.8\n6.3\n691\n2.6\n0.2\n9.5\n34.5\n1\n6.6\n54\n1.2\n1.9\n0\n18.2\n0\n0\n3.7\n0.2\n0\n1.4\n4.4\n\n\n\n\n\n\n\n\n\nShow the code\nv2_subset_reex &lt;- v2_data_reex[c(10:170),]\nv2_trans_matrix_reex &lt;- t(v2_subset_reex) #after transpose, the data is a matrix.\nv2_trans_reex &lt;- as.data.frame(v2_trans_matrix_reex) #now convert the matrix to df.\nkable(head(v2_trans_reex))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nV1\nV2\nV3\nV4\nV5\nV6\nV7\nV8\nV9\nV10\nV11\nV12\nV13\nV14\nV15\nV16\nV17\nV18\nV19\nV20\nV21\nV22\nV23\nV24\nV25\nV26\nV27\nV28\nV29\nV30\nV31\nV32\nV33\nV34\nV35\nV36\nV37\nV38\nV39\nV40\nV41\nV42\nV43\nV44\nV45\nV46\nV47\nV48\nV49\nV50\nV51\nV52\nV53\nV54\nV55\nV56\nV57\nV58\nV59\nV60\nV61\nV62\nV63\nV64\nV65\nV66\nV67\nV68\nV69\nV70\nV71\nV72\nV73\nV74\nV75\nV76\nV77\nV78\nV79\nV80\nV81\nV82\nV83\nV84\nV85\nV86\nV87\nV88\nV89\nV90\nV91\nV92\nV93\nV94\nV95\nV96\nV97\nV98\nV99\nV100\nV101\nV102\nV103\nV104\nV105\nV106\nV107\nV108\nV109\nV110\nV111\nV112\nV113\nV114\nV115\nV116\nV117\nV118\nV119\nV120\nV121\nV122\nV123\nV124\nV125\nV126\nV127\nV128\nV129\nV130\nV131\nV132\nV133\nV134\nV135\nV136\nV137\nV138\nV139\nV140\nV141\nV142\nV143\nV144\nV145\nV146\nV147\nV148\nV149\nV150\nV151\nV152\nV153\nV154\nV155\nV156\nV157\nV158\nV159\nV160\nV161\n\n\n\n\n…1\nData Series\nTotal All Markets\nAmerica\nAntigua And Barbuda\nArgentina\nBahamas\nBermuda\nBrazil\nCanada\nChile\nColombia\nCosta Rica\nCuba\nDominican Rep\nEcuador\nEl Salvador\nGuatemala\nGuyana\nHonduras\nJamaica\nMexico\nNetherlands Antilles\nPanama\nParaguay\nPeru\nPuerto Rico\nSt. Vincent And The Grenadines\nTrinidad And Tobago\nUnited States\nUnited States Virgin Islands\nUruguay\nVenezuela\nOther Markets America\nAsia\nAfghanistan\nBahrain\nBangladesh\nBrunei\nCambodia\nChina\nChristmas Island\nHong Kong\nIndia\nIndonesia\nIran\nIraq\nIsrael\nJapan\nJordan\nKazakhstan\nKorea, Dem Peo Rep Of\nKorea, Rep Of\nKuwait\nLao\nLebanon\nMacao\nMalaysia\nMaldives\nMongolia\nMyanmar\nNepal\nOman\nPakistan\nPhilippines\nQatar\nSaudi Arabia\nSri Lanka\nSyria\nTaiwan\nThailand\nTurkiye\nUnited Arab Emirates\nViet Nam\nYemen\nOther Markets Asia\nEurope\nAustria\nBelarus\nBelgium\nBulgaria\nCroatia\nCyprus\nCzech Rep\nDenmark\nEstonia\nFinland\nFrance\nGermany\nGreece\nHungary\nIreland\nItaly\nLatvia\nLithuania\nLuxembourg\nMalta\nNetherlands\nNorway\nPoland\nPortugal\nRomania\nRussia\nSlovakia\nSlovenia\nSpain\nSvalbard And Jan Mayen Islands\nSweden\nSwitzerland\nUkraine\nUnited Kingdom\nOther Markets Europe\nOceania\nAntarctica\nAustralia\nFiji\nFrench Polynesia\nGuam\nMarshall Islands\nNew Caledonia\nNew Zealand\nNorthern Mariana Islands\nPapua New Guinea\nSamoa\nSolomon Islands\nVanuatu\nOther Markets Oceania\nAfrica\nAlgeria\nAngola\nBenin\nCameroon\nCape Verde\nComoros\nCongo, Dem Rep Of\nCote D’ivoire\nDjibouti\nEgypt\nEthiopia\nGabon\nGhana\nGuinea\nKenya\nLiberia\nLibya\nMadagascar\nMauritius\nMorocco\nMozambique\nNigeria\nReunion\nSeychelles\nSierra Leone\nSomalia\nSouth Africa\nSudan\nSwaziland\nTanzania\nTunisia\nZambia\nZimbabwe\nOther Markets Africa\n\n\n…2\n2025 Jan\n34735.6\n3110.3\n1.9\n25.7\n9.8\n0.1\n203.7\n79.1\n8.9\n6.4\n1.3\n0\n0.6\n7.7\n0.6\n2.1\n1.5\n0.7\n0.6\n160.3\n0\n18\n0.1\n3.5\n2.1\n0\n0.9\n2572.1\n0\n0.5\n0.3\n1.8\n28465.5\n0\n15.7\n139.7\n47.7\n54\n3808.9\n0\n4719.1\n1162.4\n2553.4\n0.2\n3\n44.6\n1289.9\n8.8\n13.6\n0\n1628.5\n25.5\n2.3\n1.8\n17.8\n4287.6\n11.9\n32\n28.8\n17.6\n46.9\n88.5\n775.3\n42.1\n72.7\n43.5\n0.1\n3655.7\n1441.2\n70.8\n456.7\n1840.1\n0.1\n16.9\n2315.4\n11.8\n0\n60.2\n0.8\n1.7\n0.2\n47.1\n6.3\n0.4\n18.8\n170.6\n658.3\n15.6\n24.8\n13.8\n70.3\n1.2\n1.4\n2.2\n11.7\n294.7\n29.2\n43.5\n35.8\n8.3\n8.3\n2.1\n1\n28.9\n0\n5.1\n371.4\n0.3\n364.4\n5.1\n647.4\n0\n491.5\n4.2\n2.2\n1.4\n25.1\n1.3\n112.7\n0.1\n7.5\n0.1\n0\n0.8\n0.5\n197\n0.8\n7.4\n0.1\n0.6\n0\n0.4\n2.2\n2.3\n0.5\n15.9\n35.5\n2\n2\n0.1\n3.9\n15.1\n1.9\n0.4\n5.3\n9.7\n6.1\n15.4\n0.1\n0.8\n0\n0\n41.1\n0\n0.1\n12.7\n3.3\n0.1\n0.1\n11.1\n\n\n…3\n2024 Dec\n36458.2\n3893.4\n0.1\n22.3\n1.3\n0\n174.9\n67.6\n9\n8.6\n1.7\n0\n0.8\n3.9\n0.4\n2.4\n4.4\n0.4\n1\n850.1\n0\n17.4\n0\n5\n2.4\n0.5\n1.4\n2711.7\n0\n1.5\n0.1\n4.5\n29303.5\n0\n2.7\n162.8\n88.5\n53\n5812.2\n0\n5898.8\n1194.6\n2288.5\n0.2\n9.8\n50.9\n1380\n5.7\n5.3\n0\n1704\n21.1\n3.9\n2.9\n21.5\n3435.3\n11.9\n23.2\n26.7\n18.4\n28.6\n68.2\n571.6\n27\n57.7\n39.4\n0\n2828.5\n1420.6\n65.8\n366.8\n1591.9\n0.5\n14.8\n2314.1\n11.3\n0.1\n114.2\n3.7\n0.6\n2.9\n40\n5.1\n0.6\n33.7\n198.7\n608.9\n6.6\n23.2\n53.8\n61.5\n3.6\n2.9\n19.4\n6.5\n418.9\n6.9\n46.8\n88.7\n4.7\n10.8\n2.7\n3.3\n19.5\n0\n7.4\n201.7\n0.1\n299.4\n5.9\n760.1\n0\n579.1\n12.9\n0.6\n3.4\n39.2\n1.8\n112.2\n0\n8.7\n0.3\n0.4\n0.6\n0.8\n187.1\n2.8\n8.2\n2.5\n0.8\n0.1\n0.3\n2\n2\n1.5\n19.6\n38.6\n2.1\n18\n0.2\n14.3\n8.5\n2\n1.5\n3.8\n8.9\n1.3\n10.4\n0.6\n0.8\n0.1\n0.2\n20.2\n0\n0\n5.8\n1.8\n0\n0\n8.3\n\n\n…4\n2024 Nov\n34891.5\n3528.2\n0\n19.4\n3.7\n0\n149.1\n76\n6.3\n8.3\n1.4\n0\n1.1\n8.1\n0.5\n2.2\n1.4\n0.2\n1.2\n207.6\n0\n18.6\n0.1\n5.3\n1.6\n0\n1\n3011.7\n0\n0.8\n0.1\n2.3\n28020.9\n0.1\n17.3\n156\n1122.9\n93.1\n5292.4\n0\n5936.4\n979.5\n2430.1\n0.2\n18\n40.5\n1260.6\n7.8\n2.3\n0\n1525.5\n30.4\n4.5\n0.8\n21.5\n3253.9\n15.4\n28.4\n29.7\n32\n23\n64.3\n939.7\n40.4\n45.8\n43.4\n0\n1722.7\n1041.3\n80.1\n405.3\n1289.9\n0.1\n25.5\n2329\n9.9\n0.2\n90.1\n1.8\n2.2\n1.8\n56.1\n8.3\n1.4\n23.9\n201.8\n657.2\n14\n26.4\n61.6\n55.8\n1.7\n2.3\n13.3\n4.1\n374.9\n14.8\n34.3\n37.1\n9\n10\n2.9\n1.2\n17\n0\n47.1\n205.9\n0.2\n330.6\n10.3\n836.4\n0\n614.6\n11.8\n0.9\n6.4\n40.3\n5.2\n138.8\n1.5\n14.1\n0.3\n0.5\n1.1\n0.9\n176.9\n4\n8.9\n0.3\n0.3\n0\n0.3\n1.6\n3\n0.8\n9.3\n8.1\n0.4\n5.2\n0.1\n20.4\n15.5\n2.5\n1.1\n4.4\n7.4\n0.5\n8.6\n29\n0.6\n0.1\n0\n27.2\n0.2\n0\n6.8\n2.4\n0\n0\n8.1\n\n\n…5\n2024 Oct\n33962.6\n3388.8\n0.2\n23.8\n4.3\n0.1\n154.9\n58.6\n6.3\n8.8\n2.5\n0\n1.9\n4.1\n0.3\n1.2\n1.4\n0.8\n2.3\n547.6\n0\n12.6\n0.2\n4.8\n2.8\n0.9\n0.9\n2544.6\n0\n0.7\n0\n2.3\n27278.7\n0\n28\n128.8\n1184\n173.3\n5097.4\n0\n4493.7\n1048.4\n2321.3\n0.4\n17.2\n45.9\n1308.4\n9\n0.8\n0\n1496.7\n25.8\n3.8\n1.4\n26.1\n3358.9\n13\n29.6\n32.9\n26.4\n24\n103.2\n917.9\n71.5\n58.7\n51.9\n0\n1518.2\n1805.4\n112.2\n407.5\n1321.6\n0.5\n14.6\n2288\n10.9\n0\n70.5\n1.9\n3.9\n2.3\n92.6\n9.9\n2.3\n12.5\n228.7\n537\n14.3\n26.1\n174.2\n95.3\n3.9\n1.5\n12.1\n10.3\n331.3\n9\n28.7\n45.2\n11.1\n6.2\n1.3\n2.4\n23.1\n0\n10.6\n139.5\n0.5\n364.5\n4.3\n821.3\n0\n601.1\n9.7\n2.2\n2.3\n48.5\n1.7\n144.2\n0.1\n8.9\n0.3\n0.3\n0.3\n1.7\n185.7\n30.5\n4.7\n0\n0.6\n0\n0\n1.3\n1.3\n1.6\n19.9\n7.3\n1.6\n3.5\n0\n7.2\n20.7\n1.8\n0.7\n2.9\n16.8\n1.2\n7.8\n0.4\n1.1\n0.3\n0.1\n24.1\n0\n0\n9.4\n2.8\n0.1\n0.1\n16\n\n\n…6\n2024 Sep\n32477.4\n3196.7\n0\n27.1\n8.1\n0\n203.4\n107.8\n23\n6.2\n1.8\n0\n1.1\n3.6\n0.6\n2.5\n1\n0.4\n0.8\n395.4\n0\n22.8\n0.3\n6.4\n3.7\n0.5\n0.8\n2376.7\n0\n1.3\n0\n1.4\n26314.1\n0.1\n5\n138.8\n57.6\n71.1\n5439.6\n0\n4432.6\n1165.5\n2557.8\n0.5\n6.4\n48.6\n1314.9\n6.3\n2.1\n0\n1463.2\n53.5\n5.2\n1.8\n10.3\n4021.4\n10.9\n16\n27.9\n20.9\n7.2\n54.4\n566.7\n45.9\n65.1\n40.2\n0\n1641.1\n1534\n60.2\n352.1\n1062.3\n0.5\n6.5\n2127.5\n18.8\n0.2\n47.7\n43.8\n2.9\n1.1\n40.8\n16\n2.2\n30.5\n207.3\n597.2\n17.6\n20.8\n60.4\n56.2\n2.3\n2.6\n14\n5.9\n360\n6.8\n42.7\n45.9\n10.3\n7.7\n1.2\n1.1\n19.7\n0\n29.6\n129.4\n0.1\n281.3\n3.3\n711.9\n0\n513.3\n6.8\n1\n2\n27.2\n2\n146.9\n0.1\n10.4\n0.1\n0.3\n0.5\n1.3\n127.2\n1.1\n3.1\n0.3\n1\n0\n0.1\n1.3\n3.5\n0.1\n15.4\n2\n0.5\n2.9\n0.3\n3.6\n18.2\n0.9\n0.9\n3.1\n8.1\n1\n2.8\n0.2\n0.6\n0\n0\n29.7\n0\n0\n7.5\n2.1\n6.8\n0.1\n9.9\n\n\n\n\n\n\n\n\nStep 3. Data wrangling\nIn this step, I will process the total amount from the year 2024 for each country / region for each trade category.\n\nIMPORTEXPORTRE-EXPORTCOMBINED\n\n\n\n\nShow the code\n# 1. Settle the header\nv2_trans_im_original &lt;- v2_trans_im\n\nheader_row &lt;- as.character(v2_trans_im[1,])\n\n# Apply as col names\ncolnames(v2_trans_im) &lt;- header_row \n\n# Remove the first row\nv2_trans_im &lt;- v2_trans_im[-1,]\n\n# 2. Extract years from the first column\nyears &lt;- substr(v2_trans_im[[1]], 1, 4)\nyears &lt;- as.numeric(years)\n\n# Add as a new column (without modifying existing columns)\nv2_trans_im$Year &lt;- years\n\n\n# 3. Now convert country columns to numeric\ncountry_cols_im &lt;- 2:(ncol(v2_trans_im)-1)  \nv2_trans_im[, country_cols_im] &lt;- lapply(v2_trans_im[, country_cols_im], function(x) {\n  as.numeric(as.character(x))\n})\n\n\nv2_trans_im_2024 &lt;- v2_trans_im[v2_trans_im$Year == 2024, ]\n\n# 4. Sum for each country\nv2_trans_im_2024_sum &lt;- v2_trans_im_2024 %&gt;%\n  select(-1, -ncol(v2_trans_im)) %&gt;%  # Remove first column and Year column\n  summarise(across(everything(), ~sum(., na.rm = TRUE)))\n\nv2_long_im &lt;- v2_trans_im_2024_sum %&gt;%\n  pivot_longer(cols = everything(), \n               names_to = \"Country\", \n               values_to = \"Im2024\")\nprint(head(v2_long_im))\n\n\n# A tibble: 6 × 2\n  Country               Im2024\n  &lt;chr&gt;                  &lt;dbl&gt;\n1 Total All Markets   611360. \n2 America              95346. \n3 Antigua And Barbuda      0.2\n4 Argentina              327. \n5 Bahamas                 27.9\n6 Bermuda                  1.1\n\n\n\n\n\n\nShow the code\n# 1. Settle the header\nv2_trans_ex_original &lt;- v2_trans_ex\n\nheader_row_ex &lt;- as.character(v2_trans_ex[1,])\n\n# Apply as col names\ncolnames(v2_trans_ex) &lt;- header_row_ex \n\n# Remove the first row\nv2_trans_ex &lt;- v2_trans_ex[-1,]\n\n# 2. Extract years from the first column\nyears &lt;- substr(v2_trans_ex[[1]], 1, 4)\nyears &lt;- as.numeric(years)\n\n# Add as a new column (without modifying existing columns)\nv2_trans_ex$Year &lt;- years\n\n# 3. Now convert country columns to numeric\ncountry_cols_ex &lt;- 2:(ncol(v2_trans_ex)-1)  \nv2_trans_ex[, country_cols_ex] &lt;- lapply(v2_trans_ex[, country_cols_ex], function(x) {\n  as.numeric(as.character(x))\n})\n\nv2_trans_ex_2024 &lt;- v2_trans_ex[v2_trans_ex$Year == 2024, ]\n\n# 4. Sum for each country\nv2_trans_ex_2024_sum &lt;- v2_trans_ex_2024 %&gt;%\n  select(-1, -ncol(v2_trans_ex)) %&gt;%  # Remove first column and Year column\n  summarise(across(everything(), ~sum(., na.rm = TRUE)))\n\nv2_long_ex &lt;- v2_trans_ex_2024_sum %&gt;%\n  pivot_longer(cols = everything(), \n               names_to = \"Country\", \n               values_to = \"Ex2024\")\nprint(head(v2_long_ex))\n\n\n# A tibble: 6 × 2\n  Country               Ex2024\n  &lt;chr&gt;                  &lt;dbl&gt;\n1 Total All Markets   286598. \n2 America              43134  \n3 Antigua And Barbuda    127. \n4 Argentina               67.4\n5 Bahamas                849. \n6 Bermuda                 48.3\n\n\n\n\n\n\nShow the code\n# 1. Settle the header\nv2_trans_reex_original &lt;- v2_trans_reex\n\nheader_row_reex &lt;- as.character(v2_trans_reex[1,])\n\n# Apply as col names\ncolnames(v2_trans_reex) &lt;- header_row_reex \n\n# Remove the first row\nv2_trans_reex &lt;- v2_trans_reex[-1,]\n\n# 2. Extract years from the first column\nyears &lt;- substr(v2_trans_reex[[1]], 1, 4)\nyears &lt;- as.numeric(years)\n\n# Add as a new column (without modifying existing columns)\nv2_trans_reex$Year &lt;- years\n\n# 3. Now convert country columns to numeric\ncountry_cols_reex &lt;- 2:(ncol(v2_trans_reex)-1)  \nv2_trans_reex[, country_cols_reex] &lt;- lapply(v2_trans_reex[, country_cols_reex], function(x) {\n  as.numeric(as.character(x))\n})\n\nv2_trans_reex_2024 &lt;- v2_trans_reex[v2_trans_reex$Year == 2024, ]\n\n# 4. Sum for each country\nv2_trans_reex_2024_sum &lt;- v2_trans_reex_2024 %&gt;%\n  select(-1, -ncol(v2_trans_reex)) %&gt;%  # Remove first column and Year column\n  summarise(across(everything(), ~sum(., na.rm = TRUE)))\n\nv2_long_reex &lt;- v2_trans_reex_2024_sum %&gt;%\n  pivot_longer(cols = everything(), \n               names_to = \"Country\", \n               values_to = \"ReX2024\")\nprint(head(v2_long_reex))\n\n\n# A tibble: 6 × 2\n  Country              ReX2024\n  &lt;chr&gt;                  &lt;dbl&gt;\n1 Total All Markets   387907. \n2 America              35664. \n3 Antigua And Barbuda      2.1\n4 Argentina              253. \n5 Bahamas                 92.8\n6 Bermuda                  0.8\n\n\n\n\nNow I will combine the 3 data sets, and also sum up the Export values. I noticed that the original plot has EU together as a trade partner, so I will also combine the 27 EU countries into one new row “EU”.\n\n\nShow the code\n# First, join import and export data\nv2_ImEx &lt;- v2_long_im %&gt;%\n  full_join(v2_long_ex, \n            by = \"Country\")  # Join by country name\n\nv2_combine &lt;- v2_ImEx %&gt;%\n  full_join(v2_long_reex,\n            by = \"Country\")\n\n# Compute Export total\nv2_combine$Ex_total &lt;- v2_combine$Ex2024 + v2_combine$ReX2024\n\n# Compute Surplus/deficit\nv2_combine$Bal2024 &lt;- v2_combine$Ex_total - v2_combine$Im2024\nhead(v2_combine)\n\n\n# A tibble: 6 × 6\n  Country               Im2024   Ex2024  ReX2024 Ex_total   Bal2024\n  &lt;chr&gt;                  &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 Total All Markets   611360.  286598.  387907.  674505    63145.  \n2 America              95346.   43134    35664.   78798.  -16549.  \n3 Antigua And Barbuda      0.2    127.       2.1    130.     129.  \n4 Argentina              327.      67.4    253.     321.      -6.60\n5 Bahamas                 27.9    849.      92.8    942.     914.  \n6 Bermuda                  1.1     48.3      0.8     49.1     48   \n\n\nShow the code\n# Compute total trade volume\nv2_combine$Total2024 &lt;- v2_combine$Ex_total + v2_combine$Im2024\n\n# Add EU\neu_countries &lt;- c(\"Austria\", \"Belgium\", \"Bulgaria\", \"Croatia\", \"Cyprus\", \"Czech Rep\", \"Denmark\", \"Estonia\",\n                  \"Finland\", \"France\", \"Germany\", \"Greece\", \"Hungary\", \"Ireland\", \"Italy\", \"Latvia\",\n                  \"Lithuania\", \"Luxembourg\",  \"Malta\", \"Netherlands\", \"Poland\", \"Portugal\", \"Romania\",\n                  \"Slovakia\", \"Slovenia\", \"Spain\", \"Sweden\")\n\neu_values &lt;- v2_combine %&gt;%\n  filter(Country %in% eu_countries) %&gt;%\n  summarise(\n    Im2024 = sum(Im2024, na.rm = TRUE),\n    Ex2024 = sum(Ex2024, na.rm = TRUE),\n    ReX2024 = sum(ReX2024, na.rm = TRUE),\n    Ex_total = sum(Ex_total, na.rm = TRUE),\n    Bal2024 = sum(Bal2024, na.rm = TRUE),\n    Total2024 = sum(Total2024, na.rm = TRUE)\n  ) %&gt;%\n  mutate(Country = \"EU\")\n\nv2_con_eu &lt;- bind_rows(v2_combine, eu_values)\n\n\n\n\n\n\n\n2.2.4 Visualisation make-over\nLaunch packages\n\n\nShow the code\nlibrary(ggplot2)\nlibrary(scales)  # For formatting labels\nlibrary(plotly)\n\n\nPlot the visualisation\nThe plot will be a similar scatter plot with new color scheme and interactive tooltip showing more information of the country hovered over. This plot uses ggplot2 with ggplotly to show interactivity of the tooltips.\n\n\nShow the code\n# Filter data\nv2_filter &lt;- v2_con_eu %&gt;%\n  filter(!Country %in% c(\"Total All Markets\", \"America\", \"Asia\", \"Europe\", \"Oceania\", \"Africa\")) %&gt;%\n  arrange(desc(Total2024)) %&gt;%\n  head(10)  \n\n#legend breaks\nlegend_breaks &lt;- c(20, 40, 60, 80)\n\n# Create a dot plot\nv2_plot &lt;- ggplot(v2_filter, \n                  aes(x = Ex_total/1000, y = Im2024/1000)) + \n  # Create bubbles\n  geom_point(aes(size = Total2024/1000,  # Size by total trade \n                 color = Bal2024/1000,       # Color by trade balance \n                 alpha = 0.8)) +                 \n  # Custom color scale for surplus/deficit\n  scale_color_gradient2(\n    name = \"Trade Balance (S$ Bil.)\",\n    low = \"#690B22\",      \n    mid = \"white\",        \n    high = \"#1B4D3E\",    \n    midpoint = 0,        \n    labels = dollar_format(prefix = \"$\", suffix = \"B\")\n  ) +\n  \n  # Scale for bubble size\n  scale_size_continuous(\n    name = \"Total Trade (S$ Bil.)\",\n    range = c(5, 20), \n    breaks = legend_breaks,  \n    labels = dollar_format(prefix = \"$\", suffix = \"B\")\n  ) +\n  # Add country labels for bubbles\n#  geom_text(\n#    aes(label = Country),\n#    check_overlap = TRUE,\n#    vjust = 1,\n#    hjust = 1,\n#    size = 3\n#  ) +\n  # Add a diagonal reference line (imports = exports)\n  geom_abline(intercept = 0, slope = 1, linetype = \"solid\", \n              color = \"#73C7C7\", alpha = 0.5,\n              linewidth = 0.2) +\n  labs(\n    title = \"Singapore Merchandise Trade Relationships, 2024\",\n#    subtitle = \"Bubble size represents total trade volume, color indicates trade balance\",\n    x = \"Exports (S$ Bil.)\",\n    y = \"Imports (S$ Bil.)\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"right\",\n    plot.title = element_text(face = \"bold\", size = 17, family = \"Arial\"),\n    panel.grid.minor = element_blank(),\n    plot.background = element_rect(fill = \"#f1f4f5\", color = NA),\n    panel.background = element_rect(fill = \"#f1f4f5\", color = NA),\n    legend.background = element_rect(fill = \"#f1f4f5\", color = NA),\n    axis.title.x = element_text(size = 10, face = \"bold\", family = \"Arial\"),  \n    axis.title.y = element_text(size = 10, face = \"bold\", family = \"Arial\"), \n    axis.text.x = element_text(size = 8),  \n    axis.text.y = element_text(size = 8),\n    legend.text = element_text(size = 8, face = \"bold\", family = \"Arial\"),\n    legend.title = element_text(size = 10, face = \"bold\", family = \"Arial\")\n  ) +\n  # Format axis labels\n  scale_x_continuous( limits = c(0, 100)) +\n  scale_y_continuous( limits = c(0, 100)) +\n  guides(alpha = FALSE, fill = FALSE,\n         size = guide_legend(\n           override.aes = list(\n             color = \"grey90\",\n             alpha = 0.8\n           )\n         )) +\n  scale_alpha_identity() +  # Force alpha to be treated as fixed\n  scale_fill_identity() \n\n# Convert ggplot to plotly\np &lt;- ggplotly(v2_plot, tooltip = \"none\")\n\n# Set hover text\np$x$data[[1]]$text &lt;- paste(\n  \"Country:\", v2_filter$Country,\n  \"&lt;br&gt;Exports: $\", round(v2_filter$Ex_total/1000, 1), \"B\",\n  \"&lt;br&gt;Imports: $\", round(v2_filter$Im2024/1000, 1), \"B\",\n  \"&lt;br&gt;Balance: $\", round(v2_filter$Bal2024/1000, 1), \"B\",\n  \"&lt;br&gt;Total Trade: $\", round(v2_filter$Total2024/1000, 1), \"B\"\n)\np$x$data[[1]]$hoverinfo &lt;- \"text\"\np$layout$hovermode &lt;- \"closest\"\n\np &lt;- p %&gt;% add_annotations(\n  x = v2_filter$Ex_total/1000,\n  y = v2_filter$Im2024/1000,\n  text = v2_filter$Country,\n  showarrow = FALSE,\n  yshift = 15,  # Move 20 pixels up (similar to negative vjust)\n  xshift = 10,   # No horizontal shift\n  font = list(size = 12, color = \"black\", family = \"Arial\")\n)\n\np\n\n\n\n\n\n\n\n\nMake-over\n\n\n\nColor - The original plot assigns a color for each country, which makes no distinction for the countries. In the make-over, I scale down the color scheme to two, green and red. These colors are used to show whether the country is in Surplus or Deficit position to Singapore.\nInteractive tooltip - Instead of using a dotted line and label, a tooltip is applied so viewers can hover over the bubble to understand the details. This avoids overcorwding of the plot.\nTrade partner by Surplus/Deficit scale - Instead of using full color styling, the two color scheme is designed to show whether it is a surplus (Export &gt; Import) or deficit (Import &gt; Export). The color is gradient according to the amount of trade balance. If it is negative, the bubble truns red, and vice versa.\nTotal trade volume - Maintained total trade volume presentation in the form of bubble size.\n\nThese improvements make the trade relationships clearer and allow viewers to quickly identify key patterns while accessing detailed information on demand.\n\n\n\n\n\n2.3 Visualisation #3 Mirror Bar Chart\n\n\n\n\n\nPROSCONSSKETCH\n\n\n\nComprehensiveness - It clearly shows import/export data for major trading partners across two time periods (2019 and 2023)\nRanking systme - The ranking system (gold, silverm bronze medals) makes it easy to identify top trading partners.\nCountry flags - Helps with quick visual identification.\nTemporal comparison - The side-by-side comparison of 2019 and 2023 allows for easy temporal comparison.\n\n\n\nUGLY\n\nColor scheme - The visualization uses 30+ colors without a clear system. It creates visual noise and makes it difficult to focus on the most important information\nInconsistent color mapping - Colours don’t consistenly represent countries, time periods, or import/export categories.\n\nBAD\n\nFont size - The value annotations compete with the bars for visual attention.\nMulti-dimensional comparison - Trying to compare imports vs exports across multiple countries and two time periods creates high cognitive load and confusion.\nInconsistent entity classification - Mixing individual countries (US, Japan) with regional blocs (EU-27, ASEAN) without explanation.\nRanking methodology - There is no indication of what metric determines the gold/silver/bronze rankings.\n\nWRONG\n\nBar chart - It doesn’t effectively show the relationship between imports and exports for each entity.\nInconsistent period of comparison - While other visualisations on the website show data from 2020 to 2024, this chart displays 2019 vs 2023. The inconsistency disrupts the overall narrative and prevents viewers from making direct comparisons across different visualisations the holistic information of presenting the recent data.\n\n\n\n\n\n\n\n\n\n\n2.3.3 Data\nStep 1. Load and launch packages\n\n\nShow the code\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(tidyverse)  \nlibrary(stringr)\nlibrary(knitr)\nlibrary(ggflags)\nlibrary(countrycode)\nlibrary(ggiraph)\nlibrary(ggplot2)\n\n\nStep 2. Import data & make subsets\n\nIMPORT EXCELIMPORTEXPORT\n\n\n\n\nShow the code\nv3_data_import &lt;- read_xlsx(\"data/Mtrade_service.xlsx\", \"T7\")\nv3_data_export &lt;- read_xlsx(\"data/Mtrade_service.xlsx\", \"T3\")\n\nhead(v3_data_import)\n\n\n# A tibble: 6 × 25\n  ...1   ...2  ...3  ...4  ...5  ...6  ...7  ...8  ...9  ...10 ...11 ...12 ...13\n  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n1 Theme… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n2 Subje… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n3 Topic… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n4 Table… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n5 &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n6 Data … &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n# ℹ 12 more variables: ...14 &lt;chr&gt;, ...15 &lt;chr&gt;, ...16 &lt;chr&gt;, ...17 &lt;chr&gt;,\n#   ...18 &lt;chr&gt;, ...19 &lt;chr&gt;, ...20 &lt;chr&gt;, ...21 &lt;chr&gt;, ...22 &lt;chr&gt;,\n#   ...23 &lt;chr&gt;, ...24 &lt;chr&gt;, ...25 &lt;chr&gt;\n\n\n\n\nObservation\n\n\n\nThe dataset contains annual import data for services by country from 2000 to 2023.\nA key issue with the original visualization is the inconsistency in the data period. While other visualizations cover 2020-2024, this one compares 2019 to 2023. As the most recent data available in the DOS dataset is from 2023, I will use this period for the updated visualization.\nAdditionally, the dataset treats the European Union and ASEAN as single entities, so I will retain this grouping in the plot.\n\n\n\n\n\nMake a subset for data wrangling In this step, I will extrac the import data from 2019 and 2023 for all countries.\n\n\nShow the code\n# Select needed rows and change header.\nnew_header_im &lt;- as.character(unlist(v3_data_import[10,]))\nv3_subset_im &lt;- v3_data_import[11:78,]\nnames(v3_subset_im) &lt;- new_header_im\n\n# Select year 2019 and 2023\nv3_years_im &lt;- v3_subset_im %&gt;%\n  select(\"Data Series\", \"2023\", \"2019\")\n\nhead(v3_years_im)\n\n\n# A tibble: 6 × 3\n  `Data Series`     `2023`   `2019` \n  &lt;chr&gt;             &lt;chr&gt;    &lt;chr&gt;  \n1 Asia              139497.1 83242.3\n2 Bangladesh        468.8    380.9  \n3 Brunei Darussalam 196.8    49.2   \n4 Cambodia          121.2    217.9  \n5 Hong Kong         20255.7  13093.5\n6 India             13532.6  7813.9 \n\n\n\n\nMake a subset for data wrangling In this step, I will extrac the export data from 2019 and 2023 for all countries.\n\n\nShow the code\n# Select needed rows and change header.\nnew_header_ex &lt;- as.character(unlist(v3_data_export[10,]))\nv3_subset_ex &lt;- v3_data_export[11:78,]\nnames(v3_subset_ex) &lt;- new_header_ex\n\n# Select year 2019 and 2023\nv3_years_ex &lt;- v3_subset_ex %&gt;%\n  select(\"Data Series\", \"2023\", \"2019\")\n\nhead(v3_years_ex)\n\n\n# A tibble: 6 × 3\n  `Data Series`     `2023`   `2019`  \n  &lt;chr&gt;             &lt;chr&gt;    &lt;chr&gt;   \n1 Asia              170787.7 114573.1\n2 Bangladesh        985.7    642.4   \n3 Brunei Darussalam 960.1    556.4   \n4 Cambodia          475.6    259.1   \n5 Hong Kong         21686.1  11273.2 \n6 India             9909.4   6383.4  \n\n\n\n\n\nStep 3. Data Wrangling\nIn this step, I will combine the import and export data into one for ploting a slopegraphic plot.\n\n\nShow the code\n#Import set\nimport_long &lt;- v3_years_im %&gt;%\n  rename(Country = `Data Series`) %&gt;%\n  pivot_longer(\n    cols = -Country,\n    names_to = \"Year\",\n    values_to = \"Value\"\n  ) %&gt;%\n  \n  mutate(Type = \"Import\") %&gt;%\n  arrange(Country, Year)\n\n#Export set\nexport_long &lt;- v3_years_ex %&gt;%\n  rename(Country = `Data Series`) %&gt;%\n  pivot_longer(\n    cols = -Country,\n    names_to = \"Year\",\n    values_to = \"Value\"\n  ) %&gt;%\n  \n  mutate(Type = \"Export\") %&gt;%\n  arrange(Country, Year)\n\n# Combine datasets\nv3_combine &lt;- bind_rows(import_long, export_long) %&gt;%\n  arrange(Country, Year, Type)\n\n# Remove regions like Asia, North America\nregion_exclude &lt;- c(\"Asia\", \"Europe\", \"North America\", \"Africa\",\n                    \"South And Central America And The Caribbean\",\n                    \"Oceania\")\n\n# Covert Value to numeric type\nv3_convert &lt;- v3_combine %&gt;%\n  mutate(\n    Value = gsub(\"[^0-9.-]\", \"\", Value), #remove commas or non-numeric stuff\n    Value = as.numeric(Value),\n    Year = as.numeric(as.character(Year))\n    ) %&gt;%\n  filter(!Country %in% region_exclude)\n\n #Remove USA data\n#v3_convert &lt;- v3_convert %&gt;%\n#  filter(!grepl(\"United States Of America\", Country, ignore.case = TRUE)) %&gt;%\n#  filter(!grepl(\"United Kingdom\", Country, ignore.case = TRUE))\n\n#usa_data &lt;- tibble(\n#  Country = rep(c(\"U.S.\", \"U.K.\"), each = 4),\n#  Year = rep(c(2019, 2019, 2023, 2023), 2),\n#  Value = c(29277.2, 50735.4, 51122.8, 108025.0,\n#            13785, 8404.7, 20205.7, 16655.8\n#),\n#  Type = rep(c(\"Export\", \"Import\", \"Export\", \"Import\"), 2))\n\n#v3_usa &lt;- bind_rows(v3_convert, usa_data)\n\n# Filter top 10 countries by total value in 2023\ntop_countries &lt;- v3_convert %&gt;%\n  filter(Year == \"2023\") %&gt;%\n  group_by(Country) %&gt;%\n  summarize(TotalValue = sum(Value, na.rm = TRUE)) %&gt;%\n  arrange(desc(TotalValue)) %&gt;%\n  slice_head(n=10) %&gt;%\n  pull(Country)\n\n\n\n\n2.3.4 Visualisation make-over\n\n\nShow the code\nregional_groups &lt;- c(\"ASEAN\", \"European Union (EU-27)\")\n\nslope_data &lt;- v3_convert %&gt;%\n  filter(Year %in% c(2019, 2023)) %&gt;%\n  mutate(Year = as.factor(Year))\n\n\nslope_data_top &lt;- slope_data %&gt;%\n  filter(Country %in% top_countries) %&gt;%\n  mutate(\n    country_code = tolower(countrycode(Country, origin = \"country.name\", \n                                       destination = \"iso2c\")\n    )\n  )\n# Create the interactive plot\np &lt;- ggplot(slope_data_top, aes(x = Year, y = Value, \n                                group = interaction(Country, Type), color = Country)) +\n  geom_line_interactive(aes(data_id = Country), size = 1) +\n  \n  geom_flag(\n    data = subset(slope_data_top, Year == \"2023\"),\n    aes(country = country_code),\n    size = 6\n  ) +\n  \n  # Add interactive points with tooltips\n  geom_point_interactive(\n    data = subset(slope_data_top, Year == \"2019\"),\n    aes(data_id = Country, \n        tooltip = paste0(Country, \": S$\", round(Value/1000,1), \"B\")), \n    size = 2\n  ) +\n\n  geom_point_interactive(\n    data = subset(slope_data_top, Year == \"2023\"),\n    aes(data_id = Country, \n        tooltip = paste0(Country, \": S$\", round(Value/1000,1), \"B\")), \n    size = 0.1\n  ) +\n  \n  # Text labels for countries (positioned to account for flags)\n  geom_text_interactive(\n    data = subset(slope_data_top, Year == \"2023\"), \n    aes(label = Country, data_id = Country), \n    hjust = -0.2,\n    nudge_x = 0.02,\n    size = 2.5,\n    fontface = \"bold\"\n  ) +\n  #scale Y to bil.\n  scale_y_continuous(\n  \n  ) +\n  \n  # Side-by-side panels\n  facet_wrap(~Type, scales = \"free_x\") +\n  scale_color_manual(values = colorRampPalette(c(\"#A5BFCC\", \"#EFDCAB\", \"#C599B6\", \"#FFCFCF\", \"#C7DB9C\", \"#98D8EF\", \"#B6CBBD\", \"#FFCDB2\", \"#EABDE6\", \"#A9B5DF\"))(10)) +\n  scale_y_continuous(\n    name = \"Value (SGD$ Bil.)\",\n    labels = function(x) paste0(x/1000),  # Convert from millions to billions\n    limits = c(0, 109000)) +\n  labs(title = \"Major Trading Partners for Trade in Services\",\n  subtitle = \"2019 vs 2023\") +\n  geom_vline(xintercept = \"2019\", linetype = \"solid\", \n             color = \"#E3D2C3\", size = 0.7, alpha = 0.7) +\n  geom_vline(xintercept = \"2023\", linetype = \"solid\", \n             color = \"#E3D2C3\", size = 0.7, alpha = 0.7) +\n\n  theme_minimal() +\n  theme(legend.position = \"bottom\",\n        strip.text = element_text(size = 14, color = \"#F6D776\", face = \"bold\"),\n        plot.title = element_text(hjust = 0, size = 16, face = \"bold\", family = \"Arial\", color = \"white\"),\n        plot.subtitle = element_text(hjust = 0, size = 14, face = \"bold\", family = \"Arial\", color = \"white\"),\n        plot.background = element_rect(fill = \"#525E75\", color = \"#525E75\"),\n        axis.title.x = element_text(size = 12, face = \"bold\", family = \"Arial\", color = \"white\"),\n        axis.title.y = element_text(size = 12, face = \"bold\", family = \"Arial\", color = \"white\"),\n        axis.text.x = element_text(color = \"white\"),\n        axis.text.y = element_text(color = \"grey80\"),\n        panel.grid.major = element_line(color = \"gray60\", size = 0.4, linetype = \"dashed\"),\n        panel.grid.minor = element_line(color = \"grey50\", size = 0.25, linetype = \"dotted\"),\n        legend.text = element_text(color = \"grey80\"),\n        plot.margin = margin(t = 30, r = 20, b = 10, l = 20),\n        legend.title = element_text(color = \"grey80\")\n        ) \n\ngirafe(ggobj = p, width_svg = 7, height_svg = 10) %&gt;%\n  girafe_options(\n    opts_sizing(rescale = FALSE),\n    opts_hover(css = \"stroke-width:3px;\"),\n    opts_hover_inv(css = \"opacity:0.2;\")\n  )\n\n\n\n\n\n\n\n\nMake-over\n\n\n\nTitle - The title reflects the comparison between 2019 and 2023, not only 2023.\nTop 10 countries - In the original plot, it has India rather than Ireland. I took a guess that it meant top 10 total trade volume in 2023, because India is the 11th. The re-designed plot has Ireland rather than India in top 10, because it has filtered out the EU countries. Maybe it does not want to show individual countries, but I think it is better to show so viewers see the prominence and actual data insights.\nDivide Import and Export - The slopgraph has clearly defined Import and Export sections, so viewers can easily see the difference between the two trade categories.\nHover effect - With the interactive element, viewer can hover over the country slope, and it will emphasise the country while dehighlight the rest to compare how the trend is in both trade categories.\nTooltip - Tooltip is applied to show the actual Import and Export values if viewers with to know. The tool tip prevent the plot from being too crowded.\n\n\n\n\n\n\n2.4 Summary\nThe visualisations on the DOS website has a consistent theme and vibrant colors. This makes the website overall looks visually pleasant and inviting. The disadvantage is that it does not focus on enhancing understanding the data and insights quickly and meaningfully. The visualisation re-designs above took into consideration of data interpretation to ensure information is clearly conveyed to viewers. The themes together may not be coherent as it requires advanced levels of plotting with R packages. This can be the future work of the make-over task.",
    "crumbs": [
      "![](/images/house.svg)",
      "Take-home Exercise",
      "Take-home_Ex02"
    ]
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02.html#singapore-merchandise-trade-data-analysis",
    "href": "Take-home_Ex/Take-home_Ex02.html#singapore-merchandise-trade-data-analysis",
    "title": "Take-home_Ex02",
    "section": "3 Singapore Merchandise Trade Data Analysis",
    "text": "3 Singapore Merchandise Trade Data Analysis\nThis section analyses Singapore’s merchandise trade data, focusing on trading patterns and changes in partnerships over time. As a key global trading hub, Singapore facilitates significant cargo transit, influencing international trade flows. The data provides insights into Singapore’s trading relationships and the dynamics of its import and export activities.\n\n3.1 Objectives\nThis analysis aims to examine historical trading patterns and forecast future trends. The approach includes:\n\nTime-Series Analysis: Visualising Singapore’s monthly trade data from 1999 onwards to identify trends and patterns.\nTime-Series Forecasting: – Applying forecasting models to evaluate future trade dynamics and interpreting the results.\n\n\n\n3.2 Data\nThe main dataset is the Merchandise Trade Excel files downloaded from the Department of Statistics Singapore. The Excel file includes 3 sets of data: 1. Merchandise Trade By Region And Selected Market (Imports), Monthly 2. Merchandise Trade By Region And Selected Market (Domestic Exports), Monthly 3. Merchandise Trade By Region And Selected Market (Re-Exports), Monthly. The data spans from January 2003 to January 2025. However, for most analyses in this report, only data from 2015 to 2025 is used. The dataset covers 160 countries and regions, with some entries representing aggregated data.\nStep 1. Load and launch packages\n\npacman::p_load(fpp3, readxl, readr, ggplot2, patchwork, stringr, tidyr)\n\nStep 2. Import the data & make subsets\n\nMONTHLY TRADE INSTENSITYSEASONAL TRADE PATTERNSSINGAPORE RE-EXPORT ANALYSISMARKET SHARE TREND\n\n\nIn 3.3, a calendar heatmap will be plotted to show monthly merchandise trade intensity and by Import, Export, Re-Export categories. Therefore, data will be retrieved from 3 different tabs from the Merchandise Trade by REgion Excel files. The subset will be extracted to separate csv files, and will be read later in resepective data wrangling phase.\n\n\nShow the code\n# ---- Import by month\nim_region_month_data &lt;- read_xlsx(\"data/Mtrade_region.xlsx\", \"T1\")\nim_region_month_csv &lt;- im_region_month_data[c(10:170),]\n\n# After transpose, the data is a matrix.\nim_region_month_matrix &lt;- t(im_region_month_csv) \n#now convert the matrix to df.\nim_region_month &lt;- as.data.frame(im_region_month_matrix)\n\n# Correct the column name\nreal_column_names_im &lt;- as.character(im_region_month[1, ])\ncolnames(im_region_month) &lt;- real_column_names_im\n\n# remove the first row\nim_region_month &lt;- im_region_month[-1, ]\n\n\n# Turn the dataframe to a csv file for easy calling. Run only once. \n#write.csv(im_region_month, \"im_region_month.csv\") \n# Will move the file to data folder\n\n# ---- Export by month\nex_region_month_data &lt;- read_xlsx(\"data/Mtrade_region.xlsx\", \"T2\")\nex_region_month_csv &lt;- ex_region_month_data[c(10:170),]\n\n\n# After transpose, the data is a matrix.\nex_region_month_matrix &lt;- t(ex_region_month_csv) \n#now convert the matrix to df.\nex_region_month &lt;- as.data.frame(ex_region_month_matrix)\n\n# Correct the column name\nreal_column_names_ex &lt;- as.character(ex_region_month[1, ])\ncolnames(ex_region_month) &lt;- real_column_names_ex\n\n# remove the first row\nex_region_month &lt;- ex_region_month[-1, ]\n\n# Turn the dataframe to a csv file for easy calling. Run only once. \n#write.csv(ex_region_month, \"ex_region_month.csv\") \n# Will move the file to data folder\n\n\n# ---- ReExport by month\nrex_region_month_data &lt;- read_xlsx(\"data/Mtrade_region.xlsx\", \"T3\")\nrex_region_month_csv &lt;- rex_region_month_data[c(10:170),]\n#head(rex_by_month_csv)\n\n# After transpose, the data is a matrix.\nrex_region_month_matrix &lt;- t(rex_region_month_csv) \n#now convert the matrix to df.\nrex_region_month &lt;- as.data.frame(rex_region_month_matrix)\n\n# Correct the column name\nreal_column_names_rex &lt;- as.character(rex_region_month[1, ])\ncolnames(rex_region_month) &lt;- real_column_names_rex\n\n# remove the first row\nrex_region_month &lt;- rex_region_month[-1, ]\n\n# Turn the dataframe to a csv file for easy calling. Run only once. \n#write.csv(rex_region_month, \"rex_region_month.csv\") \n# Will move the file to data folder\n\n\n\n\nTo understand seasonal trade patterns by trading partner in 3.4, I will use the Merchandise Trade by Region/Market dataset from DOS. This data set has the merchandise trade by region and markets for Imports, Export and Re-export. I will combine the subsets into one csv file for the analysis. Similar to Monthly Trade Intensity Analysis, 3 tabs from this Excel file will be imported and make subsets into separate csv files.\n\n\nShow the code\n# ---- Import by region\nim_by_reg_data &lt;- read_xlsx(\"data/Mtrade_region.xlsx\", \"T1\")\nim_by_reg_csv &lt;- im_by_reg_data[c(10: 170),]\n\n# After transpose, the data is a matrix.\nim_by_reg_matrix &lt;- t(im_by_reg_csv) \n#now convert the matrix to df.\nim_by_reg &lt;- as.data.frame(im_by_reg_matrix)\n\n# Correct the column name\nreal_column_names_imreg &lt;- as.character(im_by_reg[1, ])\ncolnames(im_by_reg) &lt;- real_column_names_imreg\n\n# remove the first row\nim_by_reg &lt;- im_by_reg %&gt;%\n  slice(-1) \n\n\n# Turn the dataframe to a csv file for easy calling. Run only once. \n#write.csv(im_by_reg, \"im_by_reg.csv\") \n# Will move the file to data folder\n\n# ---- Export by region\nex_by_reg_data &lt;- read_xlsx(\"data/Mtrade_region.xlsx\", \"T2\")\nex_by_reg_csv &lt;- ex_by_reg_data[c(10: 170),]\n\n# After transpose, the data is a matrix.\nex_by_reg_matrix &lt;- t(ex_by_reg_csv) \n#now convert the matrix to df.\nex_by_reg &lt;- as.data.frame(ex_by_reg_matrix)\n\n# Correct the column name\nreal_column_names_exreg &lt;- as.character(ex_by_reg[1, ])\ncolnames(ex_by_reg) &lt;- real_column_names_exreg\n\n# remove the first row\nex_by_reg &lt;- ex_by_reg %&gt;%\n  slice(-1) \n\n# Turn the dataframe to a csv file for easy calling. Run only once. \n#write.csv(ex_by_reg, \"ex_by_reg.csv\") \n# Will move the file to data folder\n\n# ---- Re-Export by region\nrex_by_reg_data &lt;- read_xlsx(\"data/Mtrade_region.xlsx\", \"T3\")\nrex_by_reg_csv &lt;- rex_by_reg_data[c(10: 170),]\n\n# After transpose, the data is a matrix.\nrex_by_reg_matrix &lt;- t(rex_by_reg_csv) \n#now convert the matrix to df.\nrex_by_reg &lt;- as.data.frame(rex_by_reg_matrix)\n\n# Correct the column name\nreal_column_names_rexreg &lt;- as.character(rex_by_reg[1, ])\ncolnames(rex_by_reg) &lt;- real_column_names_rexreg\n\n# remove the first row\nrex_by_reg &lt;- rex_by_reg %&gt;%\n  slice(-1) \n\n# Turn the dataframe to a csv file for easy calling. Run only once. \n#write.csv(rex_by_reg, \"rex_by_reg.csv\") \n# Will move the file to data folder\n\n\n\n\nThe fact that Singapore being a pivotal trading hub, the Re-Export data is important to understand what goods have leveraged Singapore as its transition hub to see or forward to other place. 2 data sets from the Merchandise Trade by Commodity Section/Division Excel file will be used.\n\n\nShow the code\n# ---- ReX Commodity\nrex_by_com_data &lt;- read_xlsx(\"data/Mtrade_commodity.xlsx\", \"T9\")\nrex_by_com_csv &lt;- rex_by_com_data[c(10:37),]\n\n# After transpose, the data is a matrix.\nrex_by_com_matrix &lt;- t(rex_by_com_csv) \n#now convert the matrix to df.\nrex_by_com &lt;- as.data.frame(rex_by_com_matrix)\n\n# Correct the column name\nreal_column_names_rexcom &lt;- as.character(rex_by_com[1, ])\ncolnames(rex_by_com) &lt;- real_column_names_rexcom\n\n# remove the first row\nrex_by_com &lt;- rex_by_com %&gt;%\n  slice(-1) \n\n# Turn the dataframe to a csv file for easy calling. Run only once. \nwrite.csv(rex_by_com, \"rex_by_com.csv\") \n# Will move the file to data folder\n\n# ---- ReX Machinery\nrex_by_mac_data &lt;- read_xlsx(\"data/Mtrade_commodity.xlsx\", \"T10\")\nrex_by_mac_csv &lt;- rex_by_mac_data[c(10:22),]\n\n# After transpose, the data is a matrix.\nrex_by_mac_matrix &lt;- t(rex_by_mac_csv) \n#now convert the matrix to df.\nrex_by_mac &lt;- as.data.frame(rex_by_mac_matrix)\n\n# Correct the column name\nreal_column_names_rexmac &lt;- as.character(rex_by_mac[1, ])\ncolnames(rex_by_mac) &lt;- real_column_names_rexmac\n\n# remove the first row\nrex_by_mac &lt;- rex_by_mac %&gt;%\n  slice(-1) \n\n# Turn the dataframe to a csv file for easy calling. Run only once. \nwrite.csv(rex_by_mac, \"rex_by_mac.csv\") \n# Will move the file to data folder\n\n\n\n\nThe Market Share Trend Analysis in 3.6 aims to understand Singapore trade balance with its trading partners. For this analysis, the dataset derived for heatmaps will be reused for data wrangling.\n\n\n\n\n\n3.3 Monthly Trade Intensity Analysis\nIn this analysis, I will use the monthly trade data from the previously converted csv file trade_by_month.csv to plot a calendar heatmap. From the heatmap, I wish to observe the monthly intensity for the recent 25 years.\n\n3.3.1 Data wrangling\n\nIMPORTEXPORTRE-EXPORT\n\n\n\n\nShow the code\nim_mon &lt;- read_csv(\"data/im_region_month.csv\")\n\n# Prepare data for calendar heatmap\nregion_exlude_cal &lt;- c(\"Total All Markets\", \"America\", \"Asia\", \"Europe\", \"Oceania\", \"Africa\")\n\nim_mon_calendar &lt;- im_mon %&gt;%\n  select(-1) %&gt;%\n  rename(date_str = `Data Series`) %&gt;%\n  \n  pivot_longer(\n    -date_str,\n    names_to = \"Country\",\n    values_to = \"trade_value\"\n  ) %&gt;%\n  mutate(\n    year = as.numeric(str_extract(date_str, \"\\\\d{4}\")),\n    month_str = str_extract(date_str, \"[A-Za-z]{3}\"),\n    month = month_str,\n    month_num = match(month_str, month.abb),    \n    date = ymd(paste(year, month, \"01\", sep = \"-\")),\n    trade_value_mil = round(trade_value / 1000, 5),\n    yearmonth = floor_date(date, \"month\"),\n    year_factor = as.factor(year)\n  ) %&gt;%\n  \n  filter(year &gt;= 2015 & year &lt;= 2025) %&gt;%\n  \n  select(date, year, month, yearmonth, year_factor, trade_value_mil, Country) %&gt;%\n\n# Exclude regions\n  filter(!Country %in% region_exlude_cal)\n\n# Filter top 6\ntop6_calendar &lt;- im_mon_calendar %&gt;%\n  group_by(Country) %&gt;%\n  summarise(total_trade_value = sum(trade_value_mil, na.rm = TRUE)) %&gt;%\n  arrange(desc(total_trade_value)) %&gt;%\n  slice_head(n=6)\n\nim_mon_calendar_top6 &lt;- im_mon_calendar %&gt;%\n  filter(Country %in% top6_calendar$Country)\n\nhead(im_mon_calendar_top6)\n\n\n# A tibble: 6 × 7\n  date        year month yearmonth  year_factor trade_value_mil Country      \n  &lt;date&gt;     &lt;dbl&gt; &lt;chr&gt; &lt;date&gt;     &lt;fct&gt;                 &lt;dbl&gt; &lt;chr&gt;        \n1 2025-01-01  2025 Jan   2025-01-01 2025                   5.39 United States\n2 2025-01-01  2025 Jan   2025-01-01 2025                   6.80 China        \n3 2025-01-01  2025 Jan   2025-01-01 2025                   2.60 Japan        \n4 2025-01-01  2025 Jan   2025-01-01 2025                   3.78 Korea, Rep Of\n5 2025-01-01  2025 Jan   2025-01-01 2025                   6.45 Malaysia     \n6 2025-01-01  2025 Jan   2025-01-01 2025                  10.2  Taiwan       \n\n\n\n\n\n\nShow the code\nex_mon &lt;- read_csv(\"data/ex_region_month.csv\")\n\n# Prepare data for calendar heatmap\nex_mon_calendar &lt;- ex_mon %&gt;%\n  select(-1) %&gt;%\n  rename(date_str = `Data Series`) %&gt;%\n  \n  pivot_longer(\n    -date_str,\n    names_to = \"Country\",\n    values_to = \"trade_value\"\n  ) %&gt;%\n  mutate(\n    year = as.numeric(str_extract(date_str, \"\\\\d{4}\")),\n    month_str = str_extract(date_str, \"[A-Za-z]{3}\"),\n    month = month_str,\n    month_num = match(month_str, month.abb),    \n    date = ymd(paste(year, month, \"01\", sep = \"-\")),\n    trade_value_mil = round(trade_value / 1000, 5),\n    yearmonth = floor_date(date, \"month\"),\n    year_factor = as.factor(year)\n  ) %&gt;%\n  \n  filter(year &gt;= 2015 & year &lt;= 2025) %&gt;%\n  \n  select(date, year, month, yearmonth, year_factor, trade_value_mil, Country) %&gt;%\n\n# Exclude regions\n  filter(!Country %in% region_exlude_cal)\n\n# Filter top 6\ntop6_calendar_ex &lt;- ex_mon_calendar %&gt;%\n  group_by(Country) %&gt;%\n  summarise(total_trade_value = sum(trade_value_mil, na.rm = TRUE)) %&gt;%\n  arrange(desc(total_trade_value)) %&gt;%\n  slice_head(n=6)\n\nex_mon_calendar_top6 &lt;- ex_mon_calendar %&gt;%\n  filter(Country %in% top6_calendar_ex$Country)\n\nhead(ex_mon_calendar_top6)\n\n\n# A tibble: 6 × 7\n  date        year month yearmonth  year_factor trade_value_mil Country      \n  &lt;date&gt;     &lt;dbl&gt; &lt;chr&gt; &lt;date&gt;     &lt;fct&gt;                 &lt;dbl&gt; &lt;chr&gt;        \n1 2025-01-01  2025 Jan   2025-01-01 2025                   3.25 United States\n2 2025-01-01  2025 Jan   2025-01-01 2025                   2.26 China        \n3 2025-01-01  2025 Jan   2025-01-01 2025                   1.87 Hong Kong    \n4 2025-01-01  2025 Jan   2025-01-01 2025                   2.00 Indonesia    \n5 2025-01-01  2025 Jan   2025-01-01 2025                   2.47 Malaysia     \n6 2025-01-01  2025 Jan   2025-01-01 2025                   1.10 Taiwan       \n\n\n\n\n\n\nShow the code\nrex_mon &lt;- read_csv(\"data/rex_region_month.csv\")\n\n# Prepare data for calendar heatmap\nrex_mon_calendar &lt;- rex_mon %&gt;%\n  select(-1) %&gt;%\n  rename(date_str = `Data Series`) %&gt;%\n  \n  pivot_longer(\n    -date_str,\n    names_to = \"Country\",\n    values_to = \"trade_value\"\n  ) %&gt;%\n  mutate(\n    year = as.numeric(str_extract(date_str, \"\\\\d{4}\")),\n    month_str = str_extract(date_str, \"[A-Za-z]{3}\"),\n    month = month_str,\n    month_num = match(month_str, month.abb),    \n    date = ymd(paste(year, month, \"01\", sep = \"-\")),\n    trade_value_mil = round(trade_value / 1000, 5),\n    yearmonth = floor_date(date, \"month\"),\n    year_factor = as.factor(year)\n  ) %&gt;%\n  \n  filter(year &gt;= 2015 & year &lt;= 2025) %&gt;%\n  \n  select(date, year, month, yearmonth, year_factor, trade_value_mil, Country) %&gt;%\n\n# Exclude regions\n  filter(!Country %in% region_exlude_cal)\n\n# Filter top 6\ntop6_calendar_rex &lt;- rex_mon_calendar %&gt;%\n  group_by(Country) %&gt;%\n  summarise(total_trade_value = sum(trade_value_mil, na.rm = TRUE)) %&gt;%\n  arrange(desc(total_trade_value)) %&gt;%\n  slice_head(n=6)\n\nrex_mon_calendar_top6 &lt;- rex_mon_calendar %&gt;%\n  filter(Country %in% top6_calendar_ex$Country)\n\nhead(rex_mon_calendar_top6)\n\n\n# A tibble: 6 × 7\n  date        year month yearmonth  year_factor trade_value_mil Country      \n  &lt;date&gt;     &lt;dbl&gt; &lt;chr&gt; &lt;date&gt;     &lt;fct&gt;                 &lt;dbl&gt; &lt;chr&gt;        \n1 2025-01-01  2025 Jan   2025-01-01 2025                   2.57 United States\n2 2025-01-01  2025 Jan   2025-01-01 2025                   3.81 China        \n3 2025-01-01  2025 Jan   2025-01-01 2025                   4.72 Hong Kong    \n4 2025-01-01  2025 Jan   2025-01-01 2025                   2.55 Indonesia    \n5 2025-01-01  2025 Jan   2025-01-01 2025                   4.29 Malaysia     \n6 2025-01-01  2025 Jan   2025-01-01 2025                   3.66 Taiwan       \n\n\n\n\n\n\n\n3.3.2 Plot & Analysis\nLoad and launch packages\n\npacman::p_load(ggplot2, patchwork, ggthemes)\n\nPlot Heatmaps for top 6 markets\n\nIMPORTEXPORTRE-EXPORT\n\n\n\n\nShow the code\nggplot(im_mon_calendar_top6,\n       aes(\n         x = factor(month, levels = month.abb),\n         y = year_factor,\n         fill = trade_value_mil\n       )) +\n  geom_tile(color = \"white\") +  \n  coord_equal() +\n  scale_fill_gradient(name = \"Trade value (S$ Mil.)\",\n                      low = \"white\",\n                      high = \"#3D5300\") +\n  facet_wrap(~Country, ncol =3) +\n  labs(x = \"Month\", \n       y = \"Year\",\n       title = \"Import Monthly Merchandise Trade Intensity\",\n       subtitle = \"2015-2025\") +\n  coord_equal() +\n  theme(legend.position = \"right\",\n        legend.key.size = unit(0.7, \"cm\"),\n        title = element_text(size = 12, family = \"Arial\", face = \"bold\"),\n        axis.title.x = element_blank(),\n        axis.title.y = element_blank(),\n        axis.text.x = element_text(size = 6),\n        axis.text.y = element_text(size = 6),\n        legend.title = element_text(size = 7),\n        legend.text = element_text(size = 6),\n        axis.ticks = element_blank(),\n        plot.margin = margin( t = 20, r = 5, b = 10, l = 5))\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\nTop 6 markets - The top six markets by total trade value since 2015 are China, Japan, South Korea, Malaysia, Taiwan, and the United States.\nIncreasing intensity - Almost all of the top six markets show a significant increase in trade intensity starting from 2021, with Taiwan exhibiting the most remarkable rise.\nPeak import year - The highest trade intensity across all markets occurred in 2022, coinciding with Singapore’s border reopening post-COVID-19. Notably, Taiwan has seen a marked increase in imports from 2024 onwards.\nJapan - Despite being among the top six import markets, Japan demonstrates the lowest import intensity, even trailing behind South Korea.\n\n\n\n\n\n\n\nShow the code\nggplot(ex_mon_calendar_top6,\n       aes(\n         x = factor(month, levels = month.abb),\n         y = year_factor,\n         fill = trade_value_mil\n       )) +\n  geom_tile(color = \"white\") +  \n  coord_equal() +\n  scale_fill_gradient(name = \"Trade value (S$ Mil.)\",\n                      low = \"white\",\n                      high = \"#AC1754\") +\n  facet_wrap(~Country, ncol =3) +\n  labs(x = \"Month\", \n       y = \"Year\",\n       title = \"Export Monthly Merchandise Trade Intensity\",\n       subtitle = \"2015-2025\") +\n  coord_equal() +\n  theme(legend.position = \"right\",\n        legend.key.size = unit(0.7, \"cm\"),\n        title = element_text(size = 12, family = \"Arial\", face = \"bold\"),\n        axis.title.x = element_blank(),\n        axis.title.y = element_blank(),\n        axis.text.x = element_text(size = 6),\n        axis.text.y = element_text(size = 6),\n        legend.title = element_text(size = 7),\n        legend.text = element_text(size = 6),\n        axis.ticks = element_blank(),\n        plot.margin = margin( t = 20, r = 5, b = 10, l = 5))\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\nTop 6 markets - The top six markets by total export trade value since 2015 are China, Indonesia, Hong Kong, Malaysia, Taiwan, and the United States.\nIncreasing intensity - Among these markets, only the United States exhibits a clear upward trend in export trade intensity, while the others have remained relatively stable over the past decade.\nPeak export periods - No distinct peak year or month is observed. However, exports to the United States tend to show higher intensity in March, April, and July in certain years.\nTaiwan - While Taiwan ranks among the top six trading partners for both imports and exports, its export trade intensity is the lowest among them. This appears to be different from Import.\n\n\n\n\n\n\n\nShow the code\nggplot(ex_mon_calendar_top6,\n       aes(\n         x = factor(month, levels = month.abb),\n         y = year_factor,\n         fill = trade_value_mil\n       )) +\n  geom_tile(color = \"white\") +  \n  coord_equal() +\n  scale_fill_gradient(name = \"Trade value (S$ Mil.)\",\n                      low = \"white\",\n                      high = \"#640D5F\") +\n  facet_wrap(~Country, ncol =3) +\n  labs(x = \"Month\", \n       y = \"Year\",\n       title = \"Re-Export Monthly Merchandise Trade Intensity\",\n       subtitle = \"2015-2025\") +\n  coord_equal() +\n  theme(legend.position = \"right\",\n        legend.key.size = unit(0.7, \"cm\"),\n        title = element_text(size = 12, family = \"Arial\", face = \"bold\"),\n        axis.title.x = element_blank(),\n        axis.title.y = element_blank(),\n        axis.text.x = element_text(size = 6),\n        axis.text.y = element_text(size = 6),\n        legend.title = element_text(size = 7),\n        legend.text = element_text(size = 6),\n        axis.ticks = element_blank(),\n        plot.margin = margin( t = 20, r = 5, b = 10, l = 5))\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\nTop 6 markets - The top six markets by total re-export trade value since 2015 is the same as the top 6 for exports. They are China, Indonesia, Hong Kong, Malaysia, Taiwan, and the United States.\nIncreasing intensity - Only the United States and Indonesia have shown an obvious increasing trend of intensity, while the rest maintained similar intensity of export trade through the past 10 years.\nPeak re-export year - No distinct peak year or month is observed. However, exports to the United States tend to show higher intensity in March, April, and July in certain years. This is highly correlated to the domestic export trade volume.\n\n\n\n\n\n\n\n\n\n3.4 Seasonal Trade Pattern by Trading Partner\n\n\n3.4.1 Data wrangling\nIn this step, I will convert the tibble objects to tsibble object for all trade categories, using as_tsibble() from R package. In the analysis, only the top 25 partners will be analysed. I will also exclude some countries that are in fact regions, such as total markets, Asia, etc.\n\npacman::p_load(fpp3, feasts)\n\n\nIMPORTEXPORTRE-EXPORT\n\n\n\n\nShow the code\n# Import data (tibble frame)\nim_by_region &lt;- read_csv(\"data/im_by_reg.csv\")\nim_by_region &lt;- im_by_region %&gt;%\n  rename(`Date` = \"Data Series\")\n\n# Define regions to exclude\nregions_to_exclude &lt;- c(\"Asia\", \"Europe\", \"Africa\", \"America\", \n                        \"Oceania\", \"Total All Markets\")\n\n# Filter out columns that match regions to exclude\nim_by_region_filtered &lt;- im_by_region %&gt;%\n  select(-any_of(regions_to_exclude))\n\n# Calculate column sums to find top 10 countries (excluding Date column)\ncolumn_totals_im &lt;- im_by_region_filtered %&gt;%\n  select(-Date) %&gt;%\n  # Convert all columns to numeric\n  mutate(across(everything(), ~as.numeric(as.character(.)))) %&gt;%\n  summarise(across(everything(), ~sum(., na.rm = TRUE))) %&gt;%\n  pivot_longer(everything(), names_to = \"Country\", values_to = \"Total\") %&gt;%\n  arrange(desc(Total)) %&gt;%\n  slice_head(n = 10) %&gt;%\n  pull(Country)\n\n# Select only the top 10 countries plus Date\nim_by_region_top &lt;- im_by_region_filtered %&gt;%\n  select(Date, any_of(column_totals_im))\n\n\n# convert to tsibble\nim_by_region_tsb &lt;- im_by_region_top %&gt;%\n  mutate(Date = yearmonth(Date)) %&gt;%\n  as_tsibble(index = `Date`)\n\n# Pivot longer for visualisation\nim_by_region_long_data &lt;- im_by_region_tsb %&gt;%\n  pivot_longer(cols = c(2:ncol(im_by_region_tsb)),\n               names_to = \"Country\",\n               values_to = \"Value\")\n\nim_by_region_long &lt;- im_by_region_long_data %&gt;%\n  filter(year(Date) &gt;= 2015 & year(Date) &lt;= 2025)\n\n#tissible object now\nhead(im_by_region_long)\n\n\n# A tsibble: 6 x 3 [1M]\n# Key:       Country [6]\n      Date Country       Value\n     &lt;mth&gt; &lt;chr&gt;         &lt;dbl&gt;\n1 2015 Jan China         4951 \n2 2015 Jan Malaysia      3965.\n3 2015 Jan United States 3823.\n4 2015 Jan Taiwan        2586.\n5 2015 Jan Japan         2146.\n6 2015 Jan Korea, Rep Of 1631.\n\n\n\n\n\n\nShow the code\nex_by_region &lt;- read_csv(\"data/ex_by_reg.csv\")\nex_by_region &lt;- ex_by_region %&gt;%\n  rename(`Date` = \"Data Series\")\n# Filter out columns that match regions to exclude\nex_by_region_filtered &lt;- ex_by_region %&gt;%\n  select(-any_of(regions_to_exclude))\n\n# Calculate column sums to find top 10 countries (excluding Date column)\ncolumn_totals_ex &lt;- ex_by_region_filtered %&gt;%\n  select(-Date) %&gt;%\n  # Convert all columns to numeric\n  mutate(across(everything(), ~as.numeric(as.character(.)))) %&gt;%\n  summarise(across(everything(), ~sum(., na.rm = TRUE))) %&gt;%\n  pivot_longer(everything(), names_to = \"Country\", values_to = \"Total\") %&gt;%\n  arrange(desc(Total)) %&gt;%\n  slice_head(n = 10) %&gt;%\n  pull(Country)\n\n# Select only the top 10 countries plus Date\nex_by_region_top &lt;- ex_by_region_filtered %&gt;%\n  select(Date, any_of(column_totals_ex))\n\n\n# convert to tsibble\nex_by_region_tsb &lt;- ex_by_region_top %&gt;%\n  mutate(Date = yearmonth(Date)) %&gt;%\n  as_tsibble(index = `Date`)\n\n# Pivot longer for visualisation\nex_by_region_long_data &lt;- ex_by_region_tsb %&gt;%\n  pivot_longer(cols = c(2:ncol(ex_by_region_tsb)),\n               names_to = \"Country\",\n               values_to = \"Value\")\nex_by_region_long &lt;- ex_by_region_long_data %&gt;%\n  filter(year(Date) &gt;= 2015 & year(Date) &lt;= 2025)\n\n#tissible object now\nhead(ex_by_region_long)\n\n\n# A tsibble: 6 x 3 [1M]\n# Key:       Country [6]\n      Date Country       Value\n     &lt;mth&gt; &lt;chr&gt;         &lt;dbl&gt;\n1 2015 Jan China         2576.\n2 2015 Jan Malaysia      2135.\n3 2015 Jan United States 1248.\n4 2015 Jan Hong Kong     1532.\n5 2015 Jan Indonesia     1427.\n6 2015 Jan Japan          832.\n\n\n\n\n\n\nShow the code\nrex_by_region &lt;- read_csv(\"data/rex_by_reg.csv\")\nrex_by_region &lt;- rex_by_region %&gt;%\n  rename(Date = \"Data Series\")\n# Filter out columns that match regions to exclude\nrex_by_region_filtered &lt;- rex_by_region %&gt;%\n  select(-any_of(regions_to_exclude))\n\n# Calculate column sums to find top 25 countries (excluding Date column)\ncolumn_totals_rex &lt;- rex_by_region_filtered %&gt;%\n  select(-Date) %&gt;%\n  # Convert all columns to numeric\n  mutate(across(everything(), ~as.numeric(as.character(.)))) %&gt;%\n  summarise(across(everything(), ~sum(., na.rm = TRUE))) %&gt;%\n  pivot_longer(everything(), names_to = \"Country\", values_to = \"Total\") %&gt;%\n  arrange(desc(Total)) %&gt;%\n  slice_head(n = 10) %&gt;%\n  pull(Country)\n\n# Select only the top 10 countries plus Date\nrex_by_region_top &lt;- rex_by_region_filtered %&gt;%\n  select(Date, any_of(column_totals_rex))\n\n\n# convert to tsibble\nrex_by_region_tsb &lt;- rex_by_region_top %&gt;%\n  mutate(Date = yearmonth(Date)) %&gt;%\n  as_tsibble(index = `Date`)\n\n# Pivot longer for visualisation\nrex_by_region_long_data &lt;- rex_by_region_tsb %&gt;%\n  pivot_longer(cols = c(2:ncol(rex_by_region_tsb)),\n               names_to = \"Country\",\n               values_to = \"Value\")\n\nrex_by_region_long &lt;- rex_by_region_long_data %&gt;%\n  filter(year(Date) &gt;= 2015 & year(Date) &lt;= 2025)\n\n#tissible object now\nhead(rex_by_region_long)\n\n\n# A tsibble: 6 x 3 [1M]\n# Key:       Country [6]\n      Date Country       Value\n     &lt;mth&gt; &lt;chr&gt;         &lt;dbl&gt;\n1 2015 Jan Hong Kong     3689 \n2 2015 Jan China         3763.\n3 2015 Jan Malaysia      2407 \n4 2015 Jan Indonesia     1902.\n5 2015 Jan United States 1027.\n6 2015 Jan Korea, Rep Of 1148.\n\n\n\n\n\n\n\n3.4.2 Plot & Analysis\nBelow each tab shows the overall Time plot, Composite plot by country, as well as Seasonal subseries plots for a trade category, Import, Export or Re-Export. This helps observe the trend, seasonal and cyclic patterns for top 10 markets in each trade category during 2005 to 2025.\n\nIMPORTEXPORTRE-EXPORT\n\n\nThe top 10 trade markets for import include China, Japan, Malaysia, Taiwan, UAE, Indonesia, S. Korea, Saudi Arabia, Thailand and the US.\nOVERALL TIME PLOT\n\n\nShow the code\nautoplot(im_by_region_long) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\nCOMPOSITE PLOT BY COUNTRY\n\nCHINAINDONESIAJAPANKOREATAIWANMALAYSIASAUDI ARABIATHAILANDUSAUAE\n\n\n\n\nShow the code\nim_by_region_long %&gt;%\n  filter(`Country` == \"China\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nim_by_region_long %&gt;%\n  filter(`Country` == \"Indonesia\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nim_by_region_long %&gt;%\n  filter(`Country` == \"Japan\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nim_by_region_long %&gt;%\n  filter(`Country` == \"Korea, Rep Of\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nim_by_region_long %&gt;%\n  filter(`Country` == \"Taiwan\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nim_by_region_long %&gt;%\n  filter(`Country` == \"Malaysia\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nim_by_region_long %&gt;%\n  filter(`Country` == \"Saudi Arabia\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nim_by_region_long %&gt;%\n  filter(`Country` == \"Thailand\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nim_by_region_long %&gt;%\n  filter(`Country` == \"United States\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nim_by_region_long %&gt;%\n  filter(`Country` == \"United Arab Emirates\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\nSEASONAL SUBSERIES PLOTS\n\n\nShow the code\nim_by_region_long |&gt; gg_subseries(Value) +\n  theme(\n    axis.text.x = element_text(size = 5),\n    axis.text.y = element_text(size = 5)\n  )\n\n\n\n\n\n\n\n\n\n\n\nObservations | IMPORT\n\n\n\nWidening gap in strong trade markets - The time plot reveals four markets — Taiwan, China, the US, Malaysia - showing a consistent upward trend, creating a growing gap between them and other markets.\nSeasonal patterns - While most countries show little seasonality in imports, a dip in February is common, possibly due to fewer days. However, China and South Korea display a distinct spike in July, while the US shows dips in February and December, and a spike in August. Both China and the US also exhibit strong positive autocorrelation at lag 12, indicating a seasonal pattern. Indonesia shows sharp drops at lags 3 and 5, suggesting a cyclical pattern or seasonality every 3–5 months.\nTrend - Countries like China, South Korea, Taiwan, Malaysia, Thailand, USA, and UAE show an increasing trend, supported by slow decay in their ACF plots. In contrast, Saudi Arabia demonstrates a decreasing trend.\n\n\n\n\n\nOVERALL TIME PLOTS\n\n\nShow the code\nautoplot(ex_by_region_long) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\nCOMPOSITE PLOT BY COUNTRY\n\nAUSTRALIACHINAHONG KONGINDONESIAJAPANKOREATAIWANMALAYSIATHAILANDUSA\n\n\n\n\nShow the code\nex_by_region_long %&gt;%\n  filter(`Country` == \"Australia\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nex_by_region_long %&gt;%\n  filter(`Country` == \"China\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nex_by_region_long %&gt;%\n  filter(`Country` == \"Hong Kong\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nex_by_region_long %&gt;%\n  filter(`Country` == \"Indonesia\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nex_by_region_long %&gt;%\n  filter(`Country` == \"Japan\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nex_by_region_long %&gt;%\n  filter(`Country` == \"Korea, Rep Of\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nex_by_region_long %&gt;%\n  filter(`Country` == \"Taiwan\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nex_by_region_long %&gt;%\n  filter(`Country` == \"Malaysia\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nex_by_region_long %&gt;%\n  filter(`Country` == \"Thailand\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nex_by_region_long %&gt;%\n  filter(`Country` == \"United States\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\nSEASONAL SUBSERIES PLOTS\n\n\nShow the code\nex_by_region_long |&gt; gg_subseries(Value) +\n  theme(\n    axis.text.x = element_text(size = 5),\n    axis.text.y = element_text(size = 5)\n  )\n\n\n\n\n\n\n\n\n\n\n\nObservations | EXPORT\n\n\n\nConsistent gap in strong trade markets - Unlike Import, the stronger Export trade markets, including China, Malaysia, the US, and Indonesia maintains a consistent gap between them and other markets. Note that the gap isn’t as notable for Indonesia and Malaysia between year 2020-2022.\nCyclic behaviour - Hong Kong displays cyclical trade patterns with peaks at regular intervals (3, 6, 8, and 11 months), suggesting the influence of seasonality or external cyclical factors on trade. This cyclical behavior is not linked to specific months. Similarly, South Korea shows periodic peaks in the ACF plot at lags 3, 6, 9, and 12, indicating a cyclical pattern, with notable dips in February, May, and November, and peaks in March, October, and December. For Taiwan, a peak at lag 12 suggests annual seasonality, likely linked to the electronics manufacturing cycle, while Malaysia’s peak at lag 7 indicates a semi-annual rhythm, possibly driven by business or industry cycles.\nTrend - Countries such as Australia, Indonesia, South Korea, and the USA show an increasing trend, supported by slow decay in their ACF plots, indicating stable growth. In contrast, Hong Kong displays a declining trend, suggesting shifts in trade dynamics over time.\n\n\n\n\n\nOVERALL TIME PLOTS\n\n\nShow the code\nautoplot(rex_by_region_long) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\nCOMPOSITE PLOT BY COUNTRY\n\nCHINAHONG KONGINDONESIAJAPANKOREATAIWANMALAYSIATHAILANDUSAVIETNAM\n\n\n\n\nShow the code\nrex_by_region_long %&gt;%\n  filter(`Country` == \"China\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nrex_by_region_long %&gt;%\n  filter(`Country` == \"Hong Kong\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nrex_by_region_long %&gt;%\n  filter(`Country` == \"Indonesia\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nrex_by_region_long %&gt;%\n  filter(`Country` == \"Japan\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nrex_by_region_long %&gt;%\n  filter(`Country` == \"Korea, Rep Of\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nrex_by_region_long %&gt;%\n  filter(`Country` == \"Taiwan\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nrex_by_region_long %&gt;%\n  filter(`Country` == \"Malaysia\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nrex_by_region_long %&gt;%\n  filter(`Country` == \"Thailand\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nrex_by_region_long %&gt;%\n  filter(`Country` == \"United States\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nrex_by_region_long %&gt;%\n  filter(`Country` == \"Viet Nam\") %&gt;%\n  gg_tsdisplay(Value)\n\n\n\n\n\n\n\n\n\n\n\n\nSEASONAL SUBSERIES PLOTS\n\n\nShow the code\nrex_by_region_long |&gt; gg_subseries(Value) +\n  theme(\n    axis.text.x = element_text(size = 5),\n    axis.text.y = element_text(size = 5)\n  )\n\n\n\n\n\n\n\n\n\n\n\nObservations | RE_EXPORT\n\n\n\n3 distinct trade market bands - The time plot reveals three distinct bands of trade markets. The first band consists of Hong Kong and China, which have nearly identical trade values post-2023. With this, China stays as the largest Re-Export trade market. The second band evolves over time—before 2018, it includes Malaysia and Indonesia, but after 2019, the USA joins this group while Indonesia fell to band 3 until 2021. The third band consists of all remaining markets. The gaps between these bands remained stable before 2019 and after 2020, but post-2023, the distinction between bands 2 and 3 becomes less pronounced, while Malaysia pulls away from band 2, widening its gap.\nSeasonal patterns - Seasonal trends are evident across many markets. Most countries experience dips in February, likely due to fewer days in the month. China and Hong Kong show dips in February and June, with peaks in January, March, October, and December in recent years. Japan exhibits peaks in March, July, and December, with dips in May. South Korea has peaks in March, June, and December, and dips in February, May, and November. Malaysia peaks in March and October, while Thailand shows peaks in March, June, and October and dips in February and December. Vietnam experiences peaks in January, March, August, and December.\nCyclic behaviour - Many of the Re-export trade partners show cyclic behaviour. China, Hong Kong, Japan, Korea, Taiwan, Thailand, USA and Vietnam. Their ACF plots refelct the scallop effect at different lags. Notable patterns include China (lag 12), Hong Kong (lags 3, 6, 9, 12), and the USA (lags 8 and 12), that suggest periodic trade fluctuations.\nTrend - All top Re-Export trade markets show a consistent upward trend, indicating sustained growth in re-export activities.\n\n\n\n\n\n\n\n\n\n3.5 Trading Trend Analysis\n\n3.5.1 Data Wrangling\n\n\nShow the code\n# Add a trade type identifier to each dataset before stacking\nim_mon_trend &lt;- im_mon_calendar %&gt;% mutate(Type = \"Import\")\nex_mon_trend &lt;- ex_mon_calendar %&gt;% mutate(Type = \"Export\")\nrex_mon_trend &lt;- rex_mon_calendar %&gt;% mutate(Type = \"ReExport\")\n\n# Combine all datasets into one\nstacked_trend &lt;- bind_rows(im_mon_trend, ex_mon_trend, rex_mon_trend)\n\n# Create an adjusted trade value column where imports are negative and exports/re-exports are positive\nstacked_trend &lt;- stacked_trend %&gt;%\n  mutate(adjusted_trade_value = case_when(\n    Type == \"Export\" ~ trade_value_mil,\n    Type == \"ReExport\" ~ trade_value_mil,\n    Type == \"Import\" ~ -trade_value_mil,\n    TRUE ~ 0\n  ))\n\n# Compute (export + re-export - import) for each country by month\nnet_trade_df &lt;- stacked_trend %&gt;%\n  group_by(date, Country) %&gt;%\n  summarise(\n    net_trade_value_mil = sum(adjusted_trade_value, na.rm = TRUE)\n  ) %&gt;%\n  ungroup()\n\n# Convert trade values to thousands (if necessary)\nnet_trade_df$net_trade_value_mil &lt;- net_trade_df$net_trade_value_mil * 1000\n\nnet_trade_df &lt;- net_trade_df %&gt;%\n  rename(net_trade_value_k = \"net_trade_value_mil\")\n\n# View the resulting dataset\nhead(net_trade_df)\n\n\n# A tibble: 6 × 3\n  date       Country             net_trade_value_k\n  &lt;date&gt;     &lt;chr&gt;                           &lt;dbl&gt;\n1 2015-01-01 Afghanistan                       1.5\n2 2015-01-01 Algeria                           5.6\n3 2015-01-01 Angola                          117. \n4 2015-01-01 Antarctica                        0.2\n5 2015-01-01 Antigua And Barbuda              25.6\n6 2015-01-01 Argentina                         3.9\n\n\n\n\n3.5.2 Plot & Analaysis\nThe analyse the trade trends, a ggHoriPlot will be plotted to observed the trends among Singapore trade partners. This approach is employeed because I would like to see all countries in one view. To plot the ggHoriPlot, I will load and launch the following packages: ggHoriPlot, ggthemes and tidyverse.\n\npacman::p_load(ggHoriPlot, ggthemes, tidyverse)\n\nIn the HotiPlot below, the top and bottom Surplus and Deficit trade partners are plotted in one view. To have a full view of the historical changes of trade balance, all countries are included to the plot in tab 2 “ALL COUNTRIES”. All countries are ordered in alphebetical orders. Red dipicts net negative trade (Deficit) and blue means Surplus. Darker colors means larger trade deficit / surplus.\n\nTOP BOTTOM 30ALL COUNTRIES\n\n\n\n\nShow the code\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(ggHoriPlot)\n\n# Get total trade value per country\ncountry_trade_summary &lt;- net_trade_df %&gt;%\n  group_by(Country) %&gt;%\n  summarise(total_trade_value = sum(net_trade_value_k, na.rm = TRUE)) %&gt;%\n  ungroup()\n\n# Select the top 30 and bottom 30 countries\ntop_30_countries &lt;- country_trade_summary %&gt;%\n  arrange(desc(total_trade_value)) %&gt;%\n  slice_head(n = 30) %&gt;%\n  pull(Country)  # Extract country names as a vector\n\nbottom_30_countries &lt;- country_trade_summary %&gt;%\n  arrange(total_trade_value) %&gt;%\n  slice_head(n = 30) %&gt;%\n  pull(Country)  # Extract country names as a vector\n\n# Combine top and bottom 30 countries\nselected_countries &lt;- c(top_30_countries, bottom_30_countries)\n\n# Filter the original dataset for only these 60 countries\nfiltered_df &lt;- net_trade_df %&gt;%\n  filter(Country %in% selected_countries, date &gt;= \"2015-01-01\")\n\n# Plot the horizon graph for these countries\nggplot(filtered_df, aes(x = date, y = net_trade_value_k)) +\n  geom_horizon(origin = \"midpoint\", horizonscale = 6) +\n  facet_grid(Country ~ .) +\n  theme_few() +\n  scale_fill_hcl(palette = \"RdBu\") +\n  theme(\n    panel.spacing.y = unit(0, \"lines\"),\n    strip.text.y = element_text(size = 5, angle = 0, hjust = 0),\n    legend.position = \"none\",\n    axis.text.y = element_blank(),\n    axis.text.x = element_text(size = 5, angle = 45, hjust = 1),\n    axis.title.y = element_blank(),\n    axis.title.x = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.border = element_blank(),\n    plot.title = element_text(size = 12, family = \"Arial\", face = \"bold\"),\n    plot.margin = margin(t = 20, r = 15, b = 10, l = 15)\n  ) +\n  scale_x_date(expand = c(0, 0),\n               date_breaks = \"3 months\",\n               date_labels = \"%b%y\") +\n  labs(title = \"Trade Balance of Top & Bottom 30 Singapore Trading Partners \\n2015 Jan - 2025 Jan\")\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\nPersistent Trade Deficit Markets - Several markets have consistently remained in trade deficit, with occasional surplus periods. These include Bangladesh, Belgium, France, Germany, Guam, Myanmar, New Caledonia, New Zealand, Pakistan, Puerto Rico, and the UK.\nPersistent Trade Surplus Markets - Conversely, some markets have continuously maintained a trade surplus, with only brief deficit periods. Notable examples include Canada, Cyprus, Greece, Iraq, Libya, Poland, Sweden, and Venezuela.\nShifting to Surplus - Certain markets that were once in deficit have transitioned into surplus in recent years. This shift is particularly evident in Fiji, Hong Kong, India, Indonesia, Liberia, Malta, the Marshall Islands, Mexico, Papua New Guinea, and the Philippines, suggesting evolving trade dynamics.\nShifting to Deficit - A few key markets, including Brazil, Ireland, South Korea, Taiwan, and Vietnam, were historically surplus trade partners but have now become significant deficit markets or are trending in that direction.\n\n\n\n\n\n\n\nShow the code\nnet_trade_df %&gt;%\n  filter(date &gt;= \"2015-01-01\") %&gt;%\n  ggplot() +\n  geom_horizon(aes(\n    x = date, y = net_trade_value_k,\n    origin = \"midpoint\",\n    horizonscale = 6),\n    linewidth = 0.5) +\n      facet_grid(Country~.) +\n      theme_few() +\n      scale_fill_hcl(palette =\"RdBu\") +\n      theme(\n        panel.spacing.y=unit(0, \"lines\"), \n        strip.text.y = element_text(\n          size = 5, angle = 0, hjust = 0),\n        legend.position = 'none',\n        axis.text.y = element_blank(),\n        axis.text.x = element_text(size = 5, angle = 45, hjust = 1),\n        axis.title.y = element_blank(),\n        axis.title.x = element_blank(),\n        axis.ticks.y = element_blank(),\n        panel.border = element_blank(),\n        plot.title = element_text(size = 12, family = \"Arial\", face = \"bold\"),\n        plot.margin = margin(t = 20, r = 15, b = 10, l = 15)\n      ) +\n      scale_x_date(expand=c(0,0),\n                   date_breaks = \"3 months\",\n                   date_labels = \"%b%y\") +\n      labs(title = \"Trade Balance of Singapore Trading Partners \\n2015 Jan to 2025 Jan\")\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\nGenerally no obvious Surplus or Deficit trends are observed on the trading markets as a whole, but there are a few interesting patterns to pick up:\n\nDeficit Period (2020–2022) - A more pronounced trade deficit is observed during this period. This coincide with COVID-19 pandemic. This suggests the impact of external economic shocks or shifts in trade policies.\nStable Trade Positions - Most countries have maintained a consistent trade balance with Singapore, while some, as identified in previous analyses, exhibit a shifting trend towards either surplus or deficit.\n\n\n\n\n\n\n\n\n\n3.6 Trade time-series forecasting\nA time-series forecasting will be conducted for Singapore import trade daa by trade markets. The top 6 Import trade markets will be forecasted using ETS and ARIMA models, and results will be compared using plot visualisations.\nThe process is as below: Data Prep &gt; Exploratory data analysis (done in 3.4) &gt; model fitting &gt; diagnostic check &gt; forecasting &gt; forecasting check\n\npacman::p_load(dplyr, tidyr, tsibble, lubridate, forecast, fable)\n\n\n3.6.1 Time series data sampling\nThe data set I will be using is a tsibble frame derived from previous analysis v2_trans_im. This data frame contains monthly export data by trade markets (countries), from 2003 Jan to 2025 Jan. I am particularly interested in forecasting Imports from selected Singapore’s top trade partners from recent years.\nIn this analysis, I will use the last 12 months for hold-out and the rest for training.\n\n\n3.6.2 Data wrangling\n\n\nShow the code\n# Create a copy first\nim_region_df &lt;- v2_trans_im\n\nim_region_df &lt;- im_region_df %&gt;%\n  rename(Date = `Data Series`) %&gt;%\n  mutate(Date = as.Date(paste0(Date, \" 01\"), format = \"%Y %b %d\")) %&gt;%\n  slice(-1) %&gt;% \n  mutate(across(-Date, as.numeric)) %&gt;%\n  pivot_longer(-Date,\n               names_to = \"Country\",\n               values_to = \"Value\") \n\nim_region_df_top &lt;- im_region_df %&gt;%\n  filter(Country %in% c(\"Malaysia\", \"China\", \"Taiwan\", \"Japan\", \"Thailand\", \"Korea, Rep Of\", \"United States\")) %&gt;%\n  filter(Date &gt;= as.Date(\"2015-01-01\"))\n         \n# Convert tiblle to tsiblle\nim_by_region_tsb &lt;- im_region_df_top %&gt;%\n  mutate(Date = yearmonth(Date)) %&gt;%\n  as_tsibble(index = Date, key = Country)\n\nhead(im_by_region_tsb)\n\n\n# A tsibble: 6 x 3 [1M]\n# Key:       Country [1]\n      Date Country Value\n     &lt;mth&gt; &lt;chr&gt;   &lt;dbl&gt;\n1 2015 Jan China   4951 \n2 2015 Feb China   4084.\n3 2015 Mar China   4320.\n4 2015 Apr China   4987.\n5 2015 May China   4554.\n6 2015 Jun China   4686.\n\n\n\n\n3.6.3 Sampling\n\n\nShow the code\nim_top_train &lt;- im_by_region_tsb %&gt;%\n  mutate(Type = if_else(\n    `Date` &gt;= yearmonth(\"2024-01\"), \n    \"Hold-out\", \"Training\")) %&gt;%\n  filter(Type == \"Training\")\n\nhead(im_top_train)\n\n\n# A tsibble: 6 x 4 [1M]\n# Key:       Country [1]\n      Date Country Value Type    \n     &lt;mth&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;   \n1 2015 Jan China   4951  Training\n2 2015 Feb China   4084. Training\n3 2015 Mar China   4320. Training\n4 2015 Apr China   4987. Training\n5 2015 May China   4554. Training\n6 2015 Jun China   4686. Training\n\n\n\n\n3.6.4 Fit multiple time series\n\nFIT MODELSEXAMINE MODELSEXTRACT FITTED AND RESIDUAL VALUES\n\n\n\n\nShow the code\nim_top_fit &lt;- im_top_train %&gt;%\n  model(\n    ets = ETS(Value),\n    arima = ARIMA(Value)\n  )\n\n\n\n\n\nim_top_fit %&gt;%\n  glance()\n\n# A tibble: 14 × 12\n   Country      .model  sigma2 log_lik   AIC  AICc   BIC     MSE    AMSE     MAE\n   &lt;chr&gt;        &lt;chr&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1 China        ets    6.93e-3   -909. 1848. 1853. 1888. 231260. 296508.  0.0621\n 2 China        arima  3.44e+5   -834. 1679. 1680. 1696.     NA      NA  NA     \n 3 Japan        ets    8.28e-3   -826. 1683. 1688. 1723.  44688.  63564.  0.0704\n 4 Japan        arima  6.30e+4   -749. 1508. 1509. 1522.     NA      NA  NA     \n 5 Korea, Rep … ets    1.78e-2   -860. 1726. 1726. 1734.  82406. 111427.  0.107 \n 6 Korea, Rep … arima  8.16e+4   -756. 1517. 1517. 1522.     NA      NA  NA     \n 7 Malaysia     ets    9.58e-3   -917. 1839. 1839. 1847. 245189. 298955.  0.0743\n 8 Malaysia     arima  2.48e+5   -816. 1636. 1636. 1641.     NA      NA  NA     \n 9 Taiwan       ets    8.00e-3   -879. 1788. 1793. 1828. 149726. 223555.  0.0682\n10 Taiwan       arima  2.00e+5   -804. 1614. 1614. 1622.     NA      NA  NA     \n11 Thailand     ets    3.92e-2   -824. 1655. 1655. 1663.  46044.  51467.  0.138 \n12 Thailand     arima  4.68e+4   -727. 1458. 1458. 1463.     NA      NA  NA     \n13 United Stat… ets    7.91e-3   -892. 1814. 1819. 1854. 156055. 202325.  0.0656\n14 United Stat… arima  2.33e+5   -813. 1631. 1631. 1639.     NA      NA  NA     \n# ℹ 2 more variables: ar_roots &lt;list&gt;, ma_roots &lt;list&gt;\n\n\n\n\n\nim_top_fit %&gt;%\n  augment()\n\n# A tsibble: 1,512 x 7 [1M]\n# Key:       Country, .model [14]\n   Country .model     Date Value .fitted .resid   .innov\n   &lt;chr&gt;   &lt;chr&gt;     &lt;mth&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n 1 China   ets    2015 Jan 4951    5457. -506.  -0.0928 \n 2 China   ets    2015 Feb 4084.   3874.  210.   0.0543 \n 3 China   ets    2015 Mar 4320.   5137. -817.  -0.159  \n 4 China   ets    2015 Apr 4987.   4501.  486.   0.108  \n 5 China   ets    2015 May 4554.   4847. -293.  -0.0605 \n 6 China   ets    2015 Jun 4686.   4696.  -10.8 -0.00230\n 7 China   ets    2015 Jul 4996.   4799.  196.   0.0409 \n 8 China   ets    2015 Aug 4830.   4765.   65.2  0.0137 \n 9 China   ets    2015 Sep 5005.   4875.  130.   0.0266 \n10 China   ets    2015 Oct 5363.   5191.  171.   0.0330 \n# ℹ 1,502 more rows\n\n\n\n\n\n\n\n3.6.5 Compare fit models Use accuracy() to compare the performance of models\n\n\nShow the code\nim_top_fit %&gt;%\n  accuracy() %&gt;%\n  arrange(Country) %&gt;%\n  kable(digits = 4, caption = \"Forecast Accuracy Metrics for Each Country\")\n\n\n\nForecast Accuracy Metrics for Each Country\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCountry\n.model\n.type\nME\nRMSE\nMAE\nMPE\nMAPE\nMASE\nRMSSE\nACF1\n\n\n\n\nChina\nets\nTraining\n11.9574\n480.8950\n366.4509\n-0.1939\n6.2506\n0.5564\n0.5529\n0.0562\n\n\nChina\narima\nTraining\n57.8184\n569.9843\n439.2390\n0.1868\n7.6637\n0.6669\n0.6554\n-0.0147\n\n\nJapan\nets\nTraining\n-0.6291\n211.3943\n171.1785\n-0.4698\n7.0199\n0.4371\n0.4221\n-0.0621\n\n\nJapan\narima\nTraining\n4.3188\n246.3921\n190.8210\n-0.7639\n7.9715\n0.4872\n0.4920\n-0.0195\n\n\nKorea, Rep Of\nets\nTraining\n22.2084\n287.0644\n227.6461\n-0.3782\n10.6173\n0.4683\n0.4241\n0.1565\n\n\nKorea, Rep Of\narima\nTraining\n22.2147\n282.9792\n223.6307\n-0.1773\n10.4052\n0.4600\n0.4181\n0.0217\n\n\nMalaysia\nets\nTraining\n34.5795\n495.1653\n366.1790\n0.0009\n7.4907\n0.4898\n0.5004\n0.0665\n\n\nMalaysia\narima\nTraining\n26.2860\n493.0780\n359.3030\n-0.1482\n7.3579\n0.4806\n0.4983\n-0.0114\n\n\nTaiwan\nets\nTraining\n36.2225\n386.9443\n289.8459\n0.4252\n6.7591\n0.3609\n0.3660\n0.0537\n\n\nTaiwan\narima\nTraining\n33.3608\n440.6971\n322.4981\n0.2547\n7.6050\n0.4016\n0.4169\n0.0023\n\n\nThailand\nets\nTraining\n11.4115\n214.5793\n145.1930\n-1.5209\n13.2531\n0.5862\n0.6048\n-0.0085\n\n\nThailand\narima\nTraining\n11.6179\n214.2205\n143.8310\n-1.5881\n13.1478\n0.5807\n0.6038\n0.0342\n\n\nUnited States\nets\nTraining\n35.4632\n395.0378\n303.1292\n0.2329\n6.4715\n0.4084\n0.4299\n-0.0533\n\n\nUnited States\narima\nTraining\n34.1356\n475.5440\n375.5570\n-0.0171\n8.0521\n0.5060\n0.5175\n-0.0436\n\n\n\n\n\n\n\n3.6.6 Forecast future values\n\n\nShow the code\nim_top_fc &lt;- im_top_fit %&gt;%\n  forecast(h = \"12 months\")\n\n\n\n\n3.6.7 Visualisation\n\n\nShow the code\nim_top_fc %&gt;%\n  autoplot(im_by_region_tsb)\n\n\n\n\n\n\n\n\n\n\n\nAnalysis\n\n\nBased on the accuracy comparison, the ARIMA model provides the best fit for Korea, Malaysia, and Thailand, as indicated by the lowest RMSE and MAPE values. However, for China, Japan, Taiwan, and the USA, the ETS model performs better. They show lower MASE and RMSSE, which suggests improved predictive accuracy.\nThe ACF1 values are close to zero, indicating minimal autocorrelation in residuals— a desirable property for reliable forecasts. Given that different models perform optimally for different markets, a hybrid approach using both ETS and ARIMA would enhance forecast accuracy.\nThe visualisations also reveal high uncertainty, likely due to volatile trade patterns or model sensitivity. This may suggest that external factors, such as policy changes or global economic shifts, may be influencing trade fluctuations. The models generally falls in the ranges, except for the model for Taiwan, which forecasts lower than the actual.\n\n\n\n\n\n3.7 Comparative Analysis of Singapore’s Re-export (2019 vs 2024)\nSingapore, as a focal point for international trading, hsa goods come and go. I am curious to find out what goods have been imported and re-exported. Do they change over time? In this section, I will use slopegraph to display the changes for individual commodity categories between 2019 and 2024.\n\n3.7.1 Data Wrangling\nLoad pakcage\n\npacman::p_load(CGPfunctions, ggthemes)\n\nImport data & Data wrangling\n\nCOMMODITYMACHINERY & EQUIPMENT\n\n\n\n\nShow the code\nrex_com_data &lt;- read_csv(\"data/rex_by_com.csv\")\nrex_com_slope &lt;- rex_com_data %&gt;%\n  select(-1) %&gt;%  # Remove the first unwanted column\n  mutate(\n    # Extract year from the 'Data Series' column\n    Year = as.numeric(format(as.Date(paste0(`Data Series`, \"-01\"), format = \"%Y %b-%d\"), \"%Y\"))\n  ) %&gt;%\n    #shortern some item names\n  rename(`Fish, Seafood` = \"Fish, Seafood (Excl Marine Mammals) & Preparations\",\n         `Coffee, Tea, Cocoa, Spices` = \"Coffee, Tea, Cocoa, Spices & Manufactures\",\n         `Crude Fertilizers & Minerals` = \"Crude Fertilizers & Minerals (Excl Division 56 Coal Petroleum & Precious Stones)\",\n         `Animal/Veg Fats & Oils (Processed)` = \"Animal Or Vegetable Fats & Oils Processed Waxes Of Animal Or Vegetable Origin Inedible Mixtures Or Preparations Of Animal Or Vegetable Fats Or Oils Nes\",\n         `Essential Oils & Perfume` = \"Essential Oils & Resinoids & Perfume Materials; Toilet Polishing & Cleansing Preparations\",\n         `Paper & Paperboard Products` = \"Paper, Paperboard & Articles Of Paper Pulp Of Paper Or Of Paperboard\",\n         `Scientific Instruments` = \"Professional Scientific & Controlling Instruments & Apparatus Nes\",\n         `Photo & Optical Goods` = \"Photographic Apparatus Equipment & Supplies & Optical Goods Nes; Watches & Clocks\",\n         `Textile Yarns & Fabrics` = \"Textile, Yarn, Fabrics Made-Up Articles Nes & Related Products\",\n         `Vegetable Fats & Oils` = \"Fixed Vegetable Fats & Oils Crude Refined Or Fractionated\"\n  ) %&gt;% \n  # Convert columns to numeric, coercing non-numeric values to NA\n  mutate(across(\n    .cols = where(is.character) & !matches(\"Data Series\"),\n    .fns = ~as.numeric(gsub(\",\", \"\", .x)),\n    .names = \"{col}\"\n  )) %&gt;%\n  \npivot_longer(\n    cols = -c(Year, `Data Series`),\n    names_to = \"Item\",\n    values_to = \"Value\"\n  ) %&gt;%\n  group_by(Year, Item) %&gt;%\n  summarise(Value = sum(Value, na.rm = TRUE)) %&gt;%\n  ungroup()  \nhead(rex_com_slope)\n\n\n# A tibble: 6 × 3\n   Year Item                                        Value\n  &lt;dbl&gt; &lt;chr&gt;                                       &lt;dbl&gt;\n1  1976 Animal/Veg Fats & Oils (Processed)          18382\n2  1976 Articles Of Apparel & Clothing Accessories  75804\n3  1976 Beverages                                   13778\n4  1976 Coffee, Tea, Cocoa, Spices                 358866\n5  1976 Crude Animal & Vegetable Materials Nes      88581\n6  1976 Crude Fertilizers & Minerals                30984\n\n\n\n\n\n\nShow the code\nrex_mac_data &lt;- read_csv(\"data/rex_by_mac.csv\")\n\n# Remove 2 rows - total electronic and non-electronic products\n\nrex_mac_slope &lt;- rex_mac_data %&gt;%\n  select(-1) %&gt;% \n  select(-c(`Total Electronic Products`, `Non-Electronic Products`)) %&gt;%\n  mutate(\n    # Extract year from the 'Data Series' column\n    Year = as.numeric(format(as.Date(paste0(`Data Series`, \"-01\"), format = \"%Y %b-%d\"), \"%Y\"))\n  ) %&gt;%\n  # Convert columns to numeric, coercing non-numeric values to NA\n  mutate(across(\n    .cols = where(is.character) & !matches(\"Data Series\"),\n    .fns = ~as.numeric(gsub(\",\", \"\", .x)),\n    .names = \"{col}\"\n  )) %&gt;%\n  \npivot_longer(\n    cols = -c(Year, `Data Series`),\n    names_to = \"Item\",\n    values_to = \"Value\"\n  ) %&gt;%\n  group_by(Year, Item) %&gt;%\n  summarise(Value = sum(Value, na.rm = TRUE)) %&gt;%\n  ungroup()  \n\nhead(rex_mac_slope)\n\n\n# A tibble: 6 × 3\n   Year Item                                     Value\n  &lt;dbl&gt; &lt;chr&gt;                                    &lt;dbl&gt;\n1  1999 Consumer Electronics                  5014687.\n2  1999 Diodes And Transistors                3449509.\n3  1999 Disk Drives                           3902195.\n4  1999 Electrical Circuit Apparatus          1309027.\n5  1999 Electrical Machinery & Apparatus Nes  1248792.\n6  1999 Integrated Circuits                  15477220.\n\n\n\n\n\n\n\n3.7.2 Plot & Analysis\n\nMACHINERY & EQUIPMENTCOMMODITY\n\n\n\n\nShow the code\nrex_mac_slope %&gt;% \n  mutate(Year = factor(Year),\n         Value = round(Value/100000, 1)) %&gt;%\n  filter(Year %in% c(2019, 2024)) %&gt;%\n  newggslopegraph(Year, Value, Item,\n                  Title = \"Commodity Trade Evolution\",\n                  SubTitle = \"2019 vs 2024\",\n                  Caption = \"Value in S$ Bil. \\nSource of Data: Singapore Department of Statistics\",\n                  YTextSize = 3,\n                  DataLabelLineSize = 0.2,\n                  DataLabelFillColor = \"#EFDCAB\") +\n  theme_wsj() +\n  theme(plot.title = element_text(size = 15),\n        plot.subtitle = element_text(size = 11),\n        plot.caption = element_text(size = 9),\n        legend.text = element_text(size = 7),\n        legend.title = element_text(size = 8),\n        legend.position = \"bottom\",\n        axis.text.y = element_text(size = 6, color = \"grey70\"),\n        axis.text.x = element_text(size = 7))\n\n\n\n\n\n\n\n\n\n\n\nAnalysis | Re-export Machinery\n\n\n\nIntegrated circuits re-export - The analysis of Singapore’s RE-exports reveals that integrated circuits have dominated the machinery and equipment category since 2019, with values reaching 1,373.6 billion Singapore dollars. This represents approximately six times the value of Telecommunications Equipment, the second-largest export category. These re-exported integrated circuits primarily consist of semiconductor chips used in electronic devices such as computers, smartphones, and televisions. In addition, Telecommunications equipment and Personal computers are also growing. The strong upward trend in the data indicates growing international reliance on Singapore’s transshipment capabilities for distributing these critical technology components.\nFocal point for trade - What makes this data particularly significant is that it reflects re-exports rather than domestic exports. This highlights Singapore’s strategic role as a transshipment hub in the global semiconductor supply chain. The timing of this growth in semiconductor re-exports aligns with increased global demand for specialized processing chips, including those used for AI applications. While the data doesn’t explicitly categorize AI-specific chips within the broader integrated circuits category, the substantial volumes flowing through Singapore suggest it serves as a key node in the distribution network for advanced computing hardware.\n\n\n\n\n\n\n\nShow the code\nrex_com_slope %&gt;% \n  mutate(Year = factor(Year),\n         Value = round(Value/100000, 1)) %&gt;%\n  filter(Year %in% c(2019, 2024)) %&gt;%\n  newggslopegraph(Year, Value, Item,\n                  Title = \"Commodity Trade Evolution\",\n                  SubTitle = \"2019 vs 2024\",\n                  Caption = \"Value in S$ Bil. \\nSource of Data: Singapore Department of Statistics\",\n                  YTextSize = 3,\n                  DataLabelLineSize = 0.2,\n                  DataLabelFillColor = \"#EFDCAB\") +\n  theme_wsj() +\n  theme(plot.title = element_text(size = 15),\n        plot.subtitle = element_text(size = 11),\n        plot.caption = element_text(size = 9),\n        legend.text = element_text(size = 7),\n        legend.title = element_text(size = 8),\n        legend.position = \"bottom\",\n        axis.text.y = element_text(size = 6, color = \"grey70\"),\n        axis.title.x = element_text(size = 7))\n\n\n\n\n\n\n\n\n\n\n\nAnalysis | Re-export Commodity\n\n\n\nHigh-tech and healthcare-related categories — Scientific instruments (10% increase), Miscellaneous manufactured articles (22% increase), and Medicinal & pharmaceutical products (100% increase) — show consistent upward trajectories. This growth indicates Singapore’s strengthening role as a transshipment hub for these high-value goods, likely reflecting increased regional and global demand for advanced technologies and healthcare solutions.\nTraditional commodity - Conversely, several traditional commodity categories in Singapore’s re-export portfolio have declined during this period. Essential oils & perfume products (10% decrease) and plastics experienced the most pronounced decreases, followed by non-metallic mineral manufactures, crude rubber, apparel & clothing accessories, and organic chemicals.\n\nThis divergence in re-export patterns suggests a potential reconfiguration of regional supply chains, with Singapore’s transshipment activities increasingly concentrated in higher-value, specialized product categories while seeing reduced volumes in more basic industrial inputs and consumer goods. The trend may reflect changing manufacturing locations in the region, shifts in consumption patterns, or evolving trade routes that may be bypassing Singapore for certain commodity categories.",
    "crumbs": [
      "![](/images/house.svg)",
      "Take-home Exercise",
      "Take-home_Ex02"
    ]
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02.html#conclusion",
    "href": "Take-home_Ex/Take-home_Ex02.html#conclusion",
    "title": "Take-home_Ex02",
    "section": "4 Conclusion",
    "text": "4 Conclusion\n\n\n\n\n\nThe goal of this assignment was to critique and redesign three visualizations of Singapore’s trade market data, followed by a detailed time-series analysis to uncover trends and patterns in trade over time.\n\nVisualisation redesigns: The 3 visualisation make-over present more ways to show audience the same set of data and more insightful information.\n\n\n\nVisualisation & insights: Analysis revealed an upward trend for Singapore’s geographically proximate trade partners, including China, Hong Kong, Taiwan, Japan, Korea, Thailand, and the US. Time series decomposition identified distinct seasonality and cyclical patterns in several trading relationships that warrant further investigation.\nCOVID-19 period: The pandemic significantly disrupted global trade flows, clearly visible in the visualizations. Trade volumes decreased across most markets and goods during this period, with varying recovery patterns afterward.\nTime series forecasting: The ARIMA and ETS models employed demonstrated the challenges in accurately forecasting trade volumes, largely due to the complex interplay of economic conditions, policy changes, and external shocks affecting international trade.\nLimitations: This analysis did not incorporate historical policy decisions or economic events that could provide contextual explanation for the patterns observed in the data.\nRecommendation for future analysis: Future work should include statistical significance testing of the observed patterns and changes. More sophisticated machine learning techniques could be explored for more accurate trade flow predictions. Additionally, incorporating complementary datasets such as GDP, inflation rates would provide a more comprehensive view of Singapore’s trade dynamics.\n\nMy eyes soar, and feel the more I learn, the more I do not know. Working with these visualization and analysis techniques has been eye-opening! I’m amazed at how much I’ve learned, but also how much more there is to discover. Time series analysis is deeper and more complex than I initially thought, and I’m excited to keep exploring new approaches in the future.",
    "crumbs": [
      "![](/images/house.svg)",
      "Take-home Exercise",
      "Take-home_Ex02"
    ]
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02.html#reference",
    "href": "Take-home_Ex/Take-home_Ex02.html#reference",
    "title": "Take-home_Ex02",
    "section": "Reference",
    "text": "Reference\nKam, T. S. (2023, December 4). R for Visual Analytics. https://r4va.netlify.app/\nHyndman, R.J., & Athanasopoulos, G. (2021) Forecasting: principles and practice, 3rd edition, OTexts: Melbourne, Australia. OTexts.com/fpp3. Accessed on 8 Mar 2025.\nStalder, T., Holtz, Y. (2021): Extended Dumbbell Plot in R with ggplot2. R graph gallery. Access: r-graph-gallery.com/web-extended-dumbbell-plot-ggplot2.html. Date: 08-03-2015.\nDepartment of Statistics Singapore. Singapore’s International Trade. Singapore Government, https://www.singstat.gov.sg/modules/infographics/singapore-international-trade. Accessed 8 Mar. 2025.\nDepartment of Statistics Singapore. Merchandise Trade – Latest Data. Singapore Government, https://www.singstat.gov.sg/find-data/search-by-theme/trade-and-investment/merchandise-trade/latest-data. Accessed 8 Mar. 2025.",
    "crumbs": [
      "![](/images/house.svg)",
      "Take-home Exercise",
      "Take-home_Ex02"
    ]
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03.html#dashboard-2-sync-dashboards",
    "href": "In-class_Ex/In-class_Ex03.html#dashboard-2-sync-dashboards",
    "title": "In-class_Ex03",
    "section": "Dashboard 2: Sync dashboards",
    "text": "Dashboard 2: Sync dashboards\nClick on one state in the dotplot, the corresponding state Sales and Profit will be highlighted in the barcharts.",
    "crumbs": [
      "![](/images/house.svg)",
      "In-class Exercise",
      "In-class_Ex3"
    ]
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03.html#dashboard-3-interactive-visualisation-by-month-and-year",
    "href": "In-class_Ex/In-class_Ex03.html#dashboard-3-interactive-visualisation-by-month-and-year",
    "title": "In-class_Ex03",
    "section": "Dashboard 3: Interactive Visualisation by Month and Year",
    "text": "Dashboard 3: Interactive Visualisation by Month and Year\nLeverage the filters on the right to observe the history using animation. Click on one dot (state), and play the animation button on the right.",
    "crumbs": [
      "![](/images/house.svg)",
      "In-class Exercise",
      "In-class_Ex3"
    ]
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03.html#dashboard-4-story",
    "href": "In-class_Ex/In-class_Ex03.html#dashboard-4-story",
    "title": "In-class_Ex03",
    "section": "Dashboard 4: Story",
    "text": "Dashboard 4: Story\nUse a Story board to compile a worksheet and/or a dashboard to observe a roadmap.",
    "crumbs": [
      "![](/images/house.svg)",
      "In-class Exercise",
      "In-class_Ex3"
    ]
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01.html",
    "href": "In-class_Ex/In-class_Ex01.html",
    "title": "In-class_Ex01",
    "section": "",
    "text": "View my Tableau profile",
    "crumbs": [
      "![](/images/house.svg)",
      "In-class Exercise",
      "In-class_Ex1"
    ]
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04.html",
    "title": "In-class_Ex04",
    "section": "",
    "text": "🎯 Use Tool to install packages first before running the code. Helps reduce missing packages.\n\npacman:::p_load(haven, SmartEDA, tidyverse, ggdist,\n                tidymodels, ggridges, colorspace, ggthemes)\n\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nBefore plotting ridgeline plots, we plot boxplot first to have a preview.\n\n\nShow the code\nggplot(exam_data,\n       aes(x = ENGLISH,\n           y = CLASS)) +\n  geom_boxplot() +\n  labs(title = \"Boxplot showing distribution\")\n\n\n\n\n\n\n\n\n\nNow, we plot the ridgeline plot.\n\n\nShow the code\nggplot(exam_data,\n       aes(x = ENGLISH,\n           y = CLASS)) +\n  #create ridgeline\n  geom_density_ridges( \n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 2.5,\n    fill = lighten(\"pink\", .3),\n    color = \"white\"\n  ) +\n  #extension of ggplot\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0,0),\n  ) +\n  scale_y_discrete(name = \"Class\", expand = expansion(add=c(0.2, 2.6))) +\n  labs(title = \"Visualising Distribution with Ridgeline Plot\") +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\nBelow is with quantile lines:\n\n\nShow the code\nggplot(exam_data,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  labs(title = \"Ridgeline Plot with Quantile Lines\") +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\nHere, we can use half-eye plot to see the distribution:\n\n\nShow the code\nggplot(exam_data, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) + #see no outliers.\n  geom_boxplot(width = .20, #not overly crowded.\n               outlier.shape = NA) + #see no outliers.\n  coord_flip() +\n  labs(title = \"Half-eye Graph\") \n\n\n\n\n\n\n\n\n\nNext we add dot plots with stat_dots(). This gives better clarify.\n\nHigh-level distribution of probability density&gt; This smooths out. Is it skewed or normal distributed.\nDots: provides the detail of it. With this we can observe that for some categories like “Others” has very small sample.\n\n\n\nShow the code\nggplot(exam_data, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = NA, #suggested to put all dots in the range.\n            dotsize = 1.3) + #can apply transparency if too many.\n  coord_flip() + #this is to flip into horizontal graph\n  labs(title = \"Adding dot plots to the Raincloud Plot\")",
    "crumbs": [
      "![](/images/house.svg)",
      "In-class Exercise",
      "In-class_Ex4"
    ]
  }
]